<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Complete-Guide-to-Deploy-Gitlab/Gitlab-runner/docker</title>
    <url>/Tools/Complete-Guide-to-Deploy-Gitlab-Gitlab-runner-docker/index.html</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title>The high-availability deployment of the LDAP server</title>
    <url>//Linux/LDAP/The-high-availability-deployment-of-the-LDAP-server/index.html</url>
    <content><![CDATA[<h2 id="Prerequisites"><a href="#Prerequisites" class="headerlink" title="Prerequisites"></a>Prerequisites</h2><ul>
<li><p>The system must have <code>at least 2 GB of memory</code>.</p>
</li>
<li><p>It must have a <code>static hostname</code> — not <code>localhos</code>t or <code>localhost6</code>. The hostname should be in <code>FQDN</code> (Fully Qualified Domain Name) format and must be resolvable.</p>
</li>
<li><p><code>Reverse DNS lookup</code> must return a hostname that resolves correctly.</p>
</li>
</ul>
<h2 id="Deployment-process"><a href="#Deployment-process" class="headerlink" title="Deployment process"></a>Deployment process</h2><h3 id="Set-the-hostname"><a href="#Set-the-hostname" class="headerlink" title="Set the hostname"></a>Set the hostname</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># master node</span></span><br><span class="line">hostnamectl hostname shy-ipa-master.shy.local</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># slave node</span></span><br><span class="line">hostnamectl hostname shy-ipa-slave.shy.local</span><br></pre></td></tr></table></figure>

<h3 id="IPA-master-node-deployment"><a href="#IPA-master-node-deployment" class="headerlink" title="IPA master node deployment"></a>IPA master node deployment</h3><h4 id="Install-the-LDAP-server"><a href="#Install-the-LDAP-server" class="headerlink" title="Install the LDAP server"></a>Install the LDAP server</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">dnf install freeipa-server-dns -y</span><br></pre></td></tr></table></figure>

<h4 id="configure-the-LDAP-server"><a href="#configure-the-LDAP-server" class="headerlink" title="configure the LDAP server"></a>configure the LDAP server</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Check the detailed usage of ipa-server-install</span></span><br><span class="line">ipa-server-install --<span class="built_in">help</span></span><br><span class="line">man ipa-server-install</span><br><span class="line"></span><br><span class="line"><span class="comment">#</span></span><br><span class="line">ipa-server-install --setup-dns --auto-reverse --mkhomedir</span><br></pre></td></tr></table></figure>

<ul>
<li><p><code>--setup-dns</code><br>Installs and configures the DNS service (bind), allowing FreeIPA to manage DNS zones as well.</p>
</li>
<li><p><code>--auto-reverse</code><br>Automatically detects and creates reverse DNS zones (PTR records), provided that the subnet information can be determined.</p>
</li>
<li><p><code>--mkhomedir</code><br>Installs and enables the pam_mkhomedir.so module so that a user’s home directory is automatically created upon their first login.</p>
</li>
</ul>
<p>Detailed output in terminal is shown as below.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@shy-ipa-master ~]# ipa-server-install --setup-dns --auto-reverse --mkhomedir</span><br><span class="line"></span><br><span class="line">The log file for this installation can be found in /var/log/ipaserver-install.log</span><br><span class="line">==============================================================================</span><br><span class="line">This program will set up the IPA Server.</span><br><span class="line">Version 4.12.2</span><br><span class="line"></span><br><span class="line">This includes:</span><br><span class="line">  * Configure a stand-alone CA (dogtag) for certificate management</span><br><span class="line">  * Configure the NTP client (chronyd)</span><br><span class="line">  * Create and configure an instance of Directory Server</span><br><span class="line">  * Create and configure a Kerberos Key Distribution Center (KDC)</span><br><span class="line">  * Configure Apache (httpd)</span><br><span class="line">  * Configure DNS (bind)</span><br><span class="line">  * Configure SID generation</span><br><span class="line">  * Configure the KDC to enable PKINIT</span><br><span class="line"></span><br><span class="line">To accept the default shown in brackets, press the Enter key.</span><br><span class="line"></span><br><span class="line">Enter the fully qualified domain name of the computer</span><br><span class="line">on which you&#x27;re setting up server software. Using the form</span><br><span class="line">&lt;hostname&gt;.&lt;domainname&gt;</span><br><span class="line">Example: master.example.com</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Server host name [shy-ipa-master.shy.local]: // Enter here</span><br><span class="line"></span><br><span class="line">Warning: skipping DNS resolution of host shy-ipa-master.shy.local</span><br><span class="line">The domain name has been determined based on the host name.</span><br><span class="line"></span><br><span class="line">Please confirm the domain name [shy.local]: // Enter here</span><br><span class="line"></span><br><span class="line">The kerberos protocol requires a Realm name to be defined.</span><br><span class="line">This is typically the domain name converted to uppercase.</span><br><span class="line"></span><br><span class="line">Please provide a realm name [SHY.LOCAL]: // Enter here</span><br><span class="line">Certain directory server operations require an administrative user.</span><br><span class="line">This user is referred to as the Directory Manager and has full access</span><br><span class="line">to the Directory for system management tasks and will be added to the</span><br><span class="line">instance of directory server created for IPA.</span><br><span class="line">The password must be at least 8 characters long.</span><br><span class="line"></span><br><span class="line">Directory Manager password: // Set a password here</span><br><span class="line">Password (confirm):</span><br><span class="line"></span><br><span class="line">The IPA server requires an administrative user, named &#x27;admin&#x27;.</span><br><span class="line">This user is a regular system account used for IPA server administration.</span><br><span class="line"></span><br><span class="line">IPA admin password: // Set a password here</span><br><span class="line">Password (confirm):</span><br><span class="line"></span><br><span class="line">Checking DNS domain shy.local., please wait ...</span><br><span class="line">Do you want to configure DNS forwarders? [yes]: // Configure DNS Forwarder</span><br><span class="line">Following DNS servers are configured in /etc/resolv.conf: xxx.xxx.xxx.xxx</span><br><span class="line">Do you want to configure these servers as DNS forwarders? [yes]:</span><br><span class="line">All detected DNS servers were added. You can enter additional addresses now:</span><br><span class="line">Enter an IP address for a DNS forwarder, or press Enter to skip:</span><br><span class="line">DNS forwarders: xxx.xxx.xxx.xxx, xxx.xxx.xxx.xxx</span><br><span class="line">Checking DNS forwarders, please wait ...</span><br><span class="line">DNS server xxx.xxx.xxx.xxx does not support DNSSEC: answer to query &#x27;. SOA&#x27; is missing DNSSEC signatures (no RRSIG data)</span><br><span class="line">Please fix forwarder configuration to enable DNSSEC support.</span><br><span class="line"></span><br><span class="line">DNS server xxx.xxx.xxx.xxx: answer to query &#x27;. SOA&#x27; is missing DNSSEC signatures (no RRSIG data)</span><br><span class="line">Please fix forwarder configuration to enable DNSSEC support.</span><br><span class="line">DNS server xxx.xxx.xxx.xxx does not support DNSSEC: answer to query &#x27;. SOA&#x27; is missing DNSSEC signatures (no RRSIG data)</span><br><span class="line">Please fix forwarder configuration to enable DNSSEC support.</span><br><span class="line"></span><br><span class="line">DNS server xxx.xxx.xxx.xxx: answer to query &#x27;. SOA&#x27; is missing DNSSEC signatures (no RRSIG data)</span><br><span class="line">Please fix forwarder configuration to enable DNSSEC support.</span><br><span class="line">WARNING: DNSSEC validation will be disabled</span><br><span class="line">Checking DNS domain 225.168.192.in-addr.arpa., please wait ...</span><br><span class="line">Reverse zone 225.168.192.in-addr.arpa. will be created</span><br><span class="line">Using reverse zone(s) 225.168.192.in-addr.arpa.</span><br><span class="line">Trust is configured but no NetBIOS domain name found, setting it now.</span><br><span class="line">Enter the NetBIOS name for the IPA domain.</span><br><span class="line">Only up to 15 uppercase ASCII letters, digits and dashes are allowed.</span><br><span class="line">Example: EXAMPLE.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">NetBIOS domain name [SHY]: // Enter here</span><br><span class="line"></span><br><span class="line">Do you want to configure chrony with NTP server or pool address? [no]: yes // Enter yes here and configure the ntp server</span><br><span class="line">Enter NTP source server addresses separated by comma, or press Enter to skip: ntp.aliyun.com</span><br><span class="line">Enter a NTP source pool address, or press Enter to skip:</span><br><span class="line"></span><br><span class="line">The IPA Master Server will be configured with:</span><br><span class="line">Hostname:       shy-ipa-master.shy.local</span><br><span class="line">IP address(es): 192.168.225.33</span><br><span class="line">Domain name:    shy.local</span><br><span class="line">Realm name:     SHY.LOCAL</span><br><span class="line"></span><br><span class="line">The CA will be configured with:</span><br><span class="line">Subject DN:   CN=Certificate Authority,O=SHY.LOCAL</span><br><span class="line">Subject base: O=SHY.LOCAL</span><br><span class="line">Chaining:     self-signed</span><br><span class="line"></span><br><span class="line">BIND DNS server will be configured to serve IPA domain with:</span><br><span class="line">Forwarders:       xxx.xxx.xxx.xxx, xxx.xxx.xxx.xxx</span><br><span class="line">Forward policy:   only</span><br><span class="line">Reverse zone(s):  225.168.192.in-addr.arpa.</span><br><span class="line"></span><br><span class="line">NTP server: ntp.aliyun.com</span><br><span class="line">Continue to configure the system with these values? [no]: yes // Confirm that all information are right here and enter yes</span><br></pre></td></tr></table></figure>

<p>The following operations may take some minutes to complete.</p>
<p>Please be patient to wait the prompt.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Setup complete</span><br><span class="line"></span><br><span class="line">Next steps:</span><br><span class="line"> 1. You must make sure these network ports are open:</span><br><span class="line">  TCP Ports:</span><br><span class="line">    * 80, 443: HTTP/HTTPS</span><br><span class="line">    * 389, 636: LDAP/LDAPS</span><br><span class="line">    * 88, 464: kerberos</span><br><span class="line">    * 53: bind</span><br><span class="line">  UDP Ports:</span><br><span class="line">    * 88, 464: kerberos</span><br><span class="line">    * 53: bind</span><br><span class="line">    * 123: ntp</span><br><span class="line"></span><br><span class="line"> 2. You can now obtain a kerberos ticket using the command: &#x27;kinit admin&#x27;</span><br><span class="line">    This ticket will allow you to use the IPA tools (e.g., ipa user-add)</span><br><span class="line">    and the web user interface.</span><br><span class="line"></span><br><span class="line">Be sure to back up the CA certificates stored in /root/cacert.p12</span><br><span class="line">These files are required to create replicas. The password for these</span><br><span class="line">files is the Directory Manager password</span><br><span class="line">The ipa-server-install command was successful</span><br></pre></td></tr></table></figure>

<h4 id="Allow-the-Firewall"><a href="#Allow-the-Firewall" class="headerlink" title="Allow the Firewall"></a>Allow the Firewall</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">firewall-cmd --permanent --add-port=&#123;80/tcp,443/tcp,389/tcp,636/tcp,88/tcp,88/udp,464/tcp,464/udp,53/tcp,53/udp,123/tcp,123/udp&#125;</span><br><span class="line">firewall-cmd --permanent --add-service=&#123;freeipa-4,dns&#125;</span><br><span class="line">firewall-cmd --reload</span><br></pre></td></tr></table></figure>

<p>The service name is <code>freeipa-4</code>, please check in the official website.</p>
<h4 id="View-the-dashboard"><a href="#View-the-dashboard" class="headerlink" title="View the dashboard"></a>View the dashboard</h4><p>On the client machine, it is necessary to add an <code>IP-to-FQDN resolution</code> entry in the <code>hosts</code> file.</p>
<ul>
<li><p><strong>Linux</strong>: <code>/etc/hosts</code></p>
</li>
<li><p><strong>Windows</strong>: <code>C:\Windows\System32\drivers\etc\hosts</code></p>
</li>
</ul>
<p><img src="/../images/Idm_dashboard.png" alt="IdM dashboard"></p>
<p>Then, you could use the <code>admin</code> account and the password you’ve set in the process of installation to login.</p>
<h3 id="IPA-slave-node-deployment"><a href="#IPA-slave-node-deployment" class="headerlink" title="IPA slave node deployment"></a>IPA slave node deployment</h3><h4 id="Install-the-LDAP-server-1"><a href="#Install-the-LDAP-server-1" class="headerlink" title="Install the LDAP server"></a>Install the LDAP server</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">dnf install freeipa-server-dns -y</span><br></pre></td></tr></table></figure>

<h4 id="Add-the-slave-node-to-the-domain"><a href="#Add-the-slave-node-to-the-domain" class="headerlink" title="Add the slave node to the domain"></a>Add the slave node to the domain</h4><blockquote>
<p>Configure the DNS settings on the secondary node to point to the primary node’s IP address, in order to enable proper discovery of LDAP services.</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;nameserver 192.168.225.33&quot;</span> &gt; /etc/resolv.conf</span><br></pre></td></tr></table></figure>

<p>This command will automatically discover the required configuration.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ipa-client-install --mkhomedir</span><br></pre></td></tr></table></figure>

<p>The detailed output is shown as below.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@shy-ipa-slave ~]# ipa-client-install --mkhomedir</span><br><span class="line">This program will set up IPA client.</span><br><span class="line">Version 4.12.2</span><br><span class="line"></span><br><span class="line">Discovery was successful!</span><br><span class="line">Do you want to configure chrony with NTP server or pool address? [no]: yes // Enter yes here and configure the ntp server</span><br><span class="line">Enter NTP source server addresses separated by comma, or press Enter to skip: ntp.aliyun.com</span><br><span class="line">Enter a NTP source pool address, or press Enter to skip:</span><br><span class="line">Client hostname: shy-ipa-slave.shy.local</span><br><span class="line">Realm: SHY.LOCAL</span><br><span class="line">DNS Domain: shy.local</span><br><span class="line">IPA Server: shy-ipa-master.shy.local</span><br><span class="line">BaseDN: dc=shy,dc=local</span><br><span class="line">NTP server: ntp.aliyun.com</span><br><span class="line"></span><br><span class="line">Continue to configure the system with these values? [no]: yes // It automatically discovered the LDAP information. If everything looks correct, just type ‘yes’ to confirm.</span><br><span class="line"></span><br><span class="line">Synchronizing time</span><br><span class="line">Configuration of chrony was changed by installer.</span><br><span class="line">Attempting to sync time with chronyc.</span><br><span class="line">Process chronyc waitsync failed to sync time!</span><br><span class="line">Unable to sync time with chrony server, assuming the time is in sync. Please check that 123 UDP port is opened, and any time server is on network.</span><br><span class="line">User authorized to enroll computers: admin // Enter the administrator password</span><br><span class="line">Password for admin@SHY.LOCAL:</span><br><span class="line">Successfully retrieved CA cert</span><br><span class="line">    Subject:     CN=Certificate Authority,O=SHY.LOCAL</span><br><span class="line">    Issuer:      CN=Certificate Authority,O=SHY.LOCAL</span><br><span class="line">    Valid From:  2025-05-30 03:40:02+00:00</span><br><span class="line">    Valid Until: 2045-05-30 03:40:02+00:00</span><br><span class="line"></span><br><span class="line">Enrolled in IPA realm SHY.LOCAL</span><br><span class="line">Created /etc/ipa/default.conf</span><br><span class="line">Configured /etc/sssd/sssd.conf</span><br><span class="line">Systemwide CA database updated.</span><br><span class="line">Hostname (shy-ipa-slave.shy.local) does not have A/AAAA record.</span><br><span class="line">Missing reverse record(s) for address(es): 192.168.225.34.</span><br><span class="line">Adding SSH public key from /etc/ssh/ssh_host_ed25519_key.pub</span><br><span class="line">Adding SSH public key from /etc/ssh/ssh_host_ecdsa_key.pub</span><br><span class="line">Adding SSH public key from /etc/ssh/ssh_host_rsa_key.pub</span><br><span class="line">SSSD enabled</span><br><span class="line">Configured /etc/openldap/ldap.conf</span><br><span class="line">Configured /etc/ssh/ssh_config</span><br><span class="line">Configured /etc/ssh/sshd_config.d/04-ipa.conf</span><br><span class="line">Configuring shy.local as NIS domain.</span><br><span class="line">Configured /etc/krb5.conf for IPA realm SHY.LOCAL</span><br><span class="line">Client configuration complete.</span><br><span class="line">The ipa-client-install command was successful</span><br></pre></td></tr></table></figure>

<h4 id="Add-the-slave-node-to-the-ipaserver-group"><a href="#Add-the-slave-node-to-the-ipaserver-group" class="headerlink" title="Add the slave node to the ipaserver group"></a>Add the slave node to the ipaserver group</h4><p>Authorize replica installation on the client.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@shy-ipa-slave ~]# kinit admin</span><br><span class="line">Password for admin@SHY.LOCAL:</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@shy-ipa-slave ~]# ipa hostgroup-add-member ipaservers --hosts shy-ipa-slave.shy.local</span><br><span class="line">  Host-group: ipaservers</span><br><span class="line">  Description: IPA server hosts</span><br><span class="line">  Member hosts: shy-ipa-master.shy.local, shy-ipa-slave.shy.local</span><br><span class="line">-------------------------</span><br><span class="line">Number of members added 1</span><br><span class="line">-------------------------</span><br></pre></td></tr></table></figure>

<h4 id="Allow-the-Firewall-1"><a href="#Allow-the-Firewall-1" class="headerlink" title="Allow the Firewall"></a>Allow the Firewall</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">firewall-cmd --permanent --add-port=&#123;80/tcp,443/tcp,389/tcp,636/tcp,88/tcp,88/udp,464/tcp,464/udp,53/tcp,53/udp,123/tcp,123/udp&#125;</span><br><span class="line">firewall-cmd --permanent --add-service=&#123;freeipa-4,dns&#125;</span><br><span class="line">firewall-cmd --reload</span><br></pre></td></tr></table></figure>

<p>The service name is <code>freeipa-4</code>, please check in the official website.</p>
<h4 id="Set-the-replication"><a href="#Set-the-replication" class="headerlink" title="Set the replication"></a>Set the replication</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ipa-replica-install --setup-dns --forwarder 114.114.114.114 --setup-ca</span><br></pre></td></tr></table></figure>

<h4 id="Check-the-list-of-ipa-server"><a href="#Check-the-list-of-ipa-server" class="headerlink" title="Check the list of ipa server"></a>Check the list of ipa server</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@shy-ipa-master ~]# ipa-replica-manage list</span><br></pre></td></tr></table></figure>

<p>Terminal Output:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@shy-ipa-master ~]# ipa-replica-manage list</span><br><span class="line">shy-ipa-master.shy.local: master</span><br><span class="line">shy-ipa-slave.shy.local: master</span><br></pre></td></tr></table></figure>

<h3 id="Force-data-synchronization-between-master-and-slave"><a href="#Force-data-synchronization-between-master-and-slave" class="headerlink" title="Force data synchronization between master and slave"></a>Force data synchronization between master and slave</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ipa-replica-manage force-sync --from shy-ipa-master.shy.local</span><br></pre></td></tr></table></figure>

<p>Check from the web interface.</p>
<p><img src="/../images/freeipa_two_hosts.png" alt="two ipa servers"></p>
<h2 id="Test-the-ipa-server"><a href="#Test-the-ipa-server" class="headerlink" title="Test the ipa server"></a>Test the ipa server</h2><p>E.g. I will create a new user in master node.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@shy-ipa-master ~]# ipa user-add shy</span><br><span class="line">First name: Haoyang</span><br><span class="line">Last name: Sun</span><br><span class="line">----------------</span><br><span class="line">Added user &quot;shy&quot;</span><br><span class="line">----------------</span><br><span class="line">  User login: shy</span><br><span class="line">  First name: Haoyang</span><br><span class="line">  Last name: Sun</span><br><span class="line">  Full name: Haoyang Sun</span><br><span class="line">  Display name: Haoyang Sun</span><br><span class="line">  Initials: HS</span><br><span class="line">  Home directory: /home/shy</span><br><span class="line">  GECOS: Haoyang Sun</span><br><span class="line">  Login shell: /bin/sh</span><br><span class="line">  Principal name: shy@SHY.LOCAL</span><br><span class="line">  Principal alias: shy@SHY.LOCAL</span><br><span class="line">  Email address: shy@shy.local</span><br><span class="line">  UID: 1871200003</span><br><span class="line">  GID: 1871200003</span><br><span class="line">  Password: False</span><br><span class="line">  Member of groups: ipausers</span><br><span class="line">  Kerberos keys available: False</span><br></pre></td></tr></table></figure>

<p>Then, let’s search in slave node.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@shy-ipa-slave ~]# ipa user-find shy</span><br><span class="line">--------------</span><br><span class="line">1 user matched</span><br><span class="line">--------------</span><br><span class="line">  User login: shy</span><br><span class="line">  First name: Haoyang</span><br><span class="line">  Last name: Sun</span><br><span class="line">  Home directory: /home/shy</span><br><span class="line">  Login shell: /bin/sh</span><br><span class="line">  Principal name: shy@SHY.LOCAL</span><br><span class="line">  Principal alias: shy@SHY.LOCAL</span><br><span class="line">  Email address: shy@shy.local</span><br><span class="line">  UID: 1871200003</span><br><span class="line">  GID: 1871200003</span><br><span class="line">  Account disabled: False</span><br><span class="line">----------------------------</span><br><span class="line">Number of entries returned 1</span><br><span class="line">----------------------------</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>LDAP</tag>
      </tags>
  </entry>
  <entry>
    <title>2025/05/27 English accumulation</title>
    <url>//Language/English/20250527/index.html</url>
    <content><![CDATA[<ul>
<li><p><strong>encompass</strong>: Identity <code>encompasses</code> authentication and authorization functions.</p>
</li>
<li><p><strong>evolve</strong>: Token protocols have <code>evolved</code> since the early OpenStack days,<br>and are discussed later in this chapter.</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Language</category>
      </categories>
      <tags>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenStack Series Chapter7: Managing File based Component Security with AIDE</title>
    <url>//Cloud/OpenStack/Managing-File-based-Component-Security-with-AIDE/index.html</url>
    <content><![CDATA[<h2 id="What-is-AIDE"><a href="#What-is-AIDE" class="headerlink" title="What is AIDE?"></a>What is AIDE?</h2><p><code>Advanced Intrusion Detection Environment (AIDE)</code> is a tool to compare changes within files or directories. The <code>hashes</code> will be stored in the local database on the first run. After that, it will be compared on each subsequent run. If the <code>hash</code> content is different from the that in database, it will be recorded in logs. What’s more, we could configure the report and email reminder as well.</p>
<blockquote>
<p>Its working principle is analogous to using <code>md5sum</code> to calculate the MD5 hash of a file. Then, we could compare the value of MD5 to check whether the file changes or not.</p>
</blockquote>
<h2 id="Installing-and-configuring-AIDE"><a href="#Installing-and-configuring-AIDE" class="headerlink" title="Installing and configuring AIDE"></a>Installing and configuring AIDE</h2><h3 id="Installing-the-software-application"><a href="#Installing-the-software-application" class="headerlink" title="Installing the software application"></a>Installing the software application</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(undercloud) [stack@director ~]$ <span class="built_in">sudo</span> -i</span><br><span class="line"> [root@director ~]# yum install aide -y</span><br></pre></td></tr></table></figure>

<h3 id="Initialize-the-AIDE-database"><a href="#Initialize-the-AIDE-database" class="headerlink" title="Initialize the AIDE database"></a>Initialize the AIDE database</h3><p>Because this is the first time for us to use <code>aide</code> command, it’s a good idea to check the manual.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@director ~]# aide -h</span><br><span class="line">Aide 0.16</span><br><span class="line"></span><br><span class="line">Usage: aide [options] <span class="built_in">command</span></span><br><span class="line"></span><br><span class="line">Commands:</span><br><span class="line">  -i, --init  Initialize the database</span><br><span class="line">  -C, --check  Check the database</span><br><span class="line">  -u, --update  Check and update the database non-interactively</span><br><span class="line">  -E, --compare  Compare two databases</span><br><span class="line"></span><br><span class="line">Miscellaneous:</span><br><span class="line">  -D, --config-check Test the configuration file</span><br><span class="line">  -v, --version  Show version of AIDE and compilation options</span><br><span class="line">  -h, --<span class="built_in">help</span>  Show this <span class="built_in">help</span> message</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -c [cfgfile] --config=[cfgfile] Get config options from [cfgfile]</span><br><span class="line">  -l [REGEX] --<span class="built_in">limit</span>=[REGEX]  Limit <span class="built_in">command</span> to entries matching [REGEX]</span><br><span class="line">  -B <span class="string">&quot;OPTION&quot;</span> --before=<span class="string">&quot;OPTION&quot;</span> Before configuration file is <span class="built_in">read</span> define OPTION</span><br><span class="line">  -A <span class="string">&quot;OPTION&quot;</span> --after=<span class="string">&quot;OPTION&quot;</span> After configuration file is <span class="built_in">read</span> define OPTION</span><br><span class="line">  -r [reporter] --report=[reporter] Write report output to [reporter] url</span><br><span class="line">  -V[level] --verbose=[level] Set debug message level to [level]</span><br></pre></td></tr></table></figure>

<p>After learning the usage of <code>aide</code> command, Let’s Initialize the database.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@director ~]# aide --init</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Start timestamp: 2025-05-22 02:55:18 -0400 (AIDE 0.16)</span><br><span class="line">AIDE initialized database at /var/lib/aide/aide.db.new.gz</span><br><span class="line"></span><br><span class="line">Number of entries: 146260</span><br><span class="line"></span><br><span class="line">---------------------------------------------------</span><br><span class="line">The attributes of the (uncompressed) database(s):</span><br><span class="line">---------------------------------------------------</span><br><span class="line"></span><br><span class="line">/var/lib/aide/aide.db.new.gz</span><br><span class="line">  MD5      : 6SBee41U474Po/3Ez0LbzA==</span><br><span class="line">  SHA1     : gP2ufYflEIe+8fmGz4rjzsFvZZE=</span><br><span class="line">  RMD160   : Ffeno7GgHw2m4T3nO8kBkzWEJvU=</span><br><span class="line">  TIGER    : cZ4f60cWTM93LLhbnnd4UCi/Mb3wial/</span><br><span class="line">  SHA256   : dA5mb3sOorYG6TNUYv6wx3AiACaOmjik</span><br><span class="line">             pV5urYvvde0=</span><br><span class="line">  SHA512   : F7A4C03VGO89VbCJRU8/twujPdQPfigc</span><br><span class="line">             lKWaO7sGuIw4skAZnMg32uhA2xA4uZGB</span><br><span class="line">             2yvAThbJjGvsv/z5xluuoQ==</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">End timestamp: 2025-05-22 03:06:00 -0400 (run time: 10m 42s)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="Checking-the-database"><a href="#Checking-the-database" class="headerlink" title="Checking the database"></a>Checking the database</h3><blockquote>
<p>Note: The default database generated by aide is called <code>aide.db.new.gz</code>. While, when we check the database, it will check the database called <code>aide.db.gz</code>. Therefore, it is necessary for us to <code>modify the name</code> of the initialized database.</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@director ~]# aide --check</span><br><span class="line">Couldn<span class="string">&#x27;t open file /var/lib/aide/aide.db.gz for reading</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[root@director ~]# mv /var/lib/aide/aide.db.new.gz /var/lib/aide/aide.db.gz</span></span><br></pre></td></tr></table></figure>

<p>After changing the name, Let’s check the database again!</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@director ~]# aide --check</span><br><span class="line">Start timestamp: 2025-05-22 03:09:45 -0400 (AIDE 0.16)</span><br><span class="line">AIDE found NO differences between database and filesystem. Looks okay!!</span><br><span class="line"></span><br><span class="line">Number of entries: 146260</span><br><span class="line"></span><br><span class="line">---------------------------------------------------</span><br><span class="line">The attributes of the (uncompressed) database(s):</span><br><span class="line">---------------------------------------------------</span><br><span class="line"></span><br><span class="line">/var/lib/aide/aide.db.gz</span><br><span class="line">  MD5      : 6SBee41U474Po/3Ez0LbzA==</span><br><span class="line">  SHA1     : gP2ufYflEIe+8fmGz4rjzsFvZZE=</span><br><span class="line">  RMD160   : Ffeno7GgHw2m4T3nO8kBkzWEJvU=</span><br><span class="line">  TIGER    : cZ4f60cWTM93LLhbnnd4UCi/Mb3wial/</span><br><span class="line">  SHA256   : dA5mb3sOorYG6TNUYv6wx3AiACaOmjik</span><br><span class="line">             pV5urYvvde0=</span><br><span class="line">  SHA512   : F7A4C03VGO89VbCJRU8/twujPdQPfigc</span><br><span class="line">             lKWaO7sGuIw4skAZnMg32uhA2xA4uZGB</span><br><span class="line">             2yvAThbJjGvsv/z5xluuoQ==</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">End timestamp: 2025-05-22 03:17:33 -0400 (run time: 7m 48s)</span><br></pre></td></tr></table></figure>

<p>Lovely！ Everything is OKay!!!</p>
<h3 id="Testing-for-creating-and-modifying-files"><a href="#Testing-for-creating-and-modifying-files" class="headerlink" title="Testing for creating and modifying files"></a>Testing for creating and modifying files</h3><p>The basic rule is defined in <code>/etc/aide.conf</code>, Please view the configuration.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@director aide]# <span class="built_in">cat</span> /etc/aide.conf</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"> [root@director ~]# aide --check</span><br><span class="line">Start timestamp: 2025-05-22 03:45:03 -0400 (AIDE 0.16)</span><br><span class="line">AIDE found differences between database and filesystem!!</span><br><span class="line"></span><br><span class="line">Summary:</span><br><span class="line">  Total number of entries: 146260</span><br><span class="line">  Added entries:  0</span><br><span class="line">  Removed entries:  0</span><br><span class="line">  Changed entries:  8</span><br><span class="line"></span><br><span class="line">---------------------------------------------------</span><br><span class="line">Changed entries:</span><br><span class="line">---------------------------------------------------</span><br><span class="line"></span><br><span class="line">f &lt; ...    . ... : /var/log/boot.log</span><br><span class="line">f &lt; ...    . .X. : /var/log/journal/f874df04639f474cb0a9881041f4f7d4/system.journal</span><br><span class="line">f = ...    . .X. : /var/log/journal/f874df04639f474cb0a9881041f4f7d4/user-1002.journal</span><br><span class="line">f = ...    . .X. : /var/log/journal/f874df04639f474cb0a9881041f4f7d4/user-42445.journal</span><br><span class="line">f = ...    . .X. : /var/log/journal/f874df04639f474cb0a9881041f4f7d4/user-42454.journal</span><br><span class="line">f &lt; ...    . ... : /var/log/openvswitch/ovs-vswitchd.log</span><br><span class="line">f &lt; ...    . ... : /var/log/openvswitch/ovsdb-server.log</span><br><span class="line">f           C    : /var/spool/anacron/cron.daily</span><br><span class="line"></span><br><span class="line">---------------------------------------------------</span><br><span class="line">Detailed information about changes:</span><br><span class="line">---------------------------------------------------</span><br><span class="line"></span><br><span class="line">File: /var/log/boot.log</span><br><span class="line">  Size     : 20229                            | 0</span><br><span class="line"></span><br><span class="line">File: /var/log/journal/f874df04639f474cb0a9881041f4f7d4/system.journal</span><br><span class="line">  Size     : 33554432                         | 8388608</span><br><span class="line">  XAttrs   : num=1                            | num=1</span><br><span class="line">             [1] user.crtime_usec &lt;=&gt; 8itPerM | [1] user.crtime_usec &lt;=&gt; aNrhqLQ</span><br><span class="line">             1BgA=                            | 1BgA=</span><br><span class="line"></span><br><span class="line">File: /var/log/journal/f874df04639f474cb0a9881041f4f7d4/user-1002.journal</span><br><span class="line">  XAttrs   : num=1                            | num=1</span><br><span class="line">             [1] user.crtime_usec &lt;=&gt; tA1SerM | [1] user.crtime_usec &lt;=&gt; fIPkqLQ</span><br><span class="line">             1BgA=                            | 1BgA=</span><br><span class="line"></span><br><span class="line">File: /var/log/journal/f874df04639f474cb0a9881041f4f7d4/user-42445.journal</span><br><span class="line">  XAttrs   : num=1                            | num=1</span><br><span class="line">             [1] user.crtime_usec &lt;=&gt; H8tRerM | [1] user.crtime_usec &lt;=&gt; ZWjjqLQ</span><br><span class="line">             1BgA=                            | 1BgA=</span><br><span class="line"></span><br><span class="line">File: /var/log/journal/f874df04639f474cb0a9881041f4f7d4/user-42454.journal</span><br><span class="line">  XAttrs   : num=1                            | num=1</span><br><span class="line">             [1] user.crtime_usec &lt;=&gt; 0RNRerM | [1] user.crtime_usec &lt;=&gt; ssXiqLQ</span><br><span class="line">             1BgA=                            | 1BgA=</span><br><span class="line"></span><br><span class="line">File: /var/log/openvswitch/ovs-vswitchd.log</span><br><span class="line">  Size     : 9962                             | 95</span><br><span class="line"></span><br><span class="line">File: /var/log/openvswitch/ovsdb-server.log</span><br><span class="line">  Size     : 799                              | 95</span><br><span class="line"></span><br><span class="line">File: /var/spool/anacron/cron.daily</span><br><span class="line">  SHA512   : x31MHpzW9WWgozNuoqMPg1cHHVt0xQO8 | c3xpb2d16NpVt1cajv8PMqwjIx+Z8RCn</span><br><span class="line">             EG9RnlH5Qb4esO1bFTsytUoD975FOL5t | VWXKX3+wg/Z/Td1oHm/jHmlO3A3HBXF3</span><br><span class="line">             VKsfa01Fo4G65ZOPi7d+9A==         | Nb9nq+4ZK0/+9mx9vyeZDQ==</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---------------------------------------------------</span><br><span class="line">The attributes of the (uncompressed) database(s):</span><br><span class="line">---------------------------------------------------</span><br><span class="line"></span><br><span class="line">/var/lib/aide/aide.db.gz</span><br><span class="line">  MD5      : 6SBee41U474Po/3Ez0LbzA==</span><br><span class="line">  SHA1     : gP2ufYflEIe+8fmGz4rjzsFvZZE=</span><br><span class="line">  RMD160   : Ffeno7GgHw2m4T3nO8kBkzWEJvU=</span><br><span class="line">  TIGER    : cZ4f60cWTM93LLhbnnd4UCi/Mb3wial/</span><br><span class="line">  SHA256   : dA5mb3sOorYG6TNUYv6wx3AiACaOmjik</span><br><span class="line">             pV5urYvvde0=</span><br><span class="line">  SHA512   : F7A4C03VGO89VbCJRU8/twujPdQPfigc</span><br><span class="line">             lKWaO7sGuIw4skAZnMg32uhA2xA4uZGB</span><br><span class="line">             2yvAThbJjGvsv/z5xluuoQ==</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">End timestamp: 2025-05-22 03:46:29 -0400 (run time: 1m 26s)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="Updating-the-database"><a href="#Updating-the-database" class="headerlink" title="Updating the database"></a>Updating the database</h3><p>If you confirm that the modification is legal and right, you could update the current status to the database.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@director ~]# aide --update</span><br><span class="line">Start timestamp: 2025-05-22 03:51:02 -0400 (AIDE 0.16)</span><br><span class="line">AIDE found differences between database and filesystem!!</span><br><span class="line">New AIDE database written to /var/lib/aide/aide.db.new.gz</span><br><span class="line"></span><br><span class="line">Summary:</span><br><span class="line">  Total number of entries: 146260</span><br><span class="line">  Added entries:  0</span><br><span class="line">  Removed entries:  0</span><br><span class="line">  Changed entries:  8</span><br><span class="line"></span><br><span class="line">---------------------------------------------------</span><br><span class="line">Changed entries:</span><br><span class="line">---------------------------------------------------</span><br><span class="line"></span><br><span class="line">f &lt; ...    . ... : /var/log/boot.log</span><br><span class="line">f &lt; ...    . .X. : /var/log/journal/f874df04639f474cb0a9881041f4f7d4/system.journal</span><br><span class="line">f = ...    . .X. : /var/log/journal/f874df04639f474cb0a9881041f4f7d4/user-1002.journal</span><br><span class="line">f = ...    . .X. : /var/log/journal/f874df04639f474cb0a9881041f4f7d4/user-42445.journal</span><br><span class="line">f = ...    . .X. : /var/log/journal/f874df04639f474cb0a9881041f4f7d4/user-42454.journal</span><br><span class="line">f &lt; ...    . ... : /var/log/openvswitch/ovs-vswitchd.log</span><br><span class="line">f &lt; ...    . ... : /var/log/openvswitch/ovsdb-server.log</span><br><span class="line">f           C    : /var/spool/anacron/cron.daily</span><br><span class="line"></span><br><span class="line">---------------------------------------------------</span><br><span class="line">Detailed information about changes:</span><br><span class="line">---------------------------------------------------</span><br><span class="line"></span><br><span class="line">File: /var/log/boot.log</span><br><span class="line">  Size     : 20229                            | 0</span><br><span class="line"></span><br><span class="line">File: /var/log/journal/f874df04639f474cb0a9881041f4f7d4/system.journal</span><br><span class="line">  Size     : 33554432                         | 8388608</span><br><span class="line">  XAttrs   : num=1                            | num=1</span><br><span class="line">             [1] user.crtime_usec &lt;=&gt; 8itPerM | [1] user.crtime_usec &lt;=&gt; aNrhqLQ</span><br><span class="line">             1BgA=                            | 1BgA=</span><br><span class="line"></span><br><span class="line">File: /var/log/journal/f874df04639f474cb0a9881041f4f7d4/user-1002.journal</span><br><span class="line">  XAttrs   : num=1                            | num=1</span><br><span class="line">             [1] user.crtime_usec &lt;=&gt; tA1SerM | [1] user.crtime_usec &lt;=&gt; fIPkqLQ</span><br><span class="line">             1BgA=                            | 1BgA=</span><br><span class="line"></span><br><span class="line">File: /var/log/journal/f874df04639f474cb0a9881041f4f7d4/user-42445.journal</span><br><span class="line">  XAttrs   : num=1                            | num=1</span><br><span class="line">             [1] user.crtime_usec &lt;=&gt; H8tRerM | [1] user.crtime_usec &lt;=&gt; ZWjjqLQ</span><br><span class="line">             1BgA=                            | 1BgA=</span><br><span class="line"></span><br><span class="line">File: /var/log/journal/f874df04639f474cb0a9881041f4f7d4/user-42454.journal</span><br><span class="line">  XAttrs   : num=1                            | num=1</span><br><span class="line">             [1] user.crtime_usec &lt;=&gt; 0RNRerM | [1] user.crtime_usec &lt;=&gt; ssXiqLQ</span><br><span class="line">             1BgA=                            | 1BgA=</span><br><span class="line"></span><br><span class="line">File: /var/log/openvswitch/ovs-vswitchd.log</span><br><span class="line">  Size     : 9962                             | 95</span><br><span class="line"></span><br><span class="line">File: /var/log/openvswitch/ovsdb-server.log</span><br><span class="line">  Size     : 799                              | 95</span><br><span class="line"></span><br><span class="line">File: /var/spool/anacron/cron.daily</span><br><span class="line">  SHA512   : x31MHpzW9WWgozNuoqMPg1cHHVt0xQO8 | c3xpb2d16NpVt1cajv8PMqwjIx+Z8RCn</span><br><span class="line">             EG9RnlH5Qb4esO1bFTsytUoD975FOL5t | VWXKX3+wg/Z/Td1oHm/jHmlO3A3HBXF3</span><br><span class="line">             VKsfa01Fo4G65ZOPi7d+9A==         | Nb9nq+4ZK0/+9mx9vyeZDQ==</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---------------------------------------------------</span><br><span class="line">The attributes of the (uncompressed) database(s):</span><br><span class="line">---------------------------------------------------</span><br><span class="line"></span><br><span class="line">/var/lib/aide/aide.db.gz</span><br><span class="line">  MD5      : 6SBee41U474Po/3Ez0LbzA==</span><br><span class="line">  SHA1     : gP2ufYflEIe+8fmGz4rjzsFvZZE=</span><br><span class="line">  RMD160   : Ffeno7GgHw2m4T3nO8kBkzWEJvU=</span><br><span class="line">  TIGER    : cZ4f60cWTM93LLhbnnd4UCi/Mb3wial/</span><br><span class="line">  SHA256   : dA5mb3sOorYG6TNUYv6wx3AiACaOmjik</span><br><span class="line">             pV5urYvvde0=</span><br><span class="line">  SHA512   : F7A4C03VGO89VbCJRU8/twujPdQPfigc</span><br><span class="line">             lKWaO7sGuIw4skAZnMg32uhA2xA4uZGB</span><br><span class="line">             2yvAThbJjGvsv/z5xluuoQ==</span><br><span class="line"></span><br><span class="line">/var/lib/aide/aide.db.new.gz</span><br><span class="line">  MD5      : kRAvaLUIKffJjsIXOkGvBw==</span><br><span class="line">  SHA1     : Lmaax9VyxEbBBxBetixpEmdWAmU=</span><br><span class="line">  RMD160   : uNOWJnBJ6vuV9bMC/kNJT+7Tagg=</span><br><span class="line">  TIGER    : 9s27LZvANGDyxzuNPsItCg+Jj2kVpW8/</span><br><span class="line">  SHA256   : CfPQWplclKeJ/KgAmvn0sRY69VYup5nM</span><br><span class="line">             lYXg/yz1+24=</span><br><span class="line">  SHA512   : PeEcnnOWA8EeRWHpYJdpHdv3x0lmvrJD</span><br><span class="line">             QC3FQlDjsKssmneR5R6gENVSKPQjjAcH</span><br><span class="line">             o37gGmDLiXgEN0IOQZDKHQ==</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">End timestamp: 2025-05-22 03:52:27 -0400 (run time: 1m 25s)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>And do not forget to rename the database!</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@director ~]# <span class="built_in">mv</span> /var/lib/aide/aide.db.new.gz /var/lib/aide/aide.db.gz</span><br><span class="line"><span class="built_in">mv</span>: overwrite <span class="string">&#x27;/var/lib/aide/aide.db.gz&#x27;</span>? y</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>OpenStack</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenStack Series Chapter6: Using ReaR to back Up OpenStack</title>
    <url>//Cloud/OpenStack/Using-ReaR-to-back-up-OpenStack/index.html</url>
    <content><![CDATA[<h2 id="Overview-of-ReaR"><a href="#Overview-of-ReaR" class="headerlink" title="Overview of ReaR"></a>Overview of ReaR</h2><p>Red Hat Enterprise Linux provides a recovery and system migration utility, <code>Relax-and-Recover (ReaR)</code>.</p>
<p>ReaR is <code>written in Bash</code> and enables the distribution of rescue images or storage of backup files via different network transport methods.</p>
<p>ReaR produces a <code>bootable image</code> and restores from backup using this image.</p>
<h3 id="ReaR-supports-the-following-boot-media-formats"><a href="#ReaR-supports-the-following-boot-media-formats" class="headerlink" title="ReaR supports the following boot media formats"></a>ReaR supports the following boot media formats</h3><ul>
<li><p>ISO</p>
</li>
<li><p>USB</p>
</li>
<li><p>eSATA</p>
</li>
<li><p>PXE</p>
</li>
</ul>
<h3 id="ReaR-can-use-the-following-protocols-to-transport-files"><a href="#ReaR-can-use-the-following-protocols-to-transport-files" class="headerlink" title="ReaR can use the following protocols to transport files"></a>ReaR can use the following protocols to transport files</h3><ul>
<li><p>HTTP&#x2F;HTTPS</p>
</li>
<li><p>SSH&#x2F;SCP</p>
</li>
<li><p>NFS</p>
</li>
<li><p>CIFS(SMB)</p>
</li>
</ul>
<p>I use the ISO bootable file format and NFS protocol in this article.</p>
<h2 id="Automate-backup-and-restore-by-using-ansible"><a href="#Automate-backup-and-restore-by-using-ansible" class="headerlink" title="Automate backup and restore by using ansible"></a>Automate backup and restore by using <code>ansible</code></h2><p><code>Ansible</code> is the main method for creating and restoring images generated by ReaR.</p>
<p>We’ll use the built-in role called <code>backup-and-restore</code> in <u><em>tripleo-ansible</em></u> packages.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">(undercloud) [stack@director ~]$ tree /usr/share/ansible/roles/backup-and-restore</span><br><span class="line">/usr/share/ansible/roles/backup-and-restore</span><br><span class="line">├── backup</span><br><span class="line">│   └── tasks</span><br><span class="line">│       ├── db_backup.yml</span><br><span class="line">│       ├── main.yml</span><br><span class="line">│       ├── service_manager_pause.yml</span><br><span class="line">│       └── service_manager_unpause.yml</span><br><span class="line">├── defaults</span><br><span class="line">│   └── main.yml</span><br><span class="line">├── meta</span><br><span class="line">│   └── main.yml</span><br><span class="line">├── molecule</span><br><span class="line">│   └── default</span><br><span class="line">│       ├── Dockerfile</span><br><span class="line">│       ├── molecule.yml</span><br><span class="line">│       ├── playbook.yml</span><br><span class="line">│       └── prepare.yml</span><br><span class="line">├── setup_nfs</span><br><span class="line">│   └── tasks</span><br><span class="line">│       └── main.yml</span><br><span class="line">├── setup_rear</span><br><span class="line">│   └── tasks</span><br><span class="line">│       └── main.yml</span><br><span class="line">├── tasks</span><br><span class="line">│   ├── main.yml</span><br><span class="line">│   ├── pacemaker_backup.yml</span><br><span class="line">│   ├── setup_nfs.yml</span><br><span class="line">│   └── setup_rear.yml</span><br><span class="line">├── templates</span><br><span class="line">│   ├── exports.j2</span><br><span class="line">│   ├── local.conf.j2</span><br><span class="line">│   └── rescue.conf.j2</span><br><span class="line">└── vars</span><br><span class="line">    └── redhat.yml</span><br><span class="line"></span><br><span class="line">13 directories, 20 files</span><br></pre></td></tr></table></figure>

<h2 id="Backing-up-the-undercloud-director"><a href="#Backing-up-the-undercloud-director" class="headerlink" title="Backing up the undercloud director"></a>Backing up the undercloud director</h2><p><code>lab</code> has already prepared the environment, we just need to initialize the command.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[student@workstation ~]$ lab controlplane-backup start</span><br><span class="line"></span><br><span class="line">Setting up the Backup Node on utility:</span><br><span class="line"></span><br><span class="line"> · Setting up NFS server on utility............................  SUCCESS</span><br><span class="line"> · Creating playbooks for backup and restore on director.......  SUCCESS</span><br></pre></td></tr></table></figure>

<h3 id="Preparing-the-NFS-server"><a href="#Preparing-the-NFS-server" class="headerlink" title="Preparing the NFS server"></a>Preparing the NFS server</h3><p>Login to the undercloud—director node.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[student@workstation ~]$ ssh director</span><br><span class="line">Activate the web console with: systemctl enable --now cockpit.socket</span><br><span class="line"></span><br><span class="line">This system is not registered to Red Hat Insights. See https://cloud.redhat.com/</span><br><span class="line">To register this system, run: insights-client --register</span><br><span class="line"></span><br><span class="line">Last login: Fri May 16 01:33:26 2025 from 172.25.250.9</span><br></pre></td></tr></table></figure>

<p>Then, Check the inventory file.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">(undercloud) [stack@director ~]$ cat nfs-inventory.ini</span><br><span class="line">[BACKUP_NODE]</span><br><span class="line">backup ansible_host=172.25.250.220 ansible_user=student ansible_become_password=student</span><br></pre></td></tr></table></figure>

<p>Please notice that the IP address in the inventory file is the utility node.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">(undercloud) [stack@director ~]$ ping utility -c 4</span><br><span class="line">PING utility.lab.example.com (172.25.250.220) 56(84) bytes of data.</span><br><span class="line">64 bytes from utility.lab.example.com (172.25.250.220): icmp_seq=1 ttl=64 time=0.675 ms</span><br><span class="line">64 bytes from utility.lab.example.com (172.25.250.220): icmp_seq=2 ttl=64 time=0.833 ms</span><br><span class="line">64 bytes from utility.lab.example.com (172.25.250.220): icmp_seq=3 ttl=64 time=0.227 ms</span><br><span class="line">64 bytes from utility.lab.example.com (172.25.250.220): icmp_seq=4 ttl=64 time=0.253 ms</span><br><span class="line"></span><br><span class="line">--- utility.lab.example.com ping statistics ---</span><br><span class="line">4 packets transmitted, 4 received, 0% packet loss, time 101ms</span><br><span class="line">rtt min/avg/max/mdev = 0.227/0.497/0.833/0.263 ms</span><br></pre></td></tr></table></figure>

<p>Finally, use the ansible palybook to configure the <code>utility</code> server as a backup node.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">(undercloud) [stack@director ~]$ ansible-playbook -v -i ~/nfs-inventory.ini \</span><br><span class="line">--extra=&quot;ansible_ssh_common_args=&#x27;-o StrictHostKeyChecking=no&#x27;&quot; \</span><br><span class="line">--become --become-user root --tags bar_setup_nfs_server \</span><br><span class="line">~/bar_nfs_setup.yaml</span><br><span class="line"></span><br><span class="line">...output ommited...</span><br><span class="line">TASK [backup-and-restore : Gather variables for each operating system] ***********************</span><br><span class="line">ok: [backup] =&gt; (item=/usr/share/ansible/roles/backup-and-restore/vars/redhat.yml) =&gt; &#123;&quot;ansible_facts&quot;: &#123;&quot;tripleo_backup_and_restore_nfs_packages&quot;: [&quot;nfs-utils&quot;], &quot;tripleo_backup_and_restore_rear_packages&quot;: [&quot;rear&quot;, &quot;syslinux&quot;, &quot;genisoimage&quot;, &quot;nfs-utils&quot;]&#125;, &quot;ansible_included_var_files&quot;: [&quot;/usr/share/ansible/roles/backup-and-restore/vars/redhat.yml&quot;], &quot;ansible_loop_var&quot;: &quot;item&quot;, &quot;changed&quot;: false, &quot;item&quot;: &quot;/usr/share/ansible/roles/backup-and-restore/vars/redhat.yml&quot;&#125;</span><br><span class="line"></span><br><span class="line">TASK [backup-and-restore : Gather variables for each operating system] ***********************</span><br><span class="line">ok: [backup] =&gt; (item=/usr/share/ansible/roles/backup-and-restore/vars/redhat.yml) =&gt; &#123;&quot;ansible_facts&quot;: &#123;&quot;tripleo_backup_and_restore_nfs_packages&quot;: [&quot;nfs-utils&quot;], &quot;tripleo_backup_and_restore_rear_packages&quot;: [&quot;rear&quot;, &quot;syslinux&quot;, &quot;genisoimage&quot;, &quot;nfs-utils&quot;]&#125;, &quot;ansible_included_var_files&quot;: [&quot;/usr/share/ansible/roles/backup-and-restore/vars/redhat.yml&quot;], &quot;ansible_loop_var&quot;: &quot;item&quot;, &quot;changed&quot;: false, &quot;item&quot;: &quot;/usr/share/ansible/roles/backup-and-restore/vars/redhat.yml&quot;&#125;</span><br><span class="line"></span><br><span class="line">PLAY RECAP ***********************************************************************************</span><br><span class="line">backup                     : ok=12   changed=6    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0</span><br></pre></td></tr></table></figure>

<h3 id="Generating-the-host-inventory"><a href="#Generating-the-host-inventory" class="headerlink" title="Generating the host inventory"></a>Generating the host inventory</h3><p>Generate the inventory file.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">(undercloud) [stack@director ~]$ tripleo-ansible-inventory \</span><br><span class="line">--ansible_ssh_user heat-admin \</span><br><span class="line">--static-yaml-inventory /home/stack/tripleo-inventory.yaml</span><br></pre></td></tr></table></figure>

<p>Check the content in the inventory file.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">(undercloud) [stack@director ~]$ head -n 40 tripleo-inventory.yaml</span><br><span class="line">Undercloud:</span><br><span class="line">  hosts:</span><br><span class="line">    undercloud: &#123;&#125;</span><br><span class="line">  vars:</span><br><span class="line">    ansible_connection: local</span><br><span class="line">    ansible_host: localhost</span><br><span class="line">    ansible_python_interpreter: /usr/bin/python3</span><br><span class="line">    ansible_remote_tmp: /tmp/ansible-$&#123;USER&#125;</span><br><span class="line">    auth_url: https://172.25.249.201:13000</span><br><span class="line">    cacert: null</span><br><span class="line">    os_auth_token: gAAAAABoJuImd0Fz8Kgv7oZnDDJQ4r824VkxXREFzUBzQwlheWNWlSRCLX1xFN3v5yi9UbF0YCVGGTnQPEOcPQHbyyhpM51j7CpDJB_DUQ8TAg7uNcaV2It4zgvjOJwckjL75A7u8i6K1pEYcb6IJeiv9-codODORSg9ToCKKG80BEOxS9zhUxs</span><br><span class="line">    overcloud_admin_password: redhat</span><br><span class="line">    overcloud_horizon_url: http://172.25.250.50:80/dashboard</span><br><span class="line">    overcloud_keystone_url: http://172.25.250.50:5000</span><br><span class="line">    plan: overcloud</span><br><span class="line">    plans: [overcloud]</span><br><span class="line">    project_name: admin</span><br><span class="line">    undercloud_service_list: [tripleo_nova_compute, tripleo_heat_engine, tripleo_ironic_conductor,</span><br><span class="line">      tripleo_swift_container_server, tripleo_swift_object_server, tripleo_mistral_engine]</span><br><span class="line">    undercloud_swift_url: https://172.25.249.201:13808/v1/AUTH_90ef963f6dca474ba045e212c7afaa97</span><br><span class="line">    username: admin</span><br><span class="line">Controller:</span><br><span class="line">  children:</span><br><span class="line">    overcloud_Controller: &#123;&#125;</span><br><span class="line">overcloud_Controller:</span><br><span class="line">  hosts:</span><br><span class="line">    controller0: &#123;ansible_host: 172.25.249.56, canonical_hostname: controller0.overcloud.example.com,</span><br><span class="line">      ctlplane_hostname: controller0.ctlplane.overcloud.example.com, ctlplane_ip: 172.25.249.56,</span><br><span class="line">      deploy_server_id: 6d712d0a-cb71-4cdc-93dc-f2d69ffc520b, external_hostname: controller0.external.overcloud.example.com,</span><br><span class="line">      external_ip: 172.25.250.1, internal_api_hostname: controller0.internalapi.overcloud.example.com,</span><br><span class="line">      internal_api_ip: 172.24.1.1, management_hostname: controller0.management.overcloud.example.com,</span><br><span class="line">      management_ip: 172.24.5.1, storage_hostname: controller0.storage.overcloud.example.com,</span><br><span class="line">      storage_ip: 172.24.3.1, storage_mgmt_hostname: controller0.storagemgmt.overcloud.example.com,</span><br><span class="line">      storage_mgmt_ip: 172.24.4.1, tenant_hostname: controller0.tenant.overcloud.example.com,</span><br><span class="line">      tenant_ip: 172.24.2.1&#125;</span><br><span class="line">  vars:</span><br><span class="line">    ansible_ssh_user: heat-admin</span><br><span class="line">    bootstrap_server_id: 6d712d0a-cb71-4cdc-93dc-f2d69ffc520b</span><br><span class="line">    serial: &#x27;1&#x27;</span><br><span class="line">    tripleo_role_name: Controller</span><br><span class="line">...output ommited...</span><br></pre></td></tr></table></figure>

<h3 id="Installing-and-configuring-ReaR-on-the-director-server"><a href="#Installing-and-configuring-ReaR-on-the-director-server" class="headerlink" title="Installing and configuring ReaR (on the director server)"></a>Installing and configuring ReaR (on the director server)</h3><p>Whoever requires backing up should have this tool installed on them. As we need to back up the director, we ought to install and configure the tool on the director.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">(undercloud) [stack@director ~]$ ansible-playbook -v -i ~/tripleo-inventory.yaml \</span><br><span class="line">--extra=&quot;ansible_ssh_common_args=&#x27;-o StrictHostKeyChecking=no&#x27;&quot; \</span><br><span class="line">--become --become-user root --tags bar_setup_rear \</span><br><span class="line">~/bar_rear_setup-undercloud.yaml</span><br></pre></td></tr></table></figure>

<h3 id="Installing-and-configuring-ReaR-on-the-controller0-server"><a href="#Installing-and-configuring-ReaR-on-the-controller0-server" class="headerlink" title="Installing and configuring ReaR (on the controller0 server)"></a>Installing and configuring ReaR (on the controller0 server)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">(undercloud) [stack@director ~]$ ansible-playbook -v -i ~/tripleo-inventory.yaml \</span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">-e tripleo_backup_and_restore_exclude_paths_controller_non_bootrapnode=<span class="literal">false</span> \</span></span><br><span class="line"><span class="language-bash">&gt; --extra=<span class="string">&quot;ansible_ssh_common_args=&#x27;-o StrictHostKeyChecking=no&#x27;&quot;</span> \</span></span><br><span class="line"><span class="language-bash">&gt; --become --become-user root --tags bar_setup_rear \</span></span><br><span class="line"><span class="language-bash">&gt; ~/bar_rear_setup-controller.yaml</span></span><br></pre></td></tr></table></figure>

<h3 id="Backing-up-the-undercloud-director-1"><a href="#Backing-up-the-undercloud-director-1" class="headerlink" title="Backing up the undercloud - director"></a>Backing up the undercloud - director</h3><p>The total time for backing up is about 20-30 mins.(Time based on the scale.)</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">(undercloud) [stack@director ~]$ ansible-playbook -v -i ~/tripleo-inventory.yaml \</span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">--extra=<span class="string">&quot;ansible_ssh_common_args=&#x27;-o StrictHostKeyChecking=no&#x27;&quot;</span> \</span></span><br><span class="line"><span class="language-bash">&gt; --become --become-user root --tags bar_create_recover_image \</span></span><br><span class="line"><span class="language-bash">&gt; ~/bar_rear_create_restore_images-undercloud.yaml</span></span><br></pre></td></tr></table></figure>

<p>During the waiting period, we could open a new terminal to monitor&#x2F;watch the changes on the <code>/ctl_plane_backups</code>(defined in the ansible playbook) directory.</p>
<p><img src="/../images/watch_ctl_plane.png" alt="watch"></p>
<h3 id="Check-the-backup-directory-in-utility"><a href="#Check-the-backup-directory-in-utility" class="headerlink" title="Check the backup directory in utility"></a>Check the backup directory in utility</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[student@workstation ~]$ showmount -e utility</span><br><span class="line">Export list for utility:</span><br><span class="line">/ctl_plane_backups 172.25.250.0/24</span><br></pre></td></tr></table></figure>

<h3 id="Creating-the-mount-point"><a href="#Creating-the-mount-point" class="headerlink" title="Creating the mount point"></a>Creating the mount point</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[student@workstation ~]$ sudo mkdir /mnt/ctl_plane_backups</span><br><span class="line">[student@workstation ~]$ sudo mount utility:/ctl_plane_backups \</span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">/mnt/ctl_plane_backups</span></span><br><span class="line">[student@workstation ~]$ sudo tree /mnt/ctl_plane_backups</span><br><span class="line">/mnt/ctl_plane_backups</span><br><span class="line">├── director</span><br><span class="line">├── backup.log</span><br><span class="line">├── backup.tar.gz</span><br><span class="line">├── director.lab.example.com.iso</span><br><span class="line">├── README</span><br><span class="line">├── rear-director.log</span><br><span class="line">├── selinux.autorelabel</span><br><span class="line">└── VERSION</span><br><span class="line">1 directories, 7 files</span><br></pre></td></tr></table></figure>

<h3 id="Making-a-tarball"><a href="#Making-a-tarball" class="headerlink" title="Making a tarball"></a>Making a tarball</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[student@workstation ~]$ sudo tar tzvf \</span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">/mnt/ctl_plane_backups/director/backup.tar.gz</span></span><br><span class="line">drwxr-xr-x root/root</span><br><span class="line">0 2020-10-30 11:30</span><br><span class="line">lrwxrwxrwx root/root</span><br><span class="line">0 2018-08-12 05:46</span><br><span class="line">dr-xr-xr-x root/root</span><br><span class="line">0 2020-10-30 10:37</span><br><span class="line">drwx------ root/root</span><br><span class="line">0 2018-08-12 05:31</span><br><span class="line">drwxr-xr-x root/root</span><br><span class="line">0 2020-08-12 11:51</span><br><span class="line">drwx------ root/root</span><br><span class="line">0 2020-08-12 11:52</span><br><span class="line">-rwx------ root/root</span><br><span class="line">182 2020-07-31 17:18</span><br><span class="line">-rwx------ root/root</span><br><span class="line">1162528 2020-07-31 17:18</span><br><span class="line">...output omitted...</span><br><span class="line">./</span><br><span class="line">bin -&gt; usr/bin</span><br><span class="line">boot/</span><br><span class="line">boot/efi/</span><br><span class="line">boot/efi/EFI/</span><br><span class="line">boot/efi/EFI/redhat/</span><br><span class="line">boot/efi/EFI/redhat/BOOTX64.CSV</span><br><span class="line">boot/efi/EFI/redhat/mmx64.efi</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>OpenStack</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenStack Series Chapter5: Introducing Component Communiation---RabbitMQ</title>
    <url>//Cloud/OpenStack/Introducing-Component-Communication-RabbitMQ.html</url>
    <content><![CDATA[<h2 id="Introduction-and-Overview-of-RabbitMQ"><a href="#Introduction-and-Overview-of-RabbitMQ" class="headerlink" title="Introduction and Overview of RabbitMQ"></a>Introduction and Overview of RabbitMQ</h2><p>As we discussed before in the last Chapter, OpenStack is highly <code>modular—each</code> function (like Nova, Neutron, Cinder, etc.) operates as an independent service.</p>
<p>All services depend on two back end functions:</p>
<ul>
<li><p>Database (MariaDB)</p>
<p>Database is used to store the persistent data of each OpenStack component.</p>
</li>
<li><p>Message Broker (RabbitMQ)</p>
<p>Message Broker is used to support the communication between each component. Any message broker if only supports <code>AMQP</code>(Advanced Message Queueing Protocol) protocol could be used as a back end.</p>
<p>In OpenStack here, we use <code>RabbitMQ</code> as the message broker.</p>
</li>
</ul>
<h2 id="Some-common-RabbitMQ-terms-and-definitions"><a href="#Some-common-RabbitMQ-terms-and-definitions" class="headerlink" title="Some common RabbitMQ terms and definitions"></a>Some common RabbitMQ terms and definitions</h2><table>
<thead>
<tr>
<th>Term</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Binding</strong></td>
<td>The key or filter parameter used to route from an exchange to a queue.</td>
</tr>
<tr>
<td><strong>Consumer</strong></td>
<td>An application that uses the received messages.</td>
</tr>
<tr>
<td><strong>Exchange</strong></td>
<td>Routes producer-published messages to queues using message metadata.</td>
</tr>
<tr>
<td><strong>Publisher&#x2F;Producer</strong></td>
<td>Applications that publish messages.</td>
</tr>
<tr>
<td><strong>Queue</strong></td>
<td>Stores messages until consumed by an application.</td>
</tr>
<tr>
<td><strong>Routing key</strong></td>
<td>Producer-specified message metadata used by the exchange for message routing.</td>
</tr>
<tr>
<td><strong>Vhost</strong></td>
<td>A logical division of a RabbitMQ instance, used to segregate applications, queues, and exchanges.</td>
</tr>
</tbody></table>
<ul>
<li><p>Binding</p>
<p><code>Binding</code> determines the connection between the <code>queue</code> and the <code>exchange</code>.</p>
</li>
<li><p>Consumer</p>
<p><code>Consumer</code> is the application or server side to receive messages, here in OpenStack, it represents those service components.</p>
</li>
<li><p>Exchange</p>
<p><code>Exchange</code> is like an <code>allocation center</code>. Based on <code>Binding</code> the rule, it will route the message to the corresponding queue.(routing key matches the binding key)</p>
</li>
<li><p>Publisher&#x2F;Produce</p>
<p><code>Publisher/Produce</code> is the application or client side to send messages, here in OpenStack, it represents those service components.</p>
</li>
<li><p>Queue</p>
<p><code>Queue</code> is a temporary space to storage the request messages, until customers fetch messages here.</p>
</li>
<li><p>Routing Key</p>
<p><code>Routing Key</code> is the information produce send with the message, for specifying the destination, the matched queue that the message should be routed to.(routing key matches the binding key)</p>
</li>
<li><p>Vhost</p>
<p><code>Vhost</code> provides the <code>isolated</code> environment for each project, it just likes a <code>namespace</code>.</p>
</li>
</ul>
<h2 id="RabbitMQ-Message-Broker-Exchange-Concepts"><a href="#RabbitMQ-Message-Broker-Exchange-Concepts" class="headerlink" title="RabbitMQ Message Broker Exchange Concepts"></a>RabbitMQ Message Broker Exchange Concepts</h2><p>The exchange’s interaction with a queue is based on the match between the <code>routing key included in the message</code> and the <code>binding key associated with the queue</code> on the related exchange.</p>
<p>This is called the <code>Binding</code> rule.</p>
<p>Different kinds of exchange determine the match mode of <code>routing key</code> and <code>binding key</code>.</p>
<h2 id="Messaging-Patterns-in-RabbitMQ"><a href="#Messaging-Patterns-in-RabbitMQ" class="headerlink" title="Messaging Patterns in RabbitMQ"></a>Messaging Patterns in RabbitMQ</h2><blockquote>
<p><code>Exchange</code>, <code>Binding</code> and <code>Queue</code> are combined in patterns.</p>
</blockquote>
<table>
<thead>
<tr>
<th>Pattern Name</th>
<th>Description</th>
<th>One-to-Many</th>
<th>Callback</th>
</tr>
</thead>
<tbody><tr>
<td>Work Queue</td>
<td>A single queue with multiple consumers, messages are distributed in round-robin</td>
<td>❌</td>
<td>❌</td>
</tr>
<tr>
<td>Pub&#x2F;Sub</td>
<td>Each consumer has its own queue and receives all messages</td>
<td>✅</td>
<td>❌</td>
</tr>
<tr>
<td>Routing</td>
<td>Exact match on routing key</td>
<td>✅</td>
<td>❌</td>
</tr>
<tr>
<td>Topic</td>
<td>Fuzzy match on routing key (wildcards allowed)</td>
<td>✅</td>
<td>❌</td>
</tr>
<tr>
<td>Header</td>
<td>Routing based on headers</td>
<td>✅</td>
<td>❌</td>
</tr>
<tr>
<td>RPC</td>
<td>Request and response messaging (Remote Procedure Call)</td>
<td>❌ (point-to-point)</td>
<td>✅</td>
</tr>
</tbody></table>
<h3 id="1-Publish-Subscribe"><a href="#1-Publish-Subscribe" class="headerlink" title="1. Publish&#x2F;Subscribe"></a>1. Publish&#x2F;Subscribe</h3><p>Multiple consumers receive the same message.</p>
<p><strong>Characteristics:</strong></p>
<ul>
<li>Uses a <code>fanout</code> exchange</li>
<li>Messages are broadcast to all bound queues</li>
<li>Each consumer has its own queue, isolated from others</li>
</ul>
<p><strong>Use Cases:</strong></p>
<ul>
<li>Broadcasting notifications</li>
<li>Log collection</li>
<li>Multiple subsystems responding to events simultaneously</li>
</ul>
<hr>
<h3 id="2-Routing"><a href="#2-Routing" class="headerlink" title="2. Routing"></a>2. Routing</h3><p>Messages are delivered based on an exact match of the routing key.</p>
<p><strong>Characteristics:</strong></p>
<ul>
<li>Uses a <code>direct</code> exchange</li>
<li>Queues are bound with binding keys that exactly match routing keys</li>
<li>Multiple queues can be bound with different keys</li>
</ul>
<p><strong>Use Cases:</strong></p>
<ul>
<li>Processing different types of tasks in multiple modules</li>
<li>Log levels separation (e.g., error, info, debug)</li>
</ul>
<hr>
<h3 id="3-Topic"><a href="#3-Topic" class="headerlink" title="3. Topic"></a>3. Topic</h3><p>Routing key supports pattern matching with wildcards.</p>
<p><strong>Characteristics:</strong></p>
<ul>
<li>Uses a <code>topic</code> exchange</li>
<li>Supports wildcards <code>*</code> and <code>#</code></li>
<li>More flexible and complex routing logic</li>
</ul>
<p><strong>Use Cases:</strong></p>
<ul>
<li>Microservices event bus</li>
<li>Logging systems with hierarchical logs like <code>logs.system.error</code>, <code>logs.user.info</code></li>
</ul>
<hr>
<h3 id="4-Header"><a href="#4-Header" class="headerlink" title="4. Header"></a>4. Header</h3><p>Routing based on message header attributes.</p>
<p><strong>Characteristics:</strong></p>
<ul>
<li>Uses a <code>headers</code> exchange</li>
<li>Does not use routing keys, but matches based on header attributes</li>
</ul>
<p><strong>Use Cases:</strong></p>
<ul>
<li>Advanced routing policies</li>
<li>Attribute-driven message delivery (e.g., region&#x3D;us, format&#x3D;json)</li>
</ul>
<hr>
<h3 id="5-Work-Queue"><a href="#5-Work-Queue" class="headerlink" title="5. Work Queue"></a>5. Work Queue</h3><p>Multiple consumers share a single queue, and each message is delivered to only one consumer.</p>
<p>Produce sends the message with the routing key to the <code>exchange</code> (only specify the exchange name), then the exchange will based on its types to determine which queue shoud be routed to. Then, customers subscribe the queue to receive the message from produce.</p>
<p>Many customers subscribe the same queue, even if there is no exchange, queues could aslo hand out work to different multiple customers. The work queue distributes requests in chronological order and follow the rule <strong>FIFO</strong>(first in first out) in the <code>round-robin</code> way.</p>
<p><img src="/../images/work_queue.png" alt="work queue"></p>
<p><strong>Characteristics:</strong></p>
<ul>
<li>Typically uses a <code>direct or default</code> exchange</li>
<li>Multiple consumers compete for messages from the same queue</li>
<li>Enables load balancing (the idle consumer takes the message)</li>
</ul>
<p><strong>Use Cases:</strong></p>
<ul>
<li>Background task processing</li>
<li>Batch jobs</li>
<li>Data import, etc.</li>
</ul>
<hr>
<h3 id="6-RPC-Remote-Procedure-Call"><a href="#6-RPC-Remote-Procedure-Call" class="headerlink" title="6. RPC (Remote Procedure Call)"></a>6. RPC (Remote Procedure Call)</h3><p>Client sends a request, server processes it and replies back (pseudo-synchronous).</p>
<p><strong>Characteristics:</strong></p>
<ul>
<li>Uses a <code>direct</code> exchange for the <code>callback</code> and <code>topic</code> exchange for sending</li>
<li>Messages contain <code>reply_to</code> and <code>correlation_id</code> properties</li>
<li>Responses are sent back to a specified temporary queue</li>
</ul>
<p><strong>Use Cases:</strong></p>
<ul>
<li>RPC calls between OpenStack components</li>
<li>Asynchronous task tracking in Celery</li>
</ul>
<p><img src="/../images/RPC.png" alt="RPC"></p>
<h4 id="reply-to"><a href="#reply-to" class="headerlink" title="reply_to"></a>reply_to</h4><p><strong>What is <code>reply_to</code>?</strong></p>
<p><strong>Meaning:</strong> It tells the server “after processing, send the result to which queue”.</p>
<p><strong>Type:</strong> A string representing the name of the callback queue (reply queue).</p>
<p><strong>Purpose:</strong> Allows the client to receive the response message.</p>
<p><strong>Analogy:</strong> It’s like sending a parcel and writing “please send the result back to my office address” — this address is the <code>reply_to</code>.</p>
<h4 id="correlation-id"><a href="#correlation-id" class="headerlink" title="correlation_id"></a>correlation_id</h4><p><strong>What is <code>correlation_id</code>?</strong></p>
<p><strong>Meaning:</strong> A unique identifier (ID) that establishes the correspondence between request and response.</p>
<p><strong>Type:</strong> Usually a UUID or any unique string.</p>
<p><strong>Purpose:</strong> When the client sends multiple requests, it can use the <code>correlation_id</code> to identify which response corresponds to which request.</p>
<p><strong>Analogy:</strong> You send multiple questions (letters), each labelled “Question 1”, “Question 2”, etc. The reply includes the same label, so you know which answer matches which question.</p>
<h2 id="Exchanges"><a href="#Exchanges" class="headerlink" title="Exchanges"></a>Exchanges</h2><h3 id="Direct"><a href="#Direct" class="headerlink" title="Direct"></a>Direct</h3><p><strong>Direct Exchange</strong>: The routing keys are matched against a simple string, like “sales.*“. This means that any message with an exact binding key will be routed to this queue (and vice versa). “Direct” exchange type is used when you want messages sent directly from one application&#x2F;service into another.</p>
<p>In other words, the routing key must be <code>the same as</code> the binding key, one-to-one.</p>
<p>E.g. <code>taskC_create</code> message is routed to <code>taskC_queue</code> queue.</p>
<p><img src="/../images/direct.png" alt="direct"></p>
<h3 id="Topic"><a href="#Topic" class="headerlink" title="Topic"></a>Topic</h3><p><strong>Topic Exchange</strong>: This type of exchange functions like a <code>“fuzzy match”</code>. The routing key of a message and the binding key of a queue can <code>include wildcards (* and #)</code>, allowing for more flexible matching. The <code>*</code> wildcard matches <code>a single word</code>, while <code>#</code> matches <code>multiple words</code>.</p>
<p>E.g. A message can be delivered to one or more queues at the same time. Only <code>compute tasks</code> are routed to the queue named <code>compute_tasks</code>, while <code>all tasks</code>, including compute ones, are routed to the queue named <code>all_tasks</code>.</p>
<p><img src="/../images/topic.png" alt="topic"></p>
<h3 id="Fanout"><a href="#Fanout" class="headerlink" title="Fanout"></a>Fanout</h3><p><strong>Fanout Exchange</strong>: It is like a <code>“broadcast”</code>. It sends messages to <code>all bound queues</code>, <code>regardless of the routing key</code>. Simply put, “if it’s bound, it gets the message”. For example, in a logging system, all queues bound to the exchange will receive the message.</p>
<h3 id="Headers"><a href="#Headers" class="headerlink" title="Headers"></a>Headers</h3><p><strong>Headers</strong>: This exchange type makes use of the message headers to perform the match against the binding arguments of the queue. This is similar to a topic exchange except that there can be multiple key-value headers, and the queue can be matched against any or all. And headers <code>ignore the routing key</code> at all.</p>
<h2 id="Rabbitmq-common-command"><a href="#Rabbitmq-common-command" class="headerlink" title="Rabbitmq common command"></a>Rabbitmq common command</h2><h3 id="Check-the-report-summary"><a href="#Check-the-report-summary" class="headerlink" title="Check the report summary"></a>Check the report summary</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">()[root@controller0 /]# rabbitmqctl report</span><br><span class="line">Reporting server status of node rabbit@controller0 ...</span><br><span class="line"></span><br><span class="line">Status of node rabbit@controller0 ...</span><br><span class="line">[&#123;pid,701&#125;,</span><br><span class="line"> &#123;running_applications,</span><br><span class="line">     [&#123;rabbitmq_management,&quot;RabbitMQ Management Console&quot;,&quot;3.7.23&quot;&#125;,</span><br><span class="line">      &#123;rabbitmq_web_dispatch,&quot;RabbitMQ Web Dispatcher&quot;,&quot;3.7.23&quot;&#125;,</span><br><span class="line">      &#123;amqp_client,&quot;RabbitMQ AMQP Client&quot;,&quot;3.7.23&quot;&#125;,</span><br><span class="line">      &#123;rabbitmq_management_agent,&quot;RabbitMQ Management Agent&quot;,&quot;3.7.23&quot;&#125;,</span><br><span class="line">      &#123;rabbit,&quot;RabbitMQ&quot;,&quot;3.7.23&quot;&#125;,</span><br><span class="line">      &#123;mnesia,&quot;MNESIA  CXC 138 12&quot;,&quot;4.15.6&quot;&#125;,</span><br><span class="line">      &#123;rabbit_common,</span><br><span class="line">          &quot;Modules shared by rabbitmq-server and rabbitmq-erlang-client&quot;,</span><br><span class="line">          &quot;3.7.23&quot;&#125;,</span><br><span class="line">...output omitted...</span><br></pre></td></tr></table></figure>

<h3 id="List-users"><a href="#List-users" class="headerlink" title="List users"></a>List users</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">()[root@controller0 /]# rabbitmqctl list_users</span><br><span class="line">Listing users ...</span><br><span class="line">user tags</span><br><span class="line">guest [administrator]</span><br></pre></td></tr></table></figure>

<h3 id="Create-users"><a href="#Create-users" class="headerlink" title="Create users"></a>Create users</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">()[root@controller0 /]# rabbitmqctl add_user shy shypassword</span><br><span class="line">Adding user &quot;shy&quot; ...</span><br><span class="line">()[root@controller0 /]# rabbitmqctl list_users</span><br><span class="line">Listing users ...</span><br><span class="line">user tags</span><br><span class="line">shy []</span><br><span class="line">guest [administrator]</span><br></pre></td></tr></table></figure>

<h3 id="Allocate-the-permission"><a href="#Allocate-the-permission" class="headerlink" title="Allocate the permission"></a>Allocate the permission</h3><ul>
<li><p>configure: Define the resources that the user could configure.</p>
</li>
<li><p>write: Define the resources that the user could write.</p>
</li>
<li><p>read: Define the resources that the user could read.</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">()[root@controller0 /]# rabbitmqctl set_permissions shy &#x27;.*&#x27; &#x27;.*&#x27; &#x27;.*&#x27;</span><br><span class="line">Setting permissions for user &quot;shy&quot; in vhost &quot;/&quot; ...</span><br><span class="line">()[root@controller0 /]# rabbitmqctl list_permissions</span><br><span class="line">Listing permissions for vhost &quot;/&quot; ...</span><br><span class="line">user configure write read</span><br><span class="line">shy .* .* .*</span><br><span class="line">guest .* .* .*</span><br></pre></td></tr></table></figure>

<h3 id="Add-the-tag-to-users"><a href="#Add-the-tag-to-users" class="headerlink" title="Add the tag to users"></a>Add the tag to users</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">()[root@controller0 /]# rabbitmqctl set_user_tags shy administrator</span><br><span class="line">Setting tags for user &quot;shy&quot; to [administrator] ...</span><br><span class="line">()[root@controller0 /]# rabbitmqctl list_users</span><br><span class="line">Listing users ...</span><br><span class="line">user tags</span><br><span class="line">shy [administrator]</span><br><span class="line">guest [administrator]</span><br></pre></td></tr></table></figure>

<h3 id="List-all-exchanges"><a href="#List-all-exchanges" class="headerlink" title="List all exchanges"></a>List all exchanges</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">()[root@controller0 /]# rabbitmqctl list_exchanges</span><br><span class="line">Listing exchanges for vhost / ...</span><br><span class="line">name type</span><br><span class="line">heat-engine-listener_fanout fanout</span><br><span class="line">manila-share_fanout fanout</span><br><span class="line">engine_fanout fanout</span><br><span class="line">engine_worker_fanout fanout</span><br><span class="line">cinder-volume_fanout fanout</span><br><span class="line">q-server-resource-versions_fanout fanout</span><br><span class="line">openstack topic</span><br><span class="line">amq.rabbitmq.trace topic</span><br><span class="line">amq.fanout fanout</span><br><span class="line">cinder-scheduler_fanout fanout</span><br><span class="line">compute_fanout fanout</span><br><span class="line">amq.match headers</span><br><span class="line">neutron-vo-Port-1.5_fanout fanout</span><br><span class="line">q-plugin_fanout fanout</span><br><span class="line">octavia-rpc_fanout fanout</span><br><span class="line">amq.topic topic</span><br><span class="line">octavia_provisioning_v2_fanout fanout</span><br><span class="line">amq.direct direct</span><br><span class="line">heat topic</span><br><span class="line">amq.headers headers</span><br><span class="line">manila-scheduler_fanout fanout</span><br><span class="line">nova topic</span><br><span class="line">scheduler_fanout fanout</span><br><span class="line">cinder-volume.hostgroup@tripleo_ceph_fanout fanout</span><br><span class="line">conductor_fanout fanout</span><br><span class="line">neutron topic</span><br><span class="line">octavia topic</span><br><span class="line">q-reports-plugin_fanout fanout</span><br><span class="line"> direct</span><br></pre></td></tr></table></figure>

<p>The last one is an <code>implicit direct</code> type exchange.</p>
<p>Its name is an <code>empty</code> string “”.</p>
<p>Every queue is automatically bound to it with a <code>binding key</code> that matches the <code>queue’s name</code>.</p>
<h3 id="List-all-available-queues"><a href="#List-all-available-queues" class="headerlink" title="List all available queues"></a>List all available queues</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">()[root@controller0 /]# rabbitmqctl list_queues</span><br><span class="line">Timeout: 60.0 seconds ...</span><br><span class="line">Listing queues for vhost / ...</span><br><span class="line">name messages</span><br><span class="line">compute.computehci0.overcloud.example.com 0</span><br><span class="line">compute.compute1.overcloud.example.com 0</span><br><span class="line">manila-scheduler.hostgroup 0</span><br><span class="line">engine_worker_fanout_c149d365282c4d7986d35683a679ab43 0</span><br><span class="line">reply_95154a0ef0a7494c91bda27f28a2be56 0</span><br><span class="line">cinder-scheduler 0</span><br><span class="line">q-reports-plugin.controller0.overcloud.example.com 0</span><br><span class="line">scheduler_fanout_76ec3c50ae6447c39559b0311268126b 0</span><br><span class="line">compute.compute0.overcloud.example.com 0</span><br><span class="line">reply_61725f7db23a4e7bacecb41f30be9f72 0</span><br><span class="line">conductor_fanout_49fc039d21894497be4fbfd1ecadcce7 0</span><br><span class="line">octavia-rpc 0</span><br><span class="line">q-server-resource-versions.controller0.overcloud.example.com 0</span><br><span class="line">cinder-volume.hostgroup@tripleo_ceph 0</span><br><span class="line">reply_ccfd22e0f82344bb890ff371a0eaa2f9 0</span><br><span class="line">manila-share_fanout_53d504969d5647319932e92f73bb5773 0</span><br><span class="line">manila-share.hostgroup@cephfs 0</span><br><span class="line">conductor.controller0.overcloud.example.com 0</span><br><span class="line">octavia_provisioning_v2 0</span><br><span class="line">q-reports-plugin 0</span><br><span class="line">heat-engine-listener.34703093-ae25-4a65-80db-203f1ebbad36 0</span><br><span class="line">octavia-rpc.controller0 0</span><br><span class="line">engine_fanout_d9489dad34ab4a2e833e25ba5ac9bd43 0</span><br><span class="line">manila-scheduler_fanout_53141319d79548a3a5a23f472026995c 0</span><br><span class="line">engine 0</span><br><span class="line">q-server-resource-versions 0</span><br><span class="line">scheduler.controller0.overcloud.example.com 0</span><br><span class="line">octavia_provisioning_v2_fanout_516bc8a0d4a04e17b02d7a490ffad7e3 0</span><br><span class="line">q-plugin_fanout_82afdb9f58dd46fd9e12d1b9ff981b57 0</span><br><span class="line">q-plugin.controller0.overcloud.example.com 0</span><br><span class="line">manila-share 0</span><br><span class="line">heat-engine-listener_fanout_092d1af0bf034da0aafbd796ef769ec1 0</span><br><span class="line">compute_fanout_3d54889d98a84dcea09b080c23a255f5 0</span><br><span class="line">cinder-volume 0</span><br><span class="line">engine_worker 0</span><br><span class="line">engine.controller0 0</span><br><span class="line">compute_fanout_ef6b7f891f8b482188a1081436cd99b0 0</span><br><span class="line">engine_worker.34703093-ae25-4a65-80db-203f1ebbad36 0</span><br><span class="line">scheduler_fanout_56d907c013304f0b8ea9ab7ed88b6311 0</span><br><span class="line">compute 0</span><br><span class="line">q-server-resource-versions_fanout_1c237cd6f89549e6873ef5d817441b0f 0</span><br><span class="line">scheduler 0</span><br><span class="line">compute_fanout_d20e7a4456e94533b532e1941594ac6f 0</span><br><span class="line">heat-engine-listener 0</span><br><span class="line">octavia_provisioning_v2.controller0 0</span><br><span class="line">q-reports-plugin_fanout_b04fa13918b749eebcc159bb2520934b 0</span><br><span class="line">cinder-scheduler.controller0 0</span><br><span class="line">cinder-volume_fanout_c4f5af48a98e47f5acda0a01681c16a1 0</span><br><span class="line">octavia-rpc_fanout_a68e626ca08943c986a33ec185f2ad12 0</span><br><span class="line">cinder-volume.hostgroup@tripleo_ceph.hostgroup 0</span><br><span class="line">scheduler_fanout_a19884991bd64a278afed93434054535 0</span><br><span class="line">manila-scheduler 0</span><br><span class="line">cinder-volume.hostgroup@tripleo_ceph_fanout_b7c2b8bbdc494c279d6728ed5fe39f94 0</span><br><span class="line">q-reports-plugin_fanout_3a7fa6f49d9349a0ae6e8143ac075f1f 0</span><br><span class="line">q-plugin 0</span><br><span class="line">conductor 0</span><br><span class="line">cinder-scheduler_fanout_6a11c6037338474a9b3d7ce850b9966a 0</span><br></pre></td></tr></table></figure>

<h3 id="List-all-customers"><a href="#List-all-customers" class="headerlink" title="List all customers"></a>List all customers</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">()[root@controller0 /]# rabbitmqctl list_consumers</span><br><span class="line">Listing consumers in vhost / ...</span><br><span class="line">queue_name channel_pid consumer_tag ack_required prefetch_count arguments</span><br><span class="line">compute.computehci0.overcloud.example.com &lt;rabbit@controller0.3.1232.0&gt; 2 true 0 []</span><br><span class="line">compute.compute1.overcloud.example.com &lt;rabbit@controller0.3.1206.0&gt; 2 true 0 []</span><br><span class="line">manila-scheduler.hostgroup &lt;rabbit@controller0.3.725.0&gt; 2 true 0 []</span><br><span class="line">engine_worker_fanout_c149d365282c4d7986d35683a679ab43 &lt;rabbit@controller0.3.1063.0&gt; 3 true []</span><br><span class="line">reply_95154a0ef0a7494c91bda27f28a2be56 &lt;rabbit@controller0.3.1117.0&gt; 1 true 0 []</span><br><span class="line">cinder-scheduler &lt;rabbit@controller0.3.763.0&gt; 1 true 0 []</span><br><span class="line">q-reports-plugin.controller0.overcloud.example.com &lt;rabbit@controller0.3.1624.0&gt; 2 true []</span><br><span class="line">q-reports-plugin.controller0.overcloud.example.com &lt;rabbit@controller0.3.1509.0&gt; 2 true []</span><br><span class="line">scheduler_fanout_76ec3c50ae6447c39559b0311268126b &lt;rabbit@controller0.3.1165.0&gt; 3 true []</span><br><span class="line">compute.compute0.overcloud.example.com &lt;rabbit@controller0.3.953.0&gt; 2 true 0 []</span><br><span class="line">reply_61725f7db23a4e7bacecb41f30be9f72 &lt;rabbit@controller0.3.802.0&gt; 1 true 0 []</span><br><span class="line">conductor_fanout_49fc039d21894497be4fbfd1ecadcce7 &lt;rabbit@controller0.3.829.0&gt; 3 true []</span><br><span class="line">octavia-rpc &lt;rabbit@controller0.3.980.0&gt; 1 true 0 []</span><br><span class="line">q-server-resource-versions.controller0.overcloud.example.com &lt;rabbit@controller0.3.1585.0&gt; 2 true 0 []</span><br><span class="line">cinder-volume.hostgroup@tripleo_ceph &lt;rabbit@controller0.3.930.0&gt; 1 true 0 []</span><br><span class="line">cinder-volume.hostgroup@tripleo_ceph &lt;rabbit@controller0.3.904.0&gt; 2 true 0 []</span><br><span class="line">reply_ccfd22e0f82344bb890ff371a0eaa2f9 &lt;rabbit@controller0.3.856.0&gt; 1 true 0 []</span><br><span class="line">manila-share_fanout_53d504969d5647319932e92f73bb5773 &lt;rabbit@controller0.3.696.0&gt; 3 true []</span><br><span class="line">manila-share.hostgroup@cephfs &lt;rabbit@controller0.3.696.0&gt; 2 true 0 []</span><br><span class="line">conductor.controller0.overcloud.example.com &lt;rabbit@controller0.3.829.0&gt; 2 true 0 []</span><br><span class="line">octavia_provisioning_v2 &lt;rabbit@controller0.3.1008.0&gt; 1 true 0 []</span><br><span class="line">q-reports-plugin &lt;rabbit@controller0.3.1624.0&gt; 1 true 0 []</span><br><span class="line">q-reports-plugin &lt;rabbit@controller0.3.1509.0&gt; 1 true 0 []</span><br><span class="line">heat-engine-listener.34703093-ae25-4a65-80db-203f1ebbad36 &lt;rabbit@controller0.3.1035.0&gt; 2 true 0 []</span><br><span class="line">octavia-rpc.controller0 &lt;rabbit@controller0.3.980.0&gt; 2 true 0 []</span><br><span class="line">engine_fanout_d9489dad34ab4a2e833e25ba5ac9bd43 &lt;rabbit@controller0.3.1090.0&gt; 3 true 0 []</span><br><span class="line">manila-scheduler_fanout_53141319d79548a3a5a23f472026995c &lt;rabbit@controller0.3.725.0&gt; 3 true 0 []</span><br><span class="line">engine &lt;rabbit@controller0.3.1090.0&gt; 1 true 0 []</span><br><span class="line">q-server-resource-versions &lt;rabbit@controller0.3.1585.0&gt; 1 true 0 []</span><br><span class="line">scheduler.controller0.overcloud.example.com &lt;rabbit@controller0.3.1164.0&gt; 2 true 0 []</span><br><span class="line">scheduler.controller0.overcloud.example.com &lt;rabbit@controller0.3.1165.0&gt; 2 true 0 []</span><br><span class="line">scheduler.controller0.overcloud.example.com &lt;rabbit@controller0.3.1149.0&gt; 2 true 0 []</span><br><span class="line">octavia_provisioning_v2_fanout_516bc8a0d4a04e17b02d7a490ffad7e3 &lt;rabbit@controller0.3.1008.0&gt; 3 true 0 []</span><br><span class="line">q-plugin_fanout_82afdb9f58dd46fd9e12d1b9ff981b57 &lt;rabbit@controller0.3.1517.0&gt; 3 true []</span><br><span class="line">q-plugin.controller0.overcloud.example.com &lt;rabbit@controller0.3.1517.0&gt; 2 true 0 []</span><br><span class="line">manila-share &lt;rabbit@controller0.3.696.0&gt; 1 true 0 []</span><br><span class="line">heat-engine-listener_fanout_092d1af0bf034da0aafbd796ef769ec1 &lt;rabbit@controller0.3.1035.0&gt; 3 true 0 []</span><br><span class="line">compute_fanout_3d54889d98a84dcea09b080c23a255f5 &lt;rabbit@controller0.3.1232.0&gt; 3 true 0 []</span><br><span class="line">cinder-volume &lt;rabbit@controller0.3.904.0&gt; 1 true 0 []</span><br><span class="line">engine_worker &lt;rabbit@controller0.3.1063.0&gt; 1 true 0 []</span><br><span class="line">engine.controller0 &lt;rabbit@controller0.3.1090.0&gt; 2 true 0 []</span><br><span class="line">compute_fanout_ef6b7f891f8b482188a1081436cd99b0 &lt;rabbit@controller0.3.1206.0&gt; 3 true 0 []</span><br><span class="line">engine_worker.34703093-ae25-4a65-80db-203f1ebbad36 &lt;rabbit@controller0.3.1063.0&gt; 2 true []</span><br><span class="line">scheduler_fanout_56d907c013304f0b8ea9ab7ed88b6311 &lt;rabbit@controller0.3.1149.0&gt; 3 true []</span><br><span class="line">compute &lt;rabbit@controller0.3.1232.0&gt; 1 true 0 []</span><br><span class="line">compute &lt;rabbit@controller0.3.1206.0&gt; 1 true 0 []</span><br><span class="line">compute &lt;rabbit@controller0.3.953.0&gt; 1 true 0 []</span><br><span class="line">q-server-resource-versions_fanout_1c237cd6f89549e6873ef5d817441b0f &lt;rabbit@controller0.3.1585.0&gt; true 0 []</span><br><span class="line">scheduler &lt;rabbit@controller0.3.1165.0&gt; 1 true 0 []</span><br><span class="line">scheduler &lt;rabbit@controller0.3.1164.0&gt; 1 true 0 []</span><br><span class="line">scheduler &lt;rabbit@controller0.3.1149.0&gt; 1 true 0 []</span><br><span class="line">compute_fanout_d20e7a4456e94533b532e1941594ac6f &lt;rabbit@controller0.3.953.0&gt; 3 true 0 []</span><br><span class="line">heat-engine-listener &lt;rabbit@controller0.3.1035.0&gt; 1 true 0 []</span><br><span class="line">octavia_provisioning_v2.controller0 &lt;rabbit@controller0.3.1008.0&gt; 2 true 0 []</span><br><span class="line">q-reports-plugin_fanout_b04fa13918b749eebcc159bb2520934b &lt;rabbit@controller0.3.1624.0&gt; 3 true 0 []</span><br><span class="line">cinder-scheduler.controller0 &lt;rabbit@controller0.3.763.0&gt; 2 true 0 []</span><br><span class="line">cinder-volume_fanout_c4f5af48a98e47f5acda0a01681c16a1 &lt;rabbit@controller0.3.904.0&gt; 3 true []</span><br><span class="line">octavia-rpc_fanout_a68e626ca08943c986a33ec185f2ad12 &lt;rabbit@controller0.3.980.0&gt; 3 true []</span><br><span class="line">cinder-volume.hostgroup@tripleo_ceph.hostgroup &lt;rabbit@controller0.3.930.0&gt; 2 true 0 []</span><br><span class="line">scheduler_fanout_a19884991bd64a278afed93434054535 &lt;rabbit@controller0.3.1164.0&gt; 3 true []</span><br><span class="line">manila-scheduler &lt;rabbit@controller0.3.725.0&gt; 1 true 0 []</span><br><span class="line">cinder-volume.hostgroup@tripleo_ceph_fanout_b7c2b8bbdc494c279d6728ed5fe39f94 &lt;rabbit@controller0.3.930.0&gt; 3 true 0 []</span><br><span class="line">q-reports-plugin_fanout_3a7fa6f49d9349a0ae6e8143ac075f1f &lt;rabbit@controller0.3.1509.0&gt; 3 true 0 []</span><br><span class="line">q-plugin &lt;rabbit@controller0.3.1517.0&gt; 1 true 0 []</span><br><span class="line">conductor &lt;rabbit@controller0.3.829.0&gt; 1 true 0 []</span><br><span class="line">cinder-scheduler_fanout_6a11c6037338474a9b3d7ce850b9966a &lt;rabbit@controller0.3.763.0&gt; 3 true 0 []</span><br></pre></td></tr></table></figure>

<h3 id="Trace-on-the-RabbitMQ-message"><a href="#Trace-on-the-RabbitMQ-message" class="headerlink" title="Trace on the RabbitMQ message"></a>Trace on the RabbitMQ message</h3><p>This feature can be used to track all messages flowing through the system, whether incoming or outgoing. In other words, it acts like a supervisor, logging every message in motion. This capability is based on the <code>firehose</code> mechanism.</p>
<p>The name firehose comes from its function—it behaves like a firehose, <code>spraying out</code> all messages so you can see each one passing through. This feature is very useful during development and debugging, but as it records all messages, it may impact performance.</p>
<h4 id="Enable-the-trace"><a href="#Enable-the-trace" class="headerlink" title="Enable the trace"></a>Enable the trace</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rabbitmqctl trace_on</span><br></pre></td></tr></table></figure>

<p>Once enabled, all messages entering the RabbitMQ system are copied to a special exchange called <code>amq.rabbitmq.trace</code>. This allows you to observe the entire message flow within that exchange, which is particularly useful for <code>debugging and monitoring</code>.</p>
<blockquote>
<p><strong>Performance impact</strong>: Enabling the Firehose Tracer <code>increases system load</code>, as it must handle and replicate every message. Therefore, it is recommended to enable it only when debugging is necessary, and to <code>disable it promptly once debugging is complete</code>.</p>
<p><strong>Monitoring amq.rabbitmq.trace</strong>: After enabling tracing, you can monitor system activity by inspecting the messages in the <code>amq.rabbitmq.trace exchange</code>. This exchange contains copies of all messages, making it easier to analyse system behaviour.</p>
</blockquote>
<h4 id="Disable-the-trace"><a href="#Disable-the-trace" class="headerlink" title="Disable the trace"></a>Disable the trace</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rabbitmqctl trace_off</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>OpenStack</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenStack Series Chapter4: Identifying shared services and VNC</title>
    <url>//Cloud/OpenStack/Identifying-shared-services-and-VNC/index.html</url>
    <content><![CDATA[<h2 id="Shared-Services-Overview"><a href="#Shared-Services-Overview" class="headerlink" title="Shared Services Overview"></a>Shared Services Overview</h2><table>
<thead>
<tr>
<th align="left">Service</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody><tr>
<td align="left">MariaDB</td>
<td align="left">A relational database.</td>
</tr>
<tr>
<td align="left">Redis</td>
<td align="left">An in-memory key-value data store.</td>
</tr>
<tr>
<td align="left">memcached</td>
<td align="left">A distributed memory cache.</td>
</tr>
<tr>
<td align="left">Pacemaker</td>
<td align="left">Clustering software.</td>
</tr>
<tr>
<td align="left">Ceph MON and MDS</td>
<td align="left">The Ceph cluster monitor, and Metadata Server.</td>
</tr>
<tr>
<td align="left">NoVNC and Spice</td>
<td align="left">Both provide a remote console for instances.</td>
</tr>
</tbody></table>
<h3 id="MariaDB"><a href="#MariaDB" class="headerlink" title="MariaDB"></a>MariaDB</h3><p><code>MariaDB</code> is an open-source edition SQL database and it’s compatible with MySQL database.</p>
<p>It allows all components to store information.</p>
<p>In the <code>controller node</code>, the method is <code>MariaDB Galera</code>. It provides <code>multi-master replication</code> mode to confirm the stable status, all nodes are the master.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">+----------+     +----------+     +----------+</span><br><span class="line">|  Node A  | &lt;--&gt;|  Node B  | &lt;--&gt;|  Node C  |</span><br><span class="line">+----------+     +----------+     +----------+</span><br><span class="line">      ^                              ^</span><br><span class="line">      |                              |</span><br><span class="line">      +-------- Client -------------+</span><br></pre></td></tr></table></figure>

<p>The Features of MariaDB Galera:</p>
<ul>
<li><p>Multi-Master Replication</p>
<ul>
<li><p>All nodes can perform read and write operations simultaneously.</p>
</li>
<li><p>Real-time data synchronisation (synchronous replication, not asynchronous) ensures strong consistency.</p>
</li>
</ul>
</li>
<li><p>Strong Consistency (Synchronous Replication)</p>
<ul>
<li>Uses <strong>write-set replication</strong>: a write operation is considered successful only after all nodes have reached consensus.</li>
</ul>
</li>
<li><p>Automatic Membership Management and Failover</p>
<ul>
<li><p>Nodes can automatically join or leave the cluster.</p>
</li>
<li><p>A single node failure does not render the entire database unavailable.</p>
</li>
</ul>
</li>
<li><p>No Single Point of Failure (Theoretically)</p>
<ul>
<li><p>As long as the majority of nodes (typically N&#x2F;2 + 1) remain operational, the cluster can continue to function.</p>
</li>
<li><p>All nodes act as primary nodes, with strong data synchronisation between them.</p>
</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th>Type</th>
<th>Synchronous</th>
<th>Granularity</th>
<th>Characteristics</th>
<th>Common Use Cases</th>
</tr>
</thead>
<tbody><tr>
<td>Statement-based (SBR)</td>
<td>Asynchronous</td>
<td>SQL statements</td>
<td>Fast but may lead to inconsistencies</td>
<td>MySQL</td>
</tr>
<tr>
<td>Row-based (RBR)</td>
<td>Asynchronous</td>
<td>Row-level</td>
<td>Good consistency, high data volume</td>
<td>MySQL</td>
</tr>
<tr>
<td>Mixed-based</td>
<td>Asynchronous</td>
<td>Auto-switching</td>
<td>A compromise between SBR and RBR</td>
<td>MySQL</td>
</tr>
<tr>
<td>Write-set</td>
<td>Synchronous</td>
<td>Transaction write-set</td>
<td>Strong consistency, multi-master</td>
<td>Galera Cluster</td>
</tr>
<tr>
<td>Logical</td>
<td>Sync&#x2F;Async</td>
<td>Table&#x2F;statement-level</td>
<td>Highly flexible</td>
<td>PostgreSQL</td>
</tr>
<tr>
<td>Physical</td>
<td>Synchronous</td>
<td>Binary data</td>
<td>High performance but less flexible</td>
<td>PostgreSQL, Oracle, etc.</td>
</tr>
</tbody></table>
<h3 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h3><p><code>Redis</code> is a <code>high-performance</code> <code>in-memory</code> <code>key-value</code> data store.</p>
<p>It can store several types of data structures, such as <code>strings, lists, sets, sorted sets, and hashes</code>.</p>
<p>Compared with traditional database, Redis uses memory to store data. Therefore, keeping all data in memory increases performance.</p>
<p>What’s more, Redis supports to save data to disk as well.</p>
<h3 id="Memcached"><a href="#Memcached" class="headerlink" title="Memcached"></a>Memcached</h3><p><code>Memcached</code> is similar to <code>Redis</code>, it provides an in-memory cache for ephemeral data.</p>
<p>However, Memcached does not support the persistent storage in disk, it does not support various kinds of data structure(only key-value string).</p>
<p>It’s used more in <code>keystone</code>, <code>nova</code>, <code>oslo</code> and so on.</p>
<h3 id="Pacemaker"><a href="#Pacemaker" class="headerlink" title="Pacemaker"></a>Pacemaker</h3><p><code>Pacemaker</code> service manages core containers and services, such as Galera, RabbitMQ, Redis, and HAProxy.</p>
<p>It could monitor services as well as allocate the defected services to an available node, switch to a new node or restart the service.</p>
<h3 id="Ceph-MON-and-MDS"><a href="#Ceph-MON-and-MDS" class="headerlink" title="Ceph MON and MDS"></a>Ceph MON and MDS</h3><p>MON and MDS are two core components for Ceph. </p>
<p><code>MON</code> is responsible for monitorting the status of the whole ceph cluster.</p>
<p><code>MDS</code> looks like a map which manages and stores the meta data, it records the configuration information.</p>
<h3 id="NoVNC-and-SPICE"><a href="#NoVNC-and-SPICE" class="headerlink" title="NoVNC and SPICE"></a>NoVNC and SPICE</h3><p>OpenStack supports two protocols for providing remote virtual console access: <code>VNC(Virtual Network Computer)</code> and <code>SPICE(Simple Protocol for Independent Computing Environments)</code>.</p>
<ul>
<li><p>noVNC</p>
<p><code>noVNC</code> is comprised of a JavaScript library and an application that runs in desktop and mobile browsers using HTML5 and WebSockets.</p>
<p>It is a VNC client based on web, it is convenient for users to visit the virtual machine desktop by browser.</p>
</li>
<li><p>SPICE</p>
<p><code>SPICE</code> provides more advanced features than existing VNC clients.(audio or vedio)</p>
<blockquote>
<p>Red Hat recommends that you use a standalone SPICE client to access OpenStack instances from the private management network.</p>
</blockquote>
</li>
</ul>
<h2 id="Using-VNC-to-Access-an-Instance-Console"><a href="#Using-VNC-to-Access-an-Instance-Console" class="headerlink" title="Using VNC to Access an Instance Console"></a>Using VNC to Access an Instance Console</h2><p>Because all virtual machines are generated on the compute node, <code>each compute node</code> runs a <code>vncserver</code> process, listening on the internal API network on one or more ports, starting at 5900 and increasing, depending on the number of instances deployed on that compute node.</p>
<p><code>Each controller node</code> runs a <code>novncproxy</code> process, listening on port 6080 on the same internal API network. </p>
<p>The remaining services belong to the <code>Compute Service (Nova)</code> with components on <code>both the controller and compute nodes</code>.</p>
<p><img src="/../images/VNC_process.png" alt="VNC process"></p>
<p>VNC Process Flow for Accessing an Instance Console:</p>
<ol>
<li><p>Users make a request from <code>browser</code>.</p>
<p> Users open a browser and use the NoVNC plugin, call the nova-api (the main controller of OpenStack, residing on the controller node and listening on port 8774) to connect to the virtual machine. At this point, OpenStack’s Dashboard (the management interface) forwards the request via HAProxy (a highly capable traffic coordinator located on the controller node, using port 80).</p>
</li>
<li><p><code>Nova API</code> passes the request.</p>
<p> Nova-api passes a <code>get_vnc_console</code> request to nova-compute (compute, internal_API,AMQP).</p>
</li>
<li><p><code>Nova-compute</code> ask <code>libvirt</code>.</p>
<p> nova-compute passes the <code>get_vnc_console</code> request to libvirt (compute) to locate the VM’s attributes.</p>
</li>
<li><p><code>libvirt</code> generates a token.</p>
<p> libvirt generates a <code>token</code> from the VM’s UUID and returns the token to nova-compute (compute, internal_API, AMQP).</p>
<p> The token is like the ID-card of the VMs.</p>
</li>
<li><p><code>Nova-compute</code> returns the token to <code>Nova API</code>.</p>
<p> nova-compute returns the generated token and a <code>connect_info</code> object to nova-api (controller, internal API, AMQP).</p>
</li>
<li><p><code>Nova API</code> asks <code>Nova-consoleauth</code> to authorize.</p>
<p> <code>nova-api</code> passes an <code>authorize_console</code> request to <code>nova-consoleauth</code> (compute, internal API, AMQP), which caches the <code>connect_info</code> object, using the token as the index, for future use when the actual connection request occurs.</p>
</li>
<li><p><code>Nova API</code> tells the browser.</p>
<p> <code>nova-api</code> also returns a <code>nova-novncproxy URL</code> and the <code>instance-specific token</code> to the <code>browser</code> (workstation, external).</p>
</li>
<li><p><code>Browser</code> visit the <code>nova-novncproxy</code> by <code>haproxy</code>.</p>
<p> The browser (workstation, external) connects to the URL, <code>proxied by the dashboard haproxy</code> (controller, external, port 6080) to reach nova-novncproxy (controller, internal API, port 6080).</p>
</li>
<li><p><code>Nova-novncproxy</code> parses the token.</p>
<p> nova-novncproxy obtains the request and then it parses the <code>token and instance ID</code> from the URL and passes it to <code>nova-consoleauth</code> (controller, internal API, AMQP) to verify.</p>
</li>
<li><p><code>Nova-consoleauth</code> gives the feedback.</p>
<p>  Using the token, <code>nova-consoleauth</code> retrieves the <code>connect_info</code> object from the cache and <code>returns it to nova-novncproxy</code> (controller, internal API).</p>
</li>
<li><p><code>Nova-novncproxy</code> connects to the <code>VNC</code> server.</p>
<p>  <code>nova-novncproxy</code> connects directly to <code>vncserver</code> (compute, internal API, 5900+) at the port designated for the requested VM and creates a reverse proxy configuration by using <code>connect_info</code>.</p>
</li>
<li><p><code>The graphic web UI</code> will be sent to the <code>browser</code>.</p>
<p><code>nova-novncproxy</code> sends the <code>console graphics</code> back through the dashboard <code>haproxy</code> to the user’s <code>browser</code> (workstation, external).</p>
</li>
</ol>
]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>OpenStack</tag>
      </tags>
  </entry>
  <entry>
    <title>cifs mount attention</title>
    <url>//Linux/Mount/cifs-mount-attention/index.html</url>
    <content><![CDATA[<h2 id="Automatically-mount"><a href="#Automatically-mount" class="headerlink" title="Automatically mount"></a>Automatically mount</h2><h3 id="Edit-the-etc-fstab-file"><a href="#Edit-the-etc-fstab-file" class="headerlink" title="Edit the /etc/fstab file"></a>Edit the <code>/etc/fstab</code> file</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> vim /etc/fstab</span><br><span class="line"></span><br><span class="line">//xxx.xx.xx.xx/FileStorage /mnt/smb cifs credentials=/home/[user_name]/smbcredentials,vers=3.1.1,x-systemd.automount,_netdev 0 0</span><br></pre></td></tr></table></figure>

<h3 id="Modify-the-permission-of-the-credential-file"><a href="#Modify-the-permission-of-the-credential-file" class="headerlink" title="Modify the permission of the credential file"></a>Modify the permission of the credential file</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> <span class="built_in">chmod</span> 600 /home/[user_name]/smbcredentials</span><br></pre></td></tr></table></figure>

<h2 id="Check-whether-the-mount-point-is-available-or-not"><a href="#Check-whether-the-mount-point-is-available-or-not" class="headerlink" title="Check whether the mount-point is available or not"></a>Check whether the mount-point is available or not</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo cat /etc/mtab | grep cifs</span><br></pre></td></tr></table></figure>

<h2 id="Remove-all-existing-mount-record"><a href="#Remove-all-existing-mount-record" class="headerlink" title="Remove all existing mount-record"></a>Remove all existing mount-record</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> umount -l /mnt/smb</span><br></pre></td></tr></table></figure>

<h2 id="Remount"><a href="#Remount" class="headerlink" title="Remount"></a>Remount</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> systemctl daemon-reload</span><br><span class="line"><span class="built_in">sudo</span> mount -a</span><br></pre></td></tr></table></figure>

<h2 id="Confirm-the-mount-result"><a href="#Confirm-the-mount-result" class="headerlink" title="Confirm the mount result"></a>Confirm the mount result</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">df</span> -hT</span><br><span class="line"></span><br><span class="line">user@localhost:~$ <span class="built_in">df</span> -hT</span><br><span class="line">Filesystem                  Type   Size  Used Avail Use% Mounted on</span><br><span class="line">tmpfs                       tmpfs   13G  4.6M   13G   1% /run</span><br><span class="line">/dev/sdc4                   ext4   5.2T  2.0T  3.1T  39% /</span><br><span class="line">tmpfs                       tmpfs   63G  4.0K   63G   1% /dev/shm</span><br><span class="line">tmpfs                       tmpfs  5.0M     0  5.0M   0% /run/lock</span><br><span class="line">/dev/sdc2                   ext4   974M  245M  663M  27% /boot</span><br><span class="line">/dev/sdc1                   vfat   1.1G  6.1M  1.1G   1% /boot/efi</span><br><span class="line">tmpfs                       tmpfs   13G  4.0K   13G   1% /run/user/1000</span><br><span class="line">//xxx.xx.xx.xx/FileStorage cifs   2.5T  2.4T  151G  95% /mnt/smb</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Mount</tag>
      </tags>
  </entry>
  <entry>
    <title>Openstack Deployment Series Chapter0:Overview</title>
    <url>//Cloud/OpenStack/Openstack-Deployment-Overview/index.html</url>
    <content><![CDATA[<h2 id="What-is-OpenStack"><a href="#What-is-OpenStack" class="headerlink" title="What is OpenStack?"></a>What is OpenStack?</h2><p>OpenStack is an <code>open-source cloud computing platform</code> designed to provide scalable, flexible, and robust Infrastructure as a Service (IaaS). Through a suite of modular services—such as compute, storage, and network management—it offers enterprises and organisations a solution for building private or public clouds. OpenStack supports a range of virtualisation technologies, including <code>KVM</code>, <code>Xen</code>, and <code>VMware</code>, making it suitable for cloud environments of varying sizes and requirements.</p>
<p>Drawbacks of OpenStack:</p>
<ul>
<li><p>Complex architecture and heavy deployment:<br>OpenStack is highly <code>modular—each</code> function (like Nova, Neutron, Cinder, etc.) operates as an independent service. Deploying and integrating them involves considerable complexity, and upgrading or maintaining such a system comes with a high operational cost.</p>
</li>
<li><p>Performance overhead:<br>The control plane and scheduling logic introduce <code>latency</code>. For performance-critical, large-scale internet services, OpenStack is often not lightweight enough.</p>
</li>
<li><p>Limited flexibility despite high customisability:<br>While it is theoretically highly customisable, making significant changes requires <code>deep knowledge of its internal workings</code>. This demands strong in-house development capability.</p>
</li>
</ul>
<p>Domestic cloud platform:</p>
<ul>
<li><p>Alibaba Cloud’s <code>Apsara</code> is indeed its self-developed cloud platform, supporting massive computing, storage, and networking needs. Although early iterations may have drawn on open-source tools, it’s now fully proprietary.</p>
</li>
<li><p>Tencent Cloud’s <code>vStation</code> was an earlier name for part of their virtualisation platform. This evolved into a broader internal infrastructure, with “TStack” and the “Xingxinghai” architecture forming the basis of Tencent’s cloud platform.</p>
</li>
</ul>
<h1 id="Cloud-Platform-Base-Comparison-Table"><a href="#Cloud-Platform-Base-Comparison-Table" class="headerlink" title="Cloud Platform Base Comparison Table"></a>Cloud Platform Base Comparison Table</h1><table>
<thead>
<tr>
<th>Cloud Provider</th>
<th>Core Platform (Base)</th>
<th>OpenStack-Based?</th>
<th>Notes</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Alibaba Cloud</strong></td>
<td><strong>Apsara (飞天)</strong></td>
<td>❌ No</td>
<td>Fully in-house developed. Highly optimised for Alibaba’s scale.</td>
</tr>
<tr>
<td><strong>Tencent Cloud</strong></td>
<td><strong>TStack &#x2F; vStation</strong></td>
<td>❌ No</td>
<td>Self-developed virtualisation and orchestration stack.</td>
</tr>
<tr>
<td><strong>Huawei Cloud</strong></td>
<td><strong>FusionSphere</strong></td>
<td>✅ Yes (modified)</td>
<td>Based on OpenStack, heavily customised and commercialised.</td>
</tr>
<tr>
<td><strong>Baidu Cloud</strong></td>
<td><strong>ABC Stack</strong></td>
<td>❌ No</td>
<td>Proprietary platform optimised for AI and big data workloads.</td>
</tr>
<tr>
<td><strong>Open Telekom Cloud</strong></td>
<td>Based on OpenStack</td>
<td>✅ Yes</td>
<td>European carrier cloud offering. Standard OpenStack distribution.</td>
</tr>
<tr>
<td><strong>OVHcloud</strong></td>
<td>Based on OpenStack</td>
<td>✅ Yes</td>
<td>One of the largest OpenStack-based public clouds.</td>
</tr>
<tr>
<td><strong>Red Hat</strong></td>
<td><strong>TripleO (OpenStack)</strong></td>
<td>✅ Yes</td>
<td>Red Hat’s IaaS&#x2F;PaaS offering, often used for private cloud setups.</td>
</tr>
<tr>
<td><strong>Google Cloud</strong></td>
<td>Proprietary Infrastructure</td>
<td>❌ No</td>
<td>Uses fully in-house cloud platform. OpenStack not used.</td>
</tr>
<tr>
<td><strong>Amazon Web Services (AWS)</strong></td>
<td>Proprietary Infrastructure</td>
<td>❌ No</td>
<td>Entirely proprietary and highly integrated platform.</td>
</tr>
<tr>
<td><strong>Microsoft Azure</strong></td>
<td>Proprietary Infrastructure</td>
<td>❌ No</td>
<td>Microsoft’s fully self-developed cloud ecosystem.</td>
</tr>
</tbody></table>
<h2 id="Server-Configurations"><a href="#Server-Configurations" class="headerlink" title="Server Configurations"></a>Server Configurations</h2><p>One Controller node + One Compute node.</p>
<table>
<thead>
<tr>
<th align="left">Hostname</th>
<th align="left">IP address</th>
<th align="left">Operating System</th>
<th align="left">OpenStack Version</th>
</tr>
</thead>
<tbody><tr>
<td align="left">controller</td>
<td align="left">Management Network：192.168.225.33  <br> Provider Network：No IP addr</td>
<td align="left">Rocky 9.5</td>
<td align="left">Dalmatian (2025.1)</td>
</tr>
<tr>
<td align="left">node</td>
<td align="left">Management Network：192.168.225.34  <br> Provider Network：NO IP addr</td>
<td align="left">Rocky 9.5</td>
<td align="left">Dalmatian (2025.1)</td>
</tr>
</tbody></table>
<h2 id="Modular-each-Services"><a href="#Modular-each-Services" class="headerlink" title="Modular-each Services"></a>Modular-each Services</h2><h3 id="Controller"><a href="#Controller" class="headerlink" title="Controller"></a>Controller</h3><ul>
<li><p><strong>Identity service</strong>: Used for user authentication and authorisation. </p>
</li>
<li><p><strong>Image service</strong>: Used to store and manage virtual machine images.  </p>
</li>
<li><p><strong>Placement service</strong>: Used for resource tracking and allocation.  </p>
</li>
<li><p><strong>Compute management component</strong>: Manages the lifecycle of virtual machines. </p>
</li>
<li><p><strong>Networking management component</strong>: Handles the management of network resources.  </p>
</li>
<li><p><strong>Various networking agents</strong>: Implement networking functions.  </p>
</li>
<li><p><strong>Dashboard</strong>: Provides a graphical user interface for management.  </p>
</li>
<li><p><strong>Cinder block storage</strong>: Offers block storage services.  </p>
</li>
<li><p><strong>Manila file sharing service</strong>: Provides file sharing capabilities.</p>
</li>
<li><p><strong>SQL database</strong>: Stores data for OpenStack services.  </p>
</li>
<li><p><strong>ETCD database</strong>: Stores distributed configuration data.  </p>
</li>
<li><p><strong>Message queue</strong>: Facilitates communication between services.  </p>
</li>
<li><p><strong>NTP (Network Time Protocol)</strong>: Ensures time synchronisation across components.</p>
</li>
</ul>
<h3 id="Compute"><a href="#Compute" class="headerlink" title="Compute"></a>Compute</h3><ul>
<li><p><strong>Compute management component</strong>: Manages the lifecycle of virtual machines. </p>
</li>
<li><p><strong>KVM virtualisation component</strong>: Responsible for running virtual machines. </p>
</li>
<li><p><strong>Networking agent</strong>: Implements networking functions.</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>OpenStack</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenStack Series Chapter3:Introducing Overcloud</title>
    <url>//Cloud/OpenStack/Introducing-Overcloud/index.html</url>
    <content><![CDATA[<h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>In Red Hat OpenStack Platform (RHOSP), a Red Hat supported overcloud is built by the undercloud <code>Director</code> node using the Deployment service <code>TripleO</code>. At the same time, the undercloud can deploy and manage <code>multiple</code> overclouds.</p>
<h2 id="The-Deployment-template"><a href="#The-Deployment-template" class="headerlink" title="The Deployment template"></a>The Deployment template</h2><p>An overcloud consists of numerous deployed nodes, each configured using roles, which specify the services and configuration required for a node to perform that role. Predefined RHOSP role definitions are located in the <code>/usr/share/openstack-tripleo-heat-templates/roles</code> directory and can be viewed with the <code>openstack role</code> command.</p>
<h3 id="Check-all-default-roles"><a href="#Check-all-default-roles" class="headerlink" title="Check all default roles"></a>Check all default roles</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(undercloud) [stack@director ~]$ ls /usr/share/openstack-tripleo-heat-templates/roles | wc -l</span><br><span class="line">52</span><br><span class="line"></span><br><span class="line">(undercloud) [stack@director ~]$ ls /usr/share/openstack-tripleo-heat-templates/roles</span><br><span class="line">BlockStorage.yaml           ComputePPC64LE.yaml                 DistributedComputeScaleOut.yaml</span><br><span class="line">CellController.yaml         ComputeRBDEphemeral.yaml            HciCephAll.yaml</span><br><span class="line">CephAll.yaml                ComputeRealTime.yaml                HciCephFile.yaml</span><br><span class="line">CephFile.yaml               ComputeSriov.yaml                   HciCephMon.yaml</span><br><span class="line">CephObject.yaml             ComputeSriovIB.yaml                 HciCephObject.yaml</span><br><span class="line">CephStorage.yaml            ComputeSriovRT.yaml                 IronicConductor.yaml</span><br><span class="line">Compute.yaml                Controller.yaml                     Messaging.yaml</span><br><span class="line">ComputeAlt.yaml             ControllerAllNovaStandalone.yaml    Networker.yaml</span><br><span class="line">ComputeDVR.yaml             ControllerNoCeph.yaml               NetworkerSriov.yaml</span><br><span class="line">ComputeHCI.yaml             ControllerNovaStandalone.yaml       Novacontrol.yaml</span><br><span class="line">ComputeHCIOvsDpdk.yaml      ControllerOpenstack.yaml            ObjectStorage.yaml</span><br><span class="line">ComputeInstanceHA.yaml      ControllerSriov.yaml                README.rst</span><br><span class="line">ComputeLiquidio.yaml        ControllerStorageDashboard.yaml     Standalone.yaml</span><br><span class="line">ComputeLocalEphemeral.yaml  ControllerStorageNfs.yaml           Telemetry.yaml</span><br><span class="line">ComputeOvsDpdk.yaml         Database.yaml                       Undercloud.yaml</span><br><span class="line">ComputeOvsDpdkRT.yaml       DistributedCompute.yaml             UndercloudMinion.yaml</span><br><span class="line">ComputeOvsDpdkSriov.yaml    DistributedComputeHCI.yaml</span><br><span class="line">ComputeOvsDpdkSriovRT.yaml  DistributedComputeHCIScaleOut.yaml</span><br></pre></td></tr></table></figure>

<h3 id="Check-all-deployed-roles"><a href="#Check-all-deployed-roles" class="headerlink" title="Check all deployed roles"></a>Check all deployed roles</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(undercloud) [stack@director ~]$ grep &#x27;^- name:&#x27; ~/templates/roles_data.yaml</span><br><span class="line">- name: Controller</span><br><span class="line">- name: Compute</span><br><span class="line">- name: CephStorage</span><br><span class="line">- name: ComputeHCI</span><br></pre></td></tr></table></figure>

<ul>
<li><p>Controller</p>
<p>Control plane node with all core services loaded. Provides service APIs and handles database, messaging, and network processing functions.</p>
<blockquote>
<p>In the exercise case, we provide only one <code>Controller</code> node.</p>
</blockquote>
</li>
<li><p>Compute</p>
<p>Standard compute node working as a hypervisor running deployed instances and stacks.</p>
</li>
<li><p>CephStorage</p>
<p>Storage back end node using a containerized Red Hat Ceph Storage server and multiple object storage disks (OSDs).</p>
</li>
<li><p>ComputeHCI</p>
<p>Converged node. (<code>Compute node</code> + <code>CephStorage node</code>.)</p>
<p>Compute node with hyperconverged infrastructure, combining compute and Ceph OSD functionality on a single node.</p>
</li>
</ul>
<h2 id="Components-and-Services"><a href="#Components-and-Services" class="headerlink" title="Components and Services"></a>Components and Services</h2><h3 id="Core-Services"><a href="#Core-Services" class="headerlink" title="Core Services"></a>Core Services</h3><ul>
<li><p>Block Storage Service (Cinder)</p>
<p>Cinder -&gt; Ceph.</p>
<p>Original Swift only provides the object storage. So, Cinder will schedule the back-end <code>Ceph</code> for <code>block</code> and <code>file</code> storage.</p>
</li>
<li><p>Image Service (Glance)</p>
<p>The Image service stores and manages images used to deploy instances. (<code>Object Storage</code>)</p>
</li>
<li><p>Orchestration Service (Heat)</p>
<p>In the undercloud, Heat templates deploy each <code>overcloud as a stack</code>.</p>
<p>In the overcloud, Heat templates deploy <code>application workloads as stacks</code>.</p>
<p>All templates are based on <code>yaml</code> files.</p>
</li>
<li><p>Dashboard Service (Horizon)</p>
<p><code>Web UI Front-end Dashboard</code> It just looks like a console. More convenient and intuitionistic.</p>
<p>The Dashboard service provides a browser-based interface for self-service cloud users to create and configure resources and launch and manage instances and stacks.</p>
</li>
<li><p>Identity Service (Keystone)</p>
<p>It looks like a <code>gate-keeper</code> to confirm&#x2F;verify the comer.</p>
<p>The Identity service provides domain, project, and user <code>authorization</code> for other overcloud services.</p>
</li>
<li><p>OpenStack Networking Service (Neutron)</p>
<p>It’s responsible for the network.</p>
<p>The OpenStack Networking service manages <code>virtual networking infrastructure</code>. It provides the virtual network and manages the network interfaces.</p>
</li>
<li><p>Compute Service (Nova)</p>
<p>The Compute service schedules and runs on-demand virtual machines. </p>
<p>It’s responsible for <code>creating, starting, stoping and removing the virtual machines</code>.</p>
</li>
<li><p>Messaging Service (Oslo)</p>
<p>It provides a common <code>messaging framework</code> and provides a compatible and consistent <code>communication</code> feature set between each services.</p>
</li>
<li><p>Object Store (Swift)</p>
<p><code>Original and default</code> object storage back-end.</p>
<p>The Object Store service provides self-service cloud user object storage. Other overcloud services that collect data or objects can use the <code>Object Store</code> service as a back end.</p>
</li>
</ul>
<h3 id="Discretionary-and-Operational-OpenStack-Services"><a href="#Discretionary-and-Operational-OpenStack-Services" class="headerlink" title="Discretionary and Operational OpenStack Services"></a>Discretionary and Operational OpenStack Services</h3><ul>
<li><p>Bare Metal Service (Ironic)</p>
<p><code>Initializes</code> and <code>introspects</code> -&gt; <code>scaling</code>.</p>
<p>The Bare Metal service locates and prepares compute resources, including bare metal and virtual machines.</p>
</li>
<li><p>File Share Service (Manila)</p>
<p>It can use either the <code>NFS</code> or <code>CIFS</code> protocols to provide file sharing to instances. </p>
</li>
<li><p>Load Balancing Service(Octavia)</p>
<p>It is an original <code>HAProxy-based</code> service.<br>The Load Balancing service enables failover network traffic distribution to instances in a multitier application architecture.</p>
</li>
</ul>
<h2 id="Managing-the-Overcloud"><a href="#Managing-the-Overcloud" class="headerlink" title="Managing the Overcloud"></a>Managing the Overcloud</h2><h3 id="Listing-all-Overcloud-nodes"><a href="#Listing-all-Overcloud-nodes" class="headerlink" title="Listing all Overcloud nodes"></a>Listing all Overcloud nodes</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(undercloud) [stack@director ~]$ openstack server list \</span><br><span class="line">&gt; -c &#x27;Name&#x27; -c &#x27;Status&#x27; -c &#x27;Networks&#x27;</span><br><span class="line">+-------------+--------+------------------------+</span><br><span class="line">| Name        | Status | Networks               |</span><br><span class="line">+-------------+--------+------------------------+</span><br><span class="line">| controller0 | ACTIVE | ctlplane=172.25.249.56 |</span><br><span class="line">| computehci0 | ACTIVE | ctlplane=172.25.249.54 |</span><br><span class="line">| compute1    | ACTIVE | ctlplane=172.25.249.53 |</span><br><span class="line">| compute0    | ACTIVE | ctlplane=172.25.249.59 |</span><br><span class="line">| ceph0       | ACTIVE | ctlplane=172.25.249.58 |</span><br><span class="line">+-------------+--------+------------------------+</span><br></pre></td></tr></table></figure>

<h3 id="High-Availability"><a href="#High-Availability" class="headerlink" title="High Availability"></a>High Availability</h3><p>Red Hat OpenStack Platform uses <code>Pacemaker</code> as the cluster resource manager, <code>HAProxy</code> as the load balancing cluster service, and <code>MariaDB Galera</code> as the replicated database service.</p>
<p>RHOSP Director installs a <code>duplicate set</code> of OpenStack components on each controller node and manages them as a single service.</p>
<ul>
<li><p>Pacemaker -&gt; Manager and Scheduler</p>
</li>
<li><p>HAProxy -&gt; Allocate all network traffic.</p>
</li>
<li><p>MariaDB -&gt; Duplicate the data.</p>
</li>
</ul>
<p>We could use the command to check the status of our cluster.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[heat-admin@controller0 ~]$ sudo pcs status</span><br><span class="line">Cluster name: tripleo_cluster</span><br><span class="line">Cluster Summary:</span><br><span class="line">  * Stack: corosync</span><br><span class="line">  * Current DC: controller0 (version 2.0.3-5.el8_2.1-4b1f869f0f) - partition with quorum</span><br><span class="line">  * Last updated: Tue May  6 13:33:04 2025</span><br><span class="line">  * Last change:  Mon May  5 02:29:30 2025 by root via crm_resource on controller0</span><br><span class="line">  * 5 nodes configured</span><br><span class="line">  * 22 resource instances configured</span><br><span class="line"></span><br><span class="line">Node List:</span><br><span class="line">  * Online: [ controller0 ]</span><br><span class="line">  * GuestOnline: [ galera-bundle-0@controller0 ovn-dbs-bundle-0@controller0 rabbitmq-bundle-0@controller0 redis-bundle-0@controller0 ]</span><br><span class="line"></span><br><span class="line">Full List of Resources:</span><br><span class="line">  * Container bundle: galera-bundle [cluster.common.tag/gls-dle-dev-osp16-osp16_containers-openstack-mariadb:pcmklatest]:</span><br><span class="line">    * galera-bundle-0	(ocf::heartbeat:galera):	Master controller0</span><br><span class="line">  * Container bundle: rabbitmq-bundle [cluster.common.tag/gls-dle-dev-osp16-osp16_containers-openstack-rabbitmq:pcmklatest]:</span><br><span class="line">    * rabbitmq-bundle-0	(ocf::heartbeat:rabbitmq-cluster):	Started controller0</span><br><span class="line">  * Container bundle: redis-bundle [cluster.common.tag/gls-dle-dev-osp16-osp16_containers-openstack-redis:pcmklatest]:</span><br><span class="line">    * redis-bundle-0	(ocf::heartbeat:redis):	Master controller0</span><br><span class="line">  * ip-172.25.249.50	(ocf::heartbeat:IPaddr2):	Started controller0</span><br><span class="line">  * ip-172.25.250.50	(ocf::heartbeat:IPaddr2):	Started controller0</span><br><span class="line">  * ip-172.24.1.51	(ocf::heartbeat:IPaddr2):	Started controller0</span><br><span class="line">  * ip-172.24.1.50	(ocf::heartbeat:IPaddr2):	Started controller0</span><br><span class="line">  * ip-172.24.3.50	(ocf::heartbeat:IPaddr2):	Started controller0</span><br><span class="line">  * ip-172.24.4.50	(ocf::heartbeat:IPaddr2):	Started controller0</span><br><span class="line">  * Container bundle: haproxy-bundle [cluster.common.tag/gls-dle-dev-osp16-osp16_containers-openstack-haproxy:pcmklatest]:</span><br><span class="line">    * haproxy-bundle-podman-0	(ocf::heartbeat:podman):	Started controller0</span><br><span class="line">  * Container bundle: ovn-dbs-bundle [cluster.common.tag/gls-dle-dev-osp16-osp16_containers-openstack-ovn-northd:pcmklatest]:</span><br><span class="line">    * ovn-dbs-bundle-0	(ocf::ovn:ovndb-servers):	Master controller0</span><br><span class="line">  * ip-172.24.1.52	(ocf::heartbeat:IPaddr2):	Started controller0</span><br><span class="line">  * Container bundle: openstack-cinder-volume [cluster.common.tag/gls-dle-dev-osp16-osp16_containers-openstack-cinder-volume:pcmklatest]:</span><br><span class="line">    * openstack-cinder-volume-podman-0	(ocf::heartbeat:podman):	Started controller0</span><br><span class="line">  * Container bundle: openstack-manila-share [cluster.common.tag/gls-dle-dev-osp16-osp16_containers-openstack-manila-share:pcmklatest]:</span><br><span class="line">    * openstack-manila-share-podman-0	(ocf::heartbeat:podman):	Started controller0</span><br><span class="line"></span><br><span class="line">Daemon Status:</span><br><span class="line">  corosync: active/enabled</span><br><span class="line">  pacemaker: active/enabled</span><br><span class="line">  pcsd: active/enabled</span><br></pre></td></tr></table></figure>

<h2 id="Accessing-Services-on-the-Overloud"><a href="#Accessing-Services-on-the-Overloud" class="headerlink" title="Accessing Services on the Overloud"></a>Accessing Services on the Overloud</h2><p>When the overcloud is first installed, the procedure creates the <code>overcloudrc</code> identity environment file under the stackrc user’s home directory with the admin credentials to access<br>the overcloud.</p>
<ul>
<li><p>stackrc</p>
<p>It will be created automatically when deploy the undercloud which contains the environment variables in the undercloud.</p>
<p>It could be used to deploy the overcloud.</p>
</li>
<li><p>overcloudrc</p>
<p>After the overcloud was deployed, it will be generated by <code>TripleO</code>.</p>
<p>It is the token&#x2F;authentication file to access the overcloud.</p>
<p>We could check and manage the service on overcloud by CLI command with it.</p>
</li>
</ul>
<h3 id="Switch-to-overcloud-environment-variables"><a href="#Switch-to-overcloud-environment-variables" class="headerlink" title="Switch to overcloud environment variables"></a>Switch to overcloud environment variables</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Check all environment variables on the overcloud</span><br><span class="line">(overcloud) [stack@director ~]$ env | grep ^OS_*</span><br><span class="line">OS_IMAGE_API_VERSION=2</span><br><span class="line">OS_AUTH_URL=http://172.25.250.50:5000</span><br><span class="line">OS_CLOUDNAME=overcloud</span><br><span class="line">OS_REGION_NAME=regionOne</span><br><span class="line">OS_PROJECT_NAME=admin</span><br><span class="line">OS_PROJECT_DOMAIN_NAME=Default</span><br><span class="line">OS_USER_DOMAIN_NAME=Default</span><br><span class="line">OS_IDENTITY_API_VERSION=3</span><br><span class="line">OS_AUTH_TYPE=password</span><br><span class="line">OS_NO_CACHE=True</span><br><span class="line">OS_COMPUTE_API_VERSION=2.latest</span><br><span class="line">OS_PASSWORD=redhat</span><br><span class="line">OS_USERNAME=admin</span><br><span class="line">OS_VOLUME_API_VERSION=3</span><br><span class="line"></span><br><span class="line"># Check all service on the overcloud</span><br><span class="line">(overcloud) [stack@director ~]$ openstack service list</span><br><span class="line">+----------------------------------+-----------+----------------+</span><br><span class="line">| ID                               | Name      | Type           |</span><br><span class="line">+----------------------------------+-----------+----------------+</span><br><span class="line">| 0932e03c896a4e73b905b81a0e4e8b02 | cinderv2  | volumev2       |</span><br><span class="line">| 1b5a14e5ff2d4d988dcbb7d1a31aa257 | panko     | event          |</span><br><span class="line">| 1e50893246094c05b0b8b5028efa65d6 | heat      | orchestration  |</span><br><span class="line">| 20ee8664c18146639e207d1dd833066b | heat-cfn  | cloudformation |</span><br><span class="line">| 2ed07d8f7afd4126b279bd273d029962 | gnocchi   | metric         |</span><br><span class="line">| 31442049b55040d5bb52589e0fd1b31f | nova      | compute        |</span><br><span class="line">| 446c6d0b77a74d05a491393c8d4cc106 | keystone  | identity       |</span><br><span class="line">| 76870267b75a4d0bb70772f586730659 | neutron   | network        |</span><br><span class="line">| 8413046b29f44285a772a8bbd172dbd8 | manilav2  | sharev2        |</span><br><span class="line">| bb7a5e08aad345a489ce0207684ae402 | swift     | object-store   |</span><br><span class="line">| c970fbfbc71a49008760c6d9a6f3ee91 | aodh      | alarming       |</span><br><span class="line">| cc386f44375343d19e1fc78e8e78db35 | cinderv3  | volumev3       |</span><br><span class="line">| cddaafd6d76b424b946a8fdb47a8ed12 | manila    | share          |</span><br><span class="line">| d799151c504541edacd68a08324d37c0 | glance    | image          |</span><br><span class="line">| e15d67325321405b854447a92bfe866f | octavia   | load-balancer  |</span><br><span class="line">| f8ebce21244748c09b20df6e9c939b73 | placement | placement      |</span><br><span class="line">+----------------------------------+-----------+----------------+</span><br></pre></td></tr></table></figure>

<h3 id="Network"><a href="#Network" class="headerlink" title="Network"></a>Network</h3><p>Check the allocated VLAN.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[heat-admin@controller0 ~]$ sudo ovs-vsctl show</span><br><span class="line">da52b817-899b-459f-b486-b529fcbd9275</span><br><span class="line">    Bridge br-prov2</span><br><span class="line">        fail_mode: standalone</span><br><span class="line">        Port eth4</span><br><span class="line">            Interface eth4</span><br><span class="line">        Port br-prov2</span><br><span class="line">            Interface br-prov2</span><br><span class="line">                type: internal</span><br><span class="line">    Bridge br-int</span><br><span class="line">        Port br-int</span><br><span class="line">            Interface br-int</span><br><span class="line">                type: internal</span><br><span class="line">        Port o-hm0</span><br><span class="line">            Interface o-hm0</span><br><span class="line">                type: internal</span><br><span class="line">        Port patch-br-int-to-provnet-275c889d-ef54-4a38-88ff-a7cedee11506</span><br><span class="line">            Interface patch-br-int-to-provnet-275c889d-ef54-4a38-88ff-a7cedee11506</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=patch-provnet-275c889d-ef54-4a38-88ff-a7cedee11506-to-br-int&#125;</span><br><span class="line">        Port ovn-8e0b99-0</span><br><span class="line">            Interface ovn-8e0b99-0</span><br><span class="line">                type: geneve</span><br><span class="line">                options: &#123;csum=&quot;true&quot;, key=flow, remote_ip=&quot;172.24.2.2&quot;&#125;</span><br><span class="line">        Port ovn-3f678a-0</span><br><span class="line">            Interface ovn-3f678a-0</span><br><span class="line">                type: geneve</span><br><span class="line">                options: &#123;csum=&quot;true&quot;, key=flow, remote_ip=&quot;172.24.2.6&quot;&#125;</span><br><span class="line">        Port ovn-b8bd46-0</span><br><span class="line">            Interface ovn-b8bd46-0</span><br><span class="line">                type: geneve</span><br><span class="line">                options: &#123;csum=&quot;true&quot;, key=flow, remote_ip=&quot;172.24.2.12&quot;&#125;</span><br><span class="line">    Bridge br-ex</span><br><span class="line">        fail_mode: standalone</span><br><span class="line">        Port br-ex</span><br><span class="line">            Interface br-ex</span><br><span class="line">                type: internal</span><br><span class="line">        Port patch-provnet-275c889d-ef54-4a38-88ff-a7cedee11506-to-br-int</span><br><span class="line">            Interface patch-provnet-275c889d-ef54-4a38-88ff-a7cedee11506-to-br-int</span><br><span class="line">                type: patch</span><br><span class="line">                options: &#123;peer=patch-br-int-to-provnet-275c889d-ef54-4a38-88ff-a7cedee11506&#125;</span><br><span class="line">        Port eth2</span><br><span class="line">            Interface eth2</span><br><span class="line">    Bridge br-prov1</span><br><span class="line">        fail_mode: standalone</span><br><span class="line">        Port eth3</span><br><span class="line">            Interface eth3</span><br><span class="line">        Port br-prov1</span><br><span class="line">            Interface br-prov1</span><br><span class="line">                type: internal</span><br><span class="line">    Bridge br-trunk</span><br><span class="line">        fail_mode: standalone</span><br><span class="line">        Port vlan40</span><br><span class="line">            tag: 40</span><br><span class="line">            Interface vlan40</span><br><span class="line">                type: internal</span><br><span class="line">        Port eth1</span><br><span class="line">            Interface eth1</span><br><span class="line">        Port vlan20</span><br><span class="line">            tag: 20</span><br><span class="line">            Interface vlan20</span><br><span class="line">                type: internal</span><br><span class="line">        Port vlan30</span><br><span class="line">            tag: 30</span><br><span class="line">            Interface vlan30</span><br><span class="line">                type: internal</span><br><span class="line">        Port vlan50</span><br><span class="line">            tag: 50</span><br><span class="line">            Interface vlan50</span><br><span class="line">                type: internal</span><br><span class="line">        Port br-trunk</span><br><span class="line">            Interface br-trunk</span><br><span class="line">                type: internal</span><br><span class="line">        Port vlan10</span><br><span class="line">            tag: 10</span><br><span class="line">            Interface vlan10</span><br><span class="line">                type: internal</span><br><span class="line">    ovs_version: &quot;2.13.0&quot;</span><br></pre></td></tr></table></figure>

<p>Check the ip address.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[heat-admin@controller0 ~]$ ip --br a</span><br><span class="line">lo               UNKNOWN        127.0.0.1/8 ::1/128 </span><br><span class="line">eth0             UP             172.25.249.56/24 172.25.249.50/32 fe80::5054:ff:fe00:f901/64 </span><br><span class="line">eth1             UP             fe80::5054:ff:fe01:1/64 </span><br><span class="line">eth2             UP             fe80::5054:ff:fe02:fa01/64 </span><br><span class="line">eth3             UP             fe80::5054:ff:fe03:1/64 </span><br><span class="line">eth4             UP             fe80::5054:ff:fe04:1/64 </span><br><span class="line">ovs-system       DOWN           </span><br><span class="line">br-prov1         UNKNOWN        fe80::5054:ff:fe03:1/64 </span><br><span class="line">genev_sys_6081   UNKNOWN        fe80::3c78:cbff:feee:3bf0/64 </span><br><span class="line">o-hm0            UNKNOWN        172.23.3.42/16 fe80::f816:3eff:fecd:dfd4/64 </span><br><span class="line">br-int           UNKNOWN        fe80::40e:d7ff:fe34:2944/64 </span><br><span class="line">br-ex            UNKNOWN        172.25.250.1/24 172.25.250.50/32 fe80::5054:ff:fe02:fa01/64 </span><br><span class="line">br-prov2         UNKNOWN        fe80::5054:ff:fe04:1/64 </span><br><span class="line">vlan40           UNKNOWN        172.24.4.1/24 172.24.4.50/32 fe80::b4ca:55ff:fe88:4fd4/64 </span><br><span class="line">vlan10           UNKNOWN        172.24.1.1/24 172.24.1.51/32 172.24.1.50/32 172.24.1.52/32 fe80::f45f:9ff:feed:88a4/64 </span><br><span class="line">vlan20           UNKNOWN        172.24.2.1/24 fe80::8cd7:ccff:fe8a:c345/64 </span><br><span class="line">vlan50           UNKNOWN        172.24.5.1/24 fe80::c2c:bcff:fe88:d879/64 </span><br><span class="line">vlan30           UNKNOWN        172.24.3.1/24 172.24.3.50/32 fe80::14aa:e9ff:fe4e:95a2/64 </span><br><span class="line">br-trunk         UNKNOWN        fe80::5054:ff:fe01:1/64 </span><br></pre></td></tr></table></figure>

<p>The <code>eth0</code> interface is the 172.25.249.0<br><code>provisioning</code> network.</p>
<p>The <code>br-trunk</code> is the internal network.</p>
<p>The <code>br-ex bridge</code> is the 172.25.250.0 <code>public</code> network.</p>
<h2 id="Containerized-services"><a href="#Containerized-services" class="headerlink" title="Containerized services"></a>Containerized services</h2><p>As I introduced in the Chapter1, all services are containerized here.</p>
<p>Let’s check all services in podman container.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@controller0 ~]# podman ps --format &quot;table &#123;&#123;.Names&#125;&#125; &#123;&#123;.Status&#125;&#125;&quot;</span><br><span class="line">Names                              Status</span><br><span class="line">openstack-manila-share-podman-0    Up 11 hours ago</span><br><span class="line">openstack-cinder-volume-podman-0   Up 11 hours ago</span><br><span class="line">ovn-dbs-bundle-podman-0            Up 11 hours ago</span><br><span class="line">haproxy-bundle-podman-0            Up 11 hours ago</span><br><span class="line">rabbitmq-bundle-podman-0           Up 11 hours ago</span><br><span class="line">galera-bundle-podman-0             Up 11 hours ago</span><br><span class="line">redis-bundle-podman-0              Up 11 hours ago</span><br><span class="line">ceph-mgr-controller0               Up 11 hours ago</span><br><span class="line">ceph-mon-controller0               Up 11 hours ago</span><br><span class="line">ceph-mds-controller0               Up 11 hours ago</span><br><span class="line">octavia_worker                     Up 11 hours ago</span><br><span class="line">...ommited...</span><br></pre></td></tr></table></figure>

<p>More detailed configuration information could be viewed by <code>inspect</code> command.</p>
<p>E.g.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@controller0 ~]# podman inspect keystone | jq .[].HostConfig.Binds</span><br><span class="line">[</span><br><span class="line">  &quot;/etc/pki/tls/cert.pem:/etc/pki/tls/cert.pem:ro,rprivate,rbind&quot;,</span><br><span class="line">  &quot;/etc/puppet:/etc/puppet:ro,rprivate,rbind&quot;,</span><br><span class="line">  &quot;/etc/pki/ca-trust/extracted:/etc/pki/ca-trust/extracted:ro,rprivate,rbind&quot;,</span><br><span class="line">  &quot;/var/lib/config-data/puppet-generated/keystone:/var/lib/kolla/config_files/src:ro,rprivate,rbind&quot;,</span><br><span class="line">  &quot;/var/log/containers/keystone:/var/log/keystone:rw,rprivate,rbind&quot;,</span><br><span class="line">  &quot;/dev/log:/dev/log:rw,rprivate,nosuid,rbind&quot;,</span><br><span class="line">  &quot;/etc/pki/tls/certs/ca-bundle.crt:/etc/pki/tls/certs/ca-bundle.crt:ro,rprivate,rbind&quot;,</span><br><span class="line">  &quot;/etc/pki/tls/certs/ca-bundle.trust.crt:/etc/pki/tls/certs/ca-bundle.trust.crt:ro,rprivate,rbind&quot;,</span><br><span class="line">  &quot;/var/log/containers/httpd/keystone:/var/log/httpd:rw,rprivate,rbind&quot;,</span><br><span class="line">  &quot;/etc/localtime:/etc/localtime:ro,rprivate,rbind&quot;,</span><br><span class="line">  &quot;/etc/pki/ca-trust/source/anchors:/etc/pki/ca-trust/source/anchors:ro,rprivate,rbind&quot;,</span><br><span class="line">  &quot;/var/lib/kolla/config_files/keystone.json:/var/lib/kolla/config_files/config.json:ro,rprivate,rbind&quot;,</span><br><span class="line">  &quot;/etc/hosts:/etc/hosts:ro,rprivate,rbind&quot;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<h2 id="Configuration-Management-of-Containerized-Services"><a href="#Configuration-Management-of-Containerized-Services" class="headerlink" title="Configuration Management of Containerized Services"></a>Configuration Management of Containerized Services</h2><blockquote>
<p>Remember to modify the configuration in physical rather than inside the container, because all changes will be reset after restarting the container.</p>
</blockquote>
<ul>
<li><p>Configuration files path</p>
<p><code>/var/log/config-data/puppet-generated/[service_name]/etc/</code></p>
<p>Excepted for using <code>vim</code> command to modify the configuration, <code>crudini</code> also makes sense.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@controller0 puppet-generated]# podman exec -it keystone crudini --get /etc/keystone/keystone.conf DEFAULT debug</span><br><span class="line">False</span><br><span class="line"></span><br><span class="line">[root@controller0 puppet-generated]# crudini --get keystone/etc/keystone/keystone.conf DEFAULT debug</span><br><span class="line">False</span><br><span class="line"></span><br><span class="line">[root@controller0 puppet-generated]# crudini --set keystone/etc/keystone/keystone.conf DEFAULT debug </span><br><span class="line">True</span><br><span class="line"></span><br><span class="line">[root@controller0 puppet-generated]# crudini --get keystone/etc/keystone/keystone.conf DEFAULT debug</span><br><span class="line">True</span><br><span class="line"></span><br><span class="line">[root@controller0 puppet-generated]# podman restart keystone</span><br><span class="line">keystone</span><br><span class="line"></span><br><span class="line">[root@controller0 puppet-generated]# podman exec -it keystone crudini --get /etc/keystone/keystone.conf DEFAULT debug</span><br><span class="line">True</span><br></pre></td></tr></table></figure>
</li>
<li><p>Log files path</p>
<p><code>/var/log/containers/[service_name]</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@controller0 containers]# pwd</span><br><span class="line">/var/log/containers</span><br><span class="line">[root@controller0 containers]# ls</span><br><span class="line">aodh        glance   heat     keystone   mysql    octavia      placement  stdouts</span><br><span class="line">ceilometer  gnocchi  horizon  manila     neutron  openvswitch  rabbitmq   swift</span><br><span class="line">cinder      haproxy  httpd    memcached  nova     panko        redis</span><br><span class="line">[root@controller0 containers]# cd keystone/</span><br><span class="line">[root@controller0 keystone]# ls</span><br><span class="line">keystone.log        keystone.log.11.gz  keystone.log.14.gz  keystone.log.4.gz  keystone.log.7.gz</span><br><span class="line">keystone.log.1      keystone.log.12.gz  keystone.log.2.gz   keystone.log.5.gz  keystone.log.8.gz</span><br><span class="line">keystone.log.10.gz  keystone.log.13.gz  keystone.log.3.gz   keystone.log.6.gz  keystone.log.9.gz</span><br></pre></td></tr></table></figure>

<p>Containers also retain memory-based log structures that store the container’s console STDOUT activity.(<code>/var/log/containers/stdouts</code>) Use podman logs service to view the container’s console activity, for example <code>podman logs</code> keystone.</p>
</li>
</ul>
<h2 id="Managing-Storage-Nodes"><a href="#Managing-Storage-Nodes" class="headerlink" title="Managing Storage Nodes"></a>Managing Storage Nodes</h2><h3 id="Check-the-services-on-the-Controller-node"><a href="#Check-the-services-on-the-Controller-node" class="headerlink" title="Check the services on the Controller node"></a>Check the services on the Controller node</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@controller0 stdouts]# podman ps --format &quot;&#123;&#123;.Names&#125;&#125;&quot; | grep ceph</span><br><span class="line">ceph-mgr-controller0</span><br><span class="line">ceph-mon-controller0</span><br><span class="line">ceph-mds-controller0</span><br></pre></td></tr></table></figure>

<p>We obtain three ceph services <code>mgr+mon+mds</code>.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@controller0 stdouts]# systemctl list-units | grep ceph</span><br><span class="line">ceph-mds@controller0.service                                                                                                         loaded active     running         Ceph MDS                                                                                                                    </span><br><span class="line">ceph-mgr@controller0.service                                                                                                         loaded active     running         Ceph Manager                                                                                                                </span><br><span class="line">ceph-mon@controller0.service                                                                                                         loaded active     running         Ceph Monitor                                                                                                                </span><br><span class="line">system-ceph\x2dmds.slice                                                                                                             loaded active     active          system-ceph\x2dmds.slice                                                                                                    </span><br><span class="line">system-ceph\x2dmgr.slice                                                                                                             loaded active     active          system-ceph\x2dmgr.slice                                                                                                    </span><br><span class="line">system-ceph\x2dmon.slice                                                                                                             loaded active     active          system-ceph\x2dmon.slice   </span><br></pre></td></tr></table></figure>

<h3 id="Check-all-storage-pools"><a href="#Check-all-storage-pools" class="headerlink" title="Check all storage pools"></a>Check all storage pools</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@controller0 stdouts]# systemctl status ceph-mon@controller.service</span><br><span class="line">● ceph-mon@controller.service - Ceph Monitor</span><br><span class="line">   Loaded: loaded (/etc/systemd/system/ceph-mon@.service; disabled; vendor preset: disabled)</span><br><span class="line">   Active: inactive (dead)</span><br><span class="line"></span><br><span class="line">[root@controller0 stdouts]# podman exec ceph-mon-controller0 ceph osd pool ls</span><br><span class="line">vms</span><br><span class="line">volumes</span><br><span class="line">images</span><br><span class="line">manila_data</span><br><span class="line">manila_metadata</span><br></pre></td></tr></table></figure>

<h3 id="List-all-OSDs"><a href="#List-all-OSDs" class="headerlink" title="List all OSDs"></a>List all OSDs</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@controller0 stdouts]# podman exec ceph-mon-controller0 ceph osd ls</span><br><span class="line">0</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td></tr></table></figure>

<h3 id="Check-the-health-situation-of-the-ceph-cluster"><a href="#Check-the-health-situation-of-the-ceph-cluster" class="headerlink" title="Check the health situation of the ceph cluster"></a>Check the health situation of the ceph cluster</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@controller0 stdouts]# podman exec ceph-mon-controller0 ceph -s</span><br><span class="line">  cluster:</span><br><span class="line">    id:     96157d2f-395f-4a54-8a19-b6042465100d</span><br><span class="line">    health: HEALTH_OK</span><br><span class="line"> </span><br><span class="line">  services:</span><br><span class="line">    mon: 1 daemons, quorum controller0 (age 11h)</span><br><span class="line">    mgr: controller0(active, since 11h)</span><br><span class="line">    mds: cephfs:1 &#123;0=controller0=up:active&#125;</span><br><span class="line">    osd: 6 osds: 6 up (since 11h), 6 in (since 4y)</span><br><span class="line"> </span><br><span class="line">  task status:</span><br><span class="line">    scrub status:</span><br><span class="line">        mds.controller0: idle</span><br><span class="line"> </span><br><span class="line">  data:</span><br><span class="line">    pools:   5 pools, 320 pgs</span><br><span class="line">    objects: 2.62k objects, 19 GiB</span><br><span class="line">    usage:   25 GiB used, 95 GiB / 120 GiB avail</span><br><span class="line">    pgs:     320 active+clean</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>OpenStack</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenStack Series Chapter2:Introducing Undercloud</title>
    <url>//Cloud/OpenStack/Introducing-Undercloud/index.html</url>
    <content><![CDATA[<h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>The Director undercloud node is an <code>all-in-one</code> Red Hat OpenStack Platform (RHOSP) deployment which provides the services used to install and manage OpenStack overclouds. The deployment toolset is the Deployment service known as <code>TripleO</code>. TripleO uses other existing OpenStack components, such as <code>Heat</code>, and <code>Ansible Playbooks</code>, to provision, deploy, and configure bare-metal systems as OpenStack cloud nodes.</p>
<blockquote>
<p>The undercloud is a deployment cloud for overclouds, in which the workload is the overcloud nodes themselves, such as the controller, compute, and storage nodes.</p>
</blockquote>
<h2 id="Components-and-Services"><a href="#Components-and-Services" class="headerlink" title="Components and Services"></a>Components and Services</h2><ul>
<li><p>Identity Service (Keystone)</p>
<p>The Identity service provides user authentication and authorization, but only to the undercloud’s OpenStack services.</p>
</li>
<li><p>Image Service (Glance)</p>
<p>The Image service stores the initial images to be deployed to bare-metal nodes. These images contain the Red Hat Enterprise Linux (RHEL) operating system, a KVM hypervisor, and container runtimes.</p>
</li>
<li><p>Compute Service (Nova)</p>
<p>The Compute service works with the Bare Metal service to provision nodes, by introspecting available systems to obtain hardware attributes. The Compute service’s scheduling function filters the available nodes to ensure that selected nodes meet role requirements.</p>
</li>
<li><p>Bare Metal Service (Ironic)</p>
<p>The Bare Metal service manages and provisions physical machines. The ironic-inspector service performs introspection by PXE booting unregistered hardware. The undercloud uses an out-of-band management interface, such as IPMI, to perform power management during introspection.</p>
</li>
<li><p>Orchestration Service (Heat)</p>
<p>The Orchestration service provides a set of YAML templates and node roles to define configuration and provisioning instructions for overcloud deployment. Default orchestration templates are located at &#x2F;usr&#x2F;share&#x2F;openstack-tripleo-heat-templates, and are designed to be customized using environment parameter files.</p>
</li>
<li><p>Object Service (Swift)</p>
<p>The undercloud Object store holds images, deployment logs, and introspection results.</p>
</li>
<li><p>Networking Service (Neutron)</p>
<p>The Networking service configures interfaces for the required provisioning and external networks. The provisioning network provides DHCP and PXE boot functions for bare-metal nodes. The external network provides public connectivity.</p>
</li>
</ul>
<h2 id="Viewing-services"><a href="#Viewing-services" class="headerlink" title="Viewing services"></a>Viewing services</h2><p>When you complete the undercloud installation, the system will secretly place a stackrc file in the stack user’s home directory. And let me tell you, this file is a real gem! It’s like a “magic key” that lets you easily access various services on the undercloud.</p>
<p>The stackrc file will automatically “borrow” a few things from the stack user’s .bashrc file, and as a result, it gains admin-level access to the undercloud. With it, you can manage and interact with the undercloud services as if you were an administrator.</p>
<p>In this file, there’s one particularly important element called OS_AUTH_URL. It’s like a “satnav,” pointing to the public endpoint of the undercloud’s identity service. Simply put, it tells your system: “Hey, head over here to find the authentication service!” This way, you can easily communicate with the services on the undercloud.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(undercloud) [stack@director ~]$ source stackrc</span><br></pre></td></tr></table></figure>

<h3 id="Listing-all-services"><a href="#Listing-all-services" class="headerlink" title="Listing all services"></a>Listing all services</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(undercloud) [stack@director ~]$ openstack service list</span><br><span class="line">+----------------------------------+------------------+-------------------------+</span><br><span class="line">| ID                               | Name             | Type                    |</span><br><span class="line">+----------------------------------+------------------+-------------------------+</span><br><span class="line">| 2a08c08cc51a4f299536fc66e4b748b6 | nova             | compute                 |</span><br><span class="line">| 313b7a22ef534d3fa367f50d7c9e2754 | mistral          | workflowv2              |</span><br><span class="line">| 417c10b71acb4c1aa40169e251b3d16d | zaqar-websocket  | messaging-websocket     |</span><br><span class="line">| 4d957e71f3284818b3a0617218f446bd | neutron          | network                 |</span><br><span class="line">| 6402d082e73a459c93d5e0b70783b7e5 | placement        | placement               |</span><br><span class="line">| 6f778463089446f49905f6842c25d92e | ironic-inspector | baremetal-introspection |</span><br><span class="line">| 7aa774aa28c344e49aa9eb01de4900ec | zaqar            | messaging               |</span><br><span class="line">| a4158e3f67a1472cb0798ebc979e4e3a | ironic           | baremetal               |</span><br><span class="line">| a822dfa8c6da4695a702b46e38d0077d | heat             | orchestration           |</span><br><span class="line">| ba7910222ac042c6a847a9a3c3c5074a | glance           | image                   |</span><br><span class="line">| bd92462118c042a1a55967372b4b695f | keystone         | identity                |</span><br><span class="line">| d9a5f802093d48958acb7f6e857f0384 | swift            | object-store            |</span><br><span class="line">+----------------------------------+------------------+-------------------------+</span><br></pre></td></tr></table></figure>

<h3 id="Listing-all-services’-endpoint"><a href="#Listing-all-services’-endpoint" class="headerlink" title="Listing all services’ endpoint"></a>Listing all services’ endpoint</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(undercloud) [stack@director ~]$ openstack endpoint list -c &#x27;Service Type&#x27; -c &#x27;Interface&#x27; -c &#x27;URL&#x27;</span><br><span class="line">+-------------------------+-----------+----------------------------------------------------+</span><br><span class="line">| Service Type            | Interface | URL                                                |</span><br><span class="line">+-------------------------+-----------+----------------------------------------------------+</span><br><span class="line">| placement               | internal  | http://172.25.249.202:8778/placement               |</span><br><span class="line">| image                   | internal  | http://172.25.249.202:9292                         |</span><br><span class="line">| baremetal               | internal  | http://172.25.249.202:6385                         |</span><br><span class="line">| messaging-websocket     | admin     | ws://172.25.249.202:9000                           |</span><br><span class="line">| placement               | admin     | http://172.25.249.202:8778/placement               |</span><br><span class="line">| identity                | admin     | http://172.25.249.202:35357                        |</span><br><span class="line">| compute                 | internal  | http://172.25.249.202:8774/v2.1                    |</span><br><span class="line">| identity                | public    | https://172.25.249.201:13000                       |</span><br><span class="line">| baremetal-introspection | admin     | http://172.25.249.202:5050                         |</span><br><span class="line">| messaging               | internal  | http://172.25.249.202:8888                         |</span><br><span class="line">| baremetal               | public    | https://172.25.249.201:13385                       |</span><br><span class="line">| messaging-websocket     | internal  | ws://172.25.249.202:9000                           |</span><br><span class="line">| image                   | admin     | http://172.25.249.202:9292                         |</span><br><span class="line">| orchestration           | internal  | http://172.25.249.202:8004/v1/%(tenant_id)s        |</span><br><span class="line">| placement               | public    | https://172.25.249.201:13778/placement             |</span><br><span class="line">| image                   | public    | https://172.25.249.201:13292                       |</span><br><span class="line">| compute                 | admin     | http://172.25.249.202:8774/v2.1                    |</span><br><span class="line">| orchestration           | public    | https://172.25.249.201:13004/v1/%(tenant_id)s      |</span><br><span class="line">| object-store            | public    | https://172.25.249.201:13808/v1/AUTH_%(tenant_id)s |</span><br><span class="line">| orchestration           | admin     | http://172.25.249.202:8004/v1/%(tenant_id)s        |</span><br><span class="line">| baremetal-introspection | internal  | http://172.25.249.202:5050                         |</span><br><span class="line">| network                 | admin     | http://172.25.249.202:9696                         |</span><br><span class="line">| network                 | public    | https://172.25.249.201:13696                       |</span><br><span class="line">| workflowv2              | admin     | http://172.25.249.202:8989/v2                      |</span><br><span class="line">| baremetal               | admin     | http://172.25.249.202:6385                         |</span><br><span class="line">| messaging-websocket     | public    | wss://172.25.249.201:9000                          |</span><br><span class="line">| object-store            | admin     | http://172.25.249.202:8080                         |</span><br><span class="line">| identity                | internal  | http://172.25.249.202:5000                         |</span><br><span class="line">| workflowv2              | public    | https://172.25.249.201:13989/v2                    |</span><br><span class="line">| messaging               | admin     | http://172.25.249.202:8888                         |</span><br><span class="line">| messaging               | public    | https://172.25.249.201:13888                       |</span><br><span class="line">| workflowv2              | internal  | http://172.25.249.202:8989/v2                      |</span><br><span class="line">| compute                 | public    | https://172.25.249.201:13774/v2.1                  |</span><br><span class="line">| network                 | internal  | http://172.25.249.202:9696                         |</span><br><span class="line">| object-store            | internal  | http://172.25.249.202:8080/v1/AUTH_%(tenant_id)s   |</span><br><span class="line">| baremetal-introspection | public    | https://172.25.249.201:13050                       |</span><br><span class="line">+-------------------------+-----------+----------------------------------------------------+</span><br></pre></td></tr></table></figure>

<h3 id="Listing-all-services’-password"><a href="#Listing-all-services’-password" class="headerlink" title="Listing all services’ password"></a>Listing all services’ password</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(undercloud) [stack@director ~]$ cat undercloud-passwords.conf</span><br><span class="line">[auth]</span><br><span class="line">undercloud_admin_password: B7Hk2yX2zly2tKwDrVh3TGFjp</span><br><span class="line">undercloud_admin_token: B88pjtnpb7ch1bCMLUJqLdGAj</span><br><span class="line">undercloud_aodh_password: LKNMhUQNwhmapU74r8k8Llraw</span><br><span class="line">undercloud_barbican_password: Aoi7Ai5Osgh4tjcfI6cc8OyWh</span><br><span class="line">undercloud_barbican_simple_crypto_kek: bMabXDjqvX2k70V3c9Sip1na-Waw9N4VB-FQMMbxlqM=</span><br><span class="line">undercloud_ceilometer_password: fmQ3eAQ3Eo9lIv5DL9C8okMzz</span><br><span class="line">undercloud_ceph_grafana_admin_password: n42P9DzDhGxh7Emg5RPGt1SAE</span><br><span class="line">undercloud_ceph_dashboard_admin_password: KTUxEA7MHFo4CP4KqHNnz7PQc</span><br><span class="line">undercloud_cinder_password: db0EqnRpJ2JYkaIHMsPsdSwtJ</span><br><span class="line">undercloud_congress_password: 1guMjvHqlYUDdbE60XoJxapgw</span><br><span class="line">undercloud_designate_password: y4m53qVg8ulS1x3nDgwK7CdG2</span><br><span class="line">undercloud_ec2_api_password: vNSVPFS5l05F9cyDhtfOXLeyH</span><br><span class="line">undercloud_etcd_initial_cluster_token: dxmxMFJZ98HQ6eYBnX0nCCdB2</span><br><span class="line">undercloud_glance_password: 3l62WMyGenHPfIcoWDJhLlqaG</span><br><span class="line">undercloud_gnocchi_password: dAvnYVTzljdBPyn0gyi4b2LOh</span><br><span class="line">undercloud_ha_proxy_stats_password: bszPVap67n7B7h4DF6KD2gfrL</span><br><span class="line">undercloud_heat_password: IVgrfc9UKjBTAUOsjcsDUOjCx</span><br><span class="line">undercloud_heat_stack_domain_admin_password: 3DzFaXoB9DodArrdxEnA0Xclo</span><br><span class="line">undercloud_ironic_password: rcmaIUqoE3ft4vwfgGzWnUV80</span><br><span class="line">undercloud_libvirt_tls_password: McT2WnXIzmzWYfoHmg3nzDnP2</span><br><span class="line">undercloud_manila_password: PrNre8t0uKmglYPMGJrSp5DpU</span><br><span class="line">undercloud_mistral_password: u6iGEVtUbpjBus07ksfwB9v75</span><br><span class="line">undercloud_mysql_clustercheck_password: zjywUyG4OhHUhZF3FHIpagjwe</span><br><span class="line">undercloud_mysql_root_password: 2mo7UszHbM</span><br><span class="line">undercloud_neutron_password: wvaPHleiR0P2IpNIrbZ5JcPsS</span><br><span class="line">undercloud_nova_password: 12k2eWmgC0dMezTQeA2R1iLK1</span><br><span class="line">undercloud_novajoin_password: 6bYmgcdhEtcxPbGslIhIiqYuP</span><br><span class="line">undercloud_octavia_password: nm7jAQgPloK8O9lSi8dUW7aCy</span><br><span class="line">undercloud_open_daylight_password: t6ZrMUpqMce7Rls9pbkDGg9Rc</span><br><span class="line">undercloud_panko_password: iW8YEy4xPrzxHT7Uz7nP1CmfE</span><br><span class="line">undercloud_pcsd_password: BSUPMkdeMJwIUsy3</span><br><span class="line">undercloud_placement_password: oEwI1ubaJq4WwZ5HXhTc5357D</span><br><span class="line">undercloud_rpc_password: BOIlN86QyW6NnvIJrtEMgM3jx</span><br><span class="line">undercloud_notify_password: xhqWzQqHcdV1JCMhlSeM8lwzy</span><br><span class="line">undercloud_rabbit_password: 8ttaCabqb9I9ncw3lgBVrItw4</span><br><span class="line">undercloud_redis_password: xRelsoGSzeZqn12Lqk4RMQvjj</span><br><span class="line">undercloud_sahara_password: VgJjC5rDGM8hjAair44G67j7s</span><br><span class="line">undercloud_snmpd_readonly_user_password: Fxz5cmRlA0JhAK4tuzNF2Asae</span><br><span class="line">undercloud_swift_password: 9VRDEP87fnpWEBWJ623ct4x3i</span><br><span class="line">undercloud_zaqar_password: 8wS1kCJ9u5QjQQE37YqADmK5c</span><br></pre></td></tr></table></figure>

<h2 id="Viewing-the-network"><a href="#Viewing-the-network" class="headerlink" title="Viewing the network"></a>Viewing the network</h2><p>Using DHCP and PXE boot, a dedicated high-throughput provisioning network is employed to prepare and deploy the overcloud nodes. This dedicated network acts like an “exclusive lane,” purpose-built to quickly and efficiently handle node configuration and deployment.</p>
<p>Once you’ve deployed the overcloud, the undercloud continues to play a supporting role on this provisioning network—managing the overcloud nodes and updating them as needed. Since the provisioning network is isolated, it’s completely separate from the internal overcloud traffic and external workload traffic, ensuring no interference. This separation results in a more stable overcloud environment and makes ongoing management much easier.</p>
<p>In simple terms, the undercloud sets up a “fast lane” for overcloud nodes—speeding up deployment while quietly managing things in the background, without affecting any other traffic. It’s a brilliantly designed setup!</p>
<h3 id="dhcp-range"><a href="#dhcp-range" class="headerlink" title="dhcp range"></a>dhcp range</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(undercloud) [stack@director ~]$ cat undercloud.conf | egrep -v &quot;(^#.*|^$)&quot;</span><br><span class="line">[DEFAULT]</span><br><span class="line">container_images_file = /home/stack/containers-prepare-parameter.yaml</span><br><span class="line">custom_env_files = /home/stack/custom-undercloud-params.yaml</span><br><span class="line">enable_telemetry = false</span><br><span class="line">generate_service_certificate = false</span><br><span class="line">hieradata_override = /home/stack/hieradata.yaml</span><br><span class="line">local_interface = eth1</span><br><span class="line">local_ip = 172.25.249.200/24</span><br><span class="line">overcloud_domain_name = overcloud.example.com</span><br><span class="line">undercloud_admin_host = 172.25.249.202</span><br><span class="line">undercloud_debug = false</span><br><span class="line">undercloud_ntp_servers = 172.25.254.254</span><br><span class="line">undercloud_public_host = 172.25.249.201</span><br><span class="line">undercloud_service_certificate = /etc/pki/tls/certs/undercloud.pem</span><br><span class="line">[ctlplane-subnet]</span><br><span class="line">cidr = 172.25.249.0/24</span><br><span class="line">dhcp_end = 172.25.249.59</span><br><span class="line">dhcp_start = 172.25.249.51</span><br><span class="line">gateway = 172.25.249.200</span><br><span class="line">inspection_iprange = 172.25.249.150,172.25.249.180</span><br><span class="line">masquerade = true</span><br></pre></td></tr></table></figure>

<p><code>dhcp_end</code> and <code>dhcp_start</code>: Represents the range of IP addresses dynamically assigned via DHCP.</p>
<p>IPs within this range are officially allocated to nodes once they’ve completed PXE boot and registration. These become the permanent management IPs (also known as ctlplane IPs).</p>
<p>In other words, these are the addresses that nodes will ultimately use after booting.</p>
<p>Specifies the temporary IP range assigned to nodes during PXE boot, used by ironic-inspector (or other node discovery tools).</p>
<p><code>inspection_iprange</code>:</p>
<p>These IPs are <code>temporarily</code> leased to nodes that are being discovered or prepared for deployment. Once deployment is complete, the IPs are released, and the nodes will switch to using addresses <code>from the dhcp_start to dhcp_end</code> range.</p>
<h3 id="ip-info"><a href="#ip-info" class="headerlink" title="ip info"></a>ip info</h3><p>In the following output, the br-ctlplane bridge is the 172.25.249.0 provisioning network. The eth1 interface is the 172.25.250.0 public network.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(undercloud) [stack@director ~]$ ip -br a</span><br><span class="line">lo               UNKNOWN        127.0.0.1/8 ::1/128 </span><br><span class="line">eth0             UP             172.25.250.200/24 fe80::1f21:2be6:7500:dfef/64 </span><br><span class="line">eth1             UP             fe80::5054:ff:fe00:f9c8/64 </span><br><span class="line">ovs-system       DOWN           </span><br><span class="line">br-int           DOWN           </span><br><span class="line">br-ctlplane      UNKNOWN        172.25.249.200/24 172.25.249.202/32 172.25.249.201/32 fe80::5054:ff:fe00:f9c8/64 </span><br></pre></td></tr></table></figure>

<h3 id="Check-the-IP-range-assigned-to-the-br-ctlplane-bridge"><a href="#Check-the-IP-range-assigned-to-the-br-ctlplane-bridge" class="headerlink" title="Check the IP range assigned to the br_ctlplane bridge"></a>Check the IP range assigned to the br_ctlplane bridge</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(undercloud) [stack@director ~]$ openstack subnet show ctlplane-subnet</span><br><span class="line">+-------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">| Field             | Value                                                                                                                                                   |</span><br><span class="line">+-------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">| allocation_pools  | 172.25.249.51-172.25.249.59                                                                                                                             |</span><br><span class="line">| cidr              | 172.25.249.0/24                                                                                                                                         |</span><br><span class="line">| created_at        | 2020-10-22T09:22:35Z                                                                                                                                    |</span><br><span class="line">| description       |                                                                                                                                                         |</span><br><span class="line">| dns_nameservers   |                                                                                                                                                         |</span><br><span class="line">| enable_dhcp       | True                                                                                                                                                    |</span><br><span class="line">| gateway_ip        | 172.25.249.200                                                                             </span><br></pre></td></tr></table></figure>

<h2 id="Viewing-Provisioning-Resources"><a href="#Viewing-Provisioning-Resources" class="headerlink" title="Viewing Provisioning Resources"></a>Viewing Provisioning Resources</h2><p>At the very start of hardware configuration, the bare-metal provisioning service uses IPMI to give the managed nodes the “green light” to power on. Then, by default, these nodes will boot via PXE and begin “asking around”: they’ll request a temporary IP address from the DHCP server and fetch the bootable temporary kernel and ramdisk images. From there, they can begin the network boot process.</p>
<h3 id="Listing-all-images"><a href="#Listing-all-images" class="headerlink" title="Listing all images"></a>Listing all images</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(undercloud) [stack@director ~]$ openstack image list</span><br><span class="line">+--------------------------------------+------------------------+--------+</span><br><span class="line">| ID                                   | Name                   | Status |</span><br><span class="line">+--------------------------------------+------------------------+--------+</span><br><span class="line">| da2b80ea-5ffc-400c-bc0c-82b04facad9e | overcloud-full         | active |</span><br><span class="line">| 9826607c-dff5-45b0-b0c4-78c44b8665e9 | overcloud-full-initrd  | active |</span><br><span class="line">| bc188e61-99c5-4d32-8c32-e1e3d467149d | overcloud-full-vmlinuz | active |</span><br><span class="line">+--------------------------------------+------------------------+--------+</span><br></pre></td></tr></table></figure>

<ul>
<li><p>overcloud-full</p>
<p>This image typically contains a complete operating system along with all the necessary components required for deploying OpenStack.</p>
</li>
<li><p>overcloud-full-initrd</p>
<p>This is the initrd image, which includes essential files and drivers needed during the boot process.</p>
</li>
<li><p>overcloud-full-vmlinuz</p>
<p>This is the compressed Linux kernel image responsible for initiating the operating system.</p>
</li>
</ul>
<h3 id="Listing-all-registered-nodes"><a href="#Listing-all-registered-nodes" class="headerlink" title="Listing all registered nodes"></a>Listing all registered nodes</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(undercloud) [stack@director ~]$ openstack baremetal node list -c Name -c &#x27;Power State&#x27; -c &#x27;Provisioning State&#x27;</span><br><span class="line">+-------------+-------------+--------------------+</span><br><span class="line">| Name        | Power State | Provisioning State |</span><br><span class="line">+-------------+-------------+--------------------+</span><br><span class="line">| controller0 | power on    | active             |</span><br><span class="line">| compute0    | power on    | active             |</span><br><span class="line">| computehci0 | power on    | active             |</span><br><span class="line">| compute1    | power on    | active             |</span><br><span class="line">| ceph0       | power on    | active             |</span><br><span class="line">+-------------+-------------+--------------------+</span><br></pre></td></tr></table></figure>

<h2 id="Power-management-on-the-Undercloud"><a href="#Power-management-on-the-Undercloud" class="headerlink" title="Power management on the Undercloud"></a>Power management on the Undercloud</h2><p>In a typical overcloud deployment, the nodes are mostly physical machines—such as blade servers or rack-mounted servers. These systems come with a very handy feature: unattended out-of-band management interfaces that allow remote power control. Extremely convenient!</p>
<p>As for the Bare Metal service, when nodes are being registered, it loads all the power management parameters in one go. These parameters are read from a configuration file called instackenv-initial.json. Simply put, this file acts like a “manual,” instructing the Bare Metal service on how to manage the power for each node.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(undercloud) [stack@director ~]$ cat instackenv-initial.json</span><br><span class="line">&#123;</span><br><span class="line">  &quot;nodes&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;name&quot;: &quot;controller0&quot;,</span><br><span class="line">      &quot;arch&quot;: &quot;x86_64&quot;,</span><br><span class="line">      &quot;cpu&quot;: &quot;2&quot;,</span><br><span class="line">      &quot;disk&quot;: &quot;40&quot;,</span><br><span class="line">      &quot;memory&quot;: &quot;8192&quot;,</span><br><span class="line">      &quot;mac&quot;: [ &quot;52:54:00:00:f9:01&quot; ],</span><br><span class="line">      &quot;pm_addr&quot;: &quot;172.25.249.101&quot;,</span><br><span class="line">      &quot;pm_type&quot;: &quot;pxe_ipmitool&quot;,</span><br><span class="line">      &quot;pm_user&quot;: &quot;admin&quot;,</span><br><span class="line">      &quot;pm_password&quot;: &quot;password&quot;,</span><br><span class="line">      &quot;pm_port&quot;: &quot;623&quot;,</span><br><span class="line">      &quot;capabilities&quot;: &quot;node:controller0,boot_option:local&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;name&quot;: &quot;compute0&quot;,</span><br><span class="line">      &quot;arch&quot;: &quot;x86_64&quot;,</span><br><span class="line">      &quot;cpu&quot;: &quot;2&quot;,</span><br><span class="line">      &quot;disk&quot;: &quot;40&quot;,</span><br><span class="line">      &quot;memory&quot;: &quot;6144&quot;,</span><br><span class="line">      &quot;mac&quot;: [ &quot;52:54:00:00:f9:02&quot; ],</span><br><span class="line">      &quot;pm_addr&quot;: &quot;172.25.249.102&quot;,</span><br><span class="line">      &quot;pm_type&quot;: &quot;pxe_ipmitool&quot;,</span><br><span class="line">      &quot;pm_user&quot;: &quot;admin&quot;,</span><br><span class="line">      &quot;pm_password&quot;: &quot;password&quot;,</span><br><span class="line">      &quot;pm_port&quot;: &quot;623&quot;,</span><br><span class="line">      &quot;capabilities&quot;: &quot;node:compute0,boot_option:local&quot;</span><br><span class="line">    &#125;,</span><br></pre></td></tr></table></figure>

<h3 id="Performing-IPMI-Power-Management"><a href="#Performing-IPMI-Power-Management" class="headerlink" title="Performing IPMI Power Management"></a>Performing IPMI Power Management</h3><p>check the IPMI address</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(undercloud) [stack@director ~]$ cat instackenv-initial.json | jq &#x27;.nodes[] | &#123;name: .name, pm_addr: .pm_addr, pm_user: .pm_user, pm_password: .pm_password&#125;&#x27;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;: &quot;controller0&quot;,</span><br><span class="line">  &quot;pm_addr&quot;: &quot;172.25.249.101&quot;,</span><br><span class="line">  &quot;pm_user&quot;: &quot;admin&quot;,</span><br><span class="line">  &quot;pm_password&quot;: &quot;password&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;: &quot;compute0&quot;,</span><br><span class="line">  &quot;pm_addr&quot;: &quot;172.25.249.102&quot;,</span><br><span class="line">  &quot;pm_user&quot;: &quot;admin&quot;,</span><br><span class="line">  &quot;pm_password&quot;: &quot;password&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;: &quot;computehci0&quot;,</span><br><span class="line">  &quot;pm_addr&quot;: &quot;172.25.249.106&quot;,</span><br><span class="line">  &quot;pm_user&quot;: &quot;admin&quot;,</span><br><span class="line">  &quot;pm_password&quot;: &quot;password&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;: &quot;compute1&quot;,</span><br><span class="line">  &quot;pm_addr&quot;: &quot;172.25.249.112&quot;,</span><br><span class="line">  &quot;pm_user&quot;: &quot;admin&quot;,</span><br><span class="line">  &quot;pm_password&quot;: &quot;password&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;: &quot;ceph0&quot;,</span><br><span class="line">  &quot;pm_addr&quot;: &quot;172.25.249.103&quot;,</span><br><span class="line">  &quot;pm_user&quot;: &quot;admin&quot;,</span><br><span class="line">  &quot;pm_password&quot;: &quot;password&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Operation on Power</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(undercloud) [stack@director ~]$ ipmitool -I lanplus \</span><br><span class="line">&gt; -U admin -P password -H 172.25.249.101 power status</span><br><span class="line">Chassis Power is on</span><br><span class="line"></span><br><span class="line">(undercloud) [stack@director ~]$ openstack baremetal node power on controller0</span><br><span class="line">(undercloud) [stack@director ~]$ openstack baremetal node power off controller0</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>OpenStack</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL Series Chapter0: Introduction</title>
    <url>//Database/MySQL/Introduction/index.html</url>
    <content><![CDATA[<h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>MySQL is a <code>relational</code> database management system that organizes data into <code>structured</code> tables, rows, and columns for efficient programming and data management.</p>
<p>It also works as a document store, enabling the creation of both SQL and NoSQL applications without the need for separate NoSQL databases.</p>
<h2 id="Transaction"><a href="#Transaction" class="headerlink" title="Transaction"></a>Transaction</h2><p>MySQL is transactional by nature. When storing and managing data, actions such as selecting, inserting, updating, or deleting are required.</p>
<p>MySQL groups these actions into a transaction. The transaction is saved only if every part completes successfully. </p>
<p>MySQL works well with online transaction processing workloads. It handles transactions quickly and manages large volumes of transaction at once. </p>
<p><code>OLTP</code>, with low latency and high throughput, makes MySQL ideal for high-speed environments like banking or online shopping. </p>
<p>MySQL not only stores data but also <code>replicates</code> it from a main server to several replicas.</p>
<h2 id="InnoDB"><a href="#InnoDB" class="headerlink" title="InnoDB"></a>InnoDB</h2><p>MySQL is a high-performance database that uses its default storage engine, known as <code>InnoDB</code>. InnoDB helps MySQL handle complex operations and large data volumes smoothly.</p>
<h2 id="Version"><a href="#Version" class="headerlink" title="Version"></a>Version</h2><ul>
<li><p>Community edition</p>
</li>
<li><p>Oracle enterprise edition</p>
</li>
</ul>
<p><img src="/../images/community_enterprise_mysql.png" alt="differences"></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenStack Series Chapter1:Introducing Containerized Services</title>
    <url>//Cloud/OpenStack/Introducing-Containerized-Services/index.html</url>
    <content><![CDATA[<h2 id="Use-systemd-to-manage-the-containerized-services"><a href="#Use-systemd-to-manage-the-containerized-services" class="headerlink" title="Use systemd to manage the containerized services"></a>Use <code>systemd</code> to manage the containerized services</h2><p>The latest version of RHOSP uses <code>systemd units</code> to manage the lifecycle of service containers. <code>systemd</code> handles common operations such as starting, stopping, and others, managing containers in the same way as other systemd units and services, using the podman command to interact with the containers.</p>
<p>For example:</p>
<p>To verify the status of a containerized service, run the systemctl status command:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@controller0 ~]# systemctl status tripleo_cinder_api</span><br><span class="line">● tripleo_cinder_api.service - cinder_api container</span><br><span class="line">   Loaded: loaded (/etc/systemd/system/tripleo_cinder_api.service; enabled; vendor preset: di&gt;</span><br><span class="line">   Active: active (running) since Tue 2025-04-29 02:27:54 UTC; 6h ago</span><br><span class="line"> Main PID: 4963 (conmon)</span><br><span class="line">    Tasks: 0 (limit: 101103)</span><br><span class="line">   Memory: 1.7M</span><br><span class="line">   CGroup: /system.slice/tripleo_cinder_api.service</span><br><span class="line">           ‣ 4963 /usr/bin/conmon --api-version 1 -s -c a89efc04180c85f9e5a2a0f6a7d1835b543b9&gt;</span><br><span class="line"></span><br><span class="line">Apr 29 02:27:46 controller0 systemd[1]: Starting cinder_api container...</span><br><span class="line">Apr 29 02:27:54 controller0 podman[3564]: 2025-04-29 02:27:54.043315718 +0000 UTC m=+6.779304&gt;</span><br><span class="line">Apr 29 02:27:54 controller0 podman[3564]: 2025-04-29 02:27:54.375331615 +0000 UTC m=+7.111320&gt;</span><br><span class="line">Apr 29 02:27:54 controller0 podman[3564]: cinder_api</span><br><span class="line">Apr 29 02:27:54 controller0 systemd[1]: Started cinder_api container.</span><br></pre></td></tr></table></figure>

<h3 id="Timer"><a href="#Timer" class="headerlink" title="Timer"></a>Timer</h3><p>Systemd monitors container health checks, which are not displayed by <code>podman ps</code>, using <code>systemd timers</code>. To list containers timers, use the <code>systemctl list-timers</code> command. This example filters to view only <code>tripleo</code> unit services.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@controller0 ~]# systemctl list-timers | grep tripleo</span><br><span class="line">Tue 2025-04-29 10:34:36 UTC  34ms left     Tue 2025-04-29 10:33:27 UTC  1min 9s ago  tripleo_swift_rsync_healthcheck.timer                tripleo_swift_rsync_healthcheck.service</span><br><span class="line">Tue 2025-04-29 10:34:36 UTC  365ms left    Tue 2025-04-29 10:33:22 UTC  1min 14s ago tripleo_heat_engine_healthcheck.timer                tripleo_heat_engine_healthcheck.service</span><br><span class="line">Tue 2025-04-29 10:34:39 UTC  2s left       Tue 2025-04-29 10:33:12 UTC  1min 24s ago tripleo_octavia_worker_healthcheck.timer             tripleo_octavia_worker_healthcheck.service</span><br><span class="line">Tue 2025-04-29 10:34:40 UTC  4s left       Tue 2025-04-29 10:32:57 UTC  1min 39s ago tripleo_manila_scheduler_healthcheck.timer           tripleo_manila_scheduler_healthcheck.service</span><br><span class="line">Tue 2025-04-29 10:34:43 UTC  7s left       Tue 2025-04-29 10:33:12 UTC  1min 24s ago tripleo_cinder_scheduler_healthcheck.timer           tripleo_cinder_scheduler_healthcheck.service</span><br><span class="line">Tue 2025-04-29 10:34:44 UTC  8s left       Tue 2025-04-29 10:33:17 UTC  1min 19s ago tripleo_neutron_api_healthcheck.timer                tripleo_neutron_api_healthcheck.service</span><br><span class="line">Tue 2025-04-29 10:34:51 UTC  14s left      Tue 2025-04-29 10:33:12 UTC  1min 24s ago tripleo_clustercheck_healthcheck.timer               tripleo_clustercheck_healthcheck.service</span><br><span class="line">Tue 2025-04-29 10:34:55 UTC  19s left      Tue 2025-04-29 10:33:27 UTC  1min 9s ago  tripleo_logrotate_crond_healthcheck.timer            tripleo_logrotate_crond_healthcheck.service</span><br><span class="line">Tue 2025-04-29 10:35:00 UTC  24s left      Tue 2025-04-29 10:33:27 UTC  1min 9s ago  tripleo_swift_object_replicator_healthcheck.timer    tripleo_swift_object_replicator_healthcheck.service</span><br><span class="line">...output omitted...</span><br></pre></td></tr></table></figure>

<p>To verify a specific container timer, use the <code>systemctl status</code> command.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@controller0 ~]# systemctl status tripleo_cinder_api_healthcheck.timer</span><br><span class="line">● tripleo_cinder_api_healthcheck.timer - cinder_api container healthcheck</span><br><span class="line">   Loaded: loaded (/etc/systemd/system/tripleo_cinder_api_healthcheck.timer; enabled; vendor &gt;</span><br><span class="line">   Active: active (waiting) since Tue 2025-04-29 02:26:51 UTC; 8h ago</span><br><span class="line">  Trigger: Tue 2025-04-29 10:53:36 UTC; 13s left</span><br><span class="line"></span><br><span class="line">Apr 29 02:26:51 controller0 systemd[1]: Started cinder_api container healthcheck.</span><br></pre></td></tr></table></figure>

<p>Let’s check the configuration of <code>tripleo_cinder_api_healthcheck.timer</code>!</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@controller0 ~]# systemctl cat tripleo_cinder_api_healthcheck.timer</span><br><span class="line"># /etc/systemd/system/tripleo_cinder_api_healthcheck.timer</span><br><span class="line">[Unit]</span><br><span class="line">Description=cinder_api container healthcheck</span><br><span class="line">PartOf=tripleo_cinder_api.service</span><br><span class="line">[Timer]</span><br><span class="line">OnActiveSec=120</span><br><span class="line">OnUnitActiveSec=60</span><br><span class="line">RandomizedDelaySec=45.0</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=timers.target</span><br></pre></td></tr></table></figure>

<ul>
<li>[Unit] section:</li>
</ul>
<p><code>Description</code>: Describes the purpose of the timer.</p>
<p><code>PartOf=tripleo_cinder_api.service</code> only affects the lifecycle of the timer and does not change the service triggered by the timer.</p>
<p>By default, <code>the timer will trigger the service file with the same name</code>, i.e., tripleo_cinder_api_healthcheck.service. This is not controlled by PartOf, but rather by the naming convention of systemd.</p>
<p>If you want the timer to trigger a different service (such as tripleo_cinder_api.service), you need to explicitly specify the desired service in the Unit section or ExecStart of the timer file.</p>
<ul>
<li>[Timer] section:</li>
</ul>
<p><code>OnActiveSec=120</code>: The timer will start 120 seconds after the service is activated.</p>
<p><code>OnUnitActiveSec=60</code>: The timer will start again 60 seconds after the last active period of the service.</p>
<p><code>RandomizedDelaySec=45.0</code>: A random delay of up to 45 seconds will be added before each timer start.</p>
<ul>
<li>[Install] section:</li>
</ul>
<p><code>WantedBy=timers.target</code>: Specifies that this timer will start when timers.target is triggered.</p>
<p>To verify, you can repeatedly check the status <code>systemctl status tripleo_cinder_api_healthcheck</code>. After about 60 seconds, you will see the service start once again.</p>
<h3 id="Log"><a href="#Log" class="headerlink" title="Log"></a>Log</h3><p>In the latest version of RHOSP, the standard output (stdout) and standard errors (stderr) are consolidated in a single file per container, located in the <code>/var/log/containers/stdouts</code> directory.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@controller0 ~]# ls -1 /var/log/containers/stdouts</span><br><span class="line">aodh_api.log</span><br><span class="line">aodh_db_sync.log</span><br><span class="line">aodh_evaluator.log</span><br><span class="line">aodh_init_log.log</span><br><span class="line">aodh_listener.log</span><br><span class="line">aodh_notifier.log</span><br><span class="line">ceilometer_agent_central.log</span><br><span class="line">ceilometer_agent_notification.log</span><br><span class="line">ceilometer_gnocchi_upgrade.log</span><br><span class="line">ceilometer_init_log.log</span><br><span class="line">cinder_api_cron.log</span><br><span class="line">cinder_api_cron.log.1</span><br><span class="line">cinder_api_cron.log.10.gz</span><br><span class="line">cinder_api_cron.log.11.gz</span><br><span class="line">cinder_api_cron.log.12.gz</span><br><span class="line">cinder_api_cron.log.13.gz</span><br><span class="line">cinder_api_cron.log.14.gz</span><br><span class="line">cinder_api_cron.log.2.gz</span><br><span class="line">cinder_api_cron.log.3.gz</span><br><span class="line">cinder_api_cron.log.4.gz</span><br><span class="line">cinder_api_cron.log.5.gz</span><br><span class="line">cinder_api_cron.log.6.gz</span><br><span class="line">...output omitted...</span><br></pre></td></tr></table></figure>

<h3 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a>Configuration</h3><p>In RHOSP versions with containerized services, container configuration files are located in the <code>/var/lib/config-data/puppet-generated/container_name</code> directory.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@controller0 ~]# ls -1 /var/lib/config-data/puppet-generated/ | more</span><br><span class="line">aodh</span><br><span class="line">aodh.md5sum</span><br><span class="line">ceilometer</span><br><span class="line">ceilometer.md5sum</span><br><span class="line">cinder</span><br><span class="line">cinder.md5sum</span><br><span class="line">clustercheck</span><br><span class="line">clustercheck.md5sum</span><br><span class="line">crond</span><br><span class="line">crond.md5sum</span><br><span class="line">glance_api</span><br><span class="line">glance_api.md5sum</span><br><span class="line">gnocchi</span><br><span class="line">gnocchi.md5sum</span><br><span class="line">haproxy</span><br><span class="line">haproxy.md5sum</span><br><span class="line">heat</span><br><span class="line">heat_api</span><br><span class="line">heat_api_cfn</span><br><span class="line">heat_api_cfn.md5sum</span><br><span class="line">heat_api.md5sum</span><br><span class="line">heat.md5sum</span><br><span class="line">horizon</span><br><span class="line">horizon.md5sum</span><br><span class="line">...output omitted...</span><br></pre></td></tr></table></figure>

<p>The systemd unit files of containerized services are named with a <code>tripleo_ prefix</code>, because they are installed by TripleO.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@controller0 ~]# ls -1 /etc/systemd/system/tripleo* | more</span><br><span class="line">/etc/systemd/system/tripleo_cinder_api_cron_healthcheck.service</span><br><span class="line">/etc/systemd/system/tripleo_cinder_api_cron_healthcheck.timer</span><br><span class="line">/etc/systemd/system/tripleo_cinder_api_cron.service</span><br><span class="line">/etc/systemd/system/tripleo_cinder_api_healthcheck.service</span><br><span class="line">/etc/systemd/system/tripleo_cinder_api_healthcheck.timer</span><br><span class="line">/etc/systemd/system/tripleo_cinder_api.service</span><br><span class="line">/etc/systemd/system/tripleo_cinder_scheduler_healthcheck.service</span><br><span class="line">/etc/systemd/system/tripleo_cinder_scheduler_healthcheck.timer</span><br><span class="line">/etc/systemd/system/tripleo_cinder_scheduler.service</span><br><span class="line">/etc/systemd/system/tripleo_clustercheck_healthcheck.service</span><br><span class="line">/etc/systemd/system/tripleo_clustercheck_healthcheck.timer</span><br><span class="line">/etc/systemd/system/tripleo_clustercheck.service</span><br><span class="line">...output omitted...</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>OpenStack</tag>
      </tags>
  </entry>
  <entry>
    <title>Frp P2P mode</title>
    <url>//Tools/Frp/Frp-P2P-mode/index.html</url>
    <content><![CDATA[<h2 id="P2P-Peer-to-Peer"><a href="#P2P-Peer-to-Peer" class="headerlink" title="P2P (Peer-to-Peer)"></a>P2P (Peer-to-Peer)</h2><p>P2P (Peer-to-Peer) is a type of network architecture in which all the nodes (typically computers) in the network are considered equal and can communicate directly with each other, sharing resources and data without the need for an intermediary server. This contrasts with the traditional client-server model, where clients request services from servers.</p>
<h2 id="Frps-configuration"><a href="#Frps-configuration" class="headerlink" title="Frps configuration"></a>Frps configuration</h2><p>Similarly as before, edit the <code>frps.toml</code> in the server end and add the following lines here. <code>WebServer</code> service and <code>auth.token</code> could be disabled as well, just follow your heart.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim frps.toml</span><br><span class="line"></span><br><span class="line">bindPort = 7000</span><br><span class="line">auth.token = <span class="string">&quot;sunhaoyang&quot;</span></span><br><span class="line">webServer.addr = <span class="string">&quot;0.0.0.0&quot;</span></span><br><span class="line">webServer.port = 7500</span><br><span class="line">webServer.user = <span class="string">&quot;admin&quot;</span></span><br><span class="line">webServer.password = <span class="string">&quot;admin_password&quot;</span></span><br></pre></td></tr></table></figure>

<p>Then, Start frps on machine A.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /etc/systemd/system/frps.service &lt;&lt;-<span class="string">&#x27;EOF&#x27;</span></span><br><span class="line">[Unit]</span><br><span class="line">Description=FRP Server Service</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">User=root</span><br><span class="line">ExecStart=/usr/local/bin/frp/frps -c /usr/local/bin/frp/frps.toml</span><br><span class="line">Restart=on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@frp-server ~]# systemctl daemon-reload</span><br><span class="line">[root@frp-server ~]# systemctl enable frps.service --now</span><br><span class="line">Created symlink /etc/systemd/system/multi-user.target.wants/frps.service → /etc/systemd/system/frps.service.</span><br><span class="line">[root@frp-server ~]# systemctl status frps.service</span><br><span class="line">● frps.service - FRP Server Service</span><br><span class="line">     Loaded: loaded (/etc/systemd/system/frps.service; enabled; preset: disabled)</span><br><span class="line">     Active: active (running) since Fri 2025-04-25 16:06:45 CST; 4s ago</span><br><span class="line">   Main PID: 355286 (frps)</span><br><span class="line">      Tasks: 5 (limit: 12344)</span><br><span class="line">     Memory: 9.0M</span><br><span class="line">        CPU: 324ms</span><br><span class="line">     CGroup: /system.slice/frps.service</span><br><span class="line">             └─355286 /usr/local/bin/frp/frps -c /usr/local/bin/frp/frps.toml</span><br><span class="line"></span><br><span class="line">Apr 25 16:06:45 frp-server systemd[1]: Started FRP Server Service.</span><br><span class="line">Apr 25 16:06:45 frp-server frps[355286]: 2025-04-25 16:06:45.952 [I] [frps/root.go:105] frps uses config file: /usr/local/bin/frp/frps.toml</span><br><span class="line">Apr 25 16:06:46 frp-server frps[355286]: 2025-04-25 16:06:46.270 [I] [server/service.go:237] frps tcp listen on 0.0.0.0:7000</span><br><span class="line">Apr 25 16:06:46 frp-server frps[355286]: 2025-04-25 16:06:46.271 [I] [frps/root.go:114] frps started successfully</span><br><span class="line">Apr 25 16:06:46 frp-server frps[355286]: 2025-04-25 16:06:46.271 [I] [server/service.go:351] dashboard listen on 0.0.0.0:7500</span><br></pre></td></tr></table></figure>

<h2 id="Frpc-configuration"><a href="#Frpc-configuration" class="headerlink" title="Frpc configuration"></a>Frpc configuration</h2><h3 id="Proxy"><a href="#Proxy" class="headerlink" title="Proxy"></a>Proxy</h3><p>Start frpc on machine B, and expose the SSH port. Note that the remotePort field is removed.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-0-7-rockylinux ~]# mv frp_0.62.0_linux_amd64 /usr/local/bin/frp</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># frpc.toml</span><br><span class="line">serverAddr = &quot;x.x.x.x&quot;</span><br><span class="line">serverPort = 7000</span><br><span class="line"># set up a new stun server if the default one is not available.</span><br><span class="line"># natHoleStunServer = &quot;xxx&quot;</span><br><span class="line"></span><br><span class="line">[[proxies]]</span><br><span class="line">name = &quot;p2p_ssh&quot;</span><br><span class="line">type = &quot;xtcp&quot;</span><br><span class="line">secretKey = &quot;abcdefg&quot;</span><br><span class="line">localIP = &quot;127.0.0.1&quot;</span><br><span class="line">localPort = 22       # Here, I use ssh port as an example. Something else, such as 80(httpd) works as well.</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /etc/systemd/system/frpc.service &lt;&lt;-<span class="string">&#x27;EOF&#x27;</span></span><br><span class="line">[Unit]</span><br><span class="line">Description=FRP Client Service</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">User=root</span><br><span class="line">ExecStart=/usr/local/bin/frp/frpc -c /usr/local/bin/frp/frpc.toml</span><br><span class="line">Restart=on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-0-7-rockylinux frp]# systemctl daemon-reload</span><br><span class="line">[root@VM-0-7-rockylinux frp]# systemctl enable frpc.service --now</span><br><span class="line">Created symlink /etc/systemd/system/multi-user.target.wants/frpc.service → /etc/systemd/system/frpc.service.</span><br><span class="line">[root@VM-0-7-rockylinux frp]# systemctl status frpc.service</span><br><span class="line">● frpc.service - FRP Client Service</span><br><span class="line">     Loaded: loaded (/etc/systemd/system/frpc.service; enabled; preset: disabled)</span><br><span class="line">     Active: active (running) since Sun 2025-04-27 00:57:13 CST; 3s ago</span><br><span class="line">   Main PID: 72540 (frpc)</span><br><span class="line">      Tasks: 4 (limit: 12140)</span><br><span class="line">     Memory: 5.0M</span><br><span class="line">        CPU: 6ms</span><br><span class="line">     CGroup: /system.slice/frpc.service</span><br><span class="line">             └─72540 /usr/local/bin/frp/frpc -c /usr/local/bin/frp/frpc.toml</span><br><span class="line"></span><br><span class="line">Apr 27 00:57:13 VM-0-7-rockylinux systemd[1]: Started FRP Client Service.</span><br><span class="line">Apr 27 00:57:13 VM-0-7-rockylinux frpc[72540]: 2025-04-27 00:57:13.009 [I] [sub/root.go:149] s&gt;</span><br><span class="line">Apr 27 00:57:13 VM-0-7-rockylinux frpc[72540]: 2025-04-27 00:57:13.009 [I] [client/service.go:&gt;</span><br><span class="line">Apr 27 00:57:13 VM-0-7-rockylinux frpc[72540]: 2025-04-27 00:57:13.042 [I] [client/service.go:&gt;</span><br><span class="line">Apr 27 00:57:13 VM-0-7-rockylinux frpc[72540]: 2025-04-27 00:57:13.042 [I] [proxy/proxy_manage&gt;</span><br><span class="line">Apr 27 00:57:13 VM-0-7-rockylinux frpc[72540]: 2025-04-27 00:57:13.052 [I] [client/control.go:&gt;</span><br></pre></td></tr></table></figure>

<h3 id="Visitor"><a href="#Visitor" class="headerlink" title="Visitor"></a>Visitor</h3><p>Start another frpc (typically on another machine C) with the configuration to connect to SSH using P2P mode.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-48-7-rockylinux ~]# mv frp_0.62.0_linux_amd64 /usr/local/bin/frp</span><br><span class="line">[root@VM-48-7-rockylinux ~]# cd /usr/local/bin/</span><br><span class="line">[root@VM-48-7-rockylinux bin]# ls</span><br><span class="line">frp  scp  sftp  ssh  ssh-add  ssh-agent  ssh-keygen  ssh-keyscan</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># frpc.toml</span><br><span class="line">serverAddr = &quot;x.x.x.x&quot;</span><br><span class="line">serverPort = 7000</span><br><span class="line"># set up a new stun server if the default one is not available.</span><br><span class="line"># natHoleStunServer = &quot;xxx&quot;</span><br><span class="line"></span><br><span class="line">[[visitors]]</span><br><span class="line">name = &quot;p2p_ssh_visitor&quot;</span><br><span class="line">type = &quot;xtcp&quot;</span><br><span class="line">serverName = &quot;p2p_ssh&quot;      # The serverName here and that one in Proxy must be set to the same.</span><br><span class="line">secretKey = &quot;abcdefg&quot;       # The secretKey here and that one in Proxy must be set to the same.</span><br><span class="line">bindAddr = &quot;127.0.0.1&quot;</span><br><span class="line">bindPort = 6000</span><br><span class="line"># when automatic tunnel persistence is required, set it to true</span><br><span class="line"># keepTunnelOpen = false    # Comment this line</span><br></pre></td></tr></table></figure>

<h2 id="Connect"><a href="#Connect" class="headerlink" title="Connect"></a>Connect</h2><p>On machine C, connect to SSH on machine B, using this command.</p>
<h3 id="Login-Successfully"><a href="#Login-Successfully" class="headerlink" title="Login Successfully"></a>Login Successfully</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-48-7-rockylinux frp_0.62.0_linux_amd64]# ssh -oPort=6000 127.0.0.1</span><br><span class="line">root@127.0.0.1&#x27;s password: </span><br><span class="line">Activate the web console with: systemctl enable --now cockpit.socket</span><br><span class="line"></span><br><span class="line">Last login: Sat Apr 26 21:30:24 2025 from 175.162.122.18</span><br><span class="line">[root@VM-0-7-rockylinux ~]# </span><br></pre></td></tr></table></figure>

<h3 id="Check-the-log-of-frpc-in-machine-B"><a href="#Check-the-log-of-frpc-in-machine-B" class="headerlink" title="Check the log of frpc in machine B"></a>Check the log of frpc in machine B</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-0-7-rockylinux frp]# systemctl status frpc.service</span><br><span class="line">● frpc.service - FRP Client Service</span><br><span class="line">     Loaded: loaded (/etc/systemd/system/frpc.service; enabled; preset: disabled)</span><br><span class="line">     Active: active (running) since Sun 2025-04-27 00:57:13 CST; 10min ago</span><br><span class="line">   Main PID: 72540 (frpc)</span><br><span class="line">      Tasks: 4 (limit: 12140)</span><br><span class="line">     Memory: 8.1M</span><br><span class="line">        CPU: 451ms</span><br><span class="line">     CGroup: /system.slice/frpc.service</span><br><span class="line">             └─72540 /usr/local/bin/frp/frpc -c /usr/local/bin/frp/frpc.toml</span><br><span class="line"></span><br><span class="line">Apr 27 00:57:13 VM-0-7-rockylinux systemd[1]: Started FRP Client Service.</span><br><span class="line">Apr 27 00:57:13 VM-0-7-rockylinux frpc[72540]: 2025-04-27 00:57:13.009 [I] [sub/root.go:149] start frpc service for config file [/usr/local/bin/frp/frpc.toml]</span><br><span class="line">Apr 27 00:57:13 VM-0-7-rockylinux frpc[72540]: 2025-04-27 00:57:13.009 [I] [client/service.go:314] try to connect to server...</span><br><span class="line">Apr 27 00:57:13 VM-0-7-rockylinux frpc[72540]: 2025-04-27 00:57:13.042 [I] [client/service.go:306] [5dbff11603bd8e75] login to server success, get run id [5dbff11603bd&gt;</span><br><span class="line">Apr 27 00:57:13 VM-0-7-rockylinux frpc[72540]: 2025-04-27 00:57:13.042 [I] [proxy/proxy_manager.go:177] [5dbff11603bd8e75] proxy added: [p2p_ssh]</span><br><span class="line">Apr 27 00:57:13 VM-0-7-rockylinux frpc[72540]: 2025-04-27 00:57:13.052 [I] [client/control.go:172] [5dbff11603bd8e75] [p2p_ssh] start proxy success</span><br><span class="line">Apr 27 01:07:43 VM-0-7-rockylinux frpc[72540]: 2025-04-27 01:07:43.686 [I] [proxy/xtcp.go:72] [5dbff11603bd8e75] [p2p_ssh] nathole prepare success, nat type: EasyNAT, &gt;</span><br><span class="line">Apr 27 01:07:44 VM-0-7-rockylinux frpc[72540]: 2025-04-27 01:07:44.696 [I] [proxy/xtcp.go:93] [5dbff11603bd8e75] [p2p_ssh] get natHoleRespMsg, sid [17456872631ee7cb59a&gt;</span><br><span class="line">Apr 27 01:07:44 VM-0-7-rockylinux frpc[72540]: 2025-04-27 01:07:44.734 [I] [proxy/xtcp.go:109] [5dbff11603bd8e75] [p2p_ssh] establishing nat hole connection successful&gt;</span><br></pre></td></tr></table></figure>

<p>It is obviously that the hole was punched.<br>E.g. <code>nathole prepare success, nat type: EasyNAT</code>, <code>establishing nat hole connection successful</code>.</p>
<h3 id="Check-the-log-of-frps-in-machine-A"><a href="#Check-the-log-of-frps-in-machine-A" class="headerlink" title="Check the log of frps in machine A"></a>Check the log of frps in machine A</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">2025-04-27 00:57:13.038 [I] [server/service.go:582] [5dbff11603bd8e75] client login info: ip [118.195.155.132:42178] version [0.62.0] hostname [] os [linux] arch [amd64]</span><br><span class="line">2025-04-27 00:57:13.049 [I] [server/control.go:399] [5dbff11603bd8e75] new proxy [p2p_ssh] type [xtcp] success</span><br><span class="line">2025-04-27 01:00:45.040 [I] [server/control.go:357] [607581f620a645ec] client exit success</span><br><span class="line">2025-04-27 01:01:34.544 [I] [server/service.go:582] [fc60898a7eda2cb0] client login info: ip [101.43.210.253:57136] version [0.62.0] hostname [] os [linux] arch [amd64]</span><br><span class="line">2025-04-27 01:07:44.741 [I] [nathole/controller.go:280] sid [17456872631ee7cb59a2e4b72a] report make hole success: true, mode 0, index 0</span><br></pre></td></tr></table></figure>

<p><code>report make hole success</code> represents the connection between machine B and machine C is successful as well.</p>
<h2 id="Test"><a href="#Test" class="headerlink" title="Test"></a>Test</h2><h3 id="scp"><a href="#scp" class="headerlink" title="scp"></a>scp</h3><h4 id="Create-a-large-file-by-dd-command-in-machine-C"><a href="#Create-a-large-file-by-dd-command-in-machine-C" class="headerlink" title="Create a large file by dd command in machine C"></a>Create a large file by <code>dd</code> command in machine C</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-0-7-rockylinux html]# dd if=/dev/zero of=testfile bs=1M count=5120</span><br><span class="line">5120+0 records in</span><br><span class="line">5120+0 records out</span><br><span class="line">5368709120 bytes (5.4 GB, 5.0 GiB) copied, 25.0375 s, 214 MB/s</span><br></pre></td></tr></table></figure>

<h4 id="Use-scp-command-in-machine-C-and-send-the-large-file-to-machine-B"><a href="#Use-scp-command-in-machine-C-and-send-the-large-file-to-machine-B" class="headerlink" title="Use scp command in machine C and send the large file to machine B"></a>Use <code>scp</code> command in machine C and send the large file to machine B</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-48-7-rockylinux ~]# time scp -P 6000 testfile root@127.0.0.1:/root</span><br><span class="line">root@127.0.0.1&#x27;s password: </span><br><span class="line">testfile                                                      53% 2749MB  10.5MB/s   03:45 ETA^C</span><br></pre></td></tr></table></figure>

<p><img src="/../images/frps_traffic_monitor.png" alt="frps traffic monitor"></p>
<p>Congratulations! This image is an evidence to proof that The traffic did not go through the <code>frps</code> server, but instead, machine B and machine C are <code>directly connected</code>.</p>
<h3 id="wget"><a href="#wget" class="headerlink" title="wget"></a>wget</h3><h4 id="Install-the-httpd-service-in-machine-B"><a href="#Install-the-httpd-service-in-machine-B" class="headerlink" title="Install the httpd service in machine B"></a>Install the <code>httpd</code> service in machine B</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">dnf provides httpd</span><br><span class="line">dnf install httpd</span><br></pre></td></tr></table></figure>

<h4 id="Start-and-Enable-the-httpd-service-in-machine-B"><a href="#Start-and-Enable-the-httpd-service-in-machine-B" class="headerlink" title="Start and Enable the httpd service in machine B"></a>Start and Enable the <code>httpd</code> service in machine B</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-0-7-rockylinux ~]# systemctl enable httpd.service --now</span><br><span class="line">Created symlink /etc/systemd/system/multi-user.target.wants/httpd.service → /usr/lib/systemd/system/httpd.service.</span><br><span class="line">[root@VM-0-7-rockylinux ~]# systemctl status httpd.service </span><br><span class="line">● httpd.service - The Apache HTTP Server</span><br><span class="line">     Loaded: loaded (/usr/lib/systemd/system/httpd.service; enabled; preset: disabled)</span><br><span class="line">     Active: active (running) since Sat 2025-04-26 22:11:58 CST; 1s ago</span><br><span class="line">       Docs: man:httpd.service(8)</span><br><span class="line">   Main PID: 21890 (httpd)</span><br><span class="line">     Status: &quot;Started, listening on: port 80&quot;</span><br><span class="line">      Tasks: 177 (limit: 12140)</span><br><span class="line">     Memory: 24.2M</span><br><span class="line">        CPU: 47ms</span><br><span class="line">     CGroup: /system.slice/httpd.service</span><br><span class="line">             ├─21890 /usr/sbin/httpd -DFOREGROUND</span><br><span class="line">             ├─21891 /usr/sbin/httpd -DFOREGROUND</span><br><span class="line">             ├─21892 /usr/sbin/httpd -DFOREGROUND</span><br><span class="line">             ├─21893 /usr/sbin/httpd -DFOREGROUND</span><br><span class="line">             └─21894 /usr/sbin/httpd -DFOREGROUND</span><br><span class="line"></span><br><span class="line">Apr 26 22:11:58 VM-0-7-rockylinux systemd[1]: Starting The Apache HTTP Server...</span><br><span class="line">Apr 26 22:11:58 VM-0-7-rockylinux httpd[21890]: Server configured, listening on: port 80</span><br><span class="line">Apr 26 22:11:58 VM-0-7-rockylinux systemd[1]: Started The Apache HTTP Server.</span><br></pre></td></tr></table></figure>

<h4 id="Create-a-large-file-by-dd-command-in-machine-B"><a href="#Create-a-large-file-by-dd-command-in-machine-B" class="headerlink" title="Create a large file by dd command in machine B"></a>Create a large file by <code>dd</code> command in machine B</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-0-7-rockylinux html]# dd if=/dev/zero of=testfile bs=1M count=5120</span><br><span class="line">5120+0 records in</span><br><span class="line">5120+0 records out</span><br><span class="line">5368709120 bytes (5.4 GB, 5.0 GiB) copied, 25.0375 s, 214 MB/s</span><br></pre></td></tr></table></figure>

<h4 id="Move-the-large-file-to-the-httpd-root-directory-in-machine-B"><a href="#Move-the-large-file-to-the-httpd-root-directory-in-machine-B" class="headerlink" title="Move the large file to the httpd root directory in machine B"></a>Move the large file to the httpd root directory in machine B</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mv testfile /var/www/html</span><br></pre></td></tr></table></figure>

<h4 id="Use-wget-command-in-machine-C-and-download-the-large-file-from-machine-B"><a href="#Use-wget-command-in-machine-C-and-download-the-large-file-from-machine-B" class="headerlink" title="Use wget command in machine C and download the large file from machine B"></a>Use <code>wget</code> command in machine C and download the large file from machine B</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@VM-48-7-rockylinux test_http]# wget http://127.0.0.1:6000/testfile</span><br><span class="line">--2025-04-26 22:17:00--  http://127.0.0.1:6000/testfile</span><br><span class="line">Connecting to 127.0.0.1:6000... connected.</span><br><span class="line">HTTP request sent, awaiting response... 200 OK</span><br><span class="line">Length: 5368709120 (5.0G)</span><br><span class="line">Saving to: ‘testfile.1’</span><br><span class="line">testfile.1               10%[==&gt;                            ] 529.66M  11.6MB/s    eta 6m 47s ^C</span><br></pre></td></tr></table></figure>

<p><img src="/../images/frps_traffic_monitor.png" alt="frps traffic monitor"></p>
<p>Congratulations! This image is an evidence to proof that The traffic did not go through the <code>frps</code> server, but instead, machine B and machine C are <code>directly connected</code>.</p>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Frp</tag>
      </tags>
  </entry>
  <entry>
    <title>Frp supplementation and improvement</title>
    <url>//Tools/Frp/Frp-supplementation-and-improvement/index.html</url>
    <content><![CDATA[<h2 id="Set-the-frps-frpc-as-the-automatic-service-managed-by-systemd"><a href="#Set-the-frps-frpc-as-the-automatic-service-managed-by-systemd" class="headerlink" title="Set the frps&#x2F;frpc as the automatic service managed by systemd"></a>Set the frps&#x2F;frpc as the automatic service managed by <code>systemd</code></h2><h3 id="frps-service"><a href="#frps-service" class="headerlink" title="frps.service"></a>frps.service</h3><h4 id="Copy-the-folder-containing-the-installation-package-and-configuration-files-to-usr-local-bin-and-configure-systemd-accordingly"><a href="#Copy-the-folder-containing-the-installation-package-and-configuration-files-to-usr-local-bin-and-configure-systemd-accordingly" class="headerlink" title="Copy the folder containing the installation package and configuration files to /usr/local/bin, and configure systemd accordingly."></a>Copy the folder containing the installation package and configuration files to <code>/usr/local/bin</code>, and configure systemd accordingly.</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@frp-server ~]# mv frp_0.62.0_linux_amd64 /usr/local/bin/frp</span><br><span class="line">[root@frp-server ~]# ls /usr/local/bin/frp</span><br><span class="line">frpc  frpc.toml  frps  frps.toml  LICENSE</span><br></pre></td></tr></table></figure>

<h4 id="Supplementation-of-monitoring-Frp-server"><a href="#Supplementation-of-monitoring-Frp-server" class="headerlink" title="Supplementation of monitoring Frp server"></a>Supplementation of monitoring Frp server</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Edit the frps.toml configuration file, add the following lines</span></span><br><span class="line">vim frps.toml</span><br><span class="line"></span><br><span class="line">bindPort = 7000</span><br><span class="line">auth.token = <span class="string">&quot;sunhaoyang&quot;</span></span><br><span class="line">webServer.addr = <span class="string">&quot;0.0.0.0&quot;</span></span><br><span class="line">webServer.port = 7500</span><br><span class="line">webServer.user = <span class="string">&quot;admin&quot;</span></span><br><span class="line">webServer.password = <span class="string">&quot;admin_password&quot;</span></span><br></pre></td></tr></table></figure>

<p>Here’s a breakdown of the server parameters:</p>
<ul>
<li><p>bindPort &#x3D; 7000: This is the port the server listens on (7000), and the client connects to the server through this port.</p>
</li>
<li><p>auth.token &#x3D; “sunhaoyang”: This sets an authentication token. The client and server use this token to authenticate each other—like a key,only matching tokens can establish a connection.</p>
</li>
<li><p>webServer.addr &#x3D; “0.0.0.0”: The web server listens on all network interfaces, making it accessible from anywhere.</p>
</li>
<li><p>webServer.port &#x3D; 7500: This is the port for the web server (7500), which is used to access the FRP management interface.</p>
</li>
<li><p>webServer.user &#x3D; “admin” and webServer.password &#x3D; “admin_password”: These are the username and password for the web server, required for logging into the management interface.</p>
</li>
</ul>
<h4 id="Create-the-systemd-service-unit"><a href="#Create-the-systemd-service-unit" class="headerlink" title="Create the systemd service unit"></a>Create the systemd service unit</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /etc/systemd/system/frps.service &lt;&lt;-<span class="string">&#x27;EOF&#x27;</span></span><br><span class="line">[Unit]</span><br><span class="line">Description=FRP Server Service</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">User=root</span><br><span class="line">ExecStart=/usr/local/bin/frp/frps -c /usr/local/bin/frp/frps.toml</span><br><span class="line">Restart=on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h4 id="Start-the-service"><a href="#Start-the-service" class="headerlink" title="Start the service"></a>Start the service</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@frp-server ~]# systemctl daemon-reload</span><br><span class="line">[root@frp-server ~]# systemctl enable frps.service --now</span><br><span class="line">Created symlink /etc/systemd/system/multi-user.target.wants/frps.service → /etc/systemd/system/frps.service.</span><br><span class="line">[root@frp-server ~]# systemctl status frps.service</span><br><span class="line">● frps.service - FRP Server Service</span><br><span class="line">     Loaded: loaded (/etc/systemd/system/frps.service; enabled; preset: disabled)</span><br><span class="line">     Active: active (running) since Fri 2025-04-25 16:06:45 CST; 4s ago</span><br><span class="line">   Main PID: 355286 (frps)</span><br><span class="line">      Tasks: 5 (limit: 12344)</span><br><span class="line">     Memory: 9.0M</span><br><span class="line">        CPU: 324ms</span><br><span class="line">     CGroup: /system.slice/frps.service</span><br><span class="line">             └─355286 /usr/local/bin/frp/frps -c /usr/local/bin/frp/frps.toml</span><br><span class="line"></span><br><span class="line">Apr 25 16:06:45 frp-server systemd[1]: Started FRP Server Service.</span><br><span class="line">Apr 25 16:06:45 frp-server frps[355286]: 2025-04-25 16:06:45.952 [I] [frps/root.go:105] frps uses config file: /usr/local/bin/frp/frps.toml</span><br><span class="line">Apr 25 16:06:46 frp-server frps[355286]: 2025-04-25 16:06:46.270 [I] [server/service.go:237] frps tcp listen on 0.0.0.0:7000</span><br><span class="line">Apr 25 16:06:46 frp-server frps[355286]: 2025-04-25 16:06:46.271 [I] [frps/root.go:114] frps started successfully</span><br><span class="line">Apr 25 16:06:46 frp-server frps[355286]: 2025-04-25 16:06:46.271 [I] [server/service.go:351] dashboard listen on 0.0.0.0:7500</span><br></pre></td></tr></table></figure>

<p>Now, Try logging into the web interface on port 7500 by entering <code>http://&lt;public IP&gt;</code> in your browser!</p>
<p>From the chart, you can see the traffic and connection information. By clicking on the left, you can view details about different types of proxy.</p>
<p><img src="/../images/webui.png" alt="frps webui"></p>
<h3 id="frpc-service"><a href="#frpc-service" class="headerlink" title="frpc.service"></a>frpc.service</h3><p>For frpc.service, please just follow the operations above, similarl to the frps.service. Have a try!</p>
<h4 id="Copy-the-folder-containing-the-installation-package-and-configuration-files-to-usr-local-bin-and-configure-systemd-accordingly-1"><a href="#Copy-the-folder-containing-the-installation-package-and-configuration-files-to-usr-local-bin-and-configure-systemd-accordingly-1" class="headerlink" title="Copy the folder containing the installation package and configuration files to /usr/local/bin, and configure systemd accordingly."></a>Copy the folder containing the installation package and configuration files to <code>/usr/local/bin</code>, and configure systemd accordingly.</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@internal-sshserver ~]# mv frp_0.62.0_linux_amd64 /usr/local/bin/frp</span><br><span class="line">[root@internal-sshserver ~]# ls /usr/local/bin/frp</span><br><span class="line">frpc  frpc.toml  frps  frps.toml  LICENSE</span><br><span class="line">[root@internal-sshserver ~]# cd /usr/local/bin/frp</span><br><span class="line">[root@internal-sshserver frp]# vim frpc.toml</span><br></pre></td></tr></table></figure>

<h4 id="Supplementation-of-monitoring-Frp-server-1"><a href="#Supplementation-of-monitoring-Frp-server-1" class="headerlink" title="Supplementation of monitoring Frp server"></a>Supplementation of monitoring Frp server</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">serverAddr = &quot;x.x.x.x&quot;      # Frps&#x27;s public ip address</span><br><span class="line">serverPort = 7000           # Frps&#x27;s listening port</span><br><span class="line">auth.token = &quot;lixiaohui&quot;    # Same as the server&#x27;s auth.token above</span><br><span class="line">[[proxies]]</span><br><span class="line">name = &quot;ssh&quot;                # Proxy name</span><br><span class="line">type = &quot;tcp&quot;                # Proxy type (TCP)</span><br><span class="line">localIP = &quot;127.0.0.1&quot;       # Frpc&#x27;s service ip address</span><br><span class="line">localPort = 22              # Frpc&#x27;s listening port（e.g. SSH service）</span><br><span class="line">remotePort = 6000           # Expose port on the Frps&#x27;s server for external calling</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="Create-the-systemd-service-unit-1"><a href="#Create-the-systemd-service-unit-1" class="headerlink" title="Create the systemd service unit"></a>Create the systemd service unit</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /etc/systemd/system/frpc.service &lt;&lt;-<span class="string">&#x27;EOF&#x27;</span></span><br><span class="line">[Unit]</span><br><span class="line">Description=FRP Client Service</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">User=root</span><br><span class="line">ExecStart=/usr/local/bin/frp/frpc -c /usr/local/bin/frp/frpc.toml</span><br><span class="line">Restart=on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h4 id="Start-the-service-1"><a href="#Start-the-service-1" class="headerlink" title="Start the service"></a>Start the service</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@internal-sshserver ~]# systemctl daemon-reload</span><br><span class="line">[root@internal-sshserver ~]# systemctl enable frpc.service --now</span><br><span class="line">[root@internal-sshserver ~]# systemctl status frpc.service</span><br><span class="line">● frpc.service - FRP Client Service</span><br><span class="line">     Loaded: loaded (/etc/systemd/system/frps.service; enabled; preset: disabled)</span><br><span class="line">     Active: active (running) since Fri 2025-04-25 16:29:13 CST; 14s ago</span><br><span class="line">   Main PID: 94421 (frpc)</span><br><span class="line">      Tasks: 4 (limit: 12140)</span><br><span class="line">     Memory: 4.6M</span><br><span class="line">        CPU: 7ms</span><br><span class="line">     CGroup: /system.slice/frpc.service</span><br><span class="line">             └─94421 /usr/local/bin/frp/frpc -c /usr/local/bin/frp/frpc.toml</span><br><span class="line"></span><br><span class="line">Apr 25 16:29:13 internal-sshserver systemd[1]: Started FRP Client Service.</span><br><span class="line">Apr 25 16:29:13 internal-sshserver frpc[94421]: 2025-04-25 16:29:13.467 [I] [sub/root.go:149] start frpc service for config file [/usr/local/bin/frp/frpc.toml]</span><br><span class="line">Apr 25 16:29:13 internal-sshserver frpc[94421]: 2025-04-25 16:29:13.467 [I] [client/service.go:314] try to connect to server...</span><br><span class="line">Apr 25 16:29:13 internal-sshserver frpc[94421]: 2025-04-25 16:29:13.472 [I] [client/service.go:306] [66f9a7e320b717cd] login to server success, get run id [66f9a7e320b717cd]</span><br><span class="line">Apr 25 16:29:13 internal-sshserver frpc[94421]: 2025-04-25 16:29:13.472 [I] [proxy/proxy_manager.go:177] [66f9a7e320b717cd] proxy added: [ssh]</span><br><span class="line">Apr 25 16:29:13 internal-sshserver frpc[94421]: 2025-04-25 16:29:13.473 [I] [client/control.go:172] [66f9a7e320b717cd] [ssh] start proxy success</span><br></pre></td></tr></table></figure>

<blockquote>
<ol>
<li>The <code>bindPort</code>&#x3D;<code>serverPort</code> must be allowed in the settings of firewall. (E.g. ufw allow xxx&#x2F; firewall-cmd –permanent –add-port&#x3D;xxx)</li>
<li>Some vendor&#x2F;providers may filter the ports and the hardware firewall may block the nonstandard port.</li>
<li>systemctl enable frps.service&#x2F;frpc.service may be failed.<br>Please <code>sudo setenforce 0</code> change the selinux mode from <code>enforce</code> to <code>permissive</code>, and then <code>systemctl restart frps.service/frpc.service</code> again.</li>
<li>Selinux context should be set as <code>bin_t</code> <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> semanage fcontext -a -t bin_t <span class="string">&quot;/usr/local/bin/frp/frpc&quot;</span></span><br><span class="line"><span class="built_in">sudo</span> restorecon -v /usr/local/bin/frp/frpc</span><br></pre></td></tr></table></figure></li>
<li>Increase the interval between two failed restart processes and avoid to stop trying becasue of the frequent reboots. <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[Service]</span><br><span class="line">RestartSec=5s</span><br></pre></td></tr></table></figure></li>
</ol>
</blockquote>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Frp</tag>
      </tags>
  </entry>
  <entry>
    <title>Disable password-based SSH login and restrict SSH access to key-based authentication on Linux and Mac</title>
    <url>//Linux/SSH/Disable-password-based-SSH-login-and-restrict-SSH-access-to-key-based-authentication-on-Linux-and-Mac/index.html</url>
    <content><![CDATA[<h2 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h2><h3 id="Upload-the-public-key-to-the-taget-server"><a href="#Upload-the-public-key-to-the-taget-server" class="headerlink" title="Upload the public key to the taget server"></a>Upload the public key to the taget server</h3><p>At first, please confirm that you’ve already generated a pair of keys.</p>
<p>If you obtained a pair of keys, please skip to the second part.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># The pair of keys are often stored in this directory</span></span><br><span class="line"><span class="built_in">cd</span> ~/.ssh</span><br><span class="line"></span><br><span class="line"><span class="comment"># If you did not generate a pair of keys, please use the following command</span></span><br><span class="line"><span class="comment"># -t rsa: Specifies the type of key to create (RSA).</span></span><br><span class="line"><span class="comment"># -b 4096: Specifies the size of the key (4096 bits, which is more secure than the default 2048 bits).</span></span><br><span class="line">ssh-keygen -t rsa -b 4096</span><br><span class="line"></span><br><span class="line"><span class="comment"># If you would like to generate another kind of key</span></span><br><span class="line">ssh-keygen -t ed25519</span><br></pre></td></tr></table></figure>

<p>Then, you could upload your public key to the target server.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh-copy-id -f -i /path/to/pub/file -p port user@domain.or.ip</span><br></pre></td></tr></table></figure>

<h3 id="Modify-the-sshd-configuration"><a href="#Modify-the-sshd-configuration" class="headerlink" title="Modify the sshd configuration"></a>Modify the <code>sshd</code> configuration</h3><p>The configuration file of <code>sshd</code> in Linux locates at <code>/etc/ssh/sshd_config</code>.</p>
<blockquote>
<p><code>sshd</code> service is responsible for controlling the ingress flow.(Server)<br><code>ssh</code> service is responsible for controlling the egress flow.(Client)</p>
</blockquote>
<h4 id="Modify-manually"><a href="#Modify-manually" class="headerlink" title="Modify manually"></a>Modify manually</h4><p>Use <code>vim</code> or <code>nano</code> to edit the configuration file.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> nano /etc/ssh/sshd_config</span><br><span class="line"><span class="comment"># Or</span></span><br><span class="line"><span class="built_in">sudo</span> vim /etc/ssh/sshd_config</span><br></pre></td></tr></table></figure>

<p>Find the following specific line and modify.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Disable the password-based login</span><br><span class="line">#PasswordAuthentication yes</span><br><span class="line">PasswordAuthentication no</span><br><span class="line"></span><br><span class="line"># Enable the key-based login</span><br><span class="line">PubkeyAuthentication yes</span><br></pre></td></tr></table></figure>

<h4 id="Modify-by-sed"><a href="#Modify-by-sed" class="headerlink" title="Modify by sed"></a>Modify by <code>sed</code></h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> sed -i <span class="string">&#x27;s/^#*PasswordAuthentication[[:space:]]*.*$/PasswordAuthentication no/&#x27;</span> /etc/ssh/sshd_config</span><br><span class="line"><span class="built_in">sudo</span> sed -i <span class="string">&#x27;s/^#*PubkeyAuthentication[[:space:]]*.*$/PubkeyAuthentication yes/&#x27;</span> /etc/ssh/sshd_config</span><br></pre></td></tr></table></figure>

<h3 id="Restart-the-sshd-service"><a href="#Restart-the-sshd-service" class="headerlink" title="Restart the sshd service"></a>Restart the <code>sshd</code> service</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Restart the sshd service to make it work</span></span><br><span class="line"><span class="built_in">sudo</span> systemctl restart sshd</span><br></pre></td></tr></table></figure>

<h2 id="MacOs"><a href="#MacOs" class="headerlink" title="MacOs"></a>MacOs</h2><p>The steps for macOS are similar to those for Linux, although the location of the configuration file may differ slightly.</p>
<h3 id="Upload-the-public-key-to-the-taget-server-1"><a href="#Upload-the-public-key-to-the-taget-server-1" class="headerlink" title="Upload the public key to the taget server"></a>Upload the public key to the taget server</h3><p>As with Linux, you can use the <code>ssh-copy-id</code> command to upload the public key.</p>
<h3 id="Modify-the-sshd-configuration-1"><a href="#Modify-the-sshd-configuration-1" class="headerlink" title="Modify the sshd configuration"></a>Modify the <code>sshd</code> configuration</h3><p>In macOS, the configuration file is typically located at <code>/private/etc/ssh/sshd_config</code>.</p>
<h4 id="Modify-manually-1"><a href="#Modify-manually-1" class="headerlink" title="Modify manually"></a>Modify manually</h4><p>Use <code>vim</code> or <code>nano</code> to edit the configuration file.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> nano /private/etc/ssh/sshd_config</span><br><span class="line"><span class="comment"># Or</span></span><br><span class="line"><span class="built_in">sudo</span> vim /private/etc/ssh/sshd_config</span><br></pre></td></tr></table></figure>

<p>Then, follow the same instructions as for Linux to make the necessary changes.</p>
<h4 id="Modify-by-sed-1"><a href="#Modify-by-sed-1" class="headerlink" title="Modify by sed"></a>Modify by <code>sed</code></h4><p>On macOS, the usage of the sed command is slightly different. You need to add ‘’ -e to make edits.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> sed -i <span class="string">&#x27;&#x27;</span> <span class="string">&#x27;s/^#*UsePAM[[:space:]]*.*$/UsePAM yes/&#x27;</span> /private/etc/ssh/sshd_config</span><br><span class="line"><span class="built_in">sudo</span> sed -i <span class="string">&#x27;&#x27;</span> <span class="string">&#x27;/^#*ChallengeResponseAuthentication[[:space:]]*.*$/d&#x27;</span> /private/etc/ssh/sshd_config</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;ChallengeResponseAuthentication no&quot;</span> | <span class="built_in">sudo</span> <span class="built_in">tee</span> -a /private/etc/ssh/sshd_config &gt; /dev/null</span><br><span class="line"><span class="built_in">sudo</span> sed -i <span class="string">&#x27;&#x27;</span> <span class="string">&#x27;s/^#*PasswordAuthentication[[:space:]]*.*$/PasswordAuthentication no/&#x27;</span> /private/etc/ssh/sshd_config</span><br><span class="line"><span class="built_in">sudo</span> sed -i <span class="string">&#x27;&#x27;</span> <span class="string">&#x27;s/^#*kbdInteractiveAuthentication[[:space:]]*.*$/kbdInteractiveAuthentication no/&#x27;</span> /private/etc/ssh/sshd_config</span><br></pre></td></tr></table></figure>

<h3 id="Restart-the-sshd-service-1"><a href="#Restart-the-sshd-service-1" class="headerlink" title="Restart the sshd service"></a>Restart the <code>sshd</code> service</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> launchctl stop com.openssh.sshd</span><br><span class="line"><span class="built_in">sudo</span> launchctl start com.openssh.sshd</span><br><span class="line"><span class="comment"># Or</span></span><br><span class="line"><span class="built_in">sudo</span> launchctl unload /System/Library/LaunchDaemons/ssh.plist</span><br><span class="line"><span class="built_in">sudo</span> launchctl load -w /System/Library/LaunchDaemons/ssh.plist </span><br><span class="line"><span class="comment"># Or</span></span><br><span class="line"><span class="built_in">sudo</span> launchctl bootout system /System/Library/LaunchDaemons/ssh.plist</span><br><span class="line"><span class="built_in">sudo</span> launchctl bootstrap system /System/Library/LaunchDaemons/ssh.plist</span><br></pre></td></tr></table></figure>

<p>By following the above steps, you can effectively enhance the security of your server and avoid potential security threats.</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title>Complete Guide to Use Frp</title>
    <url>//Tools/Frp/Complete-Guide-to-Use-Frp/index.html</url>
    <content><![CDATA[<h2 id="Prerequisite"><a href="#Prerequisite" class="headerlink" title="Prerequisite"></a>Prerequisite</h2><p>Please purchase&#x2F;rent a cloud server online.</p>
<p>E.g. </p>
<ul>
<li>Tencent Cloud: <a href="https://cloud.tencent.com/">https://cloud.tencent.com/</a></li>
<li>Amazon Cloud: <a href="https://aws.amazon.com/">https://aws.amazon.com/</a></li>
<li>Ali Cloud: <a href="https://www.alibabacloud.com/">https://www.alibabacloud.com/</a></li>
</ul>
<h2 id="Download-the-frp-application-tarball-from-github"><a href="#Download-the-frp-application-tarball-from-github" class="headerlink" title="Download the frp application tarball from github"></a>Download the frp application tarball from github</h2><p>Please read the README at first in the following link.</p>
<p><a href="https://github.com/fatedier/frp">https://github.com/fatedier/frp</a></p>
<p>After that, please download the release tarball from the following link.</p>
<p><a href="https://github.com/fatedier/frp/releases">https://github.com/fatedier/frp/releases</a></p>
<p>It is complitable with different operating systems here: Windows&#x2F;Linux&#x2F;MacOS.</p>
<p>Method 1: Click the download link.</p>
<p>Method 2: CLI.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Check the basic structure</span></span><br><span class="line"><span class="built_in">uname</span> -a</span><br><span class="line"></span><br><span class="line"><span class="comment"># For example, download the amd64 structure Linux</span></span><br><span class="line">wget https://github.com/fatedier/frp/releases/download/v0.62.0/frp_0.62.0_linux_amd64.tar.gz</span><br></pre></td></tr></table></figure>

<h2 id="Modify-the-frp-server-configuration-file"><a href="#Modify-the-frp-server-configuration-file" class="headerlink" title="Modify the frp server configuration file"></a>Modify the frp server configuration file</h2><h3 id="Login-to-your-cloud-server"><a href="#Login-to-your-cloud-server" class="headerlink" title="Login to your cloud server"></a>Login to your cloud server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh root@&lt;public-ip&gt;</span><br><span class="line">&lt;Passwd&gt; Or download the pem keyfile.</span><br></pre></td></tr></table></figure>

<h3 id="Decompress-the-frp-tarball"><a href="#Decompress-the-frp-tarball" class="headerlink" title="Decompress the frp tarball"></a>Decompress the frp tarball</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar -xvf frp_0.62.0_linux_amd64.tar.gz</span><br></pre></td></tr></table></figure>

<h3 id="Edit-the-frps-toml-file"><a href="#Edit-the-frps-toml-file" class="headerlink" title="Edit the frps.toml file"></a>Edit the frps.toml file</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> frp_0.62.0_darwin_arm64</span><br><span class="line">vim frps.toml</span><br><span class="line"><span class="comment"># Change the port as you want(default 7000)</span></span><br><span class="line">bindPort = &lt;portnumber&gt;</span><br></pre></td></tr></table></figure>

<h3 id="Start-up-the-frps-service-in-the-backend"><a href="#Start-up-the-frps-service-in-the-backend" class="headerlink" title="Start up the frps service in the backend"></a>Start up the frps service in the backend</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">nohup</span> ./frps -c frps.toml &gt; frps.log 2&gt;&amp;1 &amp;</span><br><span class="line"><span class="comment"># Check the jobs status</span></span><br><span class="line"><span class="built_in">jobs</span></span><br></pre></td></tr></table></figure>

<h2 id="Modify-the-frp-client-configuration-file"><a href="#Modify-the-frp-client-configuration-file" class="headerlink" title="Modify the frp client configuration file"></a>Modify the frp client configuration file</h2><h3 id="Login-to-the-server-that-you-want-to-ssh-maybe-in-the-firewall"><a href="#Login-to-the-server-that-you-want-to-ssh-maybe-in-the-firewall" class="headerlink" title="Login to the server that you want to ssh(maybe in the firewall)"></a>Login to the server that you want to ssh(maybe in the firewall)</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh &lt;frpc-client-username&gt;@client-ip</span><br><span class="line">&lt;Passwd&gt; Or private key.</span><br></pre></td></tr></table></figure>

<h3 id="Decompress-the-frp-tarball-1"><a href="#Decompress-the-frp-tarball-1" class="headerlink" title="Decompress the frp tarball"></a>Decompress the frp tarball</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar -xvf frp_0.62.0_linux_amd64.tar.gz</span><br></pre></td></tr></table></figure>

<h3 id="Edit-the-frps-toml-file-1"><a href="#Edit-the-frps-toml-file-1" class="headerlink" title="Edit the frps.toml file"></a>Edit the frps.toml file</h3><h4 id="Method-1"><a href="#Method-1" class="headerlink" title="Method 1"></a>Method 1</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> frp_0.62.0_darwin_arm64</span><br><span class="line">vim frpc.toml</span><br><span class="line"></span><br><span class="line">serverAddr = <span class="string">&quot;&lt;the public ip you purchase in cloud&gt;&quot;</span></span><br><span class="line">serverPort = &lt;same as the frp server portnumber&gt;</span><br><span class="line"></span><br><span class="line">[[proxies]]</span><br><span class="line">name = <span class="string">&quot;&lt;set a name as you want&gt;&quot;</span></span><br><span class="line"><span class="built_in">type</span> = <span class="string">&quot;tcp&quot;</span></span><br><span class="line">localIP = <span class="string">&quot;127.0.0.1&quot;</span></span><br><span class="line">localPort = 22</span><br><span class="line">remotePort = &lt;allocate a remotePort&gt;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>If you would like to deploy more than one server, just modify the <code>name</code> and <code>remotePort</code> parameters to be different with each server.</p>
</blockquote>
<h4 id="Method-2"><a href="#Method-2" class="headerlink" title="Method 2"></a>Method 2</h4><p>Aonther method is to use <code>tcpmuxHTTPConnectPort</code> and set the same <code>serverPort</code>.</p>
<p>First, Install socat.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">dnf/apt install socat</span><br></pre></td></tr></table></figure>

<ul>
<li><p>frps:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> frp_0.62.0_darwin_arm64</span><br><span class="line">vim frps.toml</span><br><span class="line"><span class="comment"># Change the port as you want(default 7000)</span></span><br><span class="line">bindPort = &lt;portnumber&gt;</span><br><span class="line">tcpmuxHTTPConnectPort = &lt;portnumber&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>frpc:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">serverAddr = <span class="string">&quot;x.x.x.x&quot;</span></span><br><span class="line">serverPort = 7000</span><br><span class="line"></span><br><span class="line">[[proxies]]</span><br><span class="line">name = <span class="string">&quot;&lt;set a name as you want&gt;&quot;</span></span><br><span class="line"><span class="built_in">type</span> = <span class="string">&quot;tcpmux&quot;</span></span><br><span class="line">multiplexer = <span class="string">&quot;httpconnect&quot;</span></span><br><span class="line">customDomains = [<span class="string">&quot;&lt;set a domain name as you want&gt;&quot;</span>]</span><br><span class="line">localIP = <span class="string">&quot;127.0.0.1&quot;</span></span><br><span class="line">localPort = 22</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="Start-up-the-frpc-service-in-the-backend"><a href="#Start-up-the-frpc-service-in-the-backend" class="headerlink" title="Start up the frpc service in the backend"></a>Start up the frpc service in the backend</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">nohup</span> ./frpc -c frpc.toml &gt; frpc.log 2&gt;&amp;1 &amp;</span><br><span class="line"><span class="comment"># Check the jobs status</span></span><br><span class="line"><span class="built_in">jobs</span></span><br></pre></td></tr></table></figure>

<h2 id="How-to-use"><a href="#How-to-use" class="headerlink" title="How to use"></a>How to use</h2><p>Server A -&gt; Server B(in firewall or internel network)</p>
<h3 id="Method-1-1"><a href="#Method-1-1" class="headerlink" title="Method 1"></a>Method 1</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh -p &lt;remotePort&gt; &lt;serverB-username&gt;@&lt;public-ip you purchase <span class="keyword">in</span> cloud&gt;</span><br><span class="line">=&gt; serverB-username <span class="keyword">in</span> serverB<span class="string">&#x27;s password or private key.</span></span><br></pre></td></tr></table></figure>

<h3 id="Method-2-1"><a href="#Method-2-1" class="headerlink" title="Method 2"></a>Method 2</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh -o <span class="string">&#x27;proxycommand socat - PROXY:&lt;public ip you purchase in cloud&gt;:%h:%p,proxyport=&lt;same as the tcpmuxHTTPConnectPort number&gt;&#x27;</span> &lt;serverB-username&gt;@&lt;domain name&gt;</span><br></pre></td></tr></table></figure>

<p>Up to now, you’ve successfully use <code>frp</code> service to access services&#x2F;servers located within the internal network.</p>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Frp</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenStack Series Chapter0: Creating and Deleting VMs instaces(2)</title>
    <url>//Cloud/OpenStack/Creating-and-Deleting-VMs-instaces(2)/index.html</url>
    <content><![CDATA[<h2 id="Environment"><a href="#Environment" class="headerlink" title="Environment"></a>Environment</h2><h3 id="Undercloud"><a href="#Undercloud" class="headerlink" title="Undercloud"></a>Undercloud</h3><p>director.lab.example.com : <code>172.25.250.60</code></p>
<h3 id="Overcloud"><a href="#Overcloud" class="headerlink" title="Overcloud"></a>Overcloud</h3><ul>
<li>controller0.lab.example.com : <code>172.25.250.1</code></li>
<li>compute0.lab.example.com : <code>172.25.250.70</code></li>
<li>computehci0.lab.example.com : <code>172.25.250.21</code></li>
</ul>
<h3 id="Domain-Name"><a href="#Domain-Name" class="headerlink" title="Domain Name"></a>Domain Name</h3><p><code>Haoyang</code></p>
<h3 id="Project-Name"><a href="#Project-Name" class="headerlink" title="Project Name"></a>Project Name</h3><p><code>Engineering</code></p>
<p>Project <code>Engineering</code> belongs to the Domain <code>Haoyang</code></p>
<h3 id="Operation-Steps"><a href="#Operation-Steps" class="headerlink" title="Operation Steps"></a>Operation Steps</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Remotely login to the workstation node</span></span><br><span class="line">ssh student@workstation</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@Flash-shy ~ % ssh student@172.16.2.212</span><br><span class="line">student@172.16.2.212&#x27;s password: </span><br><span class="line">Activate the web console with: systemctl enable --now cockpit.socket</span><br><span class="line"></span><br><span class="line">This system is not registered to Red Hat Insights. See https://cloud.redhat.com/</span><br><span class="line">To register this system, run: insights-client --register</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Login to the undercloud director node</span></span><br><span class="line">ssh director</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[student@workstation ~]$ ssh director</span><br><span class="line">Activate the web console with: systemctl enable --now cockpit.socket</span><br><span class="line"></span><br><span class="line">This system is not registered to Red Hat Insights. See https://cloud.redhat.com/</span><br><span class="line">To register this system, run: insights-client --register</span><br><span class="line"></span><br><span class="line">Last login: Sun Apr 13 22:29:34 2025 from xxx.xxx.xxx.xxx</span><br><span class="line">(undercloud) [stack@director ~]$</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Use the administrator credential</span><br><span class="line">(undercloud) [stack@director ~]$ source overcloudrc </span><br><span class="line">(overcloud) [stack@director ~]$ </span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Firstly, create the domain</span><br><span class="line">(overcloud) [stack@director ~]$ openstack domain create Haoyang</span><br><span class="line">+-------------+----------------------------------+</span><br><span class="line">| Field       | Value                            |</span><br><span class="line">+-------------+----------------------------------+</span><br><span class="line">| description |                                  |</span><br><span class="line">| enabled     | True                             |</span><br><span class="line">| id          | 5ecb4e207166423494f02ade2d289efe |</span><br><span class="line">| name        | Haoyang                          |</span><br><span class="line">| options     | &#123;&#125;                               |</span><br><span class="line">| tags        | []                               |</span><br><span class="line">+-------------+----------------------------------+</span><br><span class="line"></span><br><span class="line"># Check the list of domain</span><br><span class="line">(overcloud) [stack@director ~]$ openstack domain list</span><br><span class="line">+----------------------------------+------------+---------+--------------------+</span><br><span class="line">| ID                               | Name       | Enabled | Description        |</span><br><span class="line">+----------------------------------+------------+---------+--------------------+</span><br><span class="line">| 1e9c34fd067a4c88a14959ce575aeb45 | heat_stack | True    |                    |</span><br><span class="line">| 4a52dcec731b418bb656f69dc4e0cc71 | Example    | True    | Example Domain     |</span><br><span class="line">| 5ecb4e207166423494f02ade2d289efe | Haoyang    | True    |                    |</span><br><span class="line">| default                          | Default    | True    | The default domain |</span><br><span class="line">+----------------------------------+------------+---------+--------------------+</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Create the project</span><br><span class="line">(overcloud) [stack@director ~]$ openstack project create --domain Haoyang Engineering</span><br><span class="line">+-------------+----------------------------------+</span><br><span class="line">| Field       | Value                            |</span><br><span class="line">+-------------+----------------------------------+</span><br><span class="line">| description |                                  |</span><br><span class="line">| domain_id   | 5ecb4e207166423494f02ade2d289efe |</span><br><span class="line">| enabled     | True                             |</span><br><span class="line">| id          | ec0e24ddf10841b08ae63fe094e25587 |</span><br><span class="line">| is_domain   | False                            |</span><br><span class="line">| name        | Engineering                      |</span><br><span class="line">| options     | &#123;&#125;                               |</span><br><span class="line">| parent_id   | 5ecb4e207166423494f02ade2d289efe |</span><br><span class="line">| tags        | []                               |</span><br><span class="line">+-------------+----------------------------------+</span><br><span class="line"></span><br><span class="line"># Check the list of project</span><br><span class="line">(overcloud) [stack@director ~]$ openstack project list --domain Haoyang</span><br><span class="line">+----------------------------------+-------------+</span><br><span class="line">| ID                               | Name        |</span><br><span class="line">+----------------------------------+-------------+</span><br><span class="line">| ec0e24ddf10841b08ae63fe094e25587 | Engineering |</span><br><span class="line">+----------------------------------+-------------+</span><br></pre></td></tr></table></figure>

<h2 id="User"><a href="#User" class="headerlink" title="User"></a>User</h2><ul>
<li>Robert serves as the Engineering project administrator.</li>
<li>William is a member of the Engineering project and is not permitted administrator access.</li>
<li>All users within the Engineering project belong to the Haoyang domain.</li>
<li>The password for all users is <code>Flectrag</code>.</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Use the administrator credential</span><br><span class="line">(overcloud) [stack@director ~]$ source overcloudrc</span><br><span class="line"></span><br><span class="line"># Create the users</span><br><span class="line">(undercloud) [stack@director ~]$ openstack user create -h</span><br><span class="line">(overcloud) [stack@director ~]$ openstack user create \</span><br><span class="line">&gt; --domain Haoyang \</span><br><span class="line">&gt; --project Engineering \</span><br><span class="line">&gt; --project-domain Haoyang \</span><br><span class="line">&gt; --password Flectrag \</span><br><span class="line">&gt; Robert</span><br><span class="line">+---------------------+----------------------------------+</span><br><span class="line">| Field               | Value                            |</span><br><span class="line">+---------------------+----------------------------------+</span><br><span class="line">| default_project_id  | ec0e24ddf10841b08ae63fe094e25587 |</span><br><span class="line">| domain_id           | 5ecb4e207166423494f02ade2d289efe |</span><br><span class="line">| enabled             | True                             |</span><br><span class="line">| id                  | 5a7970ef27424053913c54ebb85ae123 |</span><br><span class="line">| name                | Robert                           |</span><br><span class="line">| options             | &#123;&#125;                               |</span><br><span class="line">| password_expires_at | None                             |</span><br><span class="line">+---------------------+----------------------------------+</span><br><span class="line"></span><br><span class="line">(overcloud) [stack@director ~]$ openstack user create \</span><br><span class="line">&gt; --domain Haoyang \</span><br><span class="line">&gt; --project Engineering \</span><br><span class="line">&gt; --project-domain Haoyang \</span><br><span class="line">&gt; --password Flectrag \</span><br><span class="line">&gt; William</span><br><span class="line">+---------------------+----------------------------------+</span><br><span class="line">| Field               | Value                            |</span><br><span class="line">+---------------------+----------------------------------+</span><br><span class="line">| default_project_id  | ec0e24ddf10841b08ae63fe094e25587 |</span><br><span class="line">| domain_id           | 5ecb4e207166423494f02ade2d289efe |</span><br><span class="line">| enabled             | True                             |</span><br><span class="line">| id                  | 9615d8cee44947a4bbce4e490f1391e4 |</span><br><span class="line">| name                | William                          |</span><br><span class="line">| options             | &#123;&#125;                               |</span><br><span class="line">| password_expires_at | None                             |</span><br><span class="line">+---------------------+----------------------------------+</span><br><span class="line"></span><br><span class="line"># Check the results</span><br><span class="line">(overcloud) [stack@director ~]$ openstack user list --domain Haoyang</span><br><span class="line">+----------------------------------+---------+</span><br><span class="line">| ID                               | Name    |</span><br><span class="line">+----------------------------------+---------+</span><br><span class="line">| 5a7970ef27424053913c54ebb85ae123 | Robert  |</span><br><span class="line">| 9615d8cee44947a4bbce4e490f1391e4 | William |</span><br><span class="line">+----------------------------------+---------+</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Allocate the role to users</span><br><span class="line">(overcloud) [stack@director ~]$ openstack role add \</span><br><span class="line">&gt; --project Engineering \</span><br><span class="line">&gt; --user Robert \</span><br><span class="line">&gt; --user-domain Haoyang \</span><br><span class="line">&gt; --project-domain Haoyang \</span><br><span class="line">&gt; admin</span><br><span class="line"></span><br><span class="line">(overcloud) [stack@director ~]$ openstack role add \</span><br><span class="line">&gt; --project Engineering \</span><br><span class="line">&gt; --user William \</span><br><span class="line">&gt; --user-domain Haoyang \</span><br><span class="line">&gt; --project-domain Haoyang \</span><br><span class="line">&gt; member</span><br><span class="line"></span><br><span class="line"># Check the results</span><br><span class="line">(overcloud) [stack@director ~]$ openstack role assignment list --project-domain Haoyang --project Engineering --names</span><br><span class="line">+--------+-----------------+-------+---------------------+--------+--------+-----------+</span><br><span class="line">| Role   | User            | Group | Project             | Domain | System | Inherited |</span><br><span class="line">+--------+-----------------+-------+---------------------+--------+--------+-----------+</span><br><span class="line">| admin  | Robert@Haoyang  |       | Engineering@Haoyang |        |        | False     |</span><br><span class="line">| member | William@Haoyang |       | Engineering@Haoyang |        |        | False     |</span><br><span class="line">+--------+-----------------+-------+---------------------+--------+--------+-----------+</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Create the user called Robert credential for administration</span><br><span class="line">(overcloud) [stack@director ~]$ cp overcloudrc robertrc</span><br><span class="line">(overcloud) [stack@director ~]$ vim robertrc </span><br><span class="line"># Modify 5 line contents in total</span><br><span class="line">export OS_USERNAME=Robert</span><br><span class="line">export OS_PROJECT_NAME=Engineering</span><br><span class="line">export OS_USER_DOMAIN_NAME=Haoyang</span><br><span class="line">export OS_PROJECT_DOMAIN_NAME=Haoyang</span><br><span class="line">export OS_PASSWORD=Flectrag</span><br></pre></td></tr></table></figure>

<h2 id="Image-and-Flavor"><a href="#Image-and-Flavor" class="headerlink" title="Image and Flavor"></a>Image and Flavor</h2><h3 id="Image"><a href="#Image" class="headerlink" title="Image"></a>Image</h3><ul>
<li>Name: web</li>
<li>Format: QCOW2</li>
<li>Source: <a href="http://materials.example.com/osp-small.qcow2">http://materials.example.com/osp-small.qcow2</a></li>
</ul>
<h3 id="Flavor"><a href="#Flavor" class="headerlink" title="Flavor"></a>Flavor</h3><ul>
<li>Name: m1.petite</li>
<li>RAM: 1024MB</li>
<li>CPUs: 1</li>
<li>Disk: 10GB</li>
</ul>
<h3 id="Operation-Steps-1"><a href="#Operation-Steps-1" class="headerlink" title="Operation Steps"></a>Operation Steps</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Use the robert&#x27;s credential to manage openstack resources</span><br><span class="line">(overcloud) [stack@director ~]$ source robertrc</span><br><span class="line"></span><br><span class="line"># Obtain the basic qcow2 image</span><br><span class="line">(overcloud) [stack@director ~]$ wget http://materials.example.com/osp-small.qcow2</span><br><span class="line">--2025-04-14 09:05:27--  http://materials.example.com/osp-small.qcow2</span><br><span class="line">Resolving materials.example.com (materials.example.com)... 172.25.254.254</span><br><span class="line">Connecting to materials.example.com (materials.example.com)|172.25.254.254|:80... connected.</span><br><span class="line">HTTP request sent, awaiting response... 200 OK</span><br><span class="line">Length: 656867328 (626M)</span><br><span class="line">Saving to: &#x27;osp-small.qcow2&#x27;</span><br><span class="line"></span><br><span class="line">osp-small.qcow2             100%[===========================================&gt;] 626.44M   563MB/s    in 1.1s    </span><br><span class="line"></span><br><span class="line">2025-04-14 09:05:28 (563 MB/s) - &#x27;osp-small.qcow2&#x27; saved [656867328/656867328]</span><br><span class="line"></span><br><span class="line"># Create the image</span><br><span class="line">(overcloud) [stack@director ~]$ openstack image create \</span><br><span class="line">&gt; --disk-format qcow2 \</span><br><span class="line">&gt; --file osp-small.qcow2 \</span><br><span class="line">&gt; --public \</span><br><span class="line">&gt; web</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Create the flavor</span><br><span class="line">(overcloud) [stack@director ~]$ openstack flavor create \</span><br><span class="line">&gt; --vcpus 1 \</span><br><span class="line">&gt; --ram 1024 \</span><br><span class="line">&gt; --disk 10 \</span><br><span class="line">&gt; --public \</span><br><span class="line">&gt; m1.petite</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Check the image</span><br><span class="line">(overcloud) [stack@director ~]$ openstack image list </span><br><span class="line">+--------------------------------------+---------------------------------------------------------+--------+</span><br><span class="line">| ID                                   | Name                                                    | Status |</span><br><span class="line">+--------------------------------------+---------------------------------------------------------+--------+</span><br><span class="line">| 81a8fbe6-aeb5-4322-accb-e569b65fe92d | octavia-amphora-16.1-20200812.3.x86_64                  | active |</span><br><span class="line">| 8930ccbb-0ff0-4b8c-b0c5-d29a8a6903ec | octavia-amphora-16.1-20200812.3.x86_64_20201030T152228Z | active |</span><br><span class="line">| 65719e96-84bc-4132-ac80-742fdb6b367c | octavia-amphora-16.1-20200812.3.x86_64_20210303T085358Z | active |</span><br><span class="line">| 7dcd09a5-be2a-4f73-9dff-2ff403dea016 | rhel7-todo-app1                                         | active |</span><br><span class="line">| 5b180c17-658a-4a38-af07-efd2e30bed70 | rhel7-todo-db                                           | active |</span><br><span class="line">| 74a8ae00-9e7d-4b73-9016-98a78c04f153 | rhel7-todo-web                                          | active |</span><br><span class="line">| 1c4d5d8e-2881-4870-b922-13aaf4d2ab5f | rhel8                                                   | active |</span><br><span class="line">| c458af77-3748-401a-a4df-f55562d285cb | rhel8-db                                                | active |</span><br><span class="line">| a1449cf0-3b0e-40d1-8ce8-37ac4d30c953 | rhel8-web                                               | active |</span><br><span class="line">| 517aad0e-097f-4137-a300-be11b9f01d22 | web                                                     | active |</span><br><span class="line">+--------------------------------------+---------------------------------------------------------+--------+</span><br><span class="line"></span><br><span class="line"># Check the flavor</span><br><span class="line">(overcloud) [stack@director ~]$ openstack flavor list</span><br><span class="line">+--------------------------------------+--------------------+------+------+-----------+-------+-----------+</span><br><span class="line">| ID                                   | Name               |  RAM | Disk | Ephemeral | VCPUs | Is Public |</span><br><span class="line">+--------------------------------------+--------------------+------+------+-----------+-------+-----------+</span><br><span class="line">| 51b6a59f-4bee-4d5d-9c43-82cb67cd08fa | default-extra-disk | 2048 |   10 |         5 |     2 | True      |</span><br><span class="line">| 5c417e2d-9b66-4486-a835-507caa868b73 | default-swap       | 2048 |   10 |         0 |     2 | True      |</span><br><span class="line">| 8fb411dd-bfe8-469c-bb64-9d96c0164e08 | default            | 2048 |   10 |         0 |     2 | True      |</span><br><span class="line">| f64ea5f0-093e-4281-baaf-37c4033326a2 | m1.petite          | 1024 |   10 |         0 |     1 | True      |</span><br><span class="line">+--------------------------------------+--------------------+------+------+-----------+-------+-----------+</span><br></pre></td></tr></table></figure>

<h2 id="Security-Group-and-KeyPairs"><a href="#Security-Group-and-KeyPairs" class="headerlink" title="Security Group and KeyPairs"></a>Security Group and KeyPairs</h2><h3 id="Security-Group"><a href="#Security-Group" class="headerlink" title="Security Group"></a>Security Group</h3><ul>
<li><p>ssh: allow port 22 and all ICMP ping</p>
</li>
<li><p>web: allow port 80</p>
</li>
</ul>
<h3 id="KeyPairs"><a href="#KeyPairs" class="headerlink" title="KeyPairs"></a>KeyPairs</h3><ul>
<li><p>Name: webkey</p>
</li>
<li><p>Store Path: in director.lab.example.com &#x2F;home&#x2F;stack&#x2F;webkey.pem</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(overcloud) [stack@director ~]$ source robertrc</span><br><span class="line"></span><br><span class="line"># Create the security group</span><br><span class="line">(overcloud) [stack@director ~]$ openstack security group create ssh</span><br><span class="line"></span><br><span class="line"># Create the rule</span><br><span class="line">(overcloud) [stack@director ~]$ openstack security group rule create \</span><br><span class="line">&gt; --protocol tcp \</span><br><span class="line">&gt; --dst-port 22 \</span><br><span class="line">&gt; ssh</span><br><span class="line"></span><br><span class="line">(overcloud) [stack@director ~]$ openstack security group rule create \</span><br><span class="line">&gt; --protocol icmp \</span><br><span class="line">&gt; ssh</span><br><span class="line"></span><br><span class="line"># Create the other security group</span><br><span class="line">(overcloud) [stack@director ~]$ openstack security group create web</span><br><span class="line"></span><br><span class="line"># Create the rule</span><br><span class="line">(overcloud) [stack@director ~]$ openstack security group rule create \</span><br><span class="line">&gt; --protocol tcp \</span><br><span class="line">&gt; --dst-port 80 \</span><br><span class="line">&gt; web</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Check the results</span><br><span class="line">(overcloud) [stack@director ~]$ openstack security group list</span><br><span class="line">+--------------------------------------+-----------------------+------------------------+----------------------------------+------+</span><br><span class="line">| ID                                   | Name                  | Description            | Project                          | Tags |</span><br><span class="line">+--------------------------------------+-----------------------+------------------------+----------------------------------+------+</span><br><span class="line">| 390b4a25-4acf-48d4-a720-65a04d8278d2 | default               | Default security group | 5d0b01fa01dc48d8b04e306d40edcaeb | []   |</span><br><span class="line">| 4714ea88-543d-4a2a-ba02-6efd30e5754a | ssh                   | ssh                    | ec0e24ddf10841b08ae63fe094e25587 | []   |</span><br><span class="line">| 50d69cd1-a7ff-452a-a458-db72d360c774 | default               | Default security group | 5b51457605f64326a7fac5f66654045e | []   |</span><br><span class="line">| 5d2cf43b-25d7-4b60-a621-1124d9385e1a | default               | Default security group | 28e8e03be4f14efcbbf0618bdf135f25 | []   |</span><br><span class="line">| 8dfce81b-8906-4444-aa3f-c410f464b3ba | lb-health-mgr-sec-grp | lb-health-mgr-sec-grp  | 28e8e03be4f14efcbbf0618bdf135f25 | []   |</span><br><span class="line">| b2c48588-7f5e-4aeb-9b68-f44c0bc08b7b | default               | Default security group | ec0e24ddf10841b08ae63fe094e25587 | []   |</span><br><span class="line">| b52d709b-1336-4a5a-b08e-e9d86c9e07c5 | web                   | web                    | ec0e24ddf10841b08ae63fe094e25587 | []   |</span><br><span class="line">| c83d517a-85bb-458a-8ff4-d7cc5efdcc32 | default               | Default security group | 50e6fca93606496b8a6c043957e4cb1d | []   |</span><br><span class="line">| ef0cee68-2e5f-4204-8b2d-dbba29e13c69 | lb-mgmt-sec-grp       | lb-mgmt-sec-grp        | 28e8e03be4f14efcbbf0618bdf135f25 | []   |</span><br><span class="line">+--------------------------------------+-----------------------+------------------------+----------------------------------+------+</span><br><span class="line"></span><br><span class="line">(overcloud) [stack@director ~]$ openstack security group show web</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Create the keyPairs</span><br><span class="line">(overcloud) [stack@director ~]$ openstack keypair create webkey &gt; /home/stack/webkey.pem</span><br><span class="line"></span><br><span class="line"># Modify the permission</span><br><span class="line">(overcloud) [stack@director ~]$ chmod 600 /home/stack/webkey.pem</span><br><span class="line"></span><br><span class="line"># Check the keypair list</span><br><span class="line">(overcloud) [stack@director ~]$ openstack keypair list</span><br><span class="line">+--------+-------------------------------------------------+</span><br><span class="line">| Name   | Fingerprint                                     |</span><br><span class="line">+--------+-------------------------------------------------+</span><br><span class="line">| webkey | f7:e8:e4:be:4a:30:88:50:c2:f0:ec:99:bd:3a:11:c0 |</span><br><span class="line">+--------+-------------------------------------------------+</span><br></pre></td></tr></table></figure>

<h2 id="Network"><a href="#Network" class="headerlink" title="Network"></a>Network</h2><h3 id="Internal-Network"><a href="#Internal-Network" class="headerlink" title="Internal Network:"></a>Internal Network:</h3><ul>
<li>Network name: engnet</li>
<li>Subnet name: engsubnet</li>
<li>Network address: 192.168.101.0&#x2F;24</li>
<li>DHCP enabled: Yes</li>
</ul>
<h3 id="External-Network"><a href="#External-Network" class="headerlink" title="External Network:"></a>External Network:</h3><ul>
<li>Network name: public</li>
<li>Provider network type: Flat</li>
<li>ML2 physical network name: datacentre</li>
<li>Subnet name: external</li>
<li>Network address: 172.25.250.0&#x2F;24</li>
<li>Allocation pool: 172.25.250.101 - 172.25.250.109</li>
<li>External: Yes</li>
<li>DHCP enabled: No</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(overcloud) [stack@director ~]$ openstack subnet create \</span><br><span class="line">&gt; --dhcp \</span><br><span class="line">&gt; --subnet-range 192.168.101.0/24 \</span><br><span class="line">&gt; --network engnet \</span><br><span class="line">&gt; engsubnet</span><br><span class="line">+-------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">| Field             | Value                                                                                                                                                                  |</span><br><span class="line">+-------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">| allocation_pools  | 192.168.101.2-192.168.101.254                                                                                                                                          |</span><br><span class="line">| cidr              | 192.168.101.0/24                                                                                                                                                       |</span><br><span class="line">| created_at        | 2025-04-14T13:22:26Z                                                                                                                                                   |</span><br><span class="line">| description       |                                                                                                                                                                        |</span><br><span class="line">| dns_nameservers   |                                                                                                                                                                        |</span><br><span class="line">| enable_dhcp       | True                                                                                                                                                                   |</span><br><span class="line">| gateway_ip        | 192.168.101.1                                                                                                                                                          |</span><br><span class="line">| host_routes       |                                                                                                                                                                        |</span><br><span class="line">| id                | ff1be714-007c-4f19-bbc4-824b4509c8c5                                                                                                                                   |</span><br><span class="line">| ip_version        | 4                                                                                                                                                                      |</span><br><span class="line">| ipv6_address_mode | None                                                                                                                                                                   |</span><br><span class="line">| ipv6_ra_mode      | None                                                                                                                                                                   |</span><br><span class="line">| location          | cloud=&#x27;&#x27;, project.domain_id=, project.domain_name=&#x27;Haoyang&#x27;, project.id=&#x27;ec0e24ddf10841b08ae63fe094e25587&#x27;, project.name=&#x27;Engineering&#x27;, region_name=&#x27;regionOne&#x27;, zone= |</span><br><span class="line">| name              | engsubnet                                                                                                                                                              |</span><br><span class="line">| network_id        | 289659f2-b4eb-43c4-88d4-e368e1e59b0d                                                                                                                                   |</span><br><span class="line">| prefix_length     | None                                                                                                                                                                   |</span><br><span class="line">| project_id        | ec0e24ddf10841b08ae63fe094e25587                                                                                                                                       |</span><br><span class="line">| revision_number   | 0                                                                                                                                                                      |</span><br><span class="line">| segment_id        | None                                                                                                                                                                   |</span><br><span class="line">| service_types     |                                                                                                                                                                        |</span><br><span class="line">| subnetpool_id     | None                                                                                                                                                                   |</span><br><span class="line">| tags              |                                                                                                                                                                        |</span><br><span class="line">| updated_at        | 2025-04-14T13:22:26Z                                                                                                                                                   |</span><br><span class="line">+-------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(overcloud) [stack@director ~]$ grep -e 172.25.250 /home/stack/templates/classroom-environment/32-network-environment.yaml </span><br><span class="line">  ExternalNetCidr: &#x27;172.25.250.0/24&#x27;</span><br><span class="line">  ExternalAllocationPools: [&#123;&#x27;start&#x27;: &#x27;172.25.250.60&#x27;, &#x27;end&#x27;: &#x27;172.25.250.99&#x27;&#125;]</span><br><span class="line">  ExternalInterfaceDefaultRoute: &#x27;172.25.250.254&#x27;</span><br><span class="line">  DnsServers: [&#x27;172.25.250.254&#x27;,&#x27;8.8.8.8&#x27;]</span><br><span class="line">        source: 172.25.250.0/24</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Note:<br>The following error will occur during creation, as only one external network is allowed.<br>The system has already created provider-datacentre.<br>Please delete it first before recreating.</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(overcloud) [stack@director ~]$ openstack network create \</span><br><span class="line">&gt; --external \</span><br><span class="line">&gt; --provider-network-type flat \</span><br><span class="line">&gt; --provider-physical-network datacentre \</span><br><span class="line">&gt; public</span><br><span class="line">Error while executing command: ConflictException: 409, Unable to create the flat network. Physical network datacentre is in use.</span><br><span class="line"></span><br><span class="line">(overcloud) [stack@director ~]$ openstack network delete provider-datacentre</span><br><span class="line"></span><br><span class="line">(overcloud) [stack@director ~]$ openstack network create --external --provider-network-type flat --provider-physical-network datacentre public</span><br><span class="line">+---------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">| Field                     | Value                                                                                                                                                                  |</span><br><span class="line">+---------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">| admin_state_up            | UP                                                                                                                                                                     |</span><br><span class="line">| availability_zone_hints   |                                                                                                                                                                        |</span><br><span class="line">| availability_zones        |                                                                                                                                                                        |</span><br><span class="line">| created_at                | 2025-04-14T13:24:32Z                                                                                                                                                   |</span><br><span class="line">| description               |                                                                                                                                                                        |</span><br><span class="line">| dns_domain                |                                                                                                                                                                        |</span><br><span class="line">| id                        | 775da214-c50b-4f51-b2eb-60c631316a09                                                                                                                                   |</span><br><span class="line">| ipv4_address_scope        | None                                                                                                                                                                   |</span><br><span class="line">| ipv6_address_scope        | None                                                                                                                                                                   |</span><br><span class="line">| is_default                | False                                                                                                                                                                  |</span><br><span class="line">| is_vlan_transparent       | None                                                                                                                                                                   |</span><br><span class="line">| location                  | cloud=&#x27;&#x27;, project.domain_id=, project.domain_name=&#x27;Haoyang&#x27;, project.id=&#x27;ec0e24ddf10841b08ae63fe094e25587&#x27;, project.name=&#x27;Engineering&#x27;, region_name=&#x27;regionOne&#x27;, zone= |</span><br><span class="line">| mtu                       | 1500                                                                                                                                                                   |</span><br><span class="line">| name                      | public                                                                                                                                                                 |</span><br><span class="line">| port_security_enabled     | True                                                                                                                                                                   |</span><br><span class="line">| project_id                | ec0e24ddf10841b08ae63fe094e25587                                                                                                                                       |</span><br><span class="line">| provider:network_type     | flat                                                                                                                                                                   |</span><br><span class="line">| provider:physical_network | datacentre                                                                                                                                                             |</span><br><span class="line">| provider:segmentation_id  | None                                                                                                                                                                   |</span><br><span class="line">| qos_policy_id             | None                                                                                                                                                                   |</span><br><span class="line">| revision_number           | 1                                                                                                                                                                      |</span><br><span class="line">| router:external           | External                                                                                                                                                               |</span><br><span class="line">| segments                  | None                                                                                                                                                                   |</span><br><span class="line">| shared                    | False                                                                                                                                                                  |</span><br><span class="line">| status                    | ACTIVE                                                                                                                                                                 |</span><br><span class="line">| subnets                   |                                                                                                                                                                        |</span><br><span class="line">| tags                      |                                                                                                                                                                        |</span><br><span class="line">| updated_at                | 2025-04-14T13:24:32Z                                                                                                                                                   |</span><br><span class="line">+---------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(overcloud) [stack@director ~]$ openstack subnet create \</span><br><span class="line">&gt; --no-dhcp \</span><br><span class="line">&gt; --subnet-range 172.25.250.0/24 \</span><br><span class="line">&gt; --allocation-pool start=172.25.250.101,end=172.25.250.109 \</span><br><span class="line">&gt; --gateway 172.25.250.254 \</span><br><span class="line">&gt; --dns-nameserver 172.25.250.254 \</span><br><span class="line">&gt; --network public \</span><br><span class="line">&gt; external</span><br><span class="line">+-------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">| Field             | Value                                                                                                                                                                  |</span><br><span class="line">+-------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">| allocation_pools  | 172.25.250.101-172.25.250.109                                                                                                                                          |</span><br><span class="line">| cidr              | 172.25.250.0/24                                                                                                                                                        |</span><br><span class="line">| created_at        | 2025-04-14T13:25:27Z                                                                                                                                                   |</span><br><span class="line">| description       |                                                                                                                                                                        |</span><br><span class="line">| dns_nameservers   | 172.25.250.254                                                                                                                                                         |</span><br><span class="line">| enable_dhcp       | False                                                                                                                                                                  |</span><br><span class="line">| gateway_ip        | 172.25.250.254                                                                                                                                                         |</span><br><span class="line">| host_routes       |                                                                                                                                                                        |</span><br><span class="line">| id                | 5210573a-60d9-4c43-bab6-66ec77297b9f                                                                                                                                   |</span><br><span class="line">| ip_version        | 4                                                                                                                                                                      |</span><br><span class="line">| ipv6_address_mode | None                                                                                                                                                                   |</span><br><span class="line">| ipv6_ra_mode      | None                                                                                                                                                                   |</span><br><span class="line">| location          | cloud=&#x27;&#x27;, project.domain_id=, project.domain_name=&#x27;Haoyang&#x27;, project.id=&#x27;ec0e24ddf10841b08ae63fe094e25587&#x27;, project.name=&#x27;Engineering&#x27;, region_name=&#x27;regionOne&#x27;, zone= |</span><br><span class="line">| name              | external                                                                                                                                                               |</span><br><span class="line">| network_id        | 775da214-c50b-4f51-b2eb-60c631316a09                                                                                                                                   |</span><br><span class="line">| prefix_length     | None                                                                                                                                                                   |</span><br><span class="line">| project_id        | ec0e24ddf10841b08ae63fe094e25587                                                                                                                                       |</span><br><span class="line">| revision_number   | 0                                                                                                                                                                      |</span><br><span class="line">| segment_id        | None                                                                                                                                                                   |</span><br><span class="line">| service_types     |                                                                                                                                                                        |</span><br><span class="line">| subnetpool_id     | None                                                                                                                                                                   |</span><br><span class="line">| tags              |                                                                                                                                                                        |</span><br><span class="line">| updated_at        | 2025-04-14T13:25:27Z                                                                                                                                                   |</span><br><span class="line">+-------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(overcloud) [stack@director ~]$ openstack network list</span><br><span class="line">+--------------------------------------+---------------------+--------------------------------------+</span><br><span class="line">| ID                                   | Name                | Subnets                              |</span><br><span class="line">+--------------------------------------+---------------------+--------------------------------------+</span><br><span class="line">| 289659f2-b4eb-43c4-88d4-e368e1e59b0d | engnet              | ff1be714-007c-4f19-bbc4-824b4509c8c5 |</span><br><span class="line">| 775da214-c50b-4f51-b2eb-60c631316a09 | public              | 5210573a-60d9-4c43-bab6-66ec77297b9f |</span><br><span class="line">| d71997c1-1670-4ebe-b6f7-2c4aa8dcbc7b | lb-mgmt-net         | f772a67a-341d-413f-90ab-bf2163842a43 |</span><br><span class="line">| d75263e1-754d-4276-a663-9188216f86e6 | production-network1 | b232a80d-fe12-4ee6-a01e-b3404dcb522f |</span><br><span class="line">| dcf783e3-c104-4f21-99c3-0093364b4c81 | provider-storage    | 83c7dd52-f1d2-4f39-9ece-16b4f0942dac |</span><br><span class="line">| e6a61a45-ff39-4eb1-aac2-8e0ac624f7e5 | finance-network1    | b4df8042-184b-494f-8a72-2ec171327408 |</span><br><span class="line">+--------------------------------------+---------------------+--------------------------------------+</span><br><span class="line">(overcloud) [stack@director ~]$ openstack  subnet list</span><br><span class="line">+--------------------------------------+--------------------------+--------------------------------------+------------------+</span><br><span class="line">| ID                                   | Name                     | Network                              | Subnet           |</span><br><span class="line">+--------------------------------------+--------------------------+--------------------------------------+------------------+</span><br><span class="line">| 5210573a-60d9-4c43-bab6-66ec77297b9f | external                 | 775da214-c50b-4f51-b2eb-60c631316a09 | 172.25.250.0/24  |</span><br><span class="line">| 83c7dd52-f1d2-4f39-9ece-16b4f0942dac | provider-subnet-172.24.3 | dcf783e3-c104-4f21-99c3-0093364b4c81 | 172.24.3.0/24    |</span><br><span class="line">| b232a80d-fe12-4ee6-a01e-b3404dcb522f | production-subnet1       | d75263e1-754d-4276-a663-9188216f86e6 | 192.168.1.0/24   |</span><br><span class="line">| b4df8042-184b-494f-8a72-2ec171327408 | finance-subnet1          | e6a61a45-ff39-4eb1-aac2-8e0ac624f7e5 | 192.168.1.0/24   |</span><br><span class="line">| f772a67a-341d-413f-90ab-bf2163842a43 | lb-mgmt-subnet           | d71997c1-1670-4ebe-b6f7-2c4aa8dcbc7b | 172.23.0.0/16    |</span><br><span class="line">| ff1be714-007c-4f19-bbc4-824b4509c8c5 | engsubnet                | 289659f2-b4eb-43c4-88d4-e368e1e59b0d | 192.168.101.0/24 |</span><br><span class="line">+--------------------------------------+--------------------------+--------------------------------------+------------------+</span><br></pre></td></tr></table></figure>

<h2 id="Router"><a href="#Router" class="headerlink" title="Router"></a>Router</h2><ul>
<li>Router name: cl210-router</li>
<li>This router is connected to the external network public and the internal network engnet.</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Create the router</span><br><span class="line">(overcloud) [stack@director ~]$ openstack router create cl210-router</span><br><span class="line"></span><br><span class="line"># Set the interface of external gateway</span><br><span class="line">(overcloud) [stack@director ~]$ openstack router set --external-gateway public cl210-router</span><br><span class="line"></span><br><span class="line"># Set the interface of internal subnet</span><br><span class="line">(overcloud) [stack@director ~]$ openstack router add subnet cl210-router engsubnet</span><br><span class="line"></span><br><span class="line"># Check the list of router</span><br><span class="line">(overcloud) [stack@director ~]$ openstack router list</span><br><span class="line">+--------------------------------------+--------------+--------+-------+----------------------------------+</span><br><span class="line">| ID                                   | Name         | Status | State | Project                          |</span><br><span class="line">+--------------------------------------+--------------+--------+-------+----------------------------------+</span><br><span class="line">| 590e3024-35f4-42f2-95b4-87c1afdea3e1 | cl210-router | ACTIVE | UP    | ec0e24ddf10841b08ae63fe094e25587 |</span><br><span class="line">+--------------------------------------+--------------+--------+-------+----------------------------------+</span><br></pre></td></tr></table></figure>

<h2 id="Server"><a href="#Server" class="headerlink" title="Server"></a>Server</h2><p>Create an instance (virtual machine) named myserver:</p>
<ul>
<li>The instance belongs to the Engineering project</li>
<li>It uses the web image</li>
<li>It is launched with the m1.petite flavour</li>
<li>   The instance is connected to the engnet network</li>
<li>   The following security groups are attached:</li>
<li>   ssh</li>
<li>   web</li>
<li>   The instance uses a key pair named webkey</li>
<li>   A floating IP is associated with the instance, selected from the allowed range between 172.25.250.101 and 172.25.250.109</li>
<li>   The router is connected to both the external network public and the internal network engnet</li>
<li>   The root password for the instance is redhat</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Finally, create the server</span><br><span class="line">(overcloud) [stack@director ~]$ openstack server create \</span><br><span class="line">&gt; --flavor m1.petite \</span><br><span class="line">&gt; --image web \</span><br><span class="line">&gt; --nic net-id=engnet \</span><br><span class="line">&gt; --security-group ssh \</span><br><span class="line">&gt; --security-group web \</span><br><span class="line">&gt; --key-name webkey \</span><br><span class="line">&gt; --wait \</span><br><span class="line">&gt; shy</span><br><span class="line"></span><br><span class="line">(overcloud) [stack@director ~]$ openstack server list</span><br><span class="line">+--------------------------------------+------+--------+-----------------------+-------+--------+</span><br><span class="line">| ID                                   | Name | Status | Networks              | Image | Flavor |</span><br><span class="line">+--------------------------------------+------+--------+-----------------------+-------+--------+</span><br><span class="line">| 232caad5-f79a-4652-8995-9715c0b5cd17 | shy  | ACTIVE | engnet=192.168.101.50 | web   |        |</span><br><span class="line">+--------------------------------------+------+--------+-----------------------+-------+--------+</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Create the floating ip</span><br><span class="line">(overcloud) [stack@director ~]$ openstack floating ip create public</span><br><span class="line"></span><br><span class="line"># Check the list of floating ip</span><br><span class="line">(overcloud) [stack@director ~]$ openstack floating ip list</span><br><span class="line">+--------------------------------------+---------------------+------------------+------+--------------------------------------+----------------------------------+</span><br><span class="line">| ID                                   | Floating IP Address | Fixed IP Address | Port | Floating Network                     | Project                          |</span><br><span class="line">+--------------------------------------+---------------------+------------------+------+--------------------------------------+----------------------------------+</span><br><span class="line">| 90511fbd-e927-4882-923a-7fe140b5f8dd | 172.25.250.108      | None             | None | 775da214-c50b-4f51-b2eb-60c631316a09 | ec0e24ddf10841b08ae63fe094e25587 |</span><br><span class="line">+--------------------------------------+---------------------+------------------+------+--------------------------------------+----------------------------------+</span><br><span class="line"></span><br><span class="line"># Bind the floating ip to server &quot;shy&quot;</span><br><span class="line">(overcloud)[stack@director ~]$ openstack server add floating ip shy 172.25.250.108</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Login to the Virtual machine in compute1 node</span><br><span class="line">(overcloud) [stack@director ~]$ ssh -i webkey.pem cloud-user@172.25.250.108</span><br><span class="line">[cloud-user@shy ~]$ </span><br><span class="line"></span><br><span class="line">[cloud-user@shy ~]$ sudo -i</span><br><span class="line">[root@shy ~]# yum -y install httpd</span><br><span class="line">[root@shy ~]# systemctl enable --now httpd</span><br><span class="line">[root@shy ~]# echo 1111111111111111111111 &gt; /var/www/html/index.html</span><br><span class="line">[root@shy ~]# curl localhost</span><br><span class="line">1111111111111111111111</span><br><span class="line"></span><br><span class="line"># Test on the director node</span><br><span class="line">(overcloud) [stack@director ~]$ curl 172.25.250.108</span><br><span class="line">1111111111111111111111</span><br></pre></td></tr></table></figure>

<h2 id="Delete-a-VM-instance-in-CLI"><a href="#Delete-a-VM-instance-in-CLI" class="headerlink" title="Delete a VM instance in CLI"></a>Delete a VM instance in CLI</h2><h3 id="Delete-the-server"><a href="#Delete-the-server" class="headerlink" title="Delete the server"></a>Delete the server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">source</span> robertrc</span><br><span class="line"></span><br><span class="line">openstack server delete shy</span><br></pre></td></tr></table></figure>

<p>Then, Let’s check the server list.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(overcloud) [stack@director ~]$ openstack server list </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="Delete-the-network"><a href="#Delete-the-network" class="headerlink" title="Delete the network"></a>Delete the network</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openstack network list</span><br><span class="line">openstack network delete engnet</span><br><span class="line">openstack network delete public</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openstack subnet list</span><br><span class="line">openstack subnet delete engsubnet</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openstack port list --fixed-ip subnet=ff1be714-007c-4f19-bbc4-824b4509c8c5</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openstack port show 8af1f1d2-6811-475e-9c94-4c2eeba481dc</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Failed to delete network with name or ID &#x27;public&#x27;: ConflictException: 409: Client Error for url: http://172.25.250.50:9696/v2.0/networks/775da214-c50b-4f51-b2eb-60c631316a09, Unable to complete operation on network 775da214-c50b-4f51-b2eb-60c631316a09. There are one or more ports still in use on the network.</span><br><span class="line">1 of 1 networks failed to delete.</span><br></pre></td></tr></table></figure>

<p>After determine the port , please delete the port at first.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openstack port delete 8af1f1d2-6811-475e-9c94-4c2eeba481dc</span><br></pre></td></tr></table></figure>

<p>Then, you could delete the subnet(internal).</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openstack network delete engnet</span><br></pre></td></tr></table></figure>

<p>Check the port in public(external).</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openstack port list --network public</span><br></pre></td></tr></table></figure>

<p>Check the port info.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openstack port show 6ccb8845-879b-48cd-a871-81d5a9698e1b</span><br></pre></td></tr></table></figure>

<p>Delete the external port.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openstack port delete 6ccb8845-879b-48cd-a871-81d5a9698e1b</span><br></pre></td></tr></table></figure>

<p>There will be an error in the terminal, do not worry!<br>Because we need to cancel the bound with router gate-way.</p>
<p>List the router.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openstack router list</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openstack router <span class="built_in">unset</span> --external-gateway cl210-router</span><br></pre></td></tr></table></figure>

<p>So intersting! After we unset the external gateway, the original port we want to delete was removed automatically.</p>
<p>Then, we could delete the external network called “public”.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openstack network delete public</span><br></pre></td></tr></table></figure>

<p>Then, the router is also useless, please delete it!</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openstack router delete cl210-router</span><br></pre></td></tr></table></figure>

<h3 id="Delete-the-security-group"><a href="#Delete-the-security-group" class="headerlink" title="Delete the security group"></a>Delete the security group</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(overcloud) [stack@director ~]$ openstack security group delete ssh web</span><br></pre></td></tr></table></figure>

<p>Check the list of security groups.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openstack security group list</span><br></pre></td></tr></table></figure>

<h3 id="Delete-the-iamge"><a href="#Delete-the-iamge" class="headerlink" title="Delete the iamge"></a>Delete the iamge</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openstack image delete web</span><br></pre></td></tr></table></figure>

<p>Check the list of images.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openstack image list</span><br></pre></td></tr></table></figure>

<h3 id="Delete-the-key-pairs"><a href="#Delete-the-key-pairs" class="headerlink" title="Delete the key pairs"></a>Delete the key pairs</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openstack keypair delete webkey</span><br></pre></td></tr></table></figure>

<p>Check the list of keypairs.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openstack keypair list</span><br></pre></td></tr></table></figure>

<h3 id="Delete-the-flavor-instance-type"><a href="#Delete-the-flavor-instance-type" class="headerlink" title="Delete the flavor (instance type)"></a>Delete the flavor (instance type)</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openstack flavor delete m1.petite</span><br></pre></td></tr></table></figure>

<p>Check the list of flavor.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openstack flavor list</span><br></pre></td></tr></table></figure>

<p>Up to now, all configurations are deleted successfully!</p>
]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>OpenStack</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenStack Series Chapter0: Creating and Deleting VMs instaces(1)</title>
    <url>//Cloud/OpenStack/Creating-and-Deleting-VMs-instaces(1)/index.html</url>
    <content><![CDATA[<h2 id="Delete-resources-in-openstack-dashboard"><a href="#Delete-resources-in-openstack-dashboard" class="headerlink" title="Delete resources in openstack dashboard"></a>Delete resources in openstack dashboard</h2><h3 id="Delete-images"><a href="#Delete-images" class="headerlink" title="Delete images"></a>Delete images</h3><p><img src="/../images/delete_image.png" alt="delete images"></p>
<h3 id="Delete-flavors"><a href="#Delete-flavors" class="headerlink" title="Delete flavors"></a>Delete flavors</h3><p><img src="/../images/delete_flavor.png" alt="delete flavors"></p>
<h3 id="Delete-security-groups"><a href="#Delete-security-groups" class="headerlink" title="Delete security groups"></a>Delete security groups</h3><p><img src="/../images/delete_security_group.png" alt="delete security groups"></p>
<h3 id="Delete-interfaces"><a href="#Delete-interfaces" class="headerlink" title="Delete interfaces"></a>Delete interfaces</h3><p><img src="/../images/delete_interface.png" alt="delete interface"></p>
<h3 id="Delete-routers"><a href="#Delete-routers" class="headerlink" title="Delete routers"></a>Delete routers</h3><p><img src="/../images/delete_router.png" alt="delete router"></p>
<h3 id="Delete-internal-subnets"><a href="#Delete-internal-subnets" class="headerlink" title="Delete internal subnets"></a>Delete internal subnets</h3><p><img src="/../images/delete_internel_subnet.png" alt="delete subnet"></p>
<h3 id="Delete-internal-nets"><a href="#Delete-internal-nets" class="headerlink" title="Delete internal nets"></a>Delete internal nets</h3><p><img src="/../images/delete_internalnet.png" alt="delete subnet"></p>
<h2 id="Create-resources-in-openstack-dashboard"><a href="#Create-resources-in-openstack-dashboard" class="headerlink" title="Create resources in openstack dashboard"></a>Create resources in openstack dashboard</h2><blockquote>
<p>Flavors and External networks should be created with the <code>admin</code> priviledges.</p>
</blockquote>
<h3 id="Create-security-groups"><a href="#Create-security-groups" class="headerlink" title="Create security groups"></a>Create security groups</h3><p><img src="/../images/create_security_group.png" alt="create security groups"></p>
<p><img src="/../images/security_group_form.png" alt="type in security group form"></p>
<p><img src="/../images/add_rule.png" alt="add rule"></p>
<p><img src="/../images/rule_form.png" alt="type in rule form"></p>
<h3 id="Create-key-pairs"><a href="#Create-key-pairs" class="headerlink" title="Create key pairs"></a>Create key pairs</h3><p><img src="/../images/create_key_pair.png" alt="create key pairs"></p>
<p><img src="/../images/key_pair_form.png" alt="type in key pair form"></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Modify the permission of the pem file</span></span><br><span class="line"><span class="built_in">chmod</span> 600 webkey.pem</span><br></pre></td></tr></table></figure>

<h3 id="Create-networks"><a href="#Create-networks" class="headerlink" title="Create networks"></a>Create networks</h3><p><img src="/../images/create_internal_network.png" alt="create network"></p>
<h3 id="Create-subnetworks"><a href="#Create-subnetworks" class="headerlink" title="Create subnetworks"></a>Create subnetworks</h3><p><img src="/../images/create_subnet.png" alt="create subnet"></p>
<h3 id="Create-subnet-details"><a href="#Create-subnet-details" class="headerlink" title="Create subnet details"></a>Create subnet details</h3><p><img src="/../images/create_subnet_details.png" alt="type details"></p>
<h3 id="Create-external-networks"><a href="#Create-external-networks" class="headerlink" title="Create external networks"></a>Create external networks</h3><p><img src="/../images/create_external_network.png" alt="create external networks"></p>
<p><img src="/../images/external_network_form.png" alt="type in external network form"></p>
<p><img src="/../images/create_external_subnet.png" alt="type in external subnetwork form"></p>
<p><img src="/../images/create_external_subnet_details.png" alt="type in external subnetwork details"></p>
<h3 id="Create-routers"><a href="#Create-routers" class="headerlink" title="Create routers"></a>Create routers</h3><p><img src="/../images/create_router.png" alt="create router"></p>
<p><img src="/../images/router_form.png" alt="type in router form"></p>
<h3 id="Add-interfaces"><a href="#Add-interfaces" class="headerlink" title="Add interfaces"></a>Add interfaces</h3><p><img src="/../images/add_interface.png" alt="add interface"></p>
<p><img src="/../images/connect_subnet.png" alt="connect subnet"></p>
<h3 id="Create-an-instance"><a href="#Create-an-instance" class="headerlink" title="Create an instance"></a>Create an instance</h3><p><img src="/../images/instance_details.png" alt="details"></p>
<p><img src="/../images/instance_source.png" alt="source"></p>
<p><img src="/../images/instance_flavor.png" alt="flavor"></p>
<p><img src="/../images/instance_networks.png" alt="networks"></p>
<p><img src="/../images/instance_security_groups.png" alt="security groups"></p>
<p><img src="/../images/start_up_instance.png" alt="launch"></p>
<p><img src="/../images/manually_create_success.png" alt="manually success"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(overcloud) [stack@director ~]$ openstack server list</span><br><span class="line">+--------------------------------------+----------+--------+-----------------------------------------------+-------+--------+</span><br><span class="line">| ID                                   | Name     | Status | Networks                                      | Image | Flavor |</span><br><span class="line">+--------------------------------------+----------+--------+-----------------------------------------------+-------+--------+</span><br><span class="line">| 7967324e-b858-4359-b51d-373786bb1412 | myserver | ACTIVE | engnet=192.168.101.133; public=172.25.250.106 | web   |        |</span><br><span class="line">+--------------------------------------+----------+--------+-----------------------------------------------+-------+--------+</span><br><span class="line"></span><br><span class="line">(overcloud) [stack@director ~]$ ping 172.25.250.106</span><br><span class="line">PING 172.25.250.106 (172.25.250.106) 56(84) bytes of data.</span><br><span class="line">64 bytes from 172.25.250.106: icmp_seq=2 ttl=64 time=1.34 ms</span><br><span class="line">64 bytes from 172.25.250.106: icmp_seq=3 ttl=64 time=0.440 ms</span><br><span class="line">64 bytes from 172.25.250.106: icmp_seq=4 ttl=64 time=0.286 ms</span><br><span class="line">64 bytes from 172.25.250.106: icmp_seq=5 ttl=64 time=0.374 ms</span><br><span class="line">^C</span><br><span class="line">--- 172.25.250.106 ping statistics ---</span><br><span class="line">5 packets transmitted, 4 received, 20% packet loss, time 113ms</span><br><span class="line">rtt min/avg/max/mdev = 0.286/0.610/1.342/0.426 ms</span><br><span class="line"></span><br><span class="line">(overcloud) [stack@director ~]$ ssh -i webkey.pem cloud-user@172.25.250.106</span><br><span class="line">Warning: Permanently added &#x27;172.25.250.106&#x27; (ECDSA) to the list of known hosts.</span><br><span class="line">Activate the web console with: systemctl enable --now cockpit.socket</span><br><span class="line"></span><br><span class="line">This system is not registered to Red Hat Insights. See https://cloud.redhat.com/</span><br><span class="line">To register this system, run: insights-client --register</span><br><span class="line"></span><br><span class="line">[cloud-user@myserver ~]$ whoami</span><br><span class="line">cloud-user</span><br><span class="line">[cloud-user@myserver ~]$ hostname</span><br><span class="line">myserver</span><br><span class="line">[cloud-user@myserver ~]$ df -hT</span><br><span class="line">Filesystem     Type      Size  Used Avail Use% Mounted on</span><br><span class="line">devtmpfs       devtmpfs  396M     0  396M   0% /dev</span><br><span class="line">tmpfs          tmpfs     411M     0  411M   0% /dev/shm</span><br><span class="line">tmpfs          tmpfs     411M   11M  400M   3% /run</span><br><span class="line">tmpfs          tmpfs     411M     0  411M   0% /sys/fs/cgroup</span><br><span class="line">/dev/vda1      xfs        10G  1.6G  8.5G  16% /</span><br><span class="line">tmpfs          tmpfs      83M     0   83M   0% /run/user/1001</span><br><span class="line"></span><br><span class="line">[cloud-user@myserver ~]$ sudo -i</span><br><span class="line"></span><br><span class="line">[root@myserver ~]$ yum install httpd</span><br><span class="line">Red Hat Enterprise Linux 8 for x86_64 - High Availability (RPMs)                                                                                                                     29 MB/s | 1.8 MB     00:00    </span><br><span class="line">Red Hat Ansible Engine 2.9 for RHEL 8 x86_64 (RPMs)                                                                                                                                  18 MB/s | 918 kB     00:00    </span><br><span class="line">Red Hat OpenStack Platform 16.1 for RHEL 8 (RPMs)                                                                                                                                    23 MB/s | 1.2 MB     00:00    </span><br><span class="line">Red Hat Fast Datapath for RHEL 8 (RPMS)                                                                                                                                             3.4 MB/s | 115 kB     00:00    </span><br><span class="line">Advanced Virtualization for RHEL 8 x86_64 (RPMs)                                                                                                                                     14 MB/s | 721 kB     00:00    </span><br><span class="line">Red Hat Enterprise Linux 8 for x86_64 - BaseOS (RPMs)                                                                                                                                40 MB/s | 2.2 MB     00:00    </span><br><span class="line">Red Hat Enterprise Linux 8 for x86_64 - AppStream (RPMs)                                                                                                                             61 MB/s | 5.8 MB     00:00    </span><br><span class="line">Dependencies resolved.</span><br><span class="line">====================================================================================================================================================================================================================</span><br><span class="line"> Package                                      Architecture                     Version                                                             Repository                                                  Size</span><br><span class="line">====================================================================================================================================================================================================================</span><br><span class="line">Installing:</span><br><span class="line"> httpd                                        x86_64                           2.4.37-21.module+el8.2.0+5008+cca404a3                              rhel-8-for-x86_64-appstream-rpms                           1.4 M</span><br><span class="line">Installing dependencies:</span><br><span class="line"> mailcap                                      noarch                           2.1.48-3.el8                                                        rhel-8-for-x86_64-baseos-rpms                               39 k</span><br><span class="line"> redhat-logos-httpd                           noarch                           81.1-1.el8                                                          rhel-8-for-x86_64-baseos-rpms                               26 k</span><br><span class="line"> apr                                          x86_64                           1.6.3-9.el8                                                         rhel-8-for-x86_64-appstream-rpms                           125 k</span><br><span class="line"> apr-util                                     x86_64                           1.6.1-6.el8                                                         rhel-8-for-x86_64-appstream-rpms                           105 k</span><br><span class="line"> httpd-filesystem                             noarch                           2.4.37-21.module+el8.2.0+5008+cca404a3                              rhel-8-for-x86_64-appstream-rpms                            36 k</span><br><span class="line"> httpd-tools                                  x86_64                           2.4.37-21.module+el8.2.0+5008+cca404a3                              rhel-8-for-x86_64-appstream-rpms                           103 k</span><br><span class="line"> mod_http2                                    x86_64                           1.11.3-3.module+el8.2.0+4377+dc421495                               rhel-8-for-x86_64-appstream-rpms                           158 k</span><br><span class="line">Installing weak dependencies:</span><br><span class="line"> apr-util-bdb                                 x86_64                           1.6.1-6.el8                                                         rhel-8-for-x86_64-appstream-rpms                            25 k</span><br><span class="line"> apr-util-openssl                             x86_64                           1.6.1-6.el8                                                         rhel-8-for-x86_64-appstream-rpms                            27 k</span><br><span class="line">Enabling module streams:</span><br><span class="line"> httpd                                                                         2.4                                                                                                                                 </span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">====================================================================================================================================================================================================================</span><br><span class="line">Install  10 Packages</span><br><span class="line"></span><br><span class="line">Total download size: 2.0 M</span><br><span class="line">Installed size: 5.5 M</span><br><span class="line">Is this ok [y/N]: y</span><br><span class="line">Downloading Packages:</span><br><span class="line">(1/10): redhat-logos-httpd-81.1-1.el8.noarch.rpm                                                                                                                                    897 kB/s |  26 kB     00:00    </span><br><span class="line">(2/10): mailcap-2.1.48-3.el8.noarch.rpm                                                                                                                                             1.3 MB/s |  39 kB     00:00    </span><br><span class="line">(3/10): apr-util-bdb-1.6.1-6.el8.x86_64.rpm                                                                                                                                          24 MB/s |  25 kB     00:00    </span><br><span class="line">(4/10): apr-1.6.3-9.el8.x86_64.rpm                                                                                                                                                  3.8 MB/s | 125 kB     00:00    </span><br><span class="line">(5/10): apr-util-1.6.1-6.el8.x86_64.rpm                                                                                                                                              26 MB/s | 105 kB     00:00    </span><br><span class="line">(6/10): apr-util-openssl-1.6.1-6.el8.x86_64.rpm                                                                                                                                      12 MB/s |  27 kB     00:00    </span><br><span class="line">(7/10): httpd-filesystem-2.4.37-21.module+el8.2.0+5008+cca404a3.noarch.rpm                                                                                                           22 MB/s |  36 kB     00:00    </span><br><span class="line">(8/10): httpd-tools-2.4.37-21.module+el8.2.0+5008+cca404a3.x86_64.rpm                                                                                                                33 MB/s | 103 kB     00:00    </span><br><span class="line">(9/10): mod_http2-1.11.3-3.module+el8.2.0+4377+dc421495.x86_64.rpm                                                                                                                   34 MB/s | 158 kB     00:00    </span><br><span class="line">(10/10): httpd-2.4.37-21.module+el8.2.0+5008+cca404a3.x86_64.rpm                                                                                                                     66 MB/s | 1.4 MB     00:00    </span><br><span class="line">--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">Total                                                                                                                                                                                36 MB/s | 2.0 MB     00:00     </span><br><span class="line">Running transaction check</span><br><span class="line">Transaction check succeeded.</span><br><span class="line">Running transaction test</span><br><span class="line">Transaction test succeeded.</span><br><span class="line">Running transaction</span><br><span class="line">  Preparing        :                                                                                                                                                                                            1/1 </span><br><span class="line">  Installing       : apr-1.6.3-9.el8.x86_64                                                                                                                                                                    1/10 </span><br><span class="line">  Running scriptlet: apr-1.6.3-9.el8.x86_64                                                                                                                                                                    1/10 </span><br><span class="line">  Installing       : apr-util-bdb-1.6.1-6.el8.x86_64                                                                                                                                                           2/10 </span><br><span class="line">  Installing       : apr-util-openssl-1.6.1-6.el8.x86_64                                                                                                                                                       3/10 </span><br><span class="line">  Installing       : apr-util-1.6.1-6.el8.x86_64                                                                                                                                                               4/10 </span><br><span class="line">  Running scriptlet: apr-util-1.6.1-6.el8.x86_64                                                                                                                                                               4/10 </span><br><span class="line">  Installing       : httpd-tools-2.4.37-21.module+el8.2.0+5008+cca404a3.x86_64                                                                                                                                 5/10 </span><br><span class="line">  Running scriptlet: httpd-filesystem-2.4.37-21.module+el8.2.0+5008+cca404a3.noarch                                                                                                                            6/10 </span><br><span class="line">  Installing       : httpd-filesystem-2.4.37-21.module+el8.2.0+5008+cca404a3.noarch                                                                                                                            6/10 </span><br><span class="line">  Installing       : redhat-logos-httpd-81.1-1.el8.noarch                                                                                                                                                      7/10 </span><br><span class="line">  Installing       : mailcap-2.1.48-3.el8.noarch                                                                                                                                                               8/10 </span><br><span class="line">  Installing       : mod_http2-1.11.3-3.module+el8.2.0+4377+dc421495.x86_64                                                                                                                                    9/10 </span><br><span class="line">  Installing       : httpd-2.4.37-21.module+el8.2.0+5008+cca404a3.x86_64                                                                                                                                      10/10 </span><br><span class="line">  Running scriptlet: httpd-2.4.37-21.module+el8.2.0+5008+cca404a3.x86_64                                                                                                                                      10/10 </span><br><span class="line">  Verifying        : mailcap-2.1.48-3.el8.noarch                                                                                                                                                               1/10 </span><br><span class="line">  Verifying        : redhat-logos-httpd-81.1-1.el8.noarch                                                                                                                                                      2/10 </span><br><span class="line">  Verifying        : apr-1.6.3-9.el8.x86_64                                                                                                                                                                    3/10 </span><br><span class="line">  Verifying        : apr-util-1.6.1-6.el8.x86_64                                                                                                                                                               4/10 </span><br><span class="line">  Verifying        : apr-util-bdb-1.6.1-6.el8.x86_64                                                                                                                                                           5/10 </span><br><span class="line">  Verifying        : apr-util-openssl-1.6.1-6.el8.x86_64                                                                                                                                                       6/10 </span><br><span class="line">  Verifying        : httpd-2.4.37-21.module+el8.2.0+5008+cca404a3.x86_64                                                                                                                                       7/10 </span><br><span class="line">  Verifying        : httpd-filesystem-2.4.37-21.module+el8.2.0+5008+cca404a3.noarch                                                                                                                            8/10 </span><br><span class="line">  Verifying        : httpd-tools-2.4.37-21.module+el8.2.0+5008+cca404a3.x86_64                                                                                                                                 9/10 </span><br><span class="line">  Verifying        : mod_http2-1.11.3-3.module+el8.2.0+4377+dc421495.x86_64                                                                                                                                   10/10 </span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  httpd-2.4.37-21.module+el8.2.0+5008+cca404a3.x86_64               apr-util-bdb-1.6.1-6.el8.x86_64                                           apr-util-openssl-1.6.1-6.el8.x86_64                                 </span><br><span class="line">  mailcap-2.1.48-3.el8.noarch                                       redhat-logos-httpd-81.1-1.el8.noarch                                      apr-1.6.3-9.el8.x86_64                                              </span><br><span class="line">  apr-util-1.6.1-6.el8.x86_64                                       httpd-filesystem-2.4.37-21.module+el8.2.0+5008+cca404a3.noarch            httpd-tools-2.4.37-21.module+el8.2.0+5008+cca404a3.x86_64           </span><br><span class="line">  mod_http2-1.11.3-3.module+el8.2.0+4377+dc421495.x86_64           </span><br><span class="line"></span><br><span class="line">Complete!</span><br><span class="line"></span><br><span class="line">[root@myserver ~]$ systemctl enable --now httpd</span><br><span class="line">Created symlink /etc/systemd/system/multi-user.target.wants/httpd.service → /usr/lib/systemd/system/httpd.service.</span><br><span class="line"></span><br><span class="line">[root@myserver ~]# echo &quot;Hi Apache, I&#x27;m Haoyang Sun!&quot; &gt; /var/www/html/index.html</span><br><span class="line"></span><br><span class="line">[root@myserver ~]# curl localhost</span><br><span class="line">Hi Apache, I&#x27;m Haoyang Sun!</span><br><span class="line"></span><br><span class="line"># Test in director</span><br><span class="line">(overcloud) [stack@director ~]$ curl 172.25.250.106</span><br><span class="line">Hi Apache, I&#x27;m Haoyang Sun!</span><br></pre></td></tr></table></figure>

<p>Congratulations! Up to now, we successfully created a new instance VM in openstack compute node.</p>
]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>OpenStack</tag>
      </tags>
  </entry>
  <entry>
    <title>Complete Guide to deploy Gerrit</title>
    <url>//Tools/Gerrit/Complete-Guide-to-Deploy-Gerrit/index.html</url>
    <content><![CDATA[<h2 id="Deployment-Plan-Table"><a href="#Deployment-Plan-Table" class="headerlink" title="Deployment Plan Table"></a>Deployment Plan Table</h2><table>
<thead>
<tr>
<th>Operating System</th>
<th>IP</th>
<th>NGINX Version</th>
<th>Hostname</th>
<th>Role</th>
</tr>
</thead>
<tbody><tr>
<td>Rocky9.5(x86_64)</td>
<td>192.168.225.30</td>
<td>1.26.3</td>
<td>loadbalance.haoyang.cn</td>
<td>gerrit service 1</td>
</tr>
<tr>
<td>Rocky9.5(x86_64)</td>
<td>192.168.225.31</td>
<td>1.26.3</td>
<td>gerrit1.haoyang.cn</td>
<td>gerrit service 2</td>
</tr>
<tr>
<td>Rocky9.5(x86_64)</td>
<td>192.168.225.32</td>
<td>1.26.3</td>
<td>gerrit2.haoyang.cn</td>
<td>Loadbalance service</td>
</tr>
</tbody></table>
<h2 id="Prerequisites"><a href="#Prerequisites" class="headerlink" title="Prerequisites"></a>Prerequisites</h2><p>To run the Gerrit service, the following requirement must be met on the host:</p>
<p>JRE, versions <code>17</code> or <code>21</code>.</p>
<blockquote>
<p>Oracle’s java is paid not free any more.</p>
<p>Openjdk is available <a href="https://openjdk.org/">here</a>.</p>
</blockquote>
<h2 id="Download-the-gerrit-war-tarball"><a href="#Download-the-gerrit-war-tarball" class="headerlink" title="Download the gerrit.war tarball"></a>Download the gerrit.war tarball</h2><p>You could download the <code>gerrit.war</code> file from <a href="https://gerrit-releases.storage.googleapis.com/index.html">Gerrit official site here</a> as you want.</p>
<p>Download any current <code>*.war</code> package. The war will be referred to as <code>gerrit.war</code> from this point forward, so you may find it easier to rename the downloaded file.</p>
<h2 id="Initialize-the-Site"><a href="#Initialize-the-Site" class="headerlink" title="Initialize the Site"></a>Initialize the Site</h2><p>Gerrit stores configuration files, the server’s SSH keys, and the managed Git repositories under a local directory, typically referred to as ‘$site_path’.</p>
<p>Initialize a new site directory by running the init command, passing the path of the site directory to be created as an argument to the ‘-d’ option.</p>
<p>Its recommended that Gerrit Code Review be given its own user account on the host system:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create a new user called gerrit</span></span><br><span class="line"><span class="built_in">sudo</span> adduser gerrit</span><br><span class="line"><span class="comment"># Swith the privilages to root for gerrit user account and start it up:(inherit the environment variables from root)</span></span><br><span class="line"><span class="built_in">sudo</span> su gerrit</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize a new site directory for Gerrit: (replace /path/to/your/gerrit_application_directory with your actual path)</span></span><br><span class="line">java -jar gerrit.war init -d /path/to/your/gerrit_application_directory</span><br></pre></td></tr></table></figure>

<h2 id="Initial-Configuration"><a href="#Initial-Configuration" class="headerlink" title="Initial Configuration"></a>Initial Configuration</h2><p>I would like to show the whole process I’ve experienced here. Don’t worry, just follow my guidance.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create a new user called gerrit</span></span><br><span class="line"><span class="built_in">sudo</span> adduser gerrit</span><br><span class="line"><span class="comment"># Swith the privilages to root for gerrit user account and start it up:(inherit the environment variables from root)</span></span><br><span class="line"><span class="built_in">sudo</span> su gerrit</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make a new directory</span></span><br><span class="line"><span class="built_in">cd</span> /home/gerrit</span><br><span class="line"><span class="built_in">mkdir</span> gerrit_war</span><br></pre></td></tr></table></figure>

<p>The structure should be same as me as followed.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[gerrit@gerrit2 ~]$ pwd</span><br><span class="line">/home/gerrit</span><br><span class="line">[gerrit@gerrit2 ~]$ tree -L 2</span><br><span class="line">.</span><br><span class="line">└── gerrit_war</span><br><span class="line"></span><br><span class="line">2 directories, 0 files</span><br></pre></td></tr></table></figure>

<p>Then, download the <code>gerrit.war</code> from the <a href="https://gerrit-releases.storage.googleapis.com/index.html">Gerrit official site here</a> as you want. Then, move the <code>gerrit</code> application to your gerrit directory.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[gerrit@gerrit2 gerrit_war]$ scp root@192.168.225.30:/home/gerrit/gerrit_war/gerrit-3.11.1.war .</span><br><span class="line">The authenticity of host &#x27;192.168.225.30 (192.168.225.30)&#x27; can&#x27;t be established.</span><br><span class="line">ED25519 key fingerprint is SHA256:QZY7LFi5pVYhQHY56cn96boDi59JBU55x9o8/uyTlic.</span><br><span class="line">This key is not known by any other names</span><br><span class="line">Are you sure you want to continue connecting (yes/no/[fingerprint])? yes</span><br><span class="line">Warning: Permanently added &#x27;192.168.225.30&#x27; (ED25519) to the list of known hosts.</span><br><span class="line">root@192.168.225.30&#x27;s password:</span><br><span class="line">gerrit-3.11.1.war                                                                                                              100%   82MB 111.7MB/s   00:00</span><br><span class="line">[gerrit@gerrit2 gerrit_war]$ ls</span><br><span class="line">gerrit-3.11.1.war</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Init the gerrir.war tarball</span></span><br><span class="line"><span class="built_in">cd</span> /home/gerrit/gerrit_war</span><br><span class="line">java -jar gerrit-3.11.1.war init -d /home/gerrit/gerrit_application</span><br></pre></td></tr></table></figure>

<p>The detailed information you could based on my settings and change it as you want.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[gerrit@gerrit2 gerrit_war]$ java -jar gerrit-3.11.1.war init -d /home/gerrit/gerrit_application</span><br><span class="line">Using secure store: com.google.gerrit.server.securestore.DefaultSecureStore</span><br><span class="line">[2025-03-11 15:07:00,893] [main] INFO  com.google.gerrit.server.config.GerritServerConfigProvider : No /home/gerrit/gerrit_application/etc/gerrit.config; assuming defaults</span><br><span class="line"></span><br><span class="line">*** Gerrit Code Review 3.11.1</span><br><span class="line">***</span><br><span class="line"></span><br><span class="line">Create &#x27;/home/gerrit/gerrit_application&#x27; [Y/n]? Y</span><br><span class="line"></span><br><span class="line">*** Git Repositories</span><br><span class="line">***</span><br><span class="line"></span><br><span class="line">Location of Git repositories   [git]:</span><br><span class="line"></span><br><span class="line">*** JGit Configuration</span><br><span class="line">***</span><br><span class="line"></span><br><span class="line">Auto-configured &quot;receive.autogc = false&quot; to disable auto-gc after git-receive-pack.</span><br><span class="line"></span><br><span class="line">*** Index</span><br><span class="line">***</span><br><span class="line"></span><br><span class="line">Type                           [lucene]:</span><br><span class="line"></span><br><span class="line">*** User Authentication</span><br><span class="line">***</span><br><span class="line"></span><br><span class="line">Authentication method          [openid/?]: HTTP</span><br><span class="line">Get username from custom HTTP header [y/N]? N</span><br><span class="line">SSO logout URL                 :</span><br><span class="line">Enable signed push support     [y/N]? N</span><br><span class="line">Use case insensitive usernames [Y/n]? Y</span><br><span class="line"></span><br><span class="line">*** Review Labels</span><br><span class="line">***</span><br><span class="line"></span><br><span class="line">Install Verified label         [y/N]? y</span><br><span class="line"></span><br><span class="line">*** Email Delivery</span><br><span class="line">***</span><br><span class="line"></span><br><span class="line">SMTP server hostname           [localhost]: ***</span><br><span class="line">SMTP server port               [(default)]: **</span><br><span class="line">SMTP encryption                [none/?]: none</span><br><span class="line">SMTP username                  [gerrit]: ***@***.com</span><br><span class="line">***@***.com&#x27;s password :</span><br><span class="line">              confirm password :</span><br><span class="line"></span><br><span class="line">*** Container Process</span><br><span class="line">***</span><br><span class="line"></span><br><span class="line">Run as                         [gerrit]: gerrit</span><br><span class="line">Java runtime                   [/usr/lib/jvm/java-21-openjdk-21.0.6.0.7-1.el9.x86_64]:</span><br><span class="line">Copy gerrit-3.11.1.war to /home/gerrit/gerrit_application/bin/gerrit.war [Y/n]? Y</span><br><span class="line">Copying gerrit-3.11.1.war to /home/gerrit/gerrit_application/bin/gerrit.war</span><br><span class="line"></span><br><span class="line">*** SSH Daemon</span><br><span class="line">***</span><br><span class="line"></span><br><span class="line">Listen on address              [*]:</span><br><span class="line">Listen on port                 [29418]:</span><br><span class="line">Generating SSH host key ... rsa... ed25519... ecdsa 256... ecdsa 384... ecdsa 521... done</span><br><span class="line"></span><br><span class="line">*** HTTP Daemon</span><br><span class="line">***</span><br><span class="line"></span><br><span class="line">Behind reverse proxy           [y/N]? y</span><br><span class="line">Proxy uses SSL (https://)      [y/N]? N</span><br><span class="line">Subdirectory on proxy server   [/]:</span><br><span class="line">Listen on address              [*]:</span><br><span class="line">Listen on port                 [8081]: 8080</span><br><span class="line">Canonical URL                  [http://***/]: http://***</span><br><span class="line"></span><br><span class="line">*** Cache</span><br><span class="line">***</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">*** Plugins</span><br><span class="line">***</span><br><span class="line"></span><br><span class="line">Installing plugins.</span><br><span class="line">Install plugin codemirror-editor version v3.11.1 [y/N]? y</span><br><span class="line">Installed codemirror-editor v3.11.1</span><br><span class="line">Install plugin commit-message-length-validator version v3.11.1 [y/N]? y</span><br><span class="line">Installed commit-message-length-validator v3.11.1</span><br><span class="line">Install plugin delete-project version v3.11.1 [y/N]? y</span><br><span class="line">Installed delete-project v3.11.1</span><br><span class="line">Install plugin download-commands version v3.11.1 [y/N]? y</span><br><span class="line">Installed download-commands v3.11.1</span><br><span class="line">Install plugin gitiles version v3.11.1 [y/N]? y</span><br><span class="line">Installed gitiles v3.11.1</span><br><span class="line">Install plugin hooks version v3.11.1 [y/N]? y</span><br><span class="line">Installed hooks v3.11.1</span><br><span class="line">Install plugin plugin-manager version v3.11.1 [y/N]? y</span><br><span class="line">Installed plugin-manager v3.11.1</span><br><span class="line">Install plugin replication version v3.11.1 [y/N]? y</span><br><span class="line">Installed replication v3.11.1</span><br><span class="line">Install plugin replication-api version v3.11.1 [y/N]? y</span><br><span class="line">Installed replication-api v3.11.1</span><br><span class="line">Install plugin reviewnotes version v3.11.1 [y/N]? y</span><br><span class="line">Installed reviewnotes v3.11.1</span><br><span class="line">Install plugin singleusergroup version v3.11.1 [y/N]? y</span><br><span class="line">Installed singleusergroup v3.11.1</span><br><span class="line">Install plugin webhooks version v3.11.1 [y/N]? y</span><br><span class="line">Installed webhooks v3.11.1</span><br><span class="line">Initializing plugins.</span><br><span class="line"></span><br><span class="line">Mar 11, 2025 3:09:49 PM org.apache.lucene.store.MemorySegmentIndexInputProvider &lt;init&gt;</span><br><span class="line">INFO: Using MemorySegmentIndexInput with Java 21; to disable start with -Dorg.apache.lucene.store.MMapDirectory.enableMemorySegments=false</span><br><span class="line">============================================================================</span><br><span class="line">Welcome to the Gerrit community</span><br><span class="line"></span><br><span class="line">Find more information on the homepage: https://www.gerritcodereview.com</span><br><span class="line">Discuss Gerrit on the mailing list: https://groups.google.com/g/repo-discuss</span><br><span class="line">============================================================================</span><br><span class="line">Initialized /home/gerrit/gerrit_application</span><br><span class="line">Init complete, reindexing accounts,changes,groups,projects with: reindex --site-path /home/gerrit/gerrit_application --threads 1 --index accounts --index changes --index groups --index projectsReindexed 0 documents in accounts index in 0.0s (0.0/s)</span><br><span class="line">Index accounts in version 14 is ready</span><br><span class="line">Reindexing groups:      100% (3/3)</span><br><span class="line">Reindexed 3 documents in groups index in 0.3s (11.3/s)</span><br><span class="line">Index groups in version 11 is ready</span><br><span class="line">Reindexing changes: Slicing projects: 100% (2/2), done</span><br><span class="line">Reindexed 0 documents in changes index in 0.0s (0.0/s)</span><br><span class="line">Index changes in version 86 is ready</span><br><span class="line">Reindexing projects:    100% (2/2)</span><br><span class="line">Reindexed 2 documents in projects index in 0.1s (27.0/s)</span><br><span class="line">Index projects in version 9 is ready</span><br><span class="line">Executing /home/gerrit/gerrit_application/bin/gerrit.sh start</span><br><span class="line">Starting Gerrit Code Review: WARNING: Could not adjust Gerrit&#x27;s process for the kernel&#x27;s out-of-memory killer.</span><br><span class="line">         This may be caused by /home/gerrit/gerrit_application/bin/gerrit.sh not being run as root.</span><br><span class="line">         Consider changing the OOM score adjustment manually for Gerrit&#x27;s PID=1859 with e.g.:</span><br><span class="line">         echo &#x27;-1000&#x27; | sudo tee /proc/1859/oom_score_adj</span><br><span class="line">OK</span><br><span class="line">Waiting for server on 192.168.225.31:8080 ... OK</span><br><span class="line">Please open the following URL in the browser: http://192.168.225.31:8080/#/admin/projects/</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Tips:</p>
<p>If you would like to use reverse-proxy, the Authentication method must be set as <code>http</code>.<br>Other configurations could set as default, type <code>enter</code> to skip.</p>
<p>What’s more, please rememer to allow the <code>8080</code> port by using:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@gerrit2 ~]# firewall-cmd --permanent --add-port=8080/tcp</span><br><span class="line">success</span><br><span class="line">[root@gerrit2 ~]# firewall-cmd --reload</span><br><span class="line">success</span><br></pre></td></tr></table></figure>
</blockquote>
<p>If you see this page, please do not worry!</p>
<p>It represents you’ve deployed the gerrit application successfully.</p>
<p>For the next step, you should handle with the NGINX configuration.</p>
<p><img src="/../images/reverse_proxy.png" alt="Revers-proxy error"></p>
<h2 id="Configuring-NGINX-as-a-Reverse-Proxy-for-Gerrit"><a href="#Configuring-NGINX-as-a-Reverse-Proxy-for-Gerrit" class="headerlink" title="Configuring NGINX as a Reverse Proxy for Gerrit"></a>Configuring NGINX as a Reverse Proxy for Gerrit</h2><p>Please refer to <a href="https://blog.sunhaoyang.net/Linux/NGINX_1.Deploying-NGINX/index.html">NGIXN Series Chapter 1: Deploying NGINX</a> to deploy NGINX in your local.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@loadbalance conf.d]# pwd</span><br><span class="line">/etc/nginx/conf.d</span><br><span class="line">[root@loadbalance conf.d]# ls</span><br><span class="line">default.conf.bak  gerrit.conf</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Tips:</p>
<p>You’d better to rename the <code>default.conf</code> in <code>/etc/nginx/conf.d</code>.</p>
</blockquote>
<p>Create a new configuration file, here called <code>gerrit.conf</code>.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">upstream gerrit_backend &#123;</span><br><span class="line">    ip_hash;</span><br><span class="line">    server 192.168.225.30:8080 weight=1 max_fails=3 fail_timeout=10s;</span><br><span class="line">    server 192.168.225.31:8080 weight=1 max_fails=3 fail_timeout=10s;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    server_name loadbalance.haoyang.cn;</span><br><span class="line"></span><br><span class="line">    auth_basic &quot;Gerrit Code Review&quot;;</span><br><span class="line">    auth_basic_user_file /etc/nginx/conf.d/htpasswd;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass http://gerrit_backend;</span><br><span class="line"></span><br><span class="line">        proxy_set_header X-Real-IP $remote_addr;</span><br><span class="line">        proxy_set_header X-Forwarded-For $remote_addr;</span><br><span class="line">        proxy_set_header X-Forwarded-Proto $scheme;</span><br><span class="line"></span><br><span class="line">        proxy_set_header Host $host;</span><br><span class="line">        proxy_set_header Authorization $http_authorization;</span><br><span class="line"></span><br><span class="line">        proxy_redirect off;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Finally, install the httpd-tools to generate http-authentification account and password.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install httpd-tools -y</span><br></pre></td></tr></table></figure>

<p>Create the gerrit administrator user.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@loadbalance ~]# htpasswd -b -c /etc/nginx/conf.d/htpasswd gerritadmin ***</span><br><span class="line">Adding password <span class="keyword">for</span> user gerritadmin</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@loadbalance conf.d]# curl http://192.168.225.32:80</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;&lt;title&gt;401 Authorization Required&lt;/title&gt;&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;center&gt;&lt;h1&gt;401 Authorization Required&lt;/h1&gt;&lt;/center&gt;</span><br><span class="line">&lt;hr&gt;&lt;center&gt;nginx/1.26.3&lt;/center&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure>

<p>We could find that it needs to be authorized.</p>
<p>If you open the website in the browser(e.g. chrome), A pop-up window will appear asking you to enter your password.</p>
<p><img src="/../images/pop-up.png" alt="pop-up window"></p>
<p>Congratulations to you! Up to now, you have completed the whole process of deploying gerrit.</p>
<p><img src="/../images/gerrit.png" alt="gerrit"><br>Please enjoy yourself in using such a code review application :D</p>
<blockquote>
<p>Tips:</p>
<p>It is normal phenomenon if you could not sign out in the website.</p>
<p>Here is the reason: You are using HTTP Basic authentication. There is no way to tell a browser to quit sending basic authentication credentials, to logout with basic authentication is to close the Web browser.</p>
<p>What’s more, clear all cookies and data cache does work as well.</p>
</blockquote>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Gerrit</tag>
      </tags>
  </entry>
  <entry>
    <title>NGINX Series Chapter1: Deploying NGINX</title>
    <url>//Linux/Nginx/Deploying-NGINX/index.html</url>
    <content><![CDATA[<h2 id="Deployment-Plan-Table"><a href="#Deployment-Plan-Table" class="headerlink" title="Deployment Plan Table"></a>Deployment Plan Table</h2><table>
<thead>
<tr>
<th>Operating System</th>
<th>IP</th>
<th>NGINX Version</th>
</tr>
</thead>
<tbody><tr>
<td>Rocky9.5(x86_64)</td>
<td>192.168.225.32</td>
<td>1.26.3</td>
</tr>
</tbody></table>
<p>Here, I’ll only introduce how to install nginx by <code>the rpm repository</code>. As to the build-install method, I’ll introduce in the later chapter.</p>
<h2 id="Prerequisites"><a href="#Prerequisites" class="headerlink" title="Prerequisites"></a>Prerequisites</h2><h3 id="Preparing-the-software-repository"><a href="#Preparing-the-software-repository" class="headerlink" title="Preparing the software repository"></a>Preparing the software repository</h3><p>I would like to add a new repository in the path <code>/etc/yum.repos.d/nginx.repo</code>.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /etc/yum.repos.d/nginx.repo &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">[nginx]</span></span><br><span class="line"><span class="string">name=nginx repo</span></span><br><span class="line"><span class="string">baseurl=http://nginx.org/packages/centos/9/x86_64/</span></span><br><span class="line"><span class="string">gpgcheck=0</span></span><br><span class="line"><span class="string">enabled=1</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<h3 id="Generating-the-index-of-repository"><a href="#Generating-the-index-of-repository" class="headerlink" title="Generating the index of repository"></a>Generating the index of repository</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# dnf makecache</span><br><span class="line">nginx repo                                     8.7 kB/s | 2.9 kB     00:00</span><br><span class="line">Rocky Linux 9 - BaseOS                         4.8 kB/s | 4.1 kB     00:00</span><br><span class="line">Rocky Linux 9 - BaseOS                         1.0 MB/s | 2.3 MB     00:02</span><br><span class="line">Rocky Linux 9 - AppStream                      1.8 kB/s | 4.5 kB     00:02</span><br><span class="line">Rocky Linux 9 - AppStream                      8.4 MB/s | 8.5 MB     00:01</span><br><span class="line">Rocky Linux 9 - Extras                         3.7 kB/s | 2.9 kB     00:00</span><br><span class="line">Rocky Linux 9 - Extras                          15 kB/s |  16 kB     00:01</span><br><span class="line">Metadata cache created.</span><br></pre></td></tr></table></figure>

<p>&#96;&#96; Installing NGINX</p>
<p>Similarly, you can install nginx using the following command in RockyLinux terminal : <code>sudo yum -y install nginx</code> . After installation is complete it will be available for use via http.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# dnf install nginx -y</span><br><span class="line">...</span><br><span class="line">==============================================================================================================================================================================================================</span><br><span class="line"> Package                                       Architecture                                   Version                                                     Repository                                     Size</span><br><span class="line">==============================================================================================================================================================================================================</span><br><span class="line">Installing:</span><br><span class="line"> nginx                                         x86_64                                         2:1.26.2-2.el9.ngx                                          nginx                                         996 k</span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">==============================================================================================================================================================================================================</span><br><span class="line">Install  1 Package</span><br><span class="line"></span><br><span class="line">Total download size: 996 k</span><br><span class="line">Installed size: 3.3 M</span><br><span class="line">Downloading Packages:</span><br><span class="line">nginx-1.26.3-2.el9.ngx.x86_64.rpm                                                                                                                                             428 kB/s | 996 kB     00:02</span><br><span class="line">--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">Installed:</span><br><span class="line">  nginx-2:1.26.3-2.el9.ngx.x86_64</span><br><span class="line">...</span><br><span class="line">Complete!</span><br><span class="line">[root@localhost ~]#</span><br></pre></td></tr></table></figure>

<h2 id="Preparing-the-test-webpage"><a href="#Preparing-the-test-webpage" class="headerlink" title="Preparing the test webpage"></a>Preparing the test webpage</h2><p>NGINX has been installed, so let’s test whether it can serve a webpage. By default, NGINX requires us to place web pages in the <code>/usr/share/nginx/html</code> directory, with the homepage named either <code>index.html</code> or <code>index.htm</code>.</p>
<p>I have prepared a homepage with the content: <strong>“Hello nginx, I’m Haoyang Sun!”</strong>.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# echo &quot;Hello nginx, I&#x27;m Haoyang Sun!&quot; &gt; /usr/share/nginx/html/index.html</span><br><span class="line">[root@localhost ~]# cat /usr/share/nginx/html/index.html</span><br><span class="line">Hello nginx, I&#x27;m Haoyang Sun!</span><br></pre></td></tr></table></figure>

<h2 id="Enabling-and-starting-the-service"><a href="#Enabling-and-starting-the-service" class="headerlink" title="Enabling and starting the service"></a>Enabling and starting the service</h2><p>Here, we use the <code>enable</code> <code>--now</code> syntax to perform both the enable and start operations on the NGINX service.</p>
<p>This ensures that the NGINX service starts immediately and is configured to launch automatically on boot.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# systemctl enable nginx --now</span><br><span class="line">Created symlink /etc/systemd/system/multi-user.target.wants/nginx.service → /usr/lib/systemd/system/nginx.service.</span><br></pre></td></tr></table></figure>

<p>Check the status of nginx service.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# systemctl status nginx</span><br><span class="line">● nginx.service - nginx - high performance web server</span><br><span class="line">     Loaded: loaded (/usr/lib/systemd/system/nginx.service; enabled; preset: disabled)</span><br><span class="line">     Active: active (running) since Sun 2025-03-09 23:47:45 EDT; 3h 2min ago</span><br><span class="line">       Docs: http://nginx.org/en/docs/</span><br><span class="line">    Process: 21534 ExecStart=/usr/sbin/nginx -c $&#123;conffile&#125; (code=exited, status=0/SUCCESS)</span><br><span class="line">   Main PID: 21535 (nginx)</span><br><span class="line">      Tasks: 5 (limit: 47268)</span><br><span class="line">     Memory: 5.1M</span><br><span class="line">        CPU: 16ms</span><br><span class="line">     CGroup: /system.slice/nginx.service</span><br><span class="line">             ├─21535 &quot;nginx: master process /usr/sbin/nginx -c /etc/nginx/nginx.conf&quot;</span><br><span class="line">             ├─21536 &quot;nginx: worker process&quot;</span><br><span class="line">             ├─21537 &quot;nginx: worker process&quot;</span><br><span class="line">             ├─21538 &quot;nginx: worker process&quot;</span><br><span class="line">             └─21539 &quot;nginx: worker process&quot;</span><br><span class="line"></span><br><span class="line">Mar 09 23:47:45 localhost.localdomain systemd[1]: Starting nginx - high performance web serv&gt;</span><br><span class="line">Mar 09 23:47:45 localhost.localdomain systemd[1]: Started nginx - high performance web serve&gt;</span><br></pre></td></tr></table></figure>

<h2 id="Opening-the-firewall"><a href="#Opening-the-firewall" class="headerlink" title="Opening the firewall"></a>Opening the firewall</h2><p>To allow access to the NGINX service, configure the firewall accordingly.</p>
<p>This ensures that incoming traffic can reach the web server.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# firewall-cmd --add-service=http --permanent</span><br><span class="line">success</span><br><span class="line">[root@localhost ~]# firewall-cmd --reload</span><br><span class="line">success</span><br></pre></td></tr></table></figure>

<h2 id="Visiting-the-test-webpage"><a href="#Visiting-the-test-webpage" class="headerlink" title="Visiting the test webpage"></a>Visiting the test webpage</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# curl http://192.168.225.32</span><br><span class="line">Hello nginx, I&#x27;m Haoyang Sun!</span><br></pre></td></tr></table></figure>

<h2 id="Gracefully-reloading-NGINX"><a href="#Gracefully-reloading-NGINX" class="headerlink" title="Gracefully reloading NGINX"></a>Gracefully reloading NGINX</h2><p>To apply configuration changes without interrupting active connections, use a graceful reload.</p>
<p>This ensures that NGINX reloads its settings smoothly without downtime.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nginx -s reload</span><br></pre></td></tr></table></figure>

<p>Sending the <code>reload</code> signal to reload the configuration files without interrupting active connections.</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>Ansible Series Chapter4: Detailed Explanation of Ansible Content Collections</title>
    <url>//Linux/Ansible/detailed-explanation-of-ansible-content-collections/index.html</url>
    <content><![CDATA[<h2 id="Explanation-of-Ansible-Content-Collections"><a href="#Explanation-of-Ansible-Content-Collections" class="headerlink" title="Explanation of Ansible Content Collections"></a>Explanation of Ansible Content Collections</h2><h3 id="Introductions"><a href="#Introductions" class="headerlink" title="Introductions"></a>Introductions</h3><p>What Are Ansible Content Collections?</p>
<p>Ansible Content Collections are a structured approach within the Ansible ecosystem for organising and distributing automation resources. </p>
<p>They bundle together <code>modules</code>, <code>plugins</code>, <code>roles</code>, <code>documentation</code>, and other <code>related files</code> into a reusable and independently managed unit, allowing users to easily access and utilise the necessary resources.</p>
<p>Core Components of a Content Collection:</p>
<ul>
<li><p>Modules: Small scripts that perform specific tasks, such as managing files or installing software.</p>
</li>
<li><p>   Plugins: Pluggable components that extend Ansible’s functionality, such as callback plugins or filter plugins.</p>
</li>
<li><p>   Roles: Structured directories used to organise and reuse automation tasks.</p>
</li>
<li><p>   Documentation and Examples: Includes usage guides, YAML example files, and other resources to help users understand and implement the collection effectively.</p>
</li>
</ul>
<h3 id="Advantages"><a href="#Advantages" class="headerlink" title="Advantages"></a>Advantages</h3><ul>
<li><p>Modularity and Decoupling: Separates resources from the Ansible core, allowing independent updates.</p>
</li>
<li><pre><code>Ease of Distribution and Management: Enables quick installation and management of collections using the ansible-galaxy command.
</code></pre>
</li>
<li><pre><code>Namespace Support: Utilises the namespace.collection_name structure to prevent naming conflicts.
</code></pre>
</li>
<li><pre><code>Community-Driven: Developers and organisations can share content collections, fostering the growth of the open-source ecosystem.
</code></pre>
</li>
</ul>
<h3 id="Differences-Between-Using-Content-Collections-and-the-Traditional-Approach"><a href="#Differences-Between-Using-Content-Collections-and-the-Traditional-Approach" class="headerlink" title="Differences Between Using Content Collections and the Traditional Approach"></a>Differences Between Using Content Collections and the Traditional Approach</h3><p>Before the introduction of Ansible Content Collections, Ansible relied on role directory structures and core module packages.</p>
<p>This traditional approach had several limitations:</p>
<ul>
<li><p>Difficult Module Updates: All modules were bundled with the Ansible core version, meaning that updating a module required upgrading the entire Ansible version.</p>
</li>
<li><p>Lack of Flexibility: Roles and modules were managed separately, requiring users to handle multiple independent resources manually.</p>
</li>
</ul>
<p>In contrast, Content Collections unify these resources by packaging modules, plugins, roles, and documentation into a single, standalone distribution unit. This design eliminates the limitations of the traditional approach, making automation more modular, flexible, and easier to manage.</p>
<h3 id="Namespace"><a href="#Namespace" class="headerlink" title="Namespace"></a>Namespace</h3><p>Why Are Namespaces Needed?</p>
<p>To make it easier to specify collections and their contents by name, collection names are organized into <code>namespaces</code>.</p>
<p>The introduction of namespaces helps prevent conflicts and improve organisation when managing Ansible content.</p>
<p>In the early stages of Ansible’s development, all modules, plugins, and roles were structured in a flat manner, leading to several issues:</p>
<ul>
<li><p>Naming Conflicts: Different developers might create modules or roles with the same name, causing conflicts and confusion.</p>
</li>
<li><p>Difficult Organisation and Management: As the Ansible ecosystem expanded, the growing number of resources became harder to manage without a structured hierarchy.</p>
</li>
</ul>
<p>With namespaces, Ansible creates separate logical spaces for different sources, such as individual developers or organisations. Using the structure namespace.collection_name.module_name, resources are ensured to <code>be unique</code> while also improving code readability and maintainability.</p>
<p>The namespace is the first part of a collection name. For example, all the collections that the Ansible <code>community maintain</code> are in the community namespace, and have names such as<br><code>community.crypto</code>, <code>community.postgresql</code>, and <code>community.rabbitmq</code>. Collections that <code>Red Hat maintain</code> and support might use the redhat namespace, and have names such as <code>redhat.rhv</code>, <code>redhat.satellite</code>, and <code>redhat.insights</code>. </p>
<p>Names of namespaces are limited to <code>ASCII lowercase letters</code>, <code>numbers</code>, and <code>underscores</code>, must be <code>at least two characters long</code>, and <code>must not start with an underscore</code>.</p>
<h3 id="Accessing-Ansible-Content-Collection-Documentation"><a href="#Accessing-Ansible-Content-Collection-Documentation" class="headerlink" title="Accessing Ansible Content Collection Documentation"></a>Accessing Ansible Content Collection Documentation</h3><p>Use the <code>ansible-navigator collections</code> command to list the collections available in automation execution environments.  Type a colon before the collection number, you could check the number x line available module. Enter the module number to access its documentation.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">  Name                    Version Shadowed Type      Path</span><br><span class="line">0│amazon.aws              3.2.0   False    contained /usr/share/ansible/collec</span><br><span class="line">1│ansible.builtin         2.13.3  False    contained /usr/lib/python3.9/site-p</span><br><span class="line">2│ansible.controller      4.2.1   False    contained /usr/share/ansible/collec</span><br><span class="line">3│ansible.netcommon       3.0.0   False    contained /usr/share/ansible/collec</span><br><span class="line">4│ansible.network         1.2.0   False    contained /usr/share/ansible/collec</span><br><span class="line">5│ansible.posix           1.3.0   False    contained /usr/share/ansible/collec</span><br><span class="line">6│ansible.security        1.0.0   False    contained /usr/share/ansible/collec</span><br><span class="line">7│ansible.utils           2.6.1   False    contained /usr/share/ansible/collec</span><br><span class="line">8│ansible.windows         1.9.0   False    contained /usr/share/ansible/collec</span><br><span class="line">9│ansible.yang            1.0.0   False    contained /usr/share/ansible/collec</span><br></pre></td></tr></table></figure>

<p>Use the following command to display the help documentation in plain text format:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-navigator doc &lt;module_name&gt; -m stdout</span><br></pre></td></tr></table></figure>

<p>E.g.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[student@workstation ~]$ ansible-navigator doc redhat.insights.insights_register \</span><br><span class="line">&gt; --mode stdout</span><br><span class="line">&gt; REDHAT.INSIGHTS.INSIGHTS_REGISTER    (/usr/share/ansible/collections/ansible_&gt;</span><br><span class="line"></span><br><span class="line">        This module will check the current registration status,</span><br><span class="line">        unregister if needed, and then register the insights client</span><br><span class="line">        (and update the display_name if needed)</span><br><span class="line"></span><br><span class="line">OPTIONS (= is mandatory):</span><br><span class="line"></span><br><span class="line">- display_name</span><br><span class="line">        This option is here to enable registering with a display_name</span><br><span class="line">        outside of using a configuration file. Some may be used to</span><br><span class="line">        doing it this way so I left this in as an optional parameter.</span><br><span class="line">        [Default: (null)]</span><br><span class="line">        type: str</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="Using-Ansible-Content-Collections-in-Playbooks"><a href="#Using-Ansible-Content-Collections-in-Playbooks" class="headerlink" title="Using Ansible Content Collections in Playbooks"></a>Using Ansible Content Collections in Playbooks</h3><p>To use a module or a role from a collection, refer to it with its <code>fully qualified collection name</code> (FQCN).<br>For example, use redhat.insights.insights_register to refer to the insights_register module.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Register</span> <span class="string">new</span> <span class="string">systems</span></span><br><span class="line">  <span class="attr">hosts:</span> <span class="string">db.example.com</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Ensure</span> <span class="string">the</span> <span class="string">new</span> <span class="string">system</span> <span class="string">is</span> <span class="string">registered</span> <span class="string">with</span> <span class="string">Red</span> <span class="string">Hat</span> <span class="string">Insights</span></span><br><span class="line">      <span class="attr">redhat.insights.insights_register:</span></span><br><span class="line">        <span class="attr">state:</span> <span class="string">present</span></span><br><span class="line">        <span class="attr">force_reregister:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<p>The play in the following playbook uses the organizations role from the redhat.satellite collection.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Add</span> <span class="string">the</span> <span class="string">test</span> <span class="string">organizations</span> <span class="string">to</span> <span class="string">Red</span> <span class="string">Hat</span> <span class="string">Satellite</span></span><br><span class="line">  <span class="attr">hosts:</span> <span class="string">localhost</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Ensure</span> <span class="string">the</span> <span class="string">organizations</span> <span class="string">exist</span></span><br><span class="line">      <span class="attr">ansible.builtin.include_role:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">redhat.satellite.organizations</span></span><br><span class="line">      <span class="attr">vars:</span></span><br><span class="line">        <span class="attr">satellite_server_url:</span> <span class="string">https://sat.example.com</span></span><br><span class="line">        <span class="attr">satellite_username:</span> <span class="string">admin</span></span><br><span class="line">        <span class="attr">satellite_password:</span> <span class="string">Sup3r53cr3t</span></span><br><span class="line">        <span class="attr">satellite_organizations:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test1</span></span><br><span class="line">            <span class="attr">label:</span> <span class="string">tst1</span></span><br><span class="line">            <span class="attr">state:</span> <span class="string">present</span></span><br></pre></td></tr></table></figure>

<p>Many Ansible Content Collections also use this <code>redirection mechanism</code> to translate old short names into Fully Qualified Collection Names (FQCN). </p>
<p>For example, the acl module is now part of the ansible.posix collection, and it uses ansible.posix.acl as its FQCN.</p>
<h3 id="Using-the-Built-in-Ansible-Content-Collection"><a href="#Using-the-Built-in-Ansible-Content-Collection" class="headerlink" title="Using the Built-in Ansible Content Collection"></a>Using the Built-in Ansible Content Collection</h3><p>Ansible always includes a special collection named ansible.builtin. This collection includes a set of common modules, such as <code>copy</code>, <code>template</code>, <code>file</code>, <code>yum</code>, <code>command</code>, and <code>service</code>.</p>
<p>You can use the <code>short names</code> of these modules in your playbooks. For example, you can use <code>file</code> to refer to the <code>ansible.builtin.file</code> module. </p>
<p>However, Red Hat recommends that you use the FQCN notation to prevent conflicts with collections that might use the same module names.</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title>2025/03/08 English accumulation</title>
    <url>//Language/English/20250308/index.html</url>
    <content><![CDATA[<ul>
<li><p><strong>accomplishment</strong>: It refers to something successfully completed or achieved, often through effort, skill, or perseverance. It can describe a notable achievement in a particular field, a personal success, or even a refined skill or ability. E.g. <code>Speaking multiple languages is an impressive accomplishment.</code></p>
</li>
<li><p><strong>savor&#x2F;savour</strong>: It means to fully enjoy or appreciate something, especially a taste, smell, or experience. It often implies taking one’s time to relish and delight in the moment. E.g. <code>Savour the moment—you’ve worked hard for this success.</code></p>
</li>
<li><p><strong>catapult</strong>: It refers to propel something or someone suddenly and forcefully into motion or a new situation. E.g. <code>The film’s success catapulted the young actor to fame.</code></p>
</li>
<li><p><strong>anniversary</strong>: I refers to the annual recurrence of a significant date, marking an event that happened in a previous year. It is commonly used for celebrations or commemorations. E.g. <code>They celebrated their tenth wedding anniversary with a holiday in Italy.</code></p>
</li>
<li><p><strong>outlast</strong>: <code>outlast</code> is a verb meaning to endure or last longer than something or someone else. It implies surpassing in duration, resilience, or survival. E.g. <code>These sturdy boots will outlast cheaper alternatives.</code></p>
</li>
<li><p><strong>innovation</strong>: <code>innovation</code> refers to the introduction of new ideas, methods, or products, often involving improvement or creativity. It can apply to technology, business, science, or any field where progress is made through new developments. E.g. <code>Innovation is key to staying ahead in a competitive market.</code></p>
</li>
<li><p><strong>pressing need for</strong>: It refers to an urgent or immediate requirement for something. It emphasises the importance and necessity of taking swift action. E.g. <code>After the storm, there was a pressing need for emergency supplies and assistance.</code></p>
</li>
<li><p><strong>mainstay</strong>: <code>mainstay</code> refers to something or someone that is the most important or essential part of a system, organisation, or group, providing support and stability. E.g. <code>Agriculture is the mainstay of the country’s economy.</code></p>
</li>
<li><p><strong>be humbled by</strong>: <code>to be humbled by</code> means to feel a deep sense of modesty, gratitude, or humility due to an experience, recognition, or comparison. It often implies being moved or gaining perspective, especially when faced with something inspiring, overwhelming, or greater than oneself. E.g. <code>He was humbled by the generosity of the community after the disaster.</code></p>
</li>
<li><p><strong>hindsight</strong>: <code>hindsight</code> refers to the understanding or realisation of a situation or event after it has happened, often with the benefit of knowing the outcome. It is commonly used to reflect on past decisions or actions. E.g. <code>Hindsight is a wonderful thing, but at the time, we did what we thought was best.</code></p>
</li>
<li><p><strong>no-nonsense</strong>: <code>no-nonsense</code> describes a practical, straightforward, and efficient approach to something, without unnecessary fuss or distractions. It is often used to describe people, attitudes, or methods that are serious, direct, and focused on getting things done. E.g. <code>His no-nonsense approach to problem-solving made him highly respected.</code></p>
</li>
<li><p><strong>mentors</strong>: <code>mentors</code> are experienced and knowledgeable individuals who provide guidance, support, and advice to less experienced people, often in a professional, academic, or personal development context. A mentor helps someone grow by sharing wisdom, offering encouragement, and providing constructive feedback. E.g. <code>Good mentors can make a significant difference in a young professional’s development.</code></p>
</li>
<li><p><strong>dedication</strong>: <code>dedication</code> refers to the quality of being committed or devoted to a particular task, cause, or person. It often implies hard work, persistence, and focus in achieving goals or supporting something important. E.g. <code>The success of the project is a testament to the team’s dedication and effort.</code></p>
</li>
<li><p><strong>departure</strong>: <code>departure</code> refers to the act of leaving or moving away from a place, situation, or position. It can also refer to the moment or event when someone or something departs. E.g. <code>The departure of the flight has been delayed due to bad weather.</code></p>
</li>
</ul>
]]></content>
      <categories>
        <category>Language</category>
      </categories>
      <tags>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title>Ansible Series Chapter3: Implementing Recommended Ansible Practices</title>
    <url>//Linux/Ansible/implementing-recommended-ansible-practices/index.html</url>
    <content><![CDATA[<h2 id="The-Effectiveness-of-Ansible"><a href="#The-Effectiveness-of-Ansible" class="headerlink" title="The Effectiveness of Ansible"></a>The Effectiveness of Ansible</h2><p>As you work with more advanced features and larger, more complex projects, it becomes more difficult to manage and maintain Ansible Playbooks, or to use them effectively.</p>
<p>To paraphrase Ansible developer Jeff Geerling, using Ansible effectively relies on three key practices:</p>
<ul>
<li><p>Keeping things simple</p>
</li>
<li><p>Staying organized</p>
</li>
<li><p>Testing often</p>
</li>
</ul>
<h3 id="Keeping-things-simple"><a href="#Keeping-things-simple" class="headerlink" title="Keeping things simple"></a>Keeping things simple</h3><ul>
<li><p>Keeping Your Playbooks Readable</p>
<ol>
<li><p>Add Comments: Ensure that playbooks and tasks include meaningful comments to improve readability and maintainability.</p>
</li>
<li><p>   Use Blank Lines to Separate Logic: Insert blank lines between logical sections to enhance clarity.</p>
</li>
<li><p>   Always Name Plays and Tasks Meaningfully: Every play and task should have a clear and descriptive name to convey its purpose.</p>
</li>
<li><p>Maintain a Consistent Style: Use a uniform coding style, including consistent indentation, variable naming conventions, and structured comments.</p>
</li>
<li><p>   Leverage Roles for Efficiency: Utilize roles to modularize and organize automation tasks efficiently.</p>
</li>
<li><p>   Stick to Native YAML Syntax: Avoid writing parameters in a single line—use proper YAML formatting to ensure readability and maintainability.</p>
</li>
</ol>
<p>The following syntax is <code>easier</code> for most people to read:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Postfix</span> <span class="string">is</span> <span class="string">installed</span> <span class="string">and</span> <span class="string">updated</span></span><br><span class="line">  <span class="attr">ansible.builtin.yum:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">postfix</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">latest</span></span><br><span class="line">  <span class="attr">notify:</span> <span class="string">update_postfix</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Postfix</span> <span class="string">is</span> <span class="string">running</span></span><br><span class="line">  <span class="attr">ansible.builtin.service:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">postfix</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">started</span></span><br></pre></td></tr></table></figure>

<p>Use native YAML syntax, not the “folded” syntax. For example, the following example is <code>not a recommended format</code>:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Postfix</span> <span class="string">is</span> <span class="string">installed</span> <span class="string">and</span> <span class="string">updated</span></span><br><span class="line">  <span class="attr">ansible.builtin.yum:</span> <span class="string">name=postfix</span> <span class="string">state=latest</span></span><br><span class="line">  <span class="attr">notify:</span> <span class="string">restart_postfix</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Postfix</span> <span class="string">is</span> <span class="string">running</span></span><br><span class="line">  <span class="attr">ansible.builtin.service:</span> <span class="string">name=postfix</span> <span class="string">state=started</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Use Existing Modules</p>
<ol>
<li><p>When writing a new playbook, start with a <code>basic playbook</code> and, if possible, a <code>static inventory</code>. Use <code>ansible.builtin.debug</code> tasks as stubs as you build your design. When your playbook functions as expected, break up your playbook into smaller, logical components by using <code>imports</code> and <code>includes</code>.</p>
</li>
<li><p>Ansible playbooks are designed to be idempotent, meaning that running the same playbook multiple times should produce the same result without unintended changes. </p>
<p> It is easier to make your playbook idempotent and easier to maintain if you use the modules designed for a specific task.</p>
<p> However, using the following modules can break idempotency:</p>
<ul>
<li><code>ansible.builtin.command</code></li>
<li><code>ansible.builtin.shell</code></li>
<li><code>ansible.builtin.raw</code></li>
</ul>
</li>
<li><p>Many modules have a default state or other variables that control what they do. For example, the yum module currently assumes that the package you name should be <code>present</code> in most cases.</p>
</li>
</ol>
</li>
<li><p>Adhering to a Standard Style</p>
<p>Consider having a standard “style” that your team follows when writing Ansible projects. For example:</p>
<ol>
<li><p>How many spaces do you indent? </p>
</li>
<li><p>How do you want vertical white space used? </p>
</li>
<li><p>How should tasks, plays, roles, and variables be named? </p>
</li>
<li><p>What should get commented on and how?</p>
</li>
</ol>
<p>Having a consistent standard can help improve maintainability and readability.</p>
</li>
</ul>
<h3 id="Staying-Organized"><a href="#Staying-Organized" class="headerlink" title="Staying Organized"></a>Staying Organized</h3><ul>
<li><p>Following Conventions for Naming Variables</p>
<ol>
<li><p>Variable names should <code>clarify contents</code>.</p>
</li>
<li><p>When defining role variables, it is best to <code>prefix them with the role name</code> to avoid conflicts and improve clarity. If the name of your role is myapp then prefix your variables with myapp_ so that you can easily identify them from variables in other roles and the playbook.</p>
</li>
<li><p>Use <code>descriptive variables</code>, such as apache_tls_port rather than a less explanatory variable such as p. In roles, it is a good practice to prefix role variables with the role name.</p>
</li>
</ol>
</li>
<li><p>Standardizing the Project Structure</p>
<p>Use a consistent pattern when structuring the files of your Ansible project on a file system. The following is a good example:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">├── dbservers.yml</span><br><span class="line">├── inventories/</span><br><span class="line">│ ├── prod/</span><br><span class="line">│ │ ├── group_vars/</span><br><span class="line">│ │ ├── host_vars/</span><br><span class="line">│ │ └── inventory/</span><br><span class="line">│ └── stage/</span><br><span class="line">│ ├── group_vars/</span><br><span class="line">│ ├── host_vars/</span><br><span class="line">│ └── inventory/</span><br><span class="line">├── roles/</span><br><span class="line">│ └── std_server/</span><br><span class="line">├── site.yml</span><br><span class="line">├── storage.yml</span><br><span class="line">└── webservers.yml</span><br></pre></td></tr></table></figure>

<p>One of the playbook structure benefits is that you can divide up your extensive playbook into smaller files to make it more readable. Those smaller playbooks can contain plays for a specific purpose that you can run independently.</p>
</li>
<li><p>Using Dynamic Inventories</p>
<ol>
<li><p>Using Dynamic Inventory。</p>
</li>
<li><p>Dynamic inventory is particularly powerful when integrated with cloud providers, container platforms, and virtual machine management systems.</p>
</li>
<li><p>If dynamic inventory is not an option, other tools can be used to dynamically construct groups or gather additional information.</p>
</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Generate</span> <span class="string">dynamic</span> <span class="string">groups</span></span><br><span class="line">  <span class="attr">hosts:</span> <span class="string">all</span></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Generate</span> <span class="string">dynamic</span> <span class="string">groups</span> <span class="string">based</span> <span class="string">on</span> <span class="string">architecture</span></span><br><span class="line">      <span class="attr">ansible.builtin.group_by:</span></span><br><span class="line">        <span class="attr">key:</span> <span class="string">arch_&quot;&#123;&#123;</span> <span class="string">ansible_facts[&#x27;architecture&#x27;]</span> <span class="string">&#125;&#125;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Configure</span> <span class="string">x86_64</span> <span class="string">systems</span></span><br><span class="line">  <span class="attr">hosts:</span> <span class="string">arch_x86_64</span></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">First</span> <span class="string">task</span> <span class="string">for</span> <span class="string">x86_64</span> <span class="string">configuration</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Taking Advantage of Groups</p>
<ol>
<li><p>Geographical: Differentiate hosts from different regions, countries, continents, or data centers.</p>
</li>
<li><p>Environmental: Differentiate hosts dedicated to different stages of the software lifecycle, including development, staging, testing, and production.</p>
</li>
<li><p>Sites or services: Group hosts that offer or link to a subset of functions, such as a specific website, an application, or a subset of features.</p>
</li>
</ol>
</li>
<li><p>Reusing Content with Collections and Roles</p>
<p>Roles and collections help keep playbooks simple and enable code reuse across different projects, reducing workload. When necessary, you can also create a custom automation execution environment.</p>
<p>Common Sources for Collections and Roles:</p>
<ul>
<li>Red Hat Official Website</li>
<li>Ansible Galaxy</li>
<li>GitHub</li>
<li>   Internal Company Repository</li>
</ul>
</li>
<li><p>Running Playbooks Centrally </p>
<p>Consider using a <code>dedicated control node</code> to run all Ansible Playbooks from a single location. Ideally, an Automation <code>Controller</code> should be used.</p>
<p>The reason is simple: Ansible requires control over the managed hosts. Frequently changing the control node may lead to Playbook execution failures or security issues.</p>
</li>
</ul>
<h3 id="Performing-Regular-Testing"><a href="#Performing-Regular-Testing" class="headerlink" title="Performing Regular Testing"></a>Performing Regular Testing</h3><ul>
<li><p>Test Your Playbooks and Tasks Regularly During Development</p>
<ol>
<li><p>When confirming the success of a task, validate the task’s actual result rather than relying solely on the module’s return code.</p>
</li>
<li><p>In addition to using the <code>debug</code> module, you can also utilise the <code>uri</code> module to check whether web-based services are functioning correctly.</p>
 <figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Start</span> <span class="string">web</span> <span class="string">server</span></span><br><span class="line">  <span class="attr">ansible.builtin.service:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">httpd</span></span><br><span class="line">    <span class="attr">status:</span> <span class="string">started</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Check</span> <span class="string">web</span> <span class="string">site</span> <span class="string">from</span> <span class="string">web</span> <span class="string">server</span></span><br><span class="line">  <span class="attr">ansible.builtin.uri:</span></span><br><span class="line">    <span class="attr">url:</span> <span class="string">http://&#123;&#123;</span> <span class="string">ansible_fqdn</span> <span class="string">&#125;&#125;</span></span><br><span class="line">    <span class="attr">return_content:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">register:</span> <span class="string">example_webpage</span></span><br><span class="line">  <span class="attr">failed_when:</span> <span class="string">example_webpage.status</span> <span class="type">!=</span> <span class="number">200</span></span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p>Implement Recovery and Rollback with block&#x2F;rescue</p>
<p>The block directive is useful for grouping tasks. When combined with the rescue directive, it helps in recovering from errors or failures, making it an effective approach for implementing recovery and rollback mechanisms.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">block:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Check</span> <span class="string">web</span> <span class="string">site</span> <span class="string">from</span> <span class="string">web</span> <span class="string">server</span></span><br><span class="line">    <span class="attr">ansible.builtin.uri:</span></span><br><span class="line">      <span class="attr">url:</span> <span class="string">http://&#123;&#123;</span> <span class="string">ansible_fqdn</span> <span class="string">&#125;&#125;</span></span><br><span class="line">      <span class="attr">return_content:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">register:</span> <span class="string">example_webpage</span></span><br><span class="line">    <span class="attr">failed_when:</span> <span class="string">example_webpage.status</span> <span class="type">!=</span> <span class="number">200</span></span><br><span class="line"></span><br><span class="line"><span class="attr">rescue:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Restart</span> <span class="string">web</span> <span class="string">server</span></span><br><span class="line">    <span class="attr">ansible.builtin.service:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">httpd</span></span><br><span class="line">      <span class="attr">status:</span> <span class="string">restarted</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Using Test Tools</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[student@workstation ~]$ ansible-navigator run playbook --syntax-check -m stdout</span><br></pre></td></tr></table></figure>
</li>
<li><p>Analyzing the Playbooks</p>
<ul>
<li><p>ansible-lint </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[student@workstation ~]$ ansible-lint xxx.yaml</span><br></pre></td></tr></table></figure>
</li>
<li><p>yamllint</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[student@workstation ~]$ yamllint xxx.yaml</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>Testing with New Versions</p>
<p>Regularly test your playbooks and automation workflows against newer versions of Ansible Core. This ensures compatibility and helps identify potential issues before upgrading your production environment.</p>
<p>If your playbook displays warnings or deprecation messages during execution, you should pay attention to them and make the necessary adjustments.</p>
<p>When a feature in Ansible Core is deprecated or changed, a deprecation notice is provided <code>four minor versions</code> in advance before it is removed or modified.</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title>Ansible Series Chapter2: The introduction of ansible-navigator</title>
    <url>//Linux/Ansible/the-introduction-of-ansible-navigator/index.html</url>
    <content><![CDATA[<h2 id="Automation-Content-Navigator"><a href="#Automation-Content-Navigator" class="headerlink" title="Automation Content Navigator"></a>Automation Content Navigator</h2><p>Automation content navigator (ansible-navigator) is a new tool in Red Hat Ansible Automation Platform 2, and is designed to make it easier for you to write playbooks that can be<br>run in a reproducible manner. It combines the features formerly provided by <code>ansible-playbook</code>, <code>ansible-inventory</code>, <code>ansible-config</code>, and <code>ansible-doc</code> in one top-level interface.</p>
<p>Automation content navigator offers a new <code>interactive mode</code> with a text-based user interface (<code>TUI</code>), and can also be run using the <code>--mode stdout</code> (or <code>-m stdout</code>) option to provide output in the original format used by the earlier tools.</p>
<p>Here are its main features:</p>
<ol>
<li><p>Unified CLI Experience</p>
<ul>
<li><p>Replaces multiple Ansible commands (ansible-playbook, ansible-inventory, ansible-config, ansible-doc) with a single interface.</p>
</li>
<li><p>Provides a streamlined and consistent way to interact with Ansible.</p>
</li>
</ul>
</li>
<li><p>Containerized Execution</p>
<ul>
<li><p>Runs Ansible playbooks within a container, separating the control node from the execution environment.</p>
</li>
<li><p>Ensures compatibility across different Python versions and dependencies.</p>
</li>
<li><p>Reduces the need for local Ansible installations and dependencies.</p>
</li>
</ul>
</li>
<li><p>Interactive TUI (Text User Interface)</p>
<ul>
<li><p>Offers an interactive, user-friendly text-based interface.</p>
</li>
<li><p>Enables easier navigation through playbook results, inventory, and documentation.</p>
</li>
<li><p>Provides real-time insights into playbook execution.</p>
</li>
</ul>
</li>
<li><p>Enhanced Playbook Execution and Debugging</p>
<ul>
<li><p>Supports interactive viewing of playbook execution with detailed logs.</p>
</li>
<li><p>Allows users to explore playbook results step by step.</p>
</li>
<li><p>Helps in debugging with real-time feedback.</p>
</li>
</ul>
</li>
<li><p>Seamless Integration with Automation Hub</p>
<ul>
<li><p>Can access certified and private content collections from Automation Hub.</p>
</li>
<li><p>Helps manage and distribute automation content efficiently.</p>
</li>
</ul>
</li>
<li><p>Supports Various Execution Environments</p>
<ul>
<li><p>Works with Ansible execution environments (EEs), allowing flexibility in managing dependencies.</p>
</li>
<li><p>Users can switch between different execution environments as needed.</p>
</li>
</ul>
</li>
<li><p>Inventory and Documentation Management</p>
<ul>
<li><p>Provides easy access to inventory information with interactive views.</p>
</li>
<li><p>Enables browsing of Ansible documentation and content collections directly from the CLI.</p>
</li>
</ul>
</li>
</ol>
<p>Compared with the original method, for example, to run a playbook with <code>ansible-playbook</code>, you might enter the following command:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[student@workstation ~]$ ansible-playbook -i inventory playbook.yml </span><br></pre></td></tr></table></figure>

<p>Currently, You can use the <code>ansible-navigator</code> command to do the same thing and get output from the playbook in the same format, as follows:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[student@workstation ~]$ ansible-navigator run playbook.yml -i inventory -m stdout</span><br></pre></td></tr></table></figure>

<p>However, if you <code>omit the -m stdout option</code> for the ansible-navigator command, it starts an <code>interactive mode</code> that summarizes the output of the playbook run in real time. This enables you to investigate the results in a TUI after the run completes.</p>
<p><img src="/../images/ansible-navigator.png" alt="Output of a playbook run with automation content navigator"></p>
<p>In the preceding image, you can see that ansible-navigator ran a playbook containing three plays. </p>
<p>You can get more information about the tasks that were run by the first play by <code>pressing 0, or by typing :0</code> in ansible-navigator:</p>
<p><img src="/../images/ansible-navigator1.png" alt="Output of a playbook run with automation content navigator"></p>
<p>You can also get detailed information about particular tasks. In the preceding example, if you <code>press 2 or type :2</code>, then details of the “Ensure HAProxy is started and enabled” task are displayed, and you can use the arrow keys to scroll through the results:</p>
<p><img src="/../images/ansible-navigator2.png" alt="Output of a playbook run with automation content navigator"></p>
<p>To <code>go back</code> to previous pages or <code>exit</code> from ansible-navigator at the top-level page, <code>press Esc</code>.</p>
<h2 id="Using-Automation-Execution-Environments-to-Improve-Portability"><a href="#Using-Automation-Execution-Environments-to-Improve-Portability" class="headerlink" title="Using Automation Execution Environments to Improve Portability"></a>Using Automation Execution Environments to Improve Portability</h2><p>Automation Execution Environments (EEs) enhance portability by providing a consistent and isolated environment for running Ansible automation. Here’s how they help:</p>
<ol>
<li><p>Consistency Across Different Systems</p>
<ul>
<li><p>EEs encapsulate Ansible, dependencies, and Python libraries into a container image.</p>
</li>
<li><p>Ensures that automation runs the same way across different environments, avoiding “works on my machine” issues.</p>
</li>
</ul>
</li>
<li><p>Simplified Dependency Management</p>
<ul>
<li><p>No need to install Ansible and its dependencies on each system manually.</p>
</li>
<li><p>Eliminates conflicts between different versions of Python and Ansible modules.</p>
</li>
</ul>
</li>
<li><p>Improved Reproducibility</p>
<ul>
<li><p>   Playbooks always run within a controlled, versioned environment.</p>
</li>
<li><p>   Ensures that automation behaves predictably across development, testing, and production.</p>
</li>
</ul>
</li>
<li><p>Seamless Collaboration</p>
<ul>
<li><p>   Teams can share predefined execution environments, reducing setup inconsistencies.</p>
</li>
<li><p>   Developers and operators can work with the same automation stack, minimizing configuration drift.</p>
</li>
</ul>
</li>
<li><p>Integration with Ansible Navigator</p>
<ul>
<li><p>   ansible-navigator uses execution environments to run playbooks, making automation portable and self-contained.</p>
</li>
<li><p>   Users can easily switch between different EEs to match specific automation needs.</p>
</li>
</ul>
</li>
</ol>
<p>When you use <code>ansible-navigator</code> to run a playbook, and do not specify a particular automation execution environment, <code>ansible-navigator</code> automatically attempts to pull the default automation execution environment from <code>registry.redhat.io</code> if it is not already present on the system. For Red Hat Ansible Automation Platform 2.2, this default environment includes Ansible Core 2.13 and a standard set of Red Hat Ansible Certified Content Collections.</p>
<p>By default, the ansible-navigator command in Ansible Automation Platform 2.2 attempts to download and use the container image available at <code>registry.redhat.io/ansible-automation-platform-22/ee-supported-rhel8:latest</code>s if the automation execution environment is not specified in some other way.</p>
<p>You can also use the <code>--pull-policy (--pp)</code> option to control how ansible-navigator pulls container images. When the value of this option is set to <code>missing</code>, automation content navigator only pulls the container image if the image does not exist on the local system.</p>
<blockquote>
<p>Note:</p>
<p>Depending on your container runtime, use the corresponding command to log in to the image registry.</p>
<p>e.g. podman&#x2F;docker login <registry_url></p>
</blockquote>
<h2 id="Installing-ansible-navigator"><a href="#Installing-ansible-navigator" class="headerlink" title="Installing ansible-navigator"></a>Installing ansible-navigator</h2><p>Ansible is a <code>non-intrusive</code> automation platform, meaning it only needs to <code>be installed on the control node</code> without requiring any software or agents on managed nodes.</p>
<blockquote>
<p>Note: </p>
<p>Installation requires <code>an active Red Hat subscription</code>, but in our environment, it is already pre-configured.</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[student@workstation ~]$ <span class="built_in">sudo</span> yum -y install ansible-navigator</span><br></pre></td></tr></table></figure>

<p>After installation, you also need to generate the <code>ansible.cfg</code> configuration file and the <code>ansible-navigator.yml</code> configuration file.</p>
<ul>
<li><p><code>ansible.cfg</code> is a crucial file that controls the core behavior of Ansible.</p>
<p>ansible.cfg is the core configuration file for Ansible, used to define Ansible’s global behaviour. It mainly controls the execution of tasks, the method of connecting to remote hosts, and important parameters such as logging and role paths. This file is automatically read when running Ansible, and users can customise Ansible’s runtime environment through it.</p>
<p>Main Functions:</p>
<ul>
<li><p>Inventory Configuration: Specifies the default path for the inventory file.</p>
</li>
<li><p>Connection Management: Configures SSH connection parameters, such as timeout and control path.</p>
</li>
<li><p>Log Management: Defines the location and format of log files to record the execution process.</p>
</li>
<li><p>Role and Module Paths: Configures the search paths for custom roles and modules, facilitating the extension of functionalities.</p>
</li>
</ul>
<p>This file has a <code>high priority</code> and affects the operation of all Ansible tasks. It is the <code>core tool for controlling</code> Ansible’s behaviour.</p>
</li>
<li><p><code>ansible-navigator.yml</code> is a customization tool for configuring the Navigator interface and interactive experience.</p>
<p>ansible-navigator.yml is a configuration file designed specifically for Ansible Navigator, used to control the interactive interface behaviour, execution environment, and the interaction with inventories and content collections. It is more focused on optimising the user experience and providing a <code>customised</code> operational approach.</p>
<p>Main Functions:</p>
<ul>
<li><p>Interactive Mode: Specifies the operating mode of Navigator, such as interactive interface mode or standard output mode.</p>
</li>
<li><p>   Execution Environment: Defines whether to enable a containerised execution environment and configures the container image and runtime engine (e.g., Podman or Docker).</p>
</li>
<li><p>   Resource Management: Sets the default inventory file and playbook paths for quicker loading and usage.</p>
</li>
<li><p>   Logging and Debugging: Controls the location and level of detail for logging, making it easier for users to trace and troubleshoot issues.</p>
</li>
<li><p>   Interface Optimisation: Adjusts the behaviour and layout of the user interface to improve interaction efficiency.</p>
</li>
</ul>
<p>This file’s settings focus more on <code>user experience</code>, mainly influencing the operation of the Navigator tool, rather than the core execution logic of Ansible.</p>
</li>
</ul>
<p>These two files complement each other, providing a flexible and efficient automation environment for users.</p>
<h2 id="Configuring-Authentication-to-Managed-Hosts"><a href="#Configuring-Authentication-to-Managed-Hosts" class="headerlink" title="Configuring Authentication to Managed Hosts"></a>Configuring Authentication to Managed Hosts</h2><p>Automation content navigator needs to be able to log in to managed hosts and gain <code>superuser privileges</code> on those hosts. The easiest way to implement this is by using <code>SSH key-based authentication</code> to an account that allows privilege escalation through sudo without a password.</p>
<p>To begin with, you need to <code>generate an SSH key pair on the control node</code> for the automation user, and then <code>distribute the public key to the remote hosts</code>. This enables passwordless SSH authentication between the control node and the remote systems, where user is the remote user and host is one of the managed hosts.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[student@workstation ~]$ ssh-keygen</span><br><span class="line">[student@workstation ~]$ ssh-copy-id student@servera</span><br></pre></td></tr></table></figure>

<p>Then configure ansible.cfg on the control node or have ansible.cfg in the current directory. Set a remote_user directive to the name of the user account you plan to use on the managed hosts in the [defaults] section of your Ansible configuration file on the control node.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /etc/ansible/ansible.cfg</span><br></pre></td></tr></table></figure>

<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="section">[defaults]</span></span><br><span class="line"><span class="attr">remote_user</span>=student</span><br></pre></td></tr></table></figure>

<p>You need to configure sudo privilege escalation on all managed hosts.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[student@workstation ~]$ <span class="built_in">sudo</span> vim /etc/sudoers</span><br><span class="line">...</span><br><span class="line">student ALL=(ALL)       NOPASSWD: ALL</span><br></pre></td></tr></table></figure>

<p>The main difference between <code>authenticating ansible-navigator and ansible-playbook</code> to managed hosts is that ansible-navigator runs the playbook inside a container that cannot access your ~&#x2F;.ssh directory. However, if you are running <code>ssh-agent</code> on your control node to store SSH private keys, when you run ansible-navigator it can automatically provide those keys to the execution environment.</p>
<p>If you logged in to the control node through the graphical desktop environment, ssh-agent is automatically started and the ssh-add command is automatically run to add your private keys to the agent. If any of your SSH private keys are passphrase protected, you are prompted for the password after you log in. Authentication then automatically works for all terminals in that graphical login session.</p>
<p>If you logged in to the control node through a text-based virtual console or remotely using ssh, you must start ssh-agent yourself by running the <code>eval $(ssh-agent)</code> command. In the same shell, you then run ssh-add and if necessary provide the passphrase for your private key. You can then run ansible-navigator in the same shell and authenticate.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[student@workstation ~]$ <span class="built_in">eval</span> $(ssh-agent)</span><br><span class="line">[student@workstation ~]$ ssh-add</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>Earlier Ansible command</th>
<th>Automation content navigator subcommand</th>
</tr>
</thead>
<tbody><tr>
<td>ansible-config</td>
<td>ansible-navigator config</td>
</tr>
<tr>
<td>ansible-doc</td>
<td>ansible-navigator doc</td>
</tr>
<tr>
<td>ansible-inventory</td>
<td>ansible-navigator inventory</td>
</tr>
<tr>
<td>ansible-playbook</td>
<td>ansible-navigator run</td>
</tr>
</tbody></table>
<p>Automation content navigator also provides additional functionality. Most subcommands can be run from either the command line or from within an interactive automation content navigator session, but some commands do not support the <code>-m stdout</code> option. </p>
<p>When running a subcommand in an interactive session, type : to start the command, such as <code>:config</code>.</p>
<p>The following chart introduces some ansible-navigator subcommands.</p>
<table>
<thead>
<tr>
<th>Subcommand</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td>collections</td>
<td>Get information about installed collections.</td>
</tr>
<tr>
<td>config</td>
<td>Examine the current Ansible configuration.</td>
</tr>
<tr>
<td>doc</td>
<td>Examine the Ansible documentation for a plug-in.</td>
</tr>
<tr>
<td>help</td>
<td>Display detailed help for ansible-navigator.</td>
</tr>
<tr>
<td>images</td>
<td>Examine an execution environment.</td>
</tr>
<tr>
<td>inventory</td>
<td>Explore an inventory.</td>
</tr>
<tr>
<td>log</td>
<td>Review the current log file.</td>
</tr>
<tr>
<td>open</td>
<td>Open the current page in a text editor.</td>
</tr>
<tr>
<td>replay</td>
<td>Replay a playbook artifact.</td>
</tr>
<tr>
<td>run</td>
<td>Run a playbook.</td>
</tr>
</tbody></table>
<h3 id="Reviewing-Previous-Playbook-Runs"><a href="#Reviewing-Previous-Playbook-Runs" class="headerlink" title="Reviewing Previous Playbook Runs"></a>Reviewing Previous Playbook Runs</h3><p>Automation content navigator provides a new <code>replay</code> feature that displays the output of a previous playbook run. If playbook artifacts are enabled (the default), then the ansible-navigator run command generates an artifact file, which use names such as <code>PlaybookName-artifact-xxxxx.json</code> or similar.</p>
<p>One advantage of the replay file is that if the playbook fails then you can share the replay file with another developer or a support team. They can proceed with <code>troubleshooting without needing to have access to all the files in the project directory</code>, such as playbooks, roles, inventory files, variable<br>files, and so on.</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title>Ansible Series Chapter1: The introduction of Ansible Automation Platform 2(RHAAP2)</title>
    <url>//Linux/Ansible/the-introduction-of-ansible-automation-platform2/index.html</url>
    <content><![CDATA[<h2 id="Introduction-to-Red-Hat-Ansible-Automation-Platform-2"><a href="#Introduction-to-Red-Hat-Ansible-Automation-Platform-2" class="headerlink" title="Introduction to Red Hat Ansible Automation Platform 2"></a>Introduction to Red Hat Ansible Automation Platform 2</h2><h3 id="What-is-the-Red-Hat-Ansible-Automaion-Platform2"><a href="#What-is-the-Red-Hat-Ansible-Automaion-Platform2" class="headerlink" title="What is the Red Hat Ansible Automaion Platform2?"></a>What is the Red Hat Ansible Automaion Platform2?</h3><p>An enterprise-grade automation platform that offers a complete set of integrated automation tools and resources. </p>
<p>It provides a new level of customisation and control, delivering a higher standard of automation experience.</p>
<h3 id="What-could-you-do-with-Ansible-Automation-Platform2"><a href="#What-could-you-do-with-Ansible-Automation-Platform2" class="headerlink" title="What could you do with Ansible Automation Platform2?"></a>What could you do with Ansible Automation Platform2?</h3><ul>
<li><p>Accelerating business outcomes through automation</p>
</li>
<li><p>Achieving automation in team collaboration and orchestration</p>
</li>
<li><p>Realising automation for scalable growth and innovation</p>
</li>
</ul>
<h2 id="The-components-of-Ansible-Automation-Platform2"><a href="#The-components-of-Ansible-Automation-Platform2" class="headerlink" title="The components of Ansible Automation Platform2"></a>The components of Ansible Automation Platform2</h2><h3 id="Ansible-Core"><a href="#Ansible-Core" class="headerlink" title="Ansible Core"></a>Ansible Core</h3><p>Ansible Core is the <code>core</code> component of the Ansible project, primarily responsible for automation configuration management, application deployment, and task execution.</p>
<p>It provides the basic functionality to run Ansible Playbooks.</p>
<h3 id="Ansible-Content-Collections"><a href="#Ansible-Content-Collections" class="headerlink" title="Ansible Content Collections"></a>Ansible Content Collections</h3><p><code>Modules</code>, <code>roles</code>, and <code>plugins</code> form a <code>collection</code> of resources.</p>
<h3 id="Automation-Content-Navigator"><a href="#Automation-Content-Navigator" class="headerlink" title="Automation Content Navigator"></a>Automation Content Navigator</h3><ul>
<li><p>Introducing the <code>new top-level tool</code>, <code>ansible-navigator</code>, for developing and testing Ansible Playbooks. This tool replaces and extends several commands, including the <code>ansible-playbook</code>, <code>ansible-playbook</code>, <code>ansible-inventory</code>, <code>ansible-config</code>, <code>ansible-doc</code>, etc.</p>
</li>
<li><p>Navigator <code>runs playbooks within a container</code>, separating the Ansible control node from the automation execution environment in which it operates. This allows different automation execution environments to accommodate varying Python environment requirements.</p>
</li>
</ul>
<h3 id="Automation-Execution-Environments-EE"><a href="#Automation-Execution-Environments-EE" class="headerlink" title="Automation Execution Environments(EE)"></a>Automation Execution Environments(EE)</h3><p>EE is a container image that includes <code>Ansible Core</code>, <code>Ansible Content Collections</code>, and any <code>required Python libraries</code> for running playbooks.</p>
<p><img src="/../images/EE.png" alt="User experience: Adapting execution environments to your needs"></p>
<ul>
<li><p><code>ansible-builder</code>: This command is used to create an image. </p>
<p>Eg. We use <code>Dockerfile</code> to build up an image in docker-engine. While, we use <code>Containerfile</code> in podman. Depend on what kind of container management tool do you use.</p>
</li>
<li><p><code>ansible-navigator</code>: This command will run the playbook in EE.</p>
<p>Eg. <code>sunhaoyang.yml</code> is the playbook you could specify in the command. While, you could use the option <code>--eei</code> to specify the execution environment as you want at the same time.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-navigator run sunhaoyang.yml -m stdout --eei ee-supported-rhel8:latest</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="Automation-Controller"><a href="#Automation-Controller" class="headerlink" title="Automation Controller"></a>Automation Controller</h3><ul>
<li><p>The Automation Controller, previously known as Red Hat Ansible <code>Tower (Open source:AWX)</code>, provides a <code>central location</code> for running playbooks. It offers a <code>web UI</code> and <code>REST API</code>, which can be used for configuring, running, and evaluating automation jobs.</p>
</li>
<li><p>The new Automation Controller <code>separates the control node from the automation execution environment</code>.</p>
</li>
</ul>
<p><img src="/../images/Controller.png" alt="Components of automation controller"></p>
<h3 id="Automation-hub"><a href="#Automation-hub" class="headerlink" title="Automation hub"></a>Automation hub</h3><ul>
<li><p>The Ansible Automation Hub is a platform for managing and distributing automation content. It provides a way to manage and distribute automation content, <code>similar to an online repository</code> from which content can be downloaded.</p>
</li>
<li><p>Public service access is available on <code>console.redhat.com</code>, providing Red Hat-certified Ansible content collections.</p>
</li>
<li><p>In the practice environment, eg.<code>hub.lab.example.com</code> serves as a private automation hub for managing private Ansible content collections.</p>
</li>
</ul>
<p><img src="/../images/Hub.png" alt="Creator experience: Working with Ansible Automation Platform"></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title>20250212-English-accumulation</title>
    <url>//Language/English/20250212/index.html</url>
    <content><![CDATA[<ul>
<li><strong>on-premises</strong></li>
</ul>
]]></content>
      <categories>
        <category>Language</category>
      </categories>
      <tags>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title>Artificial Intelligence Series (Chapter 0): Local Deployment of Large Models</title>
    <url>//Artificial-Intelligence/Deepseek/Local-deployment-of-large-models/index.html</url>
    <content><![CDATA[<h2 id="The-Ice-breaking-Topic"><a href="#The-Ice-breaking-Topic" class="headerlink" title="The Ice-breaking Topic"></a>The Ice-breaking Topic</h2><p>Why should we try to deploy the AI Models in my local environment?</p>
<ol>
<li><code>Data Privacy and Security</code></li>
</ol>
<ul>
<li><p>Protecting Sensitive Data: When dealing with sensitive data (such as healthcare, finance, or personal privacy), deploying AI models locally can prevent data from being uploaded to the cloud, thereby reducing the risk of data breaches.</p>
</li>
<li><p>Compliance Requirements: Some industries have stringent regulations regarding data storage and processing, such as the GDPR in Europe, which encourages businesses to deploy AI models locally.</p>
</li>
</ul>
<ol start="2">
<li><code>Latency and Performance</code></li>
</ol>
<ul>
<li><p>Reducing Network Latency: Deploying models locally can reduce the latency associated with data transmission, particularly for applications that require real-time or low-latency processing, such as autonomous driving or video surveillance.</p>
</li>
<li><p>High-Performance Computing: Local deployment allows full utilisation of local hardware resources, providing higher computational performance. The cloud may face limitations in bandwidth and computational resources, while local hardware can be optimised and tailored to the specific needs of the task.</p>
</li>
</ul>
<ol start="3">
<li><code>Cost Control</code></li>
</ol>
<ul>
<li><p>Avoiding Cloud Service Costs: While cloud computing is flexible, it can become costly over the long term. Especially in scenarios with high computational and storage needs, local deployment can help businesses reduce their reliance on cloud resources and lower costs.</p>
</li>
<li><p>On-Demand Hardware Expansion: Businesses can purchase appropriate hardware resources as needed, avoiding the fixed costs of cloud service providers.</p>
</li>
</ul>
<ol start="4">
<li><code>Control and Customisation</code></li>
</ol>
<ul>
<li><p>Complete Control: Deploying AI models locally ensures full control over both hardware and software, allowing businesses to customise and optimise the deployment environment to meet specific needs.</p>
</li>
<li><p>Flexibility: Companies have the freedom to choose the computing platform (e.g., GPU, TPU, CPU) and system architecture, enabling finer-grained optimisation.</p>
</li>
</ul>
<ol start="5">
<li><code>Offline Operation and High Availability</code></li>
</ol>
<ul>
<li><p>No Reliance on the Internet: For certain application scenarios (such as remote areas or offshore platforms), local deployment ensures that the system continues to function without an internet connection.</p>
</li>
<li><p>High Availability: Local deployment reduces dependence on external cloud service providers, helping businesses avoid disruptions caused by network issues or cloud service outages.</p>
</li>
</ul>
<ol start="6">
<li><code>Environment Adaptation</code></li>
</ol>
<ul>
<li><p>Optimising Hardware Resources: AI models deployed locally can be optimised according to the specific hardware environment (e.g., dedicated GPUs or custom hardware accelerators).</p>
</li>
<li><p>Reducing Shared Cloud Resources: Cloud platforms often share resources among multiple customers, which can lead to performance fluctuations. Local deployment can avoid this resource contention.</p>
</li>
</ul>
<hr>
<h2 id="Deploying-Large-Models-in-local"><a href="#Deploying-Large-Models-in-local" class="headerlink" title="Deploying Large Models in local"></a>Deploying Large Models in local</h2><p>Here, I would like to introduce how to deploy <code>ollama</code> by using docker.</p>
<p>In fact, there are many methods to deploy.</p>
<p>Eg. Install in pysical machine by using <code>curl</code> command in Linux, Download compressions and unzip the packages to install in Windows&#x2F;MacOS operating system. What’s more, you could install ollama by <code>pip</code> as well.</p>
<p>More detailed information, please visit <a href="https://github.com/ollama/ollama">the ollama GitHub</a>.</p>
<h3 id="Deploying-the-Ollama"><a href="#Deploying-the-Ollama" class="headerlink" title="Deploying the Ollama"></a>Deploying the Ollama</h3><h4 id="Deploying-in-docker"><a href="#Deploying-in-docker" class="headerlink" title="Deploying in docker"></a>Deploying in docker</h4><p>The official <a href="https://hub.docker.com/r/ollama/ollama">Ollama Docker image</a> ollama&#x2F;ollama is available on Docker Hub.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># CPU Only</span></span><br><span class="line">docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama</span><br></pre></td></tr></table></figure>

<p>About the docker knowledge, I have already introduced before. You could review <a href="https://blog.sunhaoyang.net/Cloud/Docker/Installing-docker-engine-in-Ubuntu/index.html">here</a>.</p>
<p>After pulling the image from DockerHub, you could use the command <code>ollama -v</code> to check the version of the current ollama.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Check the version of ollama</span></span><br><span class="line">ollama -v</span><br></pre></td></tr></table></figure>

<h4 id="Deploying-in-the-physical-machine"><a href="#Deploying-in-the-physical-machine" class="headerlink" title="Deploying in the physical machine"></a>Deploying in the physical machine</h4><p>Different operating system has different methods to deploy ollama in physical.</p>
<p>Here, in this case we will use <code>curl</code> command for local deployment in Linux OS.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Download the deploy script from the official website and execute the installation shell</span></span><br><span class="line">curl -fsSL https://ollama.com/install.sh | sh</span><br></pre></td></tr></table></figure>

<p>After completing the download process, you could check the status of ollama service.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Use the systemctl command to check the service status</span></span><br><span class="line"><span class="built_in">sudo</span> systemctl status ollama</span><br></pre></td></tr></table></figure>

<p>Similarly, you could use the command <code>ollama -v</code> to check the version of ollama you have installed.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Check the version of ollama</span></span><br><span class="line">ollama -v</span><br></pre></td></tr></table></figure>

<p>For even more information about downloading ollama, please refer to <a href="https://ollama.com/download">the official website</a>.</p>
<h3 id="Pulling-the-models-from-ollama-library"><a href="#Pulling-the-models-from-ollama-library" class="headerlink" title="Pulling the models from ollama library"></a>Pulling the models from ollama library</h3><p>There are plenty of models you could pull from <a href="https://ollama.com/search">the ollama library</a>.</p>
<blockquote>
<p>Please refer to your own server’s performance and configuration to choose the model.</p>
</blockquote>
<p>Eg. <code>12 cores CPU + 32 GB Memory</code> &#x3D;&gt; <code>deepseek-r1:8b</code> is recommended.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Pull the model from the ollama library</span></span><br><span class="line">ollama pull deepseek-r1:8b</span><br><span class="line"></span><br><span class="line"><span class="comment"># Pull and run the model in local</span></span><br><span class="line">ollama run deepseek-r1:8b</span><br></pre></td></tr></table></figure>

<p>If you pulled the model successfully, you could use the command <code>ollama list(ls)</code> to confirm the result.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ollama list/ls</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="Interact-with-the-local-models"><a href="#Interact-with-the-local-models" class="headerlink" title="Interact with the local models"></a>Interact with the local models</h2><p>There are two ways to interact with local models.</p>
<ul>
<li><p>Use the <code>ollama run</code> command in CLI.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ollama run [the model name:tag]</span><br></pre></td></tr></table></figure>

<p>It will guide you in the CLI. You could use <code>ctrl+d</code> or <code>/bye</code> to quit the interaction in CLI.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Run the LLM in local as you specifiy</span></span><br><span class="line">ollama run deepseek-r1:8b</span><br><span class="line">&gt;&gt;&gt; Send a message (/? <span class="keyword">for</span> <span class="built_in">help</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>Visit and question in front-end website <code>open-webui</code>.</p>
<ul>
<li><p>Deploying the <code>open-webui</code> in docker.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># If Ollama is on your computer, use this command</span></span><br><span class="line">docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main</span><br><span class="line"></span><br><span class="line"><span class="comment"># If Ollama is on a Different Server, use this command</span></span><br><span class="line">docker run -d -p 3000:8080 -e OLLAMA_BASE_URL=https://example.com -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main</span><br></pre></td></tr></table></figure>
</li>
<li><p>Deploying the <code>open-webui</code> by <code>pip</code>.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Install</span></span><br><span class="line">pip install open-webui</span><br><span class="line"></span><br><span class="line"><span class="comment"># Execute</span></span><br><span class="line">open-webui serve </span><br></pre></td></tr></table></figure></li>
</ul>
<p>By the way, Deploying in docker is recommended.</p>
</li>
</ul>
<hr>
<h2 id="Login-and-Question-offline"><a href="#Login-and-Question-offline" class="headerlink" title="Login and Question offline"></a>Login and Question offline</h2><p>The final step for you here is to login the open-webui website and let’s question!</p>
<p>You could use <code>http://ip:port</code> or <code>http://localhost:port</code> to visit your local UI.</p>
<p>Set the administrator (name + email + password) and then you could login.</p>
<p>Selecting the various types of models you’ve already downloaded in local.</p>
<p>You could also select more than one model and compare the results at the same time.</p>
<p>The demo representation is shown as below.</p>
<p><img src="/../images/open-webui.png" alt="Local open-webui"></p>
<p>Congratulations to you! Now you can have a good time experimenting with large models locally ：）</p>
]]></content>
      <categories>
        <category>Artificial Intelligence</category>
      </categories>
      <tags>
        <tag>Deepseek</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Series (Chapter 4/4): Introducing Container Network and Practising Container Data Management</title>
    <url>//Cloud/Docker/Introducing-container-network-and-practising-container-data-management/index.html</url>
    <content><![CDATA[<blockquote>
<p>For information on how to install Docker, please refer to: <a href="https://blog.sunhaoyang.net/Cloud/Docker/Installing-docker-engine-in-Ubuntu/index.html">Docker Series (Chapter 0): Installing docker-engine in Ubuntu</a>.</p>
</blockquote>
<blockquote>
<p>For guidance on how to create and use Docker images, please refer to: <a href="https://blog.sunhaoyang.net/Cloud/Docker/Building-and-using-images/index.html">Docker Series (Chapter 1): Building and using images</a>.</p>
</blockquote>
<blockquote>
<p>For guidance on how to create and use Docker containers, please refer to: <a href="https://blog.sunhaoyang.net/Cloud/Docker/Creating-and-using-containers/index.html">Docker Series (Chapter 2): Creating and Using containers</a>.</p>
</blockquote>
<blockquote>
<p>For guidance on how to manage Docker resources, please refer to: <a href="https://blog.sunhaoyang.net/Cloud/Docker/Managing-container-resources/index.html">Docker Series (Chapter 3): Managing Container Resources</a>.</p>
</blockquote>
<p>This will be the final chapter of the Docker series. In this chapter, I will introduce the native networking and data management aspects of Docker containers.</p>
<h2 id="Ice-breaking-topic"><a href="#Ice-breaking-topic" class="headerlink" title="Ice-breaking topic"></a>Ice-breaking topic</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run --rm -it centos /bin/bash</span><br></pre></td></tr></table></figure>

<p>At first, let’s begin to create a container using the above command here.</p>
<p>Then, we are trying to <code>ping</code> <em>&lt;<a href="http://www.baidu.com>">www.baidu.com&gt;</a></em> in the interactive interior terminal console in the container.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:~$ docker run --rm -it centos /bin/bash</span><br><span class="line">Unable to find image &#x27;centos:latest&#x27; locally</span><br><span class="line">latest: Pulling from library/centos</span><br><span class="line">a1d0c7532777: Pull complete</span><br><span class="line">Digest: sha256:a27fd8080b517143cbbbab9dfb7c8571c40d67d534bbdee55bd6c473f432b177</span><br><span class="line">Status: Downloaded newer image for centos:latest</span><br><span class="line">[root@e82126d4b596 /]# ping www.baidu.com</span><br><span class="line">PING www.wshifen.com (119.63.197.139) 56(84) bytes of data.</span><br><span class="line">64 bytes from 119.63.197.139 (119.63.197.139): icmp_seq=1 ttl=47 time=83.3 ms</span><br><span class="line">64 bytes from 119.63.197.139 (119.63.197.139): icmp_seq=2 ttl=47 time=83.3 ms</span><br><span class="line">64 bytes from 119.63.197.139 (119.63.197.139): icmp_seq=3 ttl=47 time=83.2 ms</span><br><span class="line">64 bytes from 119.63.197.139 (119.63.197.139): icmp_seq=4 ttl=47 time=83.1 ms</span><br><span class="line">64 bytes from 119.63.197.139 (119.63.197.139): icmp_seq=5 ttl=47 time=83.1 ms</span><br><span class="line">64 bytes from 119.63.197.139 (119.63.197.139): icmp_seq=6 ttl=47 time=83.1 ms</span><br><span class="line">^C</span><br><span class="line">--- www.wshifen.com ping statistics ---</span><br><span class="line">6 packets transmitted, 6 received, 0% packet loss, time 5005ms</span><br><span class="line">rtt min/avg/max/mdev = 83.115/83.173/83.266/0.063 ms</span><br></pre></td></tr></table></figure>

<p>It’s interesting we just use these parameters when creating the container.</p>
<ul>
<li><p><code>--rm</code>: This option tells Docker to automatically remove the container once it stops running. This is useful for keeping things clean when you’re running a container for a short-term task (like we are debugging or testing).</p>
</li>
<li><p><code>-i</code>: This option stands for <strong>interactive</strong>, which keeps the container’s standard input open. i is the abbreviation of the Capital letter in interactive.</p>
</li>
<li><p><code>-t</code>: This option allocates a pseudo-TTY (a terminal interface) for the container. This is what allows you to interact with the container via a command line.</p>
</li>
<li><p><code>centos</code>: This specifies the Docker image to use.</p>
</li>
<li><p><code>/bin/bash</code>: This is the command to run inside the container. It will start a bash shell session inside the CentOS container, allowing you to interact with it like you’re logged into a normal Linux system.</p>
</li>
</ul>
<p>When we create a container, we haven’t attached a network interface card (NIC), nor have we set an IP address, let alone configured an external network route. So, how is it that our ping operation is successful?</p>
<hr>
<h2 id="Container-Original-Network"><a href="#Container-Original-Network" class="headerlink" title="Container Original Network"></a>Container Original Network</h2><p>Docker natively provides several types of networks. If we are not satisfied with the default networks, we can also create custom networks. The default networks are: none, bridge, and host. These networks are automatically created when Docker is installed. We can view them using the following command.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:~$ docker network ls</span><br><span class="line">NETWORK ID     NAME      DRIVER    SCOPE</span><br><span class="line">1b42685dde7f   bridge    bridge    local</span><br><span class="line">610f1e7d2013   host      host      local</span><br><span class="line">11d5d9017fcd   none      null      local</span><br></pre></td></tr></table></figure>

<h3 id="none-network"><a href="#none-network" class="headerlink" title="none network"></a>none network</h3><p>If a container uses the <code>none</code> network, it will not have a typical network interface card (NIC) as we generally understand it. Instead, it will only have the loopback (lo) network. To use this network, you simply need to specify <code>--network=none</code> when creating the container.</p>
<p>Now, let’s think: What might be the use case for this network?</p>
<p>The <code>none</code> network is a more <code>isolated</code> network, suitable for scenarios that require high security and no network connectivity. For instance, applications like <strong>receiving verification codes</strong> or <strong>generating random numbers on your phone</strong> could benefit from being placed on the ‘none’ network to prevent data from being intercepted.</p>
<h3 id="host-network"><a href="#host-network" class="headerlink" title="host network"></a>host network</h3><p>The <code>host</code> network, on the other hand, is a network where a container shares the host’s network stack. You can specify this network using <code>--network=host</code> when creating the container. When a container is in host network mode, its network configuration is identical to that of the host machine. This means the container can see all the network interfaces of the host, and its hostname will match that of the host as well. The major advantage of using the host network is <code>its performance</code>, as it offers <code>high speed and excellent data transfer rates</code>. However, any ports already in use by the host are unavailable to the container.”</p>
<h3 id="bridge-network"><a href="#bridge-network" class="headerlink" title="bridge network"></a>bridge network</h3><p>The <code>bridge</code> network is the <code>default network driver</code> used by Docker containers when no other network is specified. It creates a <code>private internal</code> network on the host system, and each container that uses this network can <code>communicate with other containers</code> on the same bridge network, as well as with the <code>host machine</code>.</p>
<p>In a bridge network, Docker <code>automatically assigns a private IP address to each container</code>. Containers can talk to each other using these private IPs, but they <code>can&#39;t directly communicate with the external network</code> unless you configure port forwarding. To access services running inside a container from outside, you’d typically <code>map the container&#39;s internal ports to ports on the host machine</code>.</p>
<h3 id="Key-Points-of-three-types-network"><a href="#Key-Points-of-three-types-network" class="headerlink" title="Key Points of three types network"></a>Key Points of three types network</h3><ul>
<li><p><code>None Network</code>: Completely isolated with no external network access, ideal for high-security, non-networked tasks.</p>
</li>
<li><p><code>Host Network</code>: Shares the host machine’s network stack, offering high performance, but limits port usage since the host’s ports are already in use.</p>
</li>
<li><p><code>Bridge Network</code>:</p>
<ul>
<li><p><code>Isolation</code>: Containers are isolated from the outside world, but can communicate with each other within the same network.</p>
</li>
<li><p><code>Port Mapping</code>: If you want external access to a container’s services, you have to map its internal ports to the host machine’s ports.</p>
</li>
<li><p><code>Default Mode</code>: When you create a container without specifying a network, it will automatically use the bridge network.</p>
</li>
</ul>
</li>
</ul>
<hr>
<h2 id="Container-Storage"><a href="#Container-Storage" class="headerlink" title="Container Storage"></a>Container Storage</h2><h3 id="The-Container-and-Layer"><a href="#The-Container-and-Layer" class="headerlink" title="The Container and Layer"></a>The Container and Layer</h3><p>The biggest difference between a container and an image lies in <code>the topmost writable layer</code>. Any data written or modified within the container is directly stored in this writable layer. This means that <code>when a container is deleted, the data in the writable layer is lost</code>. Although each container has its own distinct writable layer, the underlying image can be shared across multiple containers.</p>
<blockquote>
<p>The image picture here is based on <a href="https://docker-docs.uclv.cu/storage/storagedriver/#container-and-layers">the Official Website</a>.<br><img src="/./../images/sharing-layers.jpg" alt="sharing-layers"></p>
</blockquote>
<h3 id="Widely-Used-Storage-Drivers"><a href="#Widely-Used-Storage-Drivers" class="headerlink" title="Widely Used Storage Drivers"></a>Widely Used Storage Drivers</h3><p>When designing and using containers, the amount of data written to the container’s writable layer is usually very small. However, in operations, most of the data needs to be persistently stored. To address the volatility of the data in the writable layer, several storage drivers have been introduced in containers.</p>
<p>The mainstream supported storage drivers currently include as below.</p>
<blockquote>
<p>Here, I referred to <a href="https://docker-docs.uclv.cu/storage/storagedriver/select-storage-driver/#supported-storage-drivers-per-linux-distribution">the Official Website</a> and created the following table.</p>
</blockquote>
<table>
<thead>
<tr>
<th align="center">Linux distribution</th>
<th align="center">Recommended storage drivers</th>
<th align="center">Alternative drivers</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Docker Engine - Community on Ubuntu</td>
<td align="center">overlay2 or aufs (for Ubuntu 14.04 running on kernel 3.13)</td>
<td align="center">overlay¹, devicemapper², zfs, vfs</td>
</tr>
<tr>
<td align="center">Docker Engine - Community on Debian</td>
<td align="center">overlay2 (Debian Stretch), aufs or devicemapper (older versions)</td>
<td align="center">overlay¹, vfs</td>
</tr>
<tr>
<td align="center">Docker Engine - Community on CentOS</td>
<td align="center">overlay2</td>
<td align="center">overlay¹, devicemapper², zfs, vfs</td>
</tr>
<tr>
<td align="center">Docker Engine - Community on Fedora</td>
<td align="center">overlay2</td>
<td align="center">overlay¹, devicemapper², zfs, vfs</td>
</tr>
</tbody></table>
<h3 id="Copy-on-write-Strategy"><a href="#Copy-on-write-Strategy" class="headerlink" title="Copy-on-write Strategy"></a>Copy-on-write Strategy</h3><blockquote>
<p>More detailed information, please visit <a href="https://docker-docs.uclv.cu/storage/storagedriver/#the-copy-on-write-cow-strategy">the Official Website</a> here.</p>
</blockquote>
<table>
<thead>
<tr>
<th align="center">Operation</th>
<th align="center">Execution</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Create files</td>
<td align="center">A new file can only be added to the container layer.</td>
</tr>
<tr>
<td align="center">Delete files</td>
<td align="center">Following the container’s layered structure, Docker looks from top to bottom. When the file is found, the delete operation is recorded in the container layer. The actual implementation is that UnionFS creates a “whiteout” file in the container layer, which effectively “masks” the deleted file.</td>
</tr>
<tr>
<td align="center">Modify files</td>
<td align="center">Docker follows the container’s layered structure from top to bottom. Once the file is found, the data from the image layer is copied to the container layer for modification. The modified data is then saved in the container layer (using copy-on-write).</td>
</tr>
<tr>
<td align="center">Read files</td>
<td align="center">Docker follows the container’s layered structure from top to bottom when reading files.</td>
</tr>
</tbody></table>
<hr>
<h2 id="Data-Management"><a href="#Data-Management" class="headerlink" title="Data Management"></a>Data Management</h2><p>There are generally two methods for persisting data in containers:</p>
<ol>
<li>volume</li>
<li>bind mount</li>
</ol>
<h3 id="Volume"><a href="#Volume" class="headerlink" title="Volume"></a>Volume</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:~$ docker run -d --name volumetest -v /usr/local/apache2/htdocs httpd:latest</span><br><span class="line">6bd77a7a04bc9f0628135ccdf30d07f4e92f29cd631f9b5f54f196e7e04ebdd0</span><br><span class="line"></span><br><span class="line">shy@flash-shy:~$ docker exec -it volumetest /bin/bash</span><br><span class="line">root@6bd77a7a04bc:/usr/local/apache2# touch sunhaoyangfile</span><br><span class="line">root@6bd77a7a04bc:/usr/local/apache2#</span><br><span class="line">exit</span><br><span class="line"></span><br><span class="line">shy@flash-shy:~$ sudo find / -name sunhaoyangfile</span><br><span class="line">/var/lib/docker/overlay2/db6115d1b68b483e5a799e74aad3e51d1d4aa0fb7376916c38a09165e6ceaf21/diff/usr/local/apache2/sunhaoyangfile</span><br><span class="line">/var/lib/docker/overlay2/db6115d1b68b483e5a799e74aad3e51d1d4aa0fb7376916c38a09165e6ceaf21/merged/usr/local/apache2/sunhaoyangfile</span><br></pre></td></tr></table></figure>

<h3 id="Bind-Mount"><a href="#Bind-Mount" class="headerlink" title="Bind Mount"></a>Bind Mount</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:~$ docker run -d --name volumetest2 -v /mnt:/usr/local/apache2/htdocs httpd:latest</span><br><span class="line">e0fd1f0d04f4875060a6a248b666662972625a491f2739ca1547ba678a8703fe</span><br><span class="line"></span><br><span class="line">shy@flash-shy:~$ docker exec -it volumetest2 /bin/bash</span><br><span class="line">root@e0fd1f0d04f4:/usr/local/apache2# cd htdocs/</span><br><span class="line">root@e0fd1f0d04f4:/usr/local/apache2/htdocs# ls</span><br><span class="line">root@e0fd1f0d04f4:/usr/local/apache2/htdocs# echo sunhaoyang &gt; index.html</span><br><span class="line">root@e0fd1f0d04f4:/usr/local/apache2/htdocs#</span><br><span class="line">exit</span><br><span class="line"></span><br><span class="line">shy@flash-shy:~$ ls -altF /mnt/</span><br><span class="line">total 12</span><br><span class="line">drwxr-xr-x  2 root root 4096 Feb  6 13:46 ./</span><br><span class="line">-rw-r--r--  1 root root   11 Feb  6 13:46 index.html</span><br><span class="line">drwxr-xr-x 25 root root 4096 Sep 13 19:40 ../</span><br></pre></td></tr></table></figure>

<h2 id="Sharing-data-between-the-host-machine-and-the-container"><a href="#Sharing-data-between-the-host-machine-and-the-container" class="headerlink" title="Sharing data between the host machine and the container"></a>Sharing data between the host machine and the container</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:~$ docker run -d -p 9000:80 -v /mnt:/usr/local/apache2/htdocs httpd:latest</span><br><span class="line">81026dd8cafb6279974c56eaea04defe849dedbcda7361f4b9c805f2a2825682</span><br><span class="line"></span><br><span class="line">shy@flash-shy:~$ sudo cp index.html /mnt/index.html</span><br><span class="line"></span><br><span class="line">shy@flash-shy:~$ curl http://127.0.0.1:9000</span><br><span class="line">Hello, world!</span><br><span class="line">shy@flash-shy:~$ cat index.html</span><br><span class="line">Hello, world!</span><br></pre></td></tr></table></figure>

<h2 id="Sharing-data-between-containers"><a href="#Sharing-data-between-containers" class="headerlink" title="Sharing data between containers"></a>Sharing data between containers</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:~$ docker run -d --name share01 -v /mnt:/usr/local/apache2/htdocs httpd:latest</span><br><span class="line">35a5398e8dde088dc17740115abcd9b3ab84b4db2363588c0dd7445c5856a251</span><br><span class="line"></span><br><span class="line">shy@flash-shy:~$ docker run -d --name share02 -v /mnt:/usr/local/apache2/htdocs httpd:latest</span><br><span class="line">f97301cbca77fda7b6e9127acc78577d6c2d23d52e71a7e16b90bf30629e7a78</span><br><span class="line"></span><br><span class="line">shy@flash-shy:~$ sudo cp index.html /mnt/index.html</span><br><span class="line"></span><br><span class="line">shy@flash-shy:~$ docker inspect -f &#x27;&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;&#x27; share01</span><br><span class="line">172.17.0.3</span><br><span class="line"></span><br><span class="line">shy@flash-shy:~$ docker inspect -f &#x27;&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;&#x27; share02</span><br><span class="line">172.17.0.4</span><br><span class="line"></span><br><span class="line">shy@flash-shy:~$ curl http://172.17.0.3</span><br><span class="line">Hello, world!</span><br><span class="line"></span><br><span class="line">shy@flash-shy:~$ curl http://172.17.0.4</span><br><span class="line">Hello, world!</span><br></pre></td></tr></table></figure>

<h2 id="Key-Points-about-sharing-data"><a href="#Key-Points-about-sharing-data" class="headerlink" title="Key Points about sharing data"></a>Key Points about sharing data</h2><ul>
<li><p>Sharing data between the host machine and the container:</p>
<ul>
<li><p>bind mount: <code>Mount a directory or file from the host machine into the container.</code></p>
</li>
<li><p>volume: <code>Copy data from the host machine to the container&#39;s volume by using the cp command to copy the required data into the volume&#39;s directory.</code></p>
</li>
</ul>
</li>
<li><p>Sharing data between containers:</p>
<ul>
<li><p>bind mount: <code>Mount a directory or file from the host machine into multiple containers.</code></p>
</li>
<li><p>volume: <code>Mount a volume into multiple containers.</code></p>
</li>
</ul>
</li>
</ul>
<p>Congratulations to you!</p>
<p>Up to now, I have already introduced all basic knowledge about docker to you.</p>
<p>That’s all I want to discuss here, thank you for your patience~</p>
]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>2025/02/05 English accumulation</title>
    <url>//Language/English/20250205/index.html</url>
    <content><![CDATA[<ul>
<li><p><strong>subtle</strong>: It refers to something that is delicate, understated, or not immediately obvious. It’s often used to describe things that are complex or nuanced but don’t make an obvious or loud impression. Here’s an example sentence: <code>She has a subtle sense of humor, often making witty remarks that go unnoticed at first but leave you thinking and laughing later.</code></p>
</li>
<li><p><strong>understated</strong>: It refers to something that is presented in a restrained or modest way, often deliberately avoiding excessive decoration or emphasis. It’s used to describe things that are elegant or impressive in a subtle, non-showy manner. Here’s an example sentence: <code>The interior of the restaurant was beautifully understated, with minimal decoration and soft lighting that created a calm, inviting atmosphere.</code></p>
</li>
<li><p><strong>delicate</strong>: It’s about something that needs to be treated with care, whether it’s a physical object, a situation, or a person’s feelings. Here’s an example sentence: <code>The delicate fabric of the dress shimmered in the light, and she handled it with great care to avoid damaging it.</code></p>
</li>
<li><p><strong>let alone</strong>: It is a phrase used to emphasize that something is even less likely or more extreme than the previous statement. It’s typically used when you’re talking about something that would be more surprising or difficult to do, in comparison to a previous, simpler action or condition. <code>[Negative statement], let alone [something more extreme].</code> Here’s an example sentence: <code>He can&#39;t even swim, let alone dive.</code><br>let alone” with a verb, the verb is typically in its <strong>original (base) form</strong> (i.e., the infinitive without “to”).</p>
</li>
<li><p><strong>native</strong>: It refers to something that is originally from or naturally associated with a particular place, environment, or system. Here’s an example sentence: <code>The kangaroo is native to Australia, meaning it is naturally found only in that region.</code></p>
</li>
<li><p><strong>identical</strong>: It means <strong>exactly the same in every way, without any differences</strong> as well as <strong>completely matching or alike in appearance, characteristics, or nature</strong>. Here’s an example: <code>The two houses are identical, with the same layout, size, and colour.</code></p>
</li>
<li><p><strong>volatility</strong>: It refers to <strong>the tendency of something to change rapidly and unpredictably</strong> as well as <strong>the tendency of a substance to evaporate or turn into a gas at a relatively low temperature in a chemical or physical context</strong>. Here’s an example sentence: <code>The volatility of the stock market makes it difficult for investors to predict future trends.</code> What’s more, <code>The volatility of the liquid makes it dangerous to handle at high temperatures.</code></p>
</li>
</ul>
]]></content>
      <categories>
        <category>Language</category>
      </categories>
      <tags>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Series (Chapter 3/4): Managing Container Resources</title>
    <url>//Cloud/Docker/Managing-container-resources/index.html</url>
    <content><![CDATA[<blockquote>
<p>For information on how to install Docker, please refer to: <a href="https://blog.sunhaoyang.net/Cloud/Docker/Installing-docker-engine-in-Ubuntu/index.html">Docker Series (Chapter 0): Installing docker-engine in Ubuntu</a>.</p>
</blockquote>
<blockquote>
<p>For guidance on how to create and use Docker images, please refer to: <a href="https://blog.sunhaoyang.net/Cloud/Docker/Building-and-using-images/index.html">Docker Series (Chapter 1): Building and using images</a>.</p>
</blockquote>
<blockquote>
<p>For guidance on how to create and use Docker containers, please refer to: <a href="https://blog.sunhaoyang.net/Cloud/Docker/Creating-and-using-containers/index.html">Docker Series (Chapter 2): Creating and Using containers</a>.</p>
</blockquote>
<p>Up to now, you could install the docker-engine in Ubuntu operating system, pull docker images from public&#x2F;private image repositories, develop Dockerfile, use the Dockerfile to create containers and use some command to do some execution interacting with containers.</p>
<p>However, do you have some ideas about how are the resources of a created container bound? How much memory, how much disk, and what are the allocated IOPS?</p>
<p>In this Chapter3, let’s find the answer.</p>
<h2 id="Memory-Quotas"><a href="#Memory-Quotas" class="headerlink" title="Memory Quotas"></a>Memory Quotas</h2><h3 id="Identifying-issues-by-observing-memory-usage"><a href="#Identifying-issues-by-observing-memory-usage" class="headerlink" title="Identifying issues by observing memory usage"></a>Identifying issues by observing memory usage</h3><p>At first, let me create two containers.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker run -d --name=http1 httpd</span><br><span class="line">9871abf3948eeec881498356073c4ce2b11c1631d533a92ce44be64b088af880</span><br><span class="line"></span><br><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker run -d --name=http2 httpd</span><br><span class="line">92cfd46a822b69bdc55fc1460e8698a79a4af7382cda9b038b45654017aef0a2</span><br></pre></td></tr></table></figure>

<p>Then, let’s observe the memory size of each container.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker exec -it http1 grep MemTotal /proc/meminfo</span><br><span class="line">MemTotal:       32741384 kB</span><br><span class="line"></span><br><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker exec -it http2 grep MemTotal /proc/meminfo</span><br><span class="line">MemTotal:       32741384 kB</span><br></pre></td></tr></table></figure>

<p>Finally, let’s check the memory size of local physical machine.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ free -h</span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:           31Gi       7.5Gi       1.7Gi        13Gi        22Gi       9.2Gi</span><br><span class="line">Swap:          31Gi       335Mi        31Gi</span><br></pre></td></tr></table></figure>

<p>Based on the hands-on exercise just now, it is obviously that <code>the memory allocation for each container equals the total memory of the physical host</code>. This means better performance, but it also means that as business demands increase, resource contention may occur. This is something that should generally be avoided during operational planning.</p>
<h3 id="Managing-memory-quotas"><a href="#Managing-memory-quotas" class="headerlink" title="Managing memory quotas"></a>Managing memory quotas</h3><p>We could use <code>-m</code> or <code>--memory</code> parameter to specify the limitation of memory usage, to allocate the memory quotas to containers.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker run -it --name=memlimit -m 500M progrium/stress \</span><br><span class="line">--vm 1 --vm-bytes 400M</span><br><span class="line">stress: dbug: [1] using backoff sleep of 3000us</span><br><span class="line">stress: info: [1] dispatching hogs: 0 cpu, 0 io, 1 vm, 0 hdd</span><br><span class="line">stress: dbug: [1] --&gt; hogvm worker 1 [8] forked</span><br><span class="line">stress: dbug: [8] allocating 524288000 bytes ...</span><br><span class="line">stress: dbug: [8] touching bytes in strides of 4096 bytes ...</span><br><span class="line">stress: dbug: [8] freed 524288000 bytes</span><br><span class="line">stress: dbug: [8] allocating 524288000 bytes ...</span><br><span class="line">stress: dbug: [8] touching bytes in strides of 4096 bytes ...</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker run -it --name=memfailed -m 500M progrium/stress \</span><br><span class="line">--vm 1 --vm-bytes 700M</span><br><span class="line">stress: info: [1] dispatching hogs: 0 cpu, 0 io, 1 vm, 0 hdd</span><br><span class="line">stress: dbug: [1] using backoff sleep of 3000us</span><br><span class="line">stress: dbug: [1] --&gt; hogvm worker 1 [8] forked</span><br><span class="line">stress: dbug: [8] allocating 734003200 bytes ...</span><br><span class="line">stress: dbug: [8] touching bytes in strides of 4096 bytes ...</span><br><span class="line">stress: FAIL: [1] (416) &lt;-- worker 8 got signal 9</span><br><span class="line">stress: WARN: [1] (418) now reaping child worker processes</span><br><span class="line">stress: FAIL: [1] (422) kill error: No such process</span><br><span class="line">stress: FAIL: [1] (452) failed run completed in 0s</span><br></pre></td></tr></table></figure>

<ol>
<li><p>-it</p>
<p>-i: Keep the container’s standard input (stdin) open, allowing you to interact with the container.</p>
<p>-t: Allocate a pseudo-TTY (terminal) for the container, so you can see the output and interact with the container. These two flags are usually used together, meaning you want to enter the container and interact with it.</p>
</li>
<li><p>–name&#x3D;memfailed</p>
<p>Assigns a name to the container. In this case, the container is named memfailed. This allows you to reference the container by its name rather than its ID in future commands.</p>
</li>
<li><p>-m 500M</p>
<p>Limits the container’s maximum memory usage to 500MB. If the container exceeds this limit, it will be killed, and an “Out of Memory” (OOM) error will occur.</p>
</li>
<li><p>progrium&#x2F;stress</p>
<p>Specifies the Docker image to run. In this case, it’s the progrium&#x2F;stress image, which contains the stress tool that can be used to generate load on the system.</p>
</li>
<li><p>–vm 1</p>
<p>This means that the stress tool will start one virtual memory load (vm) process. The number 1 indicates that one such process will be started.</p>
</li>
<li><p>–vm-bytes 700M</p>
<p>The –vm-bytes parameter specifies the amount of memory to allocate for each virtual memory load process. In this case, it is set to 700MB. Therefore, the stress tool will attempt to allocate 700MB of virtual memory for the load process.</p>
</li>
</ol>
<p>It is clear for us why the result is different. 400M is legal, 700M is illegal.</p>
<p>Therefore, we set the parameter <code>-m</code> or <code>--memory</code> works to our containers.</p>
<h2 id="Managing-CPU-Quotas"><a href="#Managing-CPU-Quotas" class="headerlink" title="Managing CPU Quotas"></a>Managing CPU Quotas</h2><p>By default, all containers can use the same CPU resources without any restrictions.</p>
<p>Similar to memory, when the CPU demand of a container increases, it will lead to CPU resource contention. <code>However, unlike memory, where an absolute amount is specified, CPU allocation is done by specifying a relative weight.</code></p>
<p>The <code>--cpu-shares parameter</code> is used to allocate CPU resources.</p>
<p><code>By default, this value is set to 1024</code>.</p>
<p><code>Note that when the workload in the current container is idle, other containers have the right to use its idle CPU cycles, which ensures the performance of the workloads.</code></p>
<blockquote>
<p>CPU resource limits only take effect when the physical machine’s resources are insufficient, and the allocation is based on priority. When other containers are idle, the busy containers can utilize all available CPU resources.</p>
</blockquote>
<h2 id="Managing-I-O-Quotas"><a href="#Managing-I-O-Quotas" class="headerlink" title="Managing I&#x2F;O Quotas"></a>Managing I&#x2F;O Quotas</h2><p>We could use the parameter <code>--blkio-weight 300</code> to set the limitation of I&#x2F;O quotas.</p>
<p>Under normal circumstances, a container with a weight of 600 will have twice the I&#x2F;O capacity compared to one with a weight of 300. You can test the I&#x2F;O performance using the following command.</p>
<p>In actual tests, there is no resource contention. <code>This setting will only be reflected during I/O contention.</code> So, 600 weight is faster than 300 weight, but it is not twice the I&#x2F;O capacity.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker run -d --name 600io --blkio-weight 600 httpd</span><br><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker exec -it 600io /bin/bash</span><br><span class="line">root@fda33d6184a5:/usr/local/apache2# time dd if=/dev/zero of=test.out bs=1M count=10240</span><br><span class="line">10240+0 records in</span><br><span class="line">10240+0 records out</span><br><span class="line">10737418240 bytes (11 GB, 10 GiB) copied, 35.8148 s, 300 MB/s</span><br><span class="line"></span><br><span class="line">real 0m35.959s</span><br><span class="line">user 0m0.011s</span><br><span class="line">sys 0m14.162s</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker run -d --name 300io --blkio-weight 300 httpd</span><br><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker exec -it 300io /bin/bash</span><br><span class="line">root@7d406deec8ac:/usr/local/apache2# time dd if=/dev/zero of=test.out bs=1M count=10240</span><br><span class="line">10240+0 records in</span><br><span class="line">10240+0 records out</span><br><span class="line">10737418240 bytes (11 GB, 10 GiB) copied, 44.8088 s, 240 MB/s</span><br><span class="line"></span><br><span class="line">real 0m44.897s</span><br><span class="line">user 0m0.025s</span><br><span class="line">sys 0m16.777s</span><br></pre></td></tr></table></figure>

<h2 id="The-underlying-implementation-of-resource-limits"><a href="#The-underlying-implementation-of-resource-limits" class="headerlink" title="The underlying implementation of resource limits"></a>The underlying implementation of resource limits</h2><p>Linux uses <code>cgroups</code> to allocate CPU, memory, and I&#x2F;O resource quotas for processes.</p>
<p>We can view the resource quotas for containers through the settings under <code>/sys/fs/cgroup/</code>.</p>
<p>In Linux, cgroups (control groups) allow you to manage and allocate resources to processes. For Docker containers, cgroups are used to enforce resource limitations like CPU usage, memory consumption, and disk I&#x2F;O. The resource settings for these containers can be viewed in the &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F; directory, where cgroup-related files and parameters are exposed.</p>
<p>You can find specific resource limit details for a container by navigating to directories under &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F; that correspond to the container’s cgroup, and checking the values for CPU, memory, and I&#x2F;O usage.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker exec -it http1 /bin/bash</span><br><span class="line">root@9871abf3948e:/usr/local/apache2# ls /sys/fs/cgroup/</span><br><span class="line">blkio  cpu  cpu,cpuacct  cpuacct  cpuset  devices  freezer  hugetlb  memory  misc  net_cls  net_cls,net_prio  net_prio perf_event  pids  rdma systemd</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@9871abf3948e:/usr/local/apache2# ls /sys/fs/cgroup/blkio/</span><br><span class="line">blkio.prio.class   blkio.throttle.io_service_bytes_recursive  blkio.throttle.read_bps_device   blkio.throttle.write_iops_device  notify_on_release</span><br><span class="line">blkio.reset_stats   blkio.throttle.io_serviced      blkio.throttle.read_iops_device  cgroup.clone_children        tasks</span><br><span class="line">blkio.throttle.io_service_bytes  blkio.throttle.io_serviced_recursive     blkio.throttle.write_bps_device  cgroup.procs</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Series (Chapter 2/4): Creating and Using containers</title>
    <url>//Cloud/Docker/Creating-and-using-containers/index.html</url>
    <content><![CDATA[<blockquote>
<p>For information on how to install Docker, please refer to: <a href="https://blog.sunhaoyang.net/Cloud/Docker/Installing-docker-engine-in-Ubuntu/index.html">Docker Series (Chapter 0): Installing docker-engine in Ubuntu</a>.</p>
</blockquote>
<blockquote>
<p>For guidance on how to create and use Docker images, please refer to: <a href="https://blog.sunhaoyang.net/Cloud/Docker/Building-and-using-images/index.html">Docker Series (Chapter 1): Building and using images</a>.</p>
</blockquote>
<p>Alright, let’s continue learning the following Chapter.</p>
<h2 id="Best-Practices-for-Building-Dockerfiles"><a href="#Best-Practices-for-Building-Dockerfiles" class="headerlink" title="Best Practices for Building Dockerfiles"></a>Best Practices for Building Dockerfiles</h2><ol>
<li><p>Containers should be ephemeral&#x2F;temporary.</p>
</li>
<li><p>Avoid installing unnecessary packages.</p>
</li>
<li><p>Each container should have only one purpose.</p>
</li>
<li><p>Avoid having too many layers in a container.</p>
</li>
<li><p>Multi-line sorting.</p>
</li>
<li><p>Leveraging cache.</p>
</li>
</ol>
<p>Let me list an example here.</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Base image</span></span><br><span class="line"><span class="keyword">FROM</span> httpd</span><br><span class="line"><span class="comment"># The person who creates and maintains it</span></span><br><span class="line"><span class="keyword">MAINTAINER</span> Haoyang Sun</span><br><span class="line"><span class="comment"># RUN command to execute</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">echo</span> hello container &gt; \</span></span><br><span class="line"><span class="language-bash">/usr/local/apache2/htdocs/index.html</span></span><br><span class="line"><span class="comment"># expose port as 80</span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">80</span></span><br><span class="line"><span class="comment"># Define the working directory</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> /usr/local/apache2/htdocs</span></span><br></pre></td></tr></table></figure>

<p>Let’s use the Dockerfile to create a new image here.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker build -t web:v1 .</span><br><span class="line">[+] Building 14.4s (8/8) FINISHED                                docker:default</span><br><span class="line"> =&gt; [internal] load build definition from Dockerfile                       0.0s</span><br><span class="line"> =&gt; =&gt; transferring dockerfile: 189B                                       0.0s</span><br><span class="line"> =&gt; WARN: MaintainerDeprecated: Maintainer instruction is deprecated in f  0.0s</span><br><span class="line"> =&gt; [internal] load metadata for docker.io/library/httpd:latest            4.8s</span><br><span class="line"> =&gt; [auth] library/httpd:pull token for registry-1.docker.io               0.0s</span><br><span class="line"> =&gt; [internal] load .dockerignore                                          0.0s</span><br><span class="line"> =&gt; =&gt; transferring context: 2B                                            0.0s</span><br><span class="line"> =&gt; [1/3] FROM docker.io/library/httpd:latest@sha256:437b9f7d469dd606fa6d  8.9s</span><br><span class="line"> =&gt; =&gt; resolve docker.io/library/httpd:latest@sha256:437b9f7d469dd606fa6d  0.0s</span><br><span class="line"> =&gt; =&gt; sha256:3b71e7157e7a19c02c985d0962e01b5bbda6e329b24 2.10kB / 2.10kB  0.0s</span><br><span class="line"> =&gt; =&gt; sha256:c14eb63a15a0449b7f25117f57bc1846c023cd706769acb 145B / 145B  1.7s</span><br><span class="line"> =&gt; =&gt; sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d 32B / 32B  0.5s</span><br><span class="line"> =&gt; =&gt; sha256:437b9f7d469dd606fa6d2a5f9a3be55fe3af7e0c6 10.16kB / 10.16kB  0.0s</span><br><span class="line"> =&gt; =&gt; sha256:f7d8bafbd9a9fc570c19628411a8441e8dc6697aa43 7.88kB / 7.88kB  0.0s</span><br><span class="line"> =&gt; =&gt; sha256:af302e5c37e9dc1dbe2eadc8f5059d82a914066b5 28.21MB / 28.21MB  7.1s</span><br><span class="line"> =&gt; =&gt; sha256:abbcd5aab3664cf64a964a4c608f66689db8bcfe8ab 4.20MB / 4.20MB  4.9s</span><br><span class="line"> =&gt; =&gt; sha256:04e5e6c6b4973d97b8b076a550d50ef5ddbfc6d12 26.06MB / 26.06MB  8.4s</span><br><span class="line"> =&gt; =&gt; sha256:7f5fb3689eaee4c87c2455a8e061d6bb52da300369b0325 293B / 293B  5.4s</span><br><span class="line"> =&gt; =&gt; extracting sha256:af302e5c37e9dc1dbe2eadc8f5059d82a914066b541b0d1a  0.6s</span><br><span class="line"> =&gt; =&gt; extracting sha256:c14eb63a15a0449b7f25117f57bc1846c023cd706769acb8  0.0s</span><br><span class="line"> =&gt; =&gt; extracting sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6  0.0s</span><br><span class="line"> =&gt; =&gt; extracting sha256:abbcd5aab3664cf64a964a4c608f66689db8bcfe8abea5b9  0.1s</span><br><span class="line"> =&gt; =&gt; extracting sha256:04e5e6c6b4973d97b8b076a550d50ef5ddbfc6d125439f26  0.3s</span><br><span class="line"> =&gt; =&gt; extracting sha256:7f5fb3689eaee4c87c2455a8e061d6bb52da300369b03257  0.0s</span><br><span class="line"> =&gt; [2/3] RUN echo hello container &gt;   /usr/local/apache2/htdocs/index.ht  0.5s</span><br><span class="line"> =&gt; [3/3] WORKDIR /usr/local/apache2/htdocs                                0.0s</span><br><span class="line"> =&gt; exporting to image                                                     0.1s</span><br><span class="line"> =&gt; =&gt; exporting layers                                                    0.0s</span><br><span class="line"> =&gt; =&gt; writing image sha256:e30e7b98cd48deef0229fbdea27d499b039bf06f2bf3c  0.0s</span><br><span class="line"> =&gt; =&gt; naming to docker.io/library/web:v1                                  0.0s</span><br><span class="line"></span><br><span class="line"> 1 warning found (use docker --debug to expand):</span><br><span class="line"> - MaintainerDeprecated: Maintainer instruction is deprecated in favor of using label (line 3)</span><br></pre></td></tr></table></figure>

<p>After building the iamge called: web:v1, let’s check the list of images.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker images</span><br><span class="line">REPOSITORY                                                                                               TAG       IMAGE ID       CREATED         SIZE</span><br><span class="line">web                                                                                                      v1        e30e7b98cd48   7 seconds ago   148MB</span><br><span class="line">ubuntu                                                                                                   20.04     9df6d6105df2   5 months ago    72.8MB</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<h2 id="Best-Practices-for-naming-the-image"><a href="#Best-Practices-for-naming-the-image" class="headerlink" title="Best Practices for naming the image"></a>Best Practices for naming the image</h2><p>Obviously, We successfully creating a new images about 7 seconds ago. The image’s name is web and its tag is v1. Its size is about 148MB.</p>
<p>So, what is the reason we could quickly find the image we want?</p>
<h3 id="Image-naming-format"><a href="#Image-naming-format" class="headerlink" title="Image naming format"></a>Image naming format</h3><p><code>REPOSITORY+TAG</code>. It is recommended to use <code>version number</code> as the naming convention.</p>
<p>A simple and clear image naming format allows users to quickly identify the image they need without the need for testing.</p>
<h3 id="Explanation-of-the-‘latest’-tag-and-its-usage"><a href="#Explanation-of-the-‘latest’-tag-and-its-usage" class="headerlink" title="Explanation of the ‘latest’ tag and its usage"></a>Explanation of the ‘latest’ tag and its usage</h3><p>If <code>no tag</code> is specified when building the image, the default <code>latest</code> tag will be used.</p>
<p>Therefore, when you see ‘latest’ as the tag of an image, it does not necessarily mean that this is the latest version. It simply means that no tag was specified when the image was created, and nothing more.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker build -t web .</span><br><span class="line">[+] Building 2.4s (8/8) FINISHED                                                                                                                                               docker:default</span><br><span class="line"> =&gt; [internal] load build definition from Dockerfile                                                                                                                                     0.0s</span><br><span class="line"> =&gt; =&gt; transferring dockerfile: 189B                                                                                                                                                     0.0s</span><br><span class="line"> =&gt; WARN: MaintainerDeprecated: Maintainer instruction is deprecated in favor of using label (line 3)                                                                                    0.0s</span><br><span class="line"> =&gt; [internal] load metadata for docker.io/library/httpd:latest                                                                                                                          2.3s</span><br><span class="line"> =&gt; [auth] library/httpd:pull token for registry-1.docker.io                                                                                                                             0.0s</span><br><span class="line"> =&gt; [internal] load .dockerignore                                                                                                                                                        0.0s</span><br><span class="line"> =&gt; =&gt; transferring context: 2B                                                                                                                                                          0.0s</span><br><span class="line"> =&gt; [1/3] FROM docker.io/library/httpd:latest@sha256:437b9f7d469dd606fa6d2a5f9a3be55fe3af7e0c66e0329da8c14b291ae0d31c                                                                    0.0s</span><br><span class="line"> =&gt; CACHED [2/3] RUN echo hello container &gt;   /usr/local/apache2/htdocs/index.html                                                                                                       0.0s</span><br><span class="line"> =&gt; CACHED [3/3] WORKDIR /usr/local/apache2/htdocs                                                                                                                                       0.0s</span><br><span class="line"> =&gt; exporting to image                                                                                                                                                                   0.0s</span><br><span class="line"> =&gt; =&gt; exporting layers                                                                                                                                                                  0.0s</span><br><span class="line"> =&gt; =&gt; writing image sha256:e30e7b98cd48deef0229fbdea27d499b039bf06f2bf3c1d137230e5266cd40a5                                                                                             0.0s</span><br><span class="line"> =&gt; =&gt; naming to docker.io/library/web                                                                                                                                                   0.0s</span><br><span class="line"></span><br><span class="line"> 1 warning found (use docker --debug to expand):</span><br><span class="line"> - MaintainerDeprecated: Maintainer instruction is deprecated in favor of using label (line 3)</span><br></pre></td></tr></table></figure>

<p>It is visibly that each period of creating the same image is <code>zero</code>.</p>
<p>Here is the function of <code>cache</code>. Because I have already creating the same image before, it may reuse the cache this time.</p>
<p>Therefore, it will dramatically shorten the creating time.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker images</span><br><span class="line">REPOSITORY                                                                                               TAG       IMAGE ID       CREATED          SIZE</span><br><span class="line">web                                                                                                      latest    e30e7b98cd48   15 minutes ago   148MB</span><br><span class="line">web                                                                                                      v1        e30e7b98cd48   15 minutes ago   148MB</span><br><span class="line">ubuntu                                                                                                   20.04     9df6d6105df2   5 months ago     72.8MB</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<p>We could find there are two images, both of them are called web and the image id are the same. The difference is <code>tag</code>, this time I did not add the tag after the image name.</p>
<p>Therefore, the default tag is <code>latest</code>.</p>
<h2 id="Basic-commands-about-images"><a href="#Basic-commands-about-images" class="headerlink" title="Basic commands about images"></a>Basic commands about images</h2><ul>
<li><code>docker build -t image_name:tag_name .</code></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker build -t web:v1 .</span><br></pre></td></tr></table></figure>

<ul>
<li><code>docker commit container_name image_name:tag_name</code></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker commit web web:v2</span><br></pre></td></tr></table></figure>

<ul>
<li><code>docker save image_name:tag_name -o compression_name.tar</code></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker save web:v2 -o web_v2.tar</span><br></pre></td></tr></table></figure>

<ul>
<li><code>docker load -i compression_name</code></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">scp web_v2.tar user@ip:/path/to/images</span><br><span class="line">docker load -i web_v2.tar</span><br></pre></td></tr></table></figure>

<h2 id="2-Methods-of-creating-containers-with-image"><a href="#2-Methods-of-creating-containers-with-image" class="headerlink" title="2 Methods of creating containers with image"></a>2 Methods of creating containers with image</h2><p>As we discuss in <a href="https://blog.sunhaoyang.net/Cloud/Docker/Building-and-using-images/index.html">Docker Series (Chapter 1): Building and using images</a>, there are two methods to create a container by using an image.</p>
<ul>
<li><p><code>docker run</code></p>
<p><strong>docker run</strong> is a basic Docker command used to directly start a new container. It is ideal for running a container individually to perform simple tasks or experiments.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d -p 8080:80 --name my-container nginx</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>docker compose</code></p>
<p><strong>docker-compose</strong> is a tool used to define and manage <code>multi-container</code> Docker applications.</p>
<p>It configures services, networks, volumes, and more through a <code>docker-compose.yaml</code> file. docker-compose is ideal for managing applications made up of multiple containers, simplifying the configuration and startup of containers.</p>
<p>It is used for one-click start, stop, and management of multiple containers.</p>
<p>So, <code>docker-compose</code> builds on top of <code>docker run</code>, providing a more efficient and manageable way to handle multiple containers. It is especially useful for managing microservices architectures in development, testing, and production environments.</p>
</li>
</ul>
<table>
<thead>
<tr>
<th align="center">Feature</th>
<th align="center">docker run</th>
<th align="center">docker-compose</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><strong>Use Case</strong></td>
<td align="center">Single container, simple tasks or testing</td>
<td align="center">Multiple containers, complex applications, service dependencies management</td>
</tr>
<tr>
<td align="center"><strong>Configuration Method</strong></td>
<td align="center">Configured through command-line arguments</td>
<td align="center">Defined through the <code>docker-compose.yml</code> file with multiple containers, networks, volumes, etc.</td>
</tr>
<tr>
<td align="center"><strong>Start Multiple Containers</strong></td>
<td align="center">Need to start each container individually</td>
<td align="center">Use <code>docker-compose up</code> to start all containers at once</td>
</tr>
<tr>
<td align="center"><strong>Service Dependency Management</strong></td>
<td align="center">Manually manage dependencies between containers</td>
<td align="center">Define dependencies between containers in the <code>docker-compose.yml</code> file</td>
</tr>
<tr>
<td align="center"><strong>Port Mapping</strong></td>
<td align="center">Manually map ports, set individually for each container</td>
<td align="center">Unified port mapping management for multiple containers in the <code>docker-compose.yml</code> file</td>
</tr>
<tr>
<td align="center"><strong>File Management</strong></td>
<td align="center">No file configuration, relies on command-line arguments</td>
<td align="center">Uses docker-compose.yml file for centralized configuration and service management</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Scrum Guide (Part2 of 2)</title>
    <url>//Management/Scrum/Scrum-Guide2/index.html</url>
    <content><![CDATA[<p>After completing the <a href="https://blog.sunhaoyang.net/Management/Scrum/Scrum-Guide1/index.html">Scrum Guide (Part1 of 2)</a>, I will further explore the structure of Lean and Scrum, along with other related aspects in this chapter.</p>
<h2 id="Scrum-feedback-loop"><a href="#Scrum-feedback-loop" class="headerlink" title="Scrum feedback loop"></a>Scrum feedback loop</h2><p>Scrum is a <code>lightweight</code>, <code>flexible</code> <code>framework</code> that helps individuals, teams, and organisations deliver <code>adaptive solutions</code> <code>driven by value</code>, even in <code>dynamic business environments</code>. It uses an <code>iterative</code>, <code>incremental delivery</code> approach, where <code>learning occurs throughout the process</code>, enabling the delivery of maximum value in the shortest possible time and with minimal cost.</p>
<p>Such a loop includes: <code>Customer&#39;s perspective</code> -&gt; <code>Product goal</code> -&gt; <code>Product Backlog</code> -&gt; <code>Sprint Backlog</code> -&gt; <code>Execution</code> -&gt; <code>Review</code> -&gt; <code>Retrospective</code> -&gt; <code>Increments</code> -&gt; <code>linear regression testing</code> -&gt; <code>Opreation</code>-&gt;<code>Feedback</code>-&gt;<code>Validate</code>-&gt;<code>Product Backlog</code>……recycle again and again…</p>
<p>From the beginning, customers provide the perspectives for the scrum team, Product Owner generates ideas. Then Product Owner designs the product goal. In the meeting, the whole team follow the goal to design the Product Backlog, and Product Owner decide the priority based on the value in final. Then developers will pull tasks&#x2F;user stories from Product Backlog to Sprint Backlog’s TODO list. Developers are completing these tasks&#x2F;user stories in one Sprint period. In addition, the team will take the demonstration for customers during the review meeting. Finally, the whole team will hold a retrospective meeting to do the summary and look back the last sprint for the better next one.</p>
<blockquote>
<p>So, Scrum is not about cost-cutting and efficiency improvements. On the contrary, it often requires more investment.</p>
</blockquote>
<p>Here are the definitions of Working software: It meets the customer’s requirements(<code>valuable</code>) as well as has the eligible <code>quality</code>.</p>
<p>After each cycle of Scrum loop, the delivery artifact is <code>Minimal Viable Product(MVP)</code>.</p>
<p><code>Increments</code> &#x3D; <code>original functions</code> + <code>new functions</code> in total.</p>
<h2 id="Scrum-3-Accountabilities"><a href="#Scrum-3-Accountabilities" class="headerlink" title="Scrum 3 Accountabilities"></a>Scrum 3 Accountabilities</h2><ul>
<li><p><code>Developers</code></p>
<ul>
<li><p>Role: The Development Team is composed of professionals who work together to deliver potentially shippable product(PSP) increments at the end of each sprint. They are cross-functional and self-organising, with the necessary skills to design, develop, test, and deliver the product.</p>
</li>
<li><p>Key Responsibilities:</p>
<p>Deliver the product increment: Build and test features based on the requirements from the product backlog.</p>
<p>Self-organise: Decide how to organise their work and collaborate to meet the sprint goal.</p>
<p>Maintain quality: Ensure that the product is built to a high standard and is potentially shippable at the end of each sprint.</p>
<p>Continuous improvement: Participate in sprint retrospectives to reflect on the work done and look for ways to improve processes.</p>
</li>
</ul>
</li>
<li><p><code>Product Owner</code></p>
<ul>
<li><p>Role: The Product Owner is responsible for defining the product vision and managing the product backlog. They serve as the bridge between the stakeholders (such as customers, business owners, or end users) and the development team.</p>
</li>
<li><p>Key Responsibilities:</p>
<p>Define the product backlog: Prioritise the list of features, enhancements, and fixes that need to be developed.</p>
<p>Ensure value delivery: Make sure that the team works on the most valuable tasks that align with customer and business needs.</p>
<p>Clarify requirements: Provide clear requirements and make decisions on scope, priorities, and trade-offs.</p>
<p>Act as a stakeholder liaison: Communicate with customers, stakeholders, and the team to gather feedback and ensure alignment.</p>
</li>
</ul>
</li>
<li><p><code>Scrum Master</code></p>
<ul>
<li><p>Role: The Scrum Master is responsible for ensuring that the Scrum framework is followed and that the team operates efficiently. They act as a facilitator, coach, and servant leader to both the development team and the Product Owner.</p>
</li>
<li><p>Key Responsibilities:</p>
<p>Facilitate Scrum ceremonies: Help organise and facilitate Scrum events, such as daily standups, sprint planning, sprint reviews, and retrospectives.</p>
<p>Remove impediments: Identify and address obstacles that are blocking the team’s progress.</p>
<p>Coach the team: Support the team in adopting Scrum practices, encourage self-organisation, and foster continuous improvement.</p>
<p>Protect the team: Shield the team from external distractions or disruptions so they can focus on their work.</p>
</li>
</ul>
</li>
</ul>
<h2 id="Scrum-3-Artifacts"><a href="#Scrum-3-Artifacts" class="headerlink" title="Scrum 3 Artifacts"></a>Scrum 3 Artifacts</h2><ul>
<li><p><code>Product Backlog</code></p>
<ul>
<li><p>Definition: The Product Backlog is a dynamic, ordered list of everything that might be needed in the product. It is the single source of work items for the development team.</p>
</li>
<li><p>Key Characteristics:</p>
<p>Managed by the Product Owner: The Product Owner is responsible for prioritising and refining the backlog.</p>
<p>Contains user stories, features, enhancements, and bug fixes: These items are often described as Product Backlog Items (PBIs).</p>
<p>Evolves over time: The backlog is continuously updated based on new information, customer feedback, or market changes.</p>
<p>Prioritisation: Items at the top of the backlog are more important and are typically worked on first, based on their value and urgency.</p>
</li>
<li><p>Purpose: The Product Backlog provides the team with a clear view of the product’s needs and helps ensure that the most important work is always done first.</p>
</li>
</ul>
</li>
<li><p><code>Spring Backlog</code></p>
<ul>
<li><p>Definition: The Sprint Backlog is a list of tasks and Product Backlog Items (PBIs) that the development team commits to completing during a single sprint. It is derived from the Product Backlog.</p>
</li>
<li><p>Key Characteristics:</p>
<p>Owned by the Development Team: The team selects which items to work on during a sprint, based on their capacity and priorities.</p>
<p>Contains both PBIs and tasks: In addition to backlog items, the Sprint Backlog includes detailed tasks needed to complete the items.</p>
<p>Dynamic: The Sprint Backlog is updated as the team works through the sprint, adding new tasks or making adjustments as needed.</p>
<p>Visibility: It provides a clear picture of what work is currently being done and what remains to be completed during the sprint.</p>
</li>
<li><p>Purpose: The Sprint Backlog serves as a focused plan for the current sprint, enabling the team to track progress and deliver the sprint goal.</p>
</li>
</ul>
</li>
<li><p><code>Increment</code></p>
<ul>
<li><p>Definition: The Increment is the sum of all the completed Product Backlog Items during a sprint, plus the work completed in previous sprints. It represents the latest version of the product that is potentially shippable.</p>
</li>
<li><p>Key Characteristics:</p>
<p>Potentially Shippable: At the end of each sprint, the Increment should be in a usable state and could be released to customers if desired.</p>
<p>Completed and Tested: The Increment includes all the features that meet the team’s definition of “done” and are fully integrated and tested.</p>
<p>Represents Progress: Each Increment adds value and progresses the product towards meeting the overall goals and vision.</p>
<p>Visible: The Increment is typically demonstrated during the Sprint Review for inspection by stakeholders.</p>
</li>
<li><p>Purpose: The Increment represents the product’s evolution and the value delivered during a sprint. It provides a tangible result that stakeholders can see, review, and provide feedback on.</p>
</li>
</ul>
</li>
</ul>
<h2 id="Scrum-3-Commitment"><a href="#Scrum-3-Commitment" class="headerlink" title="Scrum 3 Commitment"></a>Scrum 3 Commitment</h2><ul>
<li><p><code>Product Goal</code></p>
<ul>
<li><p>Definition: The Product Goal is the commitment associated with the Product Backlog. It defines what the team is trying to achieve with the product, representing the ultimate objective or target the product is working towards.</p>
</li>
<li><p>Key Characteristics:</p>
</li>
</ul>
<p>Guiding the team: The Product Goal guides the team by providing a clear, overarching target for the product. It helps define the vision and sets direction for the work in the Product Backlog.</p>
<p>Evolving: The Product Goal may evolve over time as business priorities, market conditions, and customer needs change.</p>
<p>Focus for the Product Owner: The Product Owner is responsible for ensuring the Product Goal is well-defined and communicated to the team and stakeholders.</p>
<ul>
<li>Purpose: The Product Goal ensures the team remains focused on delivering value and aligns all product work toward a common objective.</li>
</ul>
</li>
<li><p><code>Sprint Goal</code></p>
<ul>
<li><p>Definition: The Sprint Goal is the commitment related to the Sprint Backlog. It defines what the team aims to achieve during a sprint and is created collaboratively during the Sprint Planning meeting.</p>
</li>
<li><p>Key Characteristics:</p>
</li>
</ul>
<p>Focused objective: The Sprint Goal provides the team with a clear purpose for the sprint and aligns them on what needs to be delivered.</p>
<p>Created during Sprint Planning: It is defined at the start of the sprint, and the team decides which Product Backlog items (PBIs) they will work on to achieve this goal.</p>
<p>Adaptable: The Sprint Goal may evolve slightly during the sprint if new information arises, but the team must stay focused on the overall objective.</p>
<ul>
<li>Purpose: The Sprint Goal ensures that the team is working towards a shared and specific target during the sprint, promoting alignment and providing a measure for success.</li>
</ul>
</li>
<li><p><code>Definiton of Done(DoD)</code></p>
<ul>
<li><p>Definition: The Definition of Done (DoD) is the commitment associated with the Increment. It defines the criteria that must be met for Product Backlog items to be considered complete.</p>
</li>
<li><p>Key Characteristics:</p>
</li>
</ul>
<p>Quality assurance: The DoD ensures that all work completed during the sprint is of high quality, fully tested, and integrated with the existing system.</p>
<p>Agreed by the team: The team agrees on the Definition of Done, which can evolve over time as the team improves their quality standards and practices.</p>
<p>Transparency: The Definition of Done provides transparency to stakeholders, allowing them to understand what “done” really means in terms of product quality.</p>
<ul>
<li>Purpose: The Definition of Done ensures that the Increment is truly finished and meets the necessary standards, providing confidence that the product is ready for release or further testing.</li>
</ul>
</li>
</ul>
<h2 id="Scrum-5-Events"><a href="#Scrum-5-Events" class="headerlink" title="Scrum 5 Events"></a>Scrum 5 Events</h2><ul>
<li><p><code>Sprint</code></p>
<ul>
<li><p>Definition: The Sprint is the core event in Scrum and refers to the time-boxed iteration during which the team works to complete a set of items from the Product Backlog.</p>
</li>
<li><p>Key Characteristics:</p>
<ul>
<li><p>Duration: Typically lasts between 1 to 4 weeks, depending on the team’s preference.</p>
</li>
<li><p>Goal: At the end of the Sprint, a potentially shippable product increment is delivered, which should meet the Definition of Done.</p>
</li>
<li><p>Consistency: Each Sprint follows the same cycle and is followed by a review and retrospective.</p>
</li>
</ul>
</li>
<li><p>Purpose: The Sprint serves as the fundamental cycle where all other events occur. It enables teams to focus on delivering value incrementally.</p>
</li>
</ul>
</li>
<li><p><code>Sprint Planning</code></p>
<ul>
<li><p>Definition: Sprint Planning is the event where the team and the Product Owner collaboratively define the work that will be completed in the upcoming Sprint.</p>
</li>
<li><p>Key Characteristics:</p>
<ul>
<li><p>Who: The Scrum Team (Product Owner, Scrum Master, and Development Team) participates.</p>
</li>
<li><p>What: The team defines the Sprint Goal, selects items from the Product Backlog to work on, and creates a plan for how to complete those items.</p>
</li>
<li><p>Time-box: Typically lasts between 2 to 4 hours for a 2-week Sprint.</p>
</li>
</ul>
</li>
<li><p>Purpose: Sprint Planning ensures that everyone is aligned on what needs to be achieved and how to accomplish it.</p>
</li>
</ul>
</li>
<li><p><code>Daily Scrum</code></p>
<ul>
<li><p>Definition: The Daily Scrum (also known as the Daily Standup) is a short, time-boxed meeting held every day of the Sprint to inspect progress and adapt the plan.</p>
</li>
<li><p>Key Characteristics:</p>
<ul>
<li><p>Who: Primarily the Development Team; the Product Owner and Scrum Master can attend but do not actively participate unless necessary.</p>
</li>
<li><p>Format: Each team member answers three questions:</p>
<ol>
<li><p>What did I complete yesterday to help the team achieve the Sprint Goal?</p>
</li>
<li><p>What will I do today to help the team achieve the Sprint Goal?</p>
</li>
<li><p>Are there any blockers or challenges?</p>
</li>
</ol>
</li>
<li><p>Time-box: Typically lasts 15 minutes.</p>
</li>
</ul>
</li>
<li><p>Purpose: The Daily Scrum allows the team to inspect their progress, make adjustments, and stay focused on the Sprint Goal.</p>
</li>
</ul>
</li>
<li><p><code>Sprint Review</code></p>
<ul>
<li><p>Definition: The Sprint Review is an event that occurs at the end of the Sprint where the team demonstrates the work they have completed to stakeholders and gathers feedback.</p>
</li>
<li><p>Key Characteristics:</p>
<ul>
<li><p>Who: The Scrum Team and key stakeholders (e.g., customers, managers) participate.</p>
</li>
<li><p>What: The Development Team showcases the Increment, and the Product Owner discusses the Product Backlog and progress towards the Product Goal. Stakeholders provide feedback.</p>
</li>
<li><p>Time-box: Typically lasts 1 to 2 hours for a 2-week Sprint.</p>
</li>
</ul>
</li>
<li><p>Purpose: The Sprint Review allows stakeholders to inspect the Increment, provide feedback, and ensure that the product is evolving in the right direction.</p>
</li>
</ul>
</li>
<li><p><code>Spring Retrospective</code></p>
<ul>
<li><p>Definition: The Sprint Retrospective is a meeting held after the Sprint Review and before the next Sprint Planning to reflect on the Sprint process and identify areas for improvement.</p>
</li>
<li><p>Key Characteristics:</p>
<ul>
<li><p>Who: The Scrum Team (Product Owner, Scrum Master, and Development Team) participate.</p>
</li>
<li><p>What: The team reflects on what went well, what could be improved, and what actions can be taken to improve in the next Sprint.</p>
</li>
<li><p>Time-box: Typically lasts 1 to 1.5 hours for a 2-week Sprint.</p>
</li>
</ul>
</li>
<li><p>Purpose: The Sprint Retrospective helps the team identify areas for improvement in both their processes and collaboration, fostering continuous improvement.</p>
</li>
</ul>
</li>
</ul>
<h2 id="Scrum-5-Values"><a href="#Scrum-5-Values" class="headerlink" title="Scrum 5 Values"></a>Scrum 5 Values</h2><ul>
<li><p><code>Commitment</code></p>
<ul>
<li><p>Definition: Commitment in Scrum refers to the team’s dedication to achieving the Sprint Goal and delivering the highest value possible within the agreed-upon timeframe.</p>
</li>
<li><p>Key Characteristics:</p>
<ul>
<li><p>To the Sprint Goal: The team commits to achieving the goals defined for the Sprint, ensuring that their work aligns with the overall objectives.</p>
</li>
<li><p>To the Team: Team members commit to supporting each other, sharing knowledge, and working collaboratively to achieve success.</p>
</li>
<li><p>To Continuous Improvement: The team commits to reflecting on their performance and looking for ways to improve in the future.</p>
</li>
</ul>
</li>
<li><p>Purpose: Commitment ensures that the team stays focused, works with determination, and is accountable for the work they undertake.</p>
</li>
</ul>
</li>
<li><p><code>Focus</code></p>
<ul>
<li><p>Definition: Focus refers to the ability to concentrate on the most important tasks and priorities, ensuring that the team’s energy is directed toward achieving the Sprint Goal and delivering value.</p>
</li>
<li><p>Key Characteristics:</p>
<ul>
<li><p>On the Sprint Goal: The team focuses on delivering the Sprint Goal, ensuring that they avoid distractions and work on the highest-priority tasks.</p>
</li>
<li><p>On the task at hand: During the Sprint, team members focus on completing individual tasks efficiently without being diverted by external factors.</p>
</li>
<li><p>On the customer’s needs: The team keeps the customer’s needs and the Product Goal in mind, ensuring that the work they’re doing delivers value to the end user.</p>
</li>
</ul>
</li>
<li><p>Purpose: Focus helps the team maintain alignment with the Sprint Goal and ensures that energy is not wasted on irrelevant work or distractions.</p>
</li>
</ul>
</li>
<li><p><code>Openness</code></p>
<ul>
<li><p>Definition: Openness refers to the team’s willingness to share information, feedback, and progress with each other and stakeholders, creating a culture of transparency.</p>
</li>
<li><p>Key Characteristics:</p>
<ul>
<li><p>Transparency: The team shares information openly, allowing stakeholders and each other to understand progress, challenges, and successes.</p>
</li>
<li><p>Honest communication: Team members are open and honest about what’s going well and where they might be facing difficulties, ensuring issues are addressed early.</p>
</li>
<li><p>Welcoming feedback: The team is open to receiving feedback from others, viewing it as an opportunity for improvement rather than criticism.</p>
</li>
</ul>
</li>
<li><p>Purpose: Openness fosters trust and collaboration, allowing the team to work more effectively and respond to challenges more quickly.</p>
</li>
</ul>
</li>
<li><p><code>Respect</code></p>
<ul>
<li><p>Definition: Respect in Scrum means valuing each other’s contributions, listening to different perspectives, and trusting that each person is bringing valuable expertise to the team.</p>
</li>
<li><p>Key Characteristics:</p>
<ul>
<li><p>Value each individual’s expertise: Team members respect each other’s skills, knowledge, and experiences, fostering a collaborative and supportive environment.</p>
</li>
<li><p>Listening actively: The team listens to each other’s ideas and feedback, making sure everyone’s voice is heard and valued.</p>
</li>
<li><p>Trust: Team members trust each other to do their best and contribute to the team’s success, supporting one another’s development and growth.</p>
</li>
</ul>
</li>
<li><p>Purpose: Respect ensures that team members work together harmoniously, value diversity of thought, and collaborate to achieve the best possible outcomes.</p>
</li>
</ul>
</li>
<li><p><code>Courage</code></p>
<ul>
<li><p>Definition: Courage in Scrum means having the bravery to take on challenging work, make tough decisions, and speak up when issues or concerns arise.</p>
</li>
<li><p>Key Characteristics:</p>
<ul>
<li><p>Taking on challenges: The team is willing to tackle difficult tasks, knowing that they might encounter obstacles along the way.</p>
</li>
<li><p>Speaking up: Team members have the courage to raise concerns, provide honest feedback, and address issues without fear of judgment.</p>
</li>
<li><p>Trying new things: The team is willing to experiment with new approaches or techniques to improve the product or process.</p>
</li>
</ul>
</li>
<li><p>Purpose: Courage helps the team push boundaries, innovate, and continuously improve, knowing that failure is a part of the learning process.</p>
</li>
</ul>
</li>
</ul>
<h2 id="Sprint-1-extra-activity"><a href="#Sprint-1-extra-activity" class="headerlink" title="Sprint 1 extra activity"></a>Sprint 1 extra activity</h2><p><code>Product Backlog Refinement</code></p>
<p>The entire team (PO + Dev + SM) collaborates together.</p>
<p>The PO ensures that the activity is carried out in an organised manner.</p>
<p>It typically happens before the sprint begins.</p>
<p>This is not a formal meeting: it is usually informal, offline, and happens continuously (spending a little time each day).</p>
<p>It involves a small group, with short, high-intensity brainstorming sessions.</p>
<p>The Product Owner and Developers co-create the product feature details.<br>Behaviour Driven Development (BDD) is recommended.”</p>
<p>This translation conveys the same meaning in a clear, professional British English style, highlighting the collaborative and informal nature of the process.</p>
<h2 id="Lean"><a href="#Lean" class="headerlink" title="Lean"></a>Lean</h2><p>This term was originally developed by <code>Toyota Motor Corporation</code> in the mid-20th century as a production and management philosophy aimed at improving production efficiency, reducing waste, enhancing quality, and fostering continuous improvement. This approach became known as the <code>Toyota Production System</code> (TPS), which emphasises the elimination of all forms of waste—such as time, materials, and labour and optimising processes.</p>
<p>Over time, Lean thinking has been widely adopted in various industries beyond manufacturing, including software development and services, leading to the emergence of concepts such as ‘Lean Production’ and ‘Lean Management’ in these fields.</p>
<p><code>JIT</code>: Just In Time.</p>
<h3 id="2-essential-concepts"><a href="#2-essential-concepts" class="headerlink" title="2 essential concepts"></a>2 essential concepts</h3><ul>
<li><p><code>Value</code></p>
<p>Anything that customers are prepared to pay for can be regarded as value, because it directly contributes to fulfilling their needs or solving their problems.<br>Simply to say, <code>value = customer&#39;s perspective</code>.</p>
</li>
<li><p><code>Waste</code></p>
<p>Anything that does not contribute to value can be classified as waste.</p>
<p>There are <code>8 waste in total</code>. The abbreviation of these 8 words is <code>DOWNTIME</code>.</p>
<ul>
<li><p><code>Defects</code></p>
<p>Products or services that do not meet quality standards and require rework or scrap.</p>
</li>
<li><p><code>Overproduction</code></p>
<p>Producing more than what is needed or before it is needed.</p>
</li>
<li><p><code>Waiting</code></p>
<p>Idle time where work is not being done, such as waiting for materials, information, or equipment.</p>
</li>
<li><p><code>Non-utilized Talents</code></p>
<p>Employees’ full potential, skills, and ideas are not fully utilised in the organisation’s processes or decision-making.</p>
</li>
<li><p><code>Transportation</code></p>
<p>Unnecessary movement of products, materials.</p>
</li>
<li><p><code>Inventory</code></p>
<p>Excess materials or products that are not being used immediately.</p>
</li>
<li><p><code>Motion</code></p>
<p>Unnecessary movement of people, tools, or equipment that does not add value.</p>
</li>
<li><p><code>Extra Processing</code></p>
<p>Doing more work than required or using more complex processes than necessary.</p>
</li>
</ul>
</li>
</ul>
<h3 id="Pull-vs-Push"><a href="#Pull-vs-Push" class="headerlink" title="Pull vs Push"></a>Pull vs Push</h3><ul>
<li><p><code>Pull</code></p>
<p>Developers independently pull tasks&#x2F;user stories from the Product Backlog to Sprint Backlog’s TODO list only if they completed the tasks&#x2F;user stories at hand.</p>
<p>One task&#x2F;user story at a time.</p>
</li>
<li><p><code>Push</code></p>
<p>Developers are passively receiving tasks&#x2F;user stories from the manager.</p>
<p>More than one at hand at a time. It may cause the 7 kindks of waste except for <code>Motion</code>.</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Management</category>
      </categories>
      <tags>
        <tag>Scrum</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Series (Chapter 1/4): Building and using images</title>
    <url>//Cloud/Docker/Building-and-using-images/index.html</url>
    <content><![CDATA[<h2 id="Overview-of-the-image"><a href="#Overview-of-the-image" class="headerlink" title="Overview of the image"></a>Overview of the image</h2><p>An image is a <code>read-only template</code> used to <code>create containers</code>. Typically, it includes some additional customizations.</p>
<p>For example, we could build an image based on rocky operating system that directly includes some applications like Nginx, Apache or other programs during the image build process.</p>
<p>Once the image is built, we could directly launch containers based on it to quickly achieve the desired business functionality to ensure consistent behavior across different environments.</p>
<h2 id="Sources-of-the-image"><a href="#Sources-of-the-image" class="headerlink" title="Sources of the image"></a>Sources of the image</h2><ul>
<li><p>Pull from the image repository(public:Docker Hub&#x2F;private: harbor,quay,etc)</p>
<ul>
<li><a href="https://hub.docker.com/">Public image repository</a></li>
<li><a href="https://github.com/goharbor/harbor">Private image repository</a></li>
</ul>
<p><code>Registry</code> is a <strong>stateless</strong>, highly <strong>scalable</strong> service that allows us to store and distribute images. Registry is an open source service licensed under the Apache License.</p>
<p>The public image repository is a cloud-based registry service.</p>
<p>Compared with the public image repository, the private repository has these merits:</p>
<ul>
<li>We could strictly control where images are stored.</li>
<li>We have a mirror distribution channel that belongs entirely to us.</li>
<li>We could tightly integrate image storage and distribution into internal development workflows.</li>
</ul>
</li>
<li><p>Customize and build manually from Dockerfile</p>
</li>
</ul>
<h2 id="Build-images-manually"><a href="#Build-images-manually" class="headerlink" title="Build images manually"></a>Build images manually</h2><p>There are two methods to build image.</p>
<ul>
<li><code>docker commit</code> based on original containers</li>
</ul>
<p>We could modify the applications&#x2F;services&#x2F;environments and something else based on the original dokcer image in the containers. After that, we could use <code>docker commit</code> command to export a new image from containers.</p>
<ul>
<li><code>docker build</code> by using Dockerfile</li>
</ul>
<p>Build the image you need from scratch. At the beginning of creating the image, set the various settings and requirements you need.<br>Various applications are included, and the generated images can be directly used for business deployment.</p>
<p>Dockerfile high frequency instruction set</p>
<table>
<thead>
<tr>
<th align="center">Command</th>
<th align="center">Function</th>
<th align="center">Format</th>
</tr>
</thead>
<tbody><tr>
<td align="center">FROM</td>
<td align="center">Specify the base image</td>
<td align="center">FROM image:tag</td>
</tr>
<tr>
<td align="center">MAINTAINER</td>
<td align="center">Specify the image author</td>
<td align="center">MAINTAINER name</td>
</tr>
<tr>
<td align="center">RUN</td>
<td align="center">Excute the Specified command</td>
<td align="center">RUN command</td>
</tr>
<tr>
<td align="center">ADD</td>
<td align="center">Copy files from build context copied into mirror</td>
<td align="center">ADD [–chown&#x3D;user:group]src…dest</td>
</tr>
<tr>
<td align="center">COPY</td>
<td align="center">Copy files from build context copied into mirror</td>
<td align="center">COPY -chown&#x3D;user:groupsrc…dest</td>
</tr>
<tr>
<td align="center">ENV</td>
<td align="center">Set the environmental variables</td>
<td align="center">ENV key value</td>
</tr>
<tr>
<td align="center">EXPOSE</td>
<td align="center">Specify the listen port for applications</td>
<td align="center">EXPOSE port [port&#x2F;protocol]</td>
</tr>
<tr>
<td align="center">USER</td>
<td align="center">Specify the user at boot</td>
<td align="center">USER user</td>
</tr>
<tr>
<td align="center">CMD</td>
<td align="center">Specify the command or scripts at boot</td>
<td align="center">CMD command param1 param2</td>
</tr>
<tr>
<td align="center">ENTRYPOINT</td>
<td align="center">Specify an excutable script or program path</td>
<td align="center">ENTRYPOINT command param1 param2</td>
</tr>
<tr>
<td align="center">VOLUME</td>
<td align="center">Declare files or directories as volume and mount to containers</td>
<td align="center">VOLUME [“&#x2F;data”]</td>
</tr>
<tr>
<td align="center">WORKDIR</td>
<td align="center">Specify the current working directory</td>
<td align="center">WORKDIR &#x2F;path&#x2F;to&#x2F;workdir</td>
</tr>
</tbody></table>
<p>You could use all Dockerfile commands to develop the Dockerfile.</p>
<p>After coding, you should use this command to build an image.</p>
<p>The default name of dockerfile is <code>Dockerfile</code>, you could name it as what you want. However, you should specify the file name when you build an image.</p>
<p>The dot represents the context, you also could specify the path as what you want here.</p>
<p>If you do not specify the tag name, the default name of tag is <code>latest</code>. So, please do not misunderstand and remember to set the appropriate name for easily understand!</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker build (-f Dockerfile_name) -t image_name:tag_name .(/path/to/context)</span><br></pre></td></tr></table></figure>

<h2 id="Using-an-image-to-create-containers"><a href="#Using-an-image-to-create-containers" class="headerlink" title="Using an image to create containers"></a>Using an image to create containers</h2><p>There are two methods to create containers.</p>
<ul>
<li><code>docker run</code></li>
</ul>
<p>This command can only start one container at a time.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d -p 8000:80 customized_image:v1</span><br></pre></td></tr></table></figure>

<ul>
<li><code>docker compose up -d</code></li>
</ul>
<p><span style="color:red;">You must develop a docker-compose.yaml file first, and then change the directory to it. By the way, a container that remain running only if it has a process that sustains its execution.</span></p>
<p><code>docker-compose.yaml</code> is an inventory listing all needed services, it is so convenient that you could start more than one container at a time.</p>
<h3 id="Creating-the-docker-compose-yaml-file"><a href="#Creating-the-docker-compose-yaml-file" class="headerlink" title="Creating the docker-compose.yaml file"></a>Creating the docker-compose.yaml file</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># change the directory into the docker-compose file</span></span><br><span class="line"><span class="built_in">cd</span> ~/docker</span><br><span class="line"><span class="comment"># create docker-compose.yml file</span></span><br><span class="line">vim docker-compose.yaml</span><br><span class="line"><span class="comment"># specify Docker Compose file version as 3.8</span></span><br><span class="line">version: <span class="string">&#x27;3.8&#x27;</span></span><br><span class="line"><span class="comment"># Define services，for example: &quot;build&quot;</span></span><br><span class="line">services:</span><br><span class="line">build:</span><br><span class="line"><span class="comment"># specify the based on what image to build</span></span><br><span class="line">image: nginx:latest</span><br><span class="line"><span class="comment"># specify the container name as build</span></span><br><span class="line">container_name: build</span><br><span class="line"><span class="comment"># Start the tty console terminal for interacting</span></span><br><span class="line"><span class="built_in">tty</span>: <span class="literal">true</span></span><br><span class="line"><span class="comment"># specify auto-restart when container crashed</span></span><br><span class="line">restart: always</span><br><span class="line"><span class="comment"># configure the volumes to mount into containers</span></span><br><span class="line">volumes:</span><br><span class="line">- ./src/:/root/nginx/</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>2025/01/24 English accumulation</title>
    <url>//Language/English/20250124/index.html</url>
    <content><![CDATA[<ul>
<li><p><strong>and so forth</strong>: It is used to mean <code>and other similar things</code> or <code>and so on</code>. It’s a way of indicating that the list or examples given could continue, but you’re leaving out additional details because they’re understood to follow the same pattern. It is more formal than <code>etc.</code></p>
</li>
<li><p><strong>oversight</strong>: It generally refers to <code>supervision</code> or <code>monitoring</code> of a process, activity, or organization to ensure that it is functioning properly, ethically, and in compliance with regulations or standards.</p>
</li>
<li><p><strong>manifesto</strong>: It is a public declaration of principles, beliefs, or intentions, often issued by a political party, organization, or individual. A manifesto is typically a formal and structured statement that conveys the direction or ideology behind a movement, election campaign, or cause.</p>
</li>
<li><p><strong>retrieve</strong>: It means to <code>get something back</code> or <code>bring something back</code> from a particular place, especially after it has been lost, misplaced, or taken away. It can refer to physically <code>fetching</code> or <code>recovering</code> an item, or to accessing and recovering information.</p>
</li>
<li><p><strong>viable</strong>: It refers to something that is <code>practical</code>, <code>feasible</code>, or <code>capable of working successfully</code>. It is used to describe a plan, idea, solution, or course of action that is likely to be successful or achievable, given the available resources, constraints, and conditions.</p>
</li>
<li><p><strong>adversarial</strong>: It describes a situation, relationship, or environment where there is <code>opposition</code>, <code>conflict</code>, or <code>competition</code> between two parties or groups. It often implies a hostile, competitive, or antagonistic nature, where one side’s success or position is seen as being in direct conflict with the other’s.</p>
</li>
<li><p><strong>hostile</strong>: It refers to an attitude, environment, or action that is <code>unfriendly</code>, <code>aggressive</code>, or <code>antagonistic</code>. It describes behaviour or conditions that reflect opposition, enmity, or a desire to cause harm or discomfort to someone or something.</p>
</li>
<li><p><strong>antagonistic</strong>: It describes someone or something that is opposed, hostile, or actively unfriendly. It refers to actions, attitudes, or behaviours that create or reflect conflict, opposition, or rivalry. An antagonistic person or force is one that creates tension or hostility, often in a deliberate way.</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Language</category>
      </categories>
      <tags>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title>Scrum Guide (Part1 of 2)</title>
    <url>//Management/Scrum/Scrum-Guide1/index.html</url>
    <content><![CDATA[<h2 id="Icebreaking-topics"><a href="#Icebreaking-topics" class="headerlink" title="Icebreaking topics"></a>Icebreaking topics</h2><p>The evolution of agile management indeed shows how it has expanded and gained popularity across various industries over time.</p>
<p>Here’s an analysis of agile management from the perspective of being a product of “involution” in China:</p>
<table>
<thead>
<tr>
<th align="center">2000</th>
<th align="center">2005</th>
<th align="center">2010</th>
<th align="center">2015</th>
<th align="center">2020</th>
</tr>
</thead>
<tbody><tr>
<td align="center">IT TELECOM(internet 2G)</td>
<td align="center">GAMING(intranet 3G)</td>
<td align="center">INTERNET(mobile internet 4G)</td>
<td align="center">BANKING(Alibaba)</td>
<td align="center">PHARMACY(COVID-19) FMCG(Tik Tok) AutoMobile(Tesla)</td>
</tr>
</tbody></table>
<ul>
<li><p><code>2000: IT and Telecommunications Industry</code></p>
<p>The origin of agile management can be traced back to the release of the Agile Manifesto in 2001. At that time, the IT and telecommunications industries were facing rapid technological changes and uncertain market demands. The traditional waterfall development model struggled to adapt. This led to the emergence of agile methods, such as Scrum and Extreme Programming (XP), aimed at improving development efficiency and adaptability.</p>
</li>
<li><p><code>2005: Gaming Industry</code></p>
<p>The gaming industry’s demand for innovation and rapid iteration made agile methods a major trend. In game development, fast prototyping, quick incorporation of user feedback, and cross-department collaboration became critical. Agile methods helped teams manage complexity and shorten product development cycles.</p>
</li>
<li><p><code>2010: Internet Industry</code></p>
<p>The explosive growth of the internet industry brought about fierce market competition. User experience, rapid product releases, and continuous iteration became key to survival. Agile management became the standard for internet companies, enabling small, incremental progress and frequent delivery to enhance user satisfaction and market responsiveness.</p>
</li>
<li><p><code>2015: Banking and Financial Industry</code></p>
<p>Amid the wave of digital transformation, traditional financial institutions began to feel the competitive pressure from tech companies. To accelerate product development and adapt to regulatory changes, banks and financial organizations started adopting agile management methods, establishing innovation labs and implementing agile team collaboration to improve competitiveness.</p>
</li>
<li><p><code>2020: Pharmaceutical Industries</code></p>
<p>The COVID-19 pandemic further drove the adoption of agile practices, especially in vaccine development and drug production, where rapid trials, real-time feedback, and cross-team collaboration became crucial.</p>
</li>
</ul>
<p>Therefore, businesses transitioning to agile practices is not without reason. It is a means of surviving the pressures and challenges brought about by industry-wide “involution.” Survival of the fittest, as nature dictates, follows the law of natural selection.</p>
<hr>
<h2 id="Agile"><a href="#Agile" class="headerlink" title="Agile"></a>Agile</h2><h3 id="What-is-Agile"><a href="#What-is-Agile" class="headerlink" title="What is Agile?"></a>What is Agile?</h3><p><code>Agile</code> is essentially a mindset, a philosophy for responding flexibly to rapid changes, complexity, and uncertainty.</p>
<h3 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h3><p>It includes various kind of methods: Kanban, Extreme Programming(XP), BDD, Scrum and so forth.</p>
<h3 id="4-Values"><a href="#4-Values" class="headerlink" title="4 Values"></a>4 Values</h3><ul>
<li><p><code>Individuals and interactions over processes and tools</code></p>
<p>Our processes and tools should provide services for developers, for people. Effective processes and useful tools should provide convenience for our work.</p>
<p>Effectiveness-oriented processes&#x2F;tools, rather than oversight-oriented processes&#x2F;tools. Please learn more in <a href="#taylorism">Taylorism</a>.</p>
</li>
<li><p><code>Working software over comprehensive documentation</code></p>
<p>The best design documentation is actually the test cases.</p>
<p>Substance over form, code over text.</p>
</li>
<li><p><code>Customer collaboration over contract negotiation</code></p>
<p>We should strive for win-win cooperation, not adversarial negotiation.</p>
<p>Let the other party make money first, and then we can make money.</p>
</li>
<li><p><code>Responding to change over following a plan</code></p>
<p>We prefer plans in the form of actions (verbs) rather than in the form of nouns.</p>
<p>Nothing is set in stone; the only constant is change.</p>
</li>
</ul>
<h3 id="12-Principles"><a href="#12-Principles" class="headerlink" title="12 Principles"></a>12 Principles</h3><p>More detailed infomation, please follow the <a href="https://agilemanifesto.org/principles.html">agilemanifesto</a>.</p>
<h3 id="Taylorism"><a href="#Taylorism" class="headerlink" title="Taylorism"></a>Taylorism</h3><p>It is so ridiculous to treat people as resources.</p>
<p>The management in the IT and construction industries is lagging because both have been modeled after the management practices of the manufacturing industry.</p>
<p>In 1890, Taylorism gave birth to terms like ‘bean counters,’ ‘minute men,’ ‘blue-collar workers,’ and ‘time sheets,’ all of which are associated with oversight-oriented practice. This only leads to the so-called power struggles and conflict between managers and workers.</p>
<hr>
<h2 id="Scrum"><a href="#Scrum" class="headerlink" title="Scrum"></a>Scrum</h2><p>Having introduced Agile, I will now focus on the Scrum methodology.</p>
<h3 id="What-is-Scrum"><a href="#What-is-Scrum" class="headerlink" title="What is Scrum?"></a>What is Scrum?</h3><p><code>Scrum</code> originates from <code>rugby</code>.</p>
<p><strong>Business Perspective: Quickly and continuously turning innovation into value.</strong></p>
<p><strong>Managerial Perspective: Creating the maximum value with limited time and cost.</strong></p>
<h3 id="3-Core-Practices"><a href="#3-Core-Practices" class="headerlink" title="3 Core Practices"></a>3 Core Practices</h3><ul>
<li><p><code>Value Prioritisation</code></p>
<p>Prioritising tasks based on the commercial value of the product.</p>
</li>
<li><p><code>Parallel Processes</code></p>
<p>Bottlenecks and delays in a single process are addressed.</p>
</li>
<li><p><code>Superteam</code></p>
<p>Eliminate collaboration dependencies and reduce waste of unused skills.</p>
</li>
</ul>
<h3 id="Differences-between-Scrum-and-Waterfall"><a href="#Differences-between-Scrum-and-Waterfall" class="headerlink" title="Differences between Scrum and Waterfall"></a>Differences between Scrum and Waterfall</h3><p>The Project Management Triangle: Scope, Time, and Cost, all work together in a balanced way to impact quality.</p>
<ul>
<li><p><code>Scope</code></p>
</li>
<li><p><code>Time</code></p>
</li>
<li><p><code>cost</code></p>
</li>
<li><p><code>Quality</code></p>
</li>
</ul>
<p>Different management approaches handle problems in different ways.</p>
<ul>
<li><p><code>Waterfall</code></p>
<p>Fixed scope, compressed cost.</p>
</li>
<li><p><code>Scrum</code></p>
<p>Maximize value with fixed cost.</p>
<ul>
<li><input checked="" disabled="" type="checkbox"> Prioritize doing the tasks that create the most value.</li>
<li><input disabled="" type="checkbox"> Expanding the project scope while keeping the cost unchanged puts pressure on the team.</li>
</ul>
</li>
</ul>
<hr>
<p>That’s all I would like to introduce in this article.</p>
<p>More sharing about Scrum, please stay tuned for updates about <a href="https://blog.sunhaoyang.net/Management/Scrum/Scrum-Guide2/index.html">Scrum Guide (Part2 of 2)</a>.</p>
]]></content>
      <categories>
        <category>Management</category>
      </categories>
      <tags>
        <tag>Scrum</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Series (Chapter 0/4): Installing docker-engine in Ubuntu</title>
    <url>//Cloud/Docker/Installing-docker-engine-in-Ubuntu/index.html</url>
    <content><![CDATA[<h2 id="What-is-Docker"><a href="#What-is-Docker" class="headerlink" title="What is Docker?"></a>What is Docker?</h2><p>The name <code>Docker</code> is derived from the term used in maritime shipping, referring to <code>dockworkers</code>. It serves as a metaphorical representation.</p>
<p>In traditional shipping, goods are packed into standardized containers, enabling seamless transfer across different modes of transportation, such as trucks, trains, and ships. Similarly, Docker provides a <code>standardized container</code> that packages applications and all their dependencies together, allowing them to run efficiently and reliably across different environments, such as development, testing, and production. Docker is just one of the most commmon technical tools in the area of containerization. What’s more, such as: Podman, CRI-O, Containerd are also useful containerization tools.</p>
<p>Containerization leverages Linux container technologies such as LXC and cgroups to provide a lightweight method for running applications in isolation. Container looks like a box including all dependencies files or applications, developers only need to develop in this environment. After developing, they could delivery programs&#x2F;projects to operation teams by image directly. This method avoid the confliction between development &amp; production environment due to configuration differences or dependency conflicts.</p>
<h2 id="Prerequisites"><a href="#Prerequisites" class="headerlink" title="Prerequisites"></a>Prerequisites</h2><h3 id="Firewall"><a href="#Firewall" class="headerlink" title="Firewall"></a>Firewall</h3><blockquote>
<p>Docker is only compatible with <code>iptables-nft</code> and <code>iptables-legacy</code>. Firewall rules created with <code>nft</code> are not supported on a system with Docker installed. Make sure that any firewall rulesets you use are created with <code>iptables</code> or <code>ip6tables</code>, and that you add them to the <code>DOCKER-USER</code> chain.</p>
</blockquote>
<h3 id="Operating-system"><a href="#Operating-system" class="headerlink" title="Operating system"></a>Operating system</h3><ul>
<li><p>Ubuntu Oracular 24.10</p>
</li>
<li><p>Ubuntu Noble 24.04 (LTS)</p>
</li>
<li><p>Ubuntu Jammy 22.04 (LTS)</p>
</li>
<li><p>Ubuntu Focal 20.04 (LTS)</p>
</li>
</ul>
<blockquote>
<p>Docker Engine for Ubuntu is compatible with x86_64 (or amd64), armhf, arm64, s390x, and ppc64le (ppc64el) architectures.</p>
</blockquote>
<h2 id="Installing-docker-engine"><a href="#Installing-docker-engine" class="headerlink" title="Installing docker-engine"></a>Installing docker-engine</h2><p>I followed the <a href="https://docs.docker.com/engine/install/ubuntu/">Docker official website</a> for the installation.</p>
<h3 id="Uninstalling-the-old-version"><a href="#Uninstalling-the-old-version" class="headerlink" title="Uninstalling the old version"></a>Uninstalling the old version</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> pkg <span class="keyword">in</span> docker.io docker-doc docker-compose docker-compose-v2 podman-docker containerd runc; <span class="keyword">do</span> <span class="built_in">sudo</span> apt-get remove <span class="variable">$pkg</span>; <span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<h3 id="Installing-by-using-apt-repository"><a href="#Installing-by-using-apt-repository" class="headerlink" title="Installing by using apt repository"></a>Installing by using <code>apt</code> repository</h3><p>There are many various methods to install docker-engine, I will use the recommended method to install here.</p>
<h4 id="Setting-up-Docker’s-apt-repository"><a href="#Setting-up-Docker’s-apt-repository" class="headerlink" title="Setting up Docker’s apt repository"></a>Setting up Docker’s apt repository</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Add Docker&#x27;s official GPG key:</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get update</span><br><span class="line"><span class="built_in">sudo</span> apt-get install ca-certificates curl</span><br><span class="line"><span class="built_in">sudo</span> install -m 0755 -d /etc/apt/keyrings</span><br><span class="line"><span class="built_in">sudo</span> curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">chmod</span> a+r /etc/apt/keyrings/docker.asc</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add the repository to Apt sources:</span></span><br><span class="line"><span class="built_in">echo</span> \</span><br><span class="line">  <span class="string">&quot;deb [arch=<span class="subst">$(dpkg --print-architecture)</span> signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \</span></span><br><span class="line"><span class="string">  <span class="subst">$(. /etc/os-release &amp;&amp; echo <span class="string">&quot;<span class="variable">$VERSION_CODENAME</span>&quot;</span>)</span> stable&quot;</span> | \</span><br><span class="line">  <span class="built_in">sudo</span> <span class="built_in">tee</span> /etc/apt/sources.list.d/docker.list &gt; /dev/null</span><br><span class="line"><span class="built_in">sudo</span> apt-get update</span><br></pre></td></tr></table></figure>

<h4 id="Installing-the-latest-version"><a href="#Installing-the-latest-version" class="headerlink" title="Installing the latest version"></a>Installing the latest version</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin</span><br></pre></td></tr></table></figure>

<h3 id="Setting-auto-start-automatically-at-boot-and-take-effect-immediately"><a href="#Setting-auto-start-automatically-at-boot-and-take-effect-immediately" class="headerlink" title="Setting auto-start automatically at boot and take effect immediately"></a>Setting auto-start automatically at boot and take effect immediately</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> systemctl <span class="built_in">enable</span> docker.service</span><br><span class="line"><span class="built_in">sudo</span> systemctl <span class="built_in">enable</span> containerd.service</span><br></pre></td></tr></table></figure>

<h3 id="Confirming-the-installation-result"><a href="#Confirming-the-installation-result" class="headerlink" title="Confirming the installation result"></a>Confirming the installation result</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> docker run hello-world</span><br></pre></td></tr></table></figure>

<p>If you install the docker-engine successfully, there is a sentence to inform and congratulate to you.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:~$ sudo docker run hello-world</span><br><span class="line">Unable to find image &#x27;hello-world:latest&#x27; locally</span><br><span class="line">latest: Pulling from library/hello-world</span><br><span class="line">e6590344b1a5: Pull complete</span><br><span class="line">Digest: sha256:d715f14f9eca81473d9112df50457893aa4d099adeb4729f679006bf5ea12407</span><br><span class="line">Status: Downloaded newer image for hello-world:latest</span><br><span class="line"></span><br><span class="line">Hello from Docker!</span><br><span class="line">This message shows that your installation appears to be working correctly.</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<p>And then, you could find the image called <code>hello-world</code> in the image list.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:~$ sudo docker images</span><br><span class="line">REPOSITORY                                                                                               TAG       IMAGE ID       CREATED         SIZE</span><br><span class="line">hello-world                                                                                              latest    74cc54e27dc4   32 hours ago    10.1kB</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<h3 id="Granting-regular-users-access-to-the-docker-engine"><a href="#Granting-regular-users-access-to-the-docker-engine" class="headerlink" title="Granting regular users access to the docker-engine"></a>Granting regular users access to the docker-engine</h3><p>You must receive errors when trying to run without root. The reason is that the docker user group exists but contains no users, which is why you’re required to use sudo to run Docker commands.</p>
<p>The Docker daemon binds to a Unix socket, not a TCP port. By default it’s the root user that owns the Unix socket, and other users can only access it using sudo. The Docker daemon always runs as the root user.</p>
<h4 id="Creating-the-docker-group-and-add-your-user"><a href="#Creating-the-docker-group-and-add-your-user" class="headerlink" title="Creating the docker group and add your user"></a>Creating the docker group and add your user</h4><p>Sometimes, you could skip this step because the docker group has already been created.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> groupadd docker</span><br></pre></td></tr></table></figure>

<h4 id="Adding-your-user-to-the-docker-group"><a href="#Adding-your-user-to-the-docker-group" class="headerlink" title="Adding your user to the docker group"></a>Adding your user to the docker group</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> usermod -aG docker <span class="variable">$USER</span></span><br></pre></td></tr></table></figure>

<h4 id="Restarting"><a href="#Restarting" class="headerlink" title="Restarting"></a>Restarting</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">reboot</span><br></pre></td></tr></table></figure>

<h3 id="Confirming-without-root-privilege"><a href="#Confirming-without-root-privilege" class="headerlink" title="Confirming without root privilege"></a>Confirming without root privilege</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:~$ docker images</span><br><span class="line">REPOSITORY                                                                                               TAG       IMAGE ID       CREATED         SIZE</span><br><span class="line">hello-world                                                                                              latest    74cc54e27dc4   32 hours ago    10.1kB</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<p>Congratulations to you! Up to now, you installed docker-engine successfully!</p>
]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>2025/01/23 English accumulation</title>
    <url>//Language/English/20250123/index.html</url>
    <content><![CDATA[<ul>
<li><p><strong>utilize</strong>: It means to make practical or effective use of something. It often conveys a slightly more formal tone compared to “use.” Utilize is typically reserved for professional, academic, or technical contexts, whereas “use” is more versatile and widely applicable in casual settings.</p>
</li>
<li><p><strong>okra</strong>: Okra is a green, pod-shaped vegetable that is commonly used in cooking, particularly in dishes from South Asia, Africa, and the Caribbean. It is sometimes referred to as “ladies’ fingers” because of its slender shape.</p>
</li>
<li><p><strong>cephalopods</strong>: It is a type of marine animal belonging to the mollusc family, characterized by bilateral body symmetry, a prominent head, and a set of tentacles or arms. Common examples of cephalopods include octopuses, squids, cuttlefish, and nautiluses. Cephalopods are fascinating and highly adaptable creatures of the sea, admired for their complex behaviors and unique physiology.</p>
</li>
<li><p><strong>prerequisites</strong>: Prerequisites refer to the essential requirements or conditions that must be met before something else can happen or be achieved. prerequisites is a formal word than “requirement”.</p>
</li>
<li><p><strong>anchor</strong>: A heavy object, usually made of metal, attached to a ship or boat by a cable or chain and dropped into the water to keep the vessel in place.</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Language</category>
      </categories>
      <tags>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title>Ceph Series (Chapter 0): Deploying the ceph cluster by cephadm</title>
    <url>//Cloud/Ceph/Deploying-the-ceph-cluster-by-cephadm/index.html</url>
    <content><![CDATA[<h2 id="What-is-Ceph"><a href="#What-is-Ceph" class="headerlink" title="What is Ceph?"></a>What is Ceph?</h2><p>At first, the phonetic transcription of ‘Ceph’ is &#x2F;sɛf&#x2F;. The name ‘Ceph’ comes from ‘cephalopod,’ which refers to marine animals such as octopuses and squids. </p>
<p>Similarly, Ceph, as an open-source distributed storage system, has garnered widespread attention and application due to its high scalability, reliability, and performance. </p>
<p>Ceph supports multiple storage interfaces such as <strong><code>object storage</code></strong>, <strong><code>block storage</code></strong>, and <strong><code>file system storage</code></strong>, meeting the storage needs in various business scenarios.</p>
<p>This article will provide a detailed guide on how to deploy a Ceph distributed storage cluster from scratch using containerization on the Rocky 9.5 operating system. Through this guide, you will be able to master the installation, configuration, and management of Ceph.</p>
<p>Replacing ceph-ansible, through containerization, <code>cephadm</code> provides a standardized approach to operate Ceph clusters, effectively reducing operational complexity.</p>
<hr>
<h2 id="Deployment-Plan-Table"><a href="#Deployment-Plan-Table" class="headerlink" title="Deployment Plan Table"></a>Deployment Plan Table</h2><p>Most readers are encountering Ceph for the first time. To make it clearer and more intuitive, I have created the following deployment plan table to help you deploy the ceph cluster in VMware virtual environment.</p>
<table>
<thead>
<tr>
<th align="center">Number</th>
<th align="center">Operating System</th>
<th align="center">Ceph Version</th>
<th align="center">Role</th>
<th align="center">IP</th>
<th align="center">Configuration</th>
<th align="center">Hostname</th>
</tr>
</thead>
<tbody><tr>
<td align="center">001</td>
<td align="center">Rocky9.5(x86_64)</td>
<td align="center">squid (latest 19.2.0)</td>
<td align="center">bootstrap，mon，mgr，osd</td>
<td align="center">172.16.173.129</td>
<td align="center">core(s):4, memeory:4G, disk: 500G*4</td>
<td align="center">ceph001.haoyang.cn</td>
</tr>
<tr>
<td align="center">002</td>
<td align="center">Rocky9.5(x86_64)</td>
<td align="center">squid (latest 19.2.0)</td>
<td align="center">mon，mgr，osd</td>
<td align="center">172.16.173.130</td>
<td align="center">core(s):4, memeory:4G, disk: 500G*4</td>
<td align="center">ceph002.haoyang.cn</td>
</tr>
<tr>
<td align="center">003</td>
<td align="center">Rocky9.5(x86_64)</td>
<td align="center">squid (latest 19.2.0)</td>
<td align="center">mon，mgr，osd</td>
<td align="center">172.16.173.131</td>
<td align="center">core(s):4, memeory:4G, disk: 500G*4</td>
<td align="center">ceph003.haoyang.cn</td>
</tr>
</tbody></table>
<ul>
<li><p>Because you will deploy the ceph cluster in VMware, you need to download the x86_64 structure iso image from <strong><a href="https://download.rockylinux.org/pub/rocky/9/isos/x86_64/Rocky-9.5-x86_64-minimal.iso">Rocky Linux Official Website</a></strong> to install the Rocky9.5 operating system as the base. I used the minimal version to install rocky, so you could not copy&#x2F;paste from your desktop to rocky. You’d better use <strong>ssh command</strong> to login in Rocky Linux remotely.</p>
</li>
<li><p>More information about the Ceph Release Version, please visit the <strong><a href ="https://docs.ceph.com/en/latest/releases/">Official Website</a></strong>.</p>
</li>
<li><p>More detailed information about the Role, for example: “What’s the meaning of mon&#x2F;mgr&#x2F;osd?” or “What do these words stand for?” .etc, please visit my another blog: <strong><a href="https://blog.sunhaoyang.net/Cloud/Ceph/Introducing-Red-Hat-Ceph-Storage-Architecture/index.html">Ceph Series (Chapter 1):Introducing Red Hat Ceph Storage Architecture</a></strong>. </p>
</li>
<li><p>From the aspect of IP address, I just set the network adaptor to NAT mode and I used the default subnet IP as well as the default generated IP address here. It doesn’t matter if you’d like to modify the subnet IP as what you want, and you may get another random IP address finally. As long as these three virtual machines can communicate with each other, that’s enough.</p>
</li>
<li><p>According to the performance of your hardware, I recommend you to set 4C&#x2F;4G&#x2F;500G*4 here. Don’t worry about disk space issues because of the <strong><code>Thin Provisioning Mechanism</code></strong>. When creating virtual disks, only the space for the actual data used is allocated. The total capacity declared by the virtual disk is just a logical value, and the actual storage space is dynamically allocated as the data grows.</p>
</li>
<li><p>As for the hostname, it’s fine as long as it’s simple and easy to understand. You can name it however you like. I used my Chinese name to represent the hostname here.</p>
</li>
</ul>
<hr>
<h2 id="Prerequisites"><a href="#Prerequisites" class="headerlink" title="Prerequisites"></a>Prerequisites</h2><p><span style="color: red;">Please note that, unless specified，otherwise, the following prerequisites must be completed on all nodes.</span></p>
<h3 id="Setting-the-specified-hostname"><a href="#Setting-the-specified-hostname" class="headerlink" title="Setting the specified hostname"></a>Setting the specified hostname</h3><p>Set an appropriate hostname on each node for resolution.</p>
<p>Take the first node, 001, as an example here.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hostnamectl hostname ceph001.haoyang.cn</span><br></pre></td></tr></table></figure>

<h3 id="Setting-the-resolution-between-the-cluster"><a href="#Setting-the-resolution-between-the-cluster" class="headerlink" title="Setting the resolution between the cluster"></a>Setting the resolution between the cluster</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /etc/hosts &lt;&lt;-<span class="string">&#x27;EOF&#x27;</span></span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">172.16.173.129 ceph001.haoyang.cn ceph001</span><br><span class="line">172.16.173.130 ceph002.haoyang.cn ceph002</span><br><span class="line">172.16.173.131 ceph003.haoyang.cn ceph003</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="Configuring-the-dnf-software-repository"><a href="#Configuring-the-dnf-software-repository" class="headerlink" title="Configuring the dnf software repository"></a>Configuring the dnf software repository</h3><p>I provided two configurations here.</p>
<blockquote>
<p>The repository provided by Ceph’s official site.</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /etc/yum.repos.d/ceph.repo &lt;&lt;-<span class="string">&#x27;EOF&#x27;</span></span><br><span class="line">[ceph]</span><br><span class="line">name=Ceph packages <span class="keyword">for</span> x86_64</span><br><span class="line">baseurl=https://download.ceph.com/rpm-squid/el9/x86_64</span><br><span class="line">enabled=1</span><br><span class="line">priority=2</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://download.ceph.com/keys/release.asc</span><br><span class="line"></span><br><span class="line">[ceph-noarch]</span><br><span class="line">name=Ceph noarch packages</span><br><span class="line">baseurl=https://download.ceph.com/rpm-squid/el9/noarch</span><br><span class="line">enabled=1</span><br><span class="line">priority=2</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://download.ceph.com/keys/release.asc</span><br><span class="line"></span><br><span class="line">[ceph-source]</span><br><span class="line">name=Ceph <span class="built_in">source</span> packages</span><br><span class="line">baseurl=https://download.ceph.com/rpm-squid/el9/SRPMS</span><br><span class="line">enabled=0</span><br><span class="line">priority=2</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://download.ceph.com/keys/release.asc</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Using Nanjing University for repository acceleration.</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /etc/yum.repos.d/ceph.repo &lt;&lt;-<span class="string">&#x27;EOF&#x27;</span></span><br><span class="line">[ceph]</span><br><span class="line">name=Ceph packages <span class="keyword">for</span> x86_64</span><br><span class="line">baseurl=https://mirrors.nju.edu.cn/ceph/rpm-squid/el9/x86_64</span><br><span class="line">enabled=1</span><br><span class="line">priority=2</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://mirrors.nju.edu.cn/ceph/keys/release.asc</span><br><span class="line"></span><br><span class="line">[ceph-noarch]</span><br><span class="line">name=Ceph noarch packages</span><br><span class="line">baseurl=https://mirrors.nju.edu.cn/ceph/rpm-squid/el9/noarch</span><br><span class="line">enabled=1</span><br><span class="line">priority=2</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://mirrors.nju.edu.cn/ceph/keys/release.asc</span><br><span class="line"></span><br><span class="line">[ceph-source]</span><br><span class="line">name=Ceph <span class="built_in">source</span> packages</span><br><span class="line">baseurl=https://mirrors.nju.edu.cn/ceph/rpm-squid/el9/SRPMS</span><br><span class="line">enabled=0</span><br><span class="line">priority=2</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://mirrors.nju.edu.cn/ceph/keys/release.asc</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="Updating-and-generating-the-cache-for-the-dnf-package-manager"><a href="#Updating-and-generating-the-cache-for-the-dnf-package-manager" class="headerlink" title="Updating and generating the cache for the dnf package manager"></a>Updating and generating the cache for the dnf package manager</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">dnf makecache</span><br></pre></td></tr></table></figure>

<h3 id="Installing-the-necessary-software-packages"><a href="#Installing-the-necessary-software-packages" class="headerlink" title="Installing the necessary software packages"></a>Installing the necessary software packages</h3><ul>
<li>Python 3</li>
<li>Systemd</li>
<li>Podman</li>
<li>Chrony</li>
<li>LVM2</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">dnf install podman chrony lvm2 systemd python3 bash-completion wget curl epel-release -y</span><br></pre></td></tr></table></figure>

<p>It may update critical components like systemd, so please <strong><code>restart</code></strong> the server after the installation.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">reboot</span><br></pre></td></tr></table></figure>

<h3 id="Enabling-NTP-synchronization"><a href="#Enabling-NTP-synchronization" class="headerlink" title="Enabling NTP synchronization"></a>Enabling NTP synchronization</h3><p>By default, it syncs from public network sources, but you can specify your own time source. Here, I use <em><strong>ntp.aliyun.com</strong></em>.</p>
<p>Edit the configuration file and add the following line <code>pool ntp.aliyun.com iburst</code> at the very beginning.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vi /etc/chrony.conf</span><br><span class="line"><span class="comment"># Use public servers from the pool.ntp.org project.</span></span><br><span class="line"><span class="comment"># Please consider joining the pool (https://www.pool.ntp.org/join.html).</span></span><br><span class="line">pool ntp.aliyun.com iburst</span><br><span class="line">pool 2.rocky.pool.ntp.org iburst</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<p>After editing the <code>/etc/chrony.conf</code> file, please set the <code>chronyd.service</code> to start automatically at boot and take effect immediately.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl <span class="built_in">enable</span> chronyd --now</span><br><span class="line">systemctl restart chronyd</span><br></pre></td></tr></table></figure>

<h3 id="Installing-cephadm"><a href="#Installing-cephadm" class="headerlink" title="Installing cephadm"></a>Installing cephadm</h3><p>Installing the cephadm tool is sufficient, but I also install the <code>ceph-common</code> package to execute various Ceph commands like ceph and rados directly on the host. Since Ceph is deployed in a containerized manner with cephadm, these commands are not available on the host by default. By installing <code>ceph-common</code>, you can avoid logging into the container each time, making it more efficient.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">dnf install cephadm ceph-common -y</span><br></pre></td></tr></table></figure>

<p>Up to this point, all prerequisites have been completed.</p>
<hr>
<h2 id="Deploying-a-new-ceph-cluster"><a href="#Deploying-a-new-ceph-cluster" class="headerlink" title="Deploying a new ceph cluster"></a>Deploying a new ceph cluster</h2><p>Cephadm bootstrap is the first step in initializing a Ceph cluster. It creates a small initial Ceph cluster by bootstrapping, which includes a monitor (mon) and a manager (mgr). This is the foundational step for the entire Ceph cluster deployment and management process.</p>
<p>The <code>cephadm bootstrap</code> command will perform the following actions:</p>
<ul>
<li><p>Create a monitor (mon) and a manager (mgr) <code>daemon</code> on the local host for the new cluster.</p>
</li>
<li><p>Generate a new SSH key for the Ceph cluster and add it to the root user’s <code>/root/.ssh/authorized_keys</code> file.</p>
</li>
<li><p>Write a copy of the public key to the <code>/etc/ceph/ceph.pub</code> file.</p>
</li>
<li><p>Write a minimal configuration file to <code>/etc/ceph/ceph.conf</code>, which is used for communication with the Ceph daemons.</p>
</li>
<li><p>Write a copy of the client.admin administrator (privileged) key to the <code>/etc/ceph/ceph.client.admin.keyring</code> file.</p>
</li>
<li><p>Add the _admin label to the bootstrap host. By default, any host with this label will also receive copies of the <code>/etc/ceph/ceph.conf</code> and <code>/etc/ceph/ceph.client.admin.keyring</code> files.</p>
</li>
</ul>
<p>If the hostname is <strong><u>Fully Qualified Domain Name</u></strong>(<code>FQDN</code>), you need to add the specific parameter: <code>--allow-fqdn-hostname</code>.</p>
<p>P.S. FQDN format could be like that, for example: <code>host.example.com.</code></p>
<p>host name: <code>host</code></p>
<p>domain name: <code>example.com</code></p>
<p>root domain: <code>.</code> (Omitted in daily use)</p>
<p>If you are doing a <strong><u>single-node</u></strong> deployment, you need to add the specific parameter: <code>--single-host-defaults</code>. </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cephadm bootstrap --mon-ip 172.16.173.129 --single-host-defaults --initial-dashboard-user admin --initial-dashboard-password Sunhaoyang --dashboard-password-noupdate --allow-fqdn-hostname</span><br></pre></td></tr></table></figure>

<p>This deployment uses a <strong><u>multi-node</u></strong> setup.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cephadm bootstrap --mon-ip 172.16.173.129 --initial-dashboard-user admin --initial-dashboard-password Sunhaoyang --dashboard-password-noupdate --allow-fqdn-hostname</span><br></pre></td></tr></table></figure>

<p>More than these parameters, all usage of all parameters could be checked by using <code>cephadm bootstrap --help</code>.</p>
<ul>
<li><p><code>--mon-ip</code> specifies the IP address of the monitor (mon) that will be created during the bootstrap process. This is the IP address of the host where the initial MON daemon will run.</p>
</li>
<li><p><code>--initial-dashboard-user</code> sets the username for the Ceph dashboard’s initial administrative user. In this case, the username will be admin.</p>
</li>
<li><p><code>--initial-dashboard-password</code> specifies the password for the initial administrative user of the Ceph dashboard. The password will be set to Sunhaoyang.</p>
</li>
<li><p><code>--dashboard-password-noupdate</code> prevents the Ceph cluster from automatically updating the dashboard password after the bootstrap process. This ensures the password specified in <code>--initial-dashboard-password</code> remains unchanged.</p>
</li>
<li><p><code>--allow-fqdn-hostname</code> allows the use of a Fully Qualified Domain Name (FQDN) as the hostname for the Ceph cluster’s initial node. This is useful when the hostname includes domain information, such as ceph.example.com.</p>
</li>
</ul>
<p>Finally, the installation console output looks like this.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Ceph Dashboard is now available at:</span><br><span class="line"></span><br><span class="line">             URL: https://ceph001.haoyang.cn:8443/</span><br><span class="line">            User: admin</span><br><span class="line">        Password: Sunhaoyang</span><br><span class="line">...</span><br><span class="line">Bootstrap complete.</span><br></pre></td></tr></table></figure>

<p>You could not use the promption <code>URL</code> to visit the front-end ceph website, because you did not set the resolution in your local <code>/etc/hosts</code> file. While, you could use IP address + port to visit it directly, such as: <a href="https://172.16.173.129:8443/">https://172.16.173.129:8443/</a>.</p>
<p>When you are opening the website, you may be reminded that the website is unsafe. Now, you need to agree with it by clicking <code>advanced</code> button and then clicking <code>continue</code> button.</p>
<p><img src="/../images/dashboard_yellow.png" alt="ceph_dashboard_yellow"></p>
<p>As shown in the image, the page has already prompted us to expand the cluster, and there is a yellow warning next to the dashboard icon in the top left corner. Next, let’s add some disks to the cluster.</p>
<h2 id="Deploying-OSD-resources"><a href="#Deploying-OSD-resources" class="headerlink" title="Deploying OSD resources"></a>Deploying OSD resources</h2><p>In Ceph, OSD (Object Storage Daemon) is one of the essential components of the storage cluster. Its main responsibilities include storing data, handling data replication, recovery, backfilling, and rebalancing operations.</p>
<p>Key Concepts of Ceph OSD:</p>
<ul>
<li><p>Data Storage:</p>
<p>OSDs are responsible for storing data objects. Each OSD usually corresponds to a physical storage device, such as a hard drive or SSD.</p>
</li>
<li><p>Data Replication:</p>
<p>To ensure high availability and durability, OSDs replicate data among themselves. Ceph uses the CRUSH algorithm to determine the placement of data.</p>
</li>
<li><p>Data Recovery:</p>
<p>When an OSD fails or goes offline, the cluster automatically recovers data from other OSDs and replicates it to new OSDs.</p>
</li>
<li><p>Backfilling and Rebalancing:</p>
<p>Backfilling refers to redistributing data after an OSD is restored or new OSDs are added to ensure data is evenly distributed.</p>
<p>Rebalancing ensures load balancing across OSDs to prevent overloading certain OSDs.</p>
</li>
<li><p>Monitoring and Management:</p>
<p>OSDs use a heartbeat mechanism to report their status to the Ceph cluster, ensuring cluster health and consistency.</p>
</li>
</ul>
<p>Having understood Ceph OSDs, let’s proceed to add some OSDs to the cluster to complete the expansion of the Ceph cluster.</p>
<p>Based on the <a href="#Deployment-Plan-Table">Deployment Plan Table</a>, you have already added four disks in total for each node. </p>
<p>Excluding the partation used for installing the operating system, there are three remaining disks: <code>nvme0n2</code>, <code>nvme0n3</code> and <code>nvme0n4</code>.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph001 ~]# lsblk</span><br><span class="line">NAME        MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS</span><br><span class="line">sr0          11:0    1  1024M  0 rom</span><br><span class="line">nvme0n1     259:0    0   500G  0 disk</span><br><span class="line">├─nvme0n1p1 259:1    0   600M  0 part /boot/efi</span><br><span class="line">├─nvme0n1p2 259:2    0     1G  0 part /boot</span><br><span class="line">└─nvme0n1p3 259:3    0 498.4G  0 part</span><br><span class="line">  ├─rl-root 253:0    0 494.5G  0 lvm  /var/lib/containers/storage/overlay</span><br><span class="line">  │                                   /</span><br><span class="line">  └─rl-swap 253:1    0   3.9G  0 lvm  [SWAP]</span><br><span class="line">nvme0n2     259:4    0   500G  0 disk</span><br><span class="line">nvme0n3     259:5    0   500G  0 disk</span><br><span class="line">nvme0n4     259:6    0   500G  0 disk</span><br></pre></td></tr></table></figure>

<p>Then, you could use these three remaining disks and add OSD daemon into the cluster.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph001 ~]# ceph orch daemon add osd ceph001.haoyang.cn:/dev/nvme0n2</span><br><span class="line">Created osd(s) 0 on host &#x27;ceph001.haoyang.cn&#x27;</span><br><span class="line">[root@ceph001 ~]# ceph orch daemon add osd ceph001.haoyang.cn:/dev/nvme0n3</span><br><span class="line">Created osd(s) 1 on host &#x27;ceph001.haoyang.cn&#x27;</span><br><span class="line">[root@ceph001 ~]# ceph orch daemon add osd ceph001.haoyang.cn:/dev/nvme0n4</span><br><span class="line">Created osd(s) 2 on host &#x27;ceph001.haoyang.cn&#x27;</span><br></pre></td></tr></table></figure>

<p>Let’s check the list of OSD now.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph001 ~]# ceph osd crush tree</span><br><span class="line">ID  CLASS  WEIGHT   TYPE NAME</span><br><span class="line">-1         1.46489  root default</span><br><span class="line">-3         1.46489      host ceph001</span><br><span class="line"> 0    ssd  0.48830          osd.0</span><br><span class="line"> 1    ssd  0.48830          osd.1</span><br><span class="line"> 2    ssd  0.48830          osd.2</span><br></pre></td></tr></table></figure>

<p>If we manually add all the disks on each node one by one, it would be too tedious. Fortunately, we can use the parameter <code>--all-available-devices</code> to automatically detect and utilize all available storage devices in the system as OSDs. This simplifies the process of adding OSDs, eliminating the need to specify each device manually.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph001 ~]# ceph orch apply osd --all-available-devices</span><br><span class="line">Scheduled osd.all-available-devices update...</span><br></pre></td></tr></table></figure>

<h2 id="Add-new-hosts-to-the-cluster"><a href="#Add-new-hosts-to-the-cluster" class="headerlink" title="Add new hosts to the cluster"></a>Add new hosts to the cluster</h2><p><span style="color: red;">The New host must meet all the <a href="#Prerequisites">Prerequisites</a> of this article before it can be added to the cluster.</span></p>
<p>Distribute the cluster’s SSH key to the authorized_keys file of the root user on all hosts to enable passwordless operations.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph001 ~]# ssh-copy-id -f -i /etc/ceph/ceph.pub root@ceph001.haoyang.cn</span><br><span class="line">Are you sure you want to continue connecting (yes/no/[fingerprint])? yes</span><br><span class="line"></span><br><span class="line">[root@ceph001 ~]# ssh-copy-id -f -i /etc/ceph/ceph.pub root@ceph002.haoyang.cn</span><br><span class="line">Are you sure you want to continue connecting (yes/no/[fingerprint])? yes</span><br><span class="line"></span><br><span class="line">[root@ceph001 ~]# ssh-copy-id -f -i /etc/ceph/ceph.pub root@ceph003.haoyang.cn</span><br><span class="line">Are you sure you want to continue connecting (yes/no/[fingerprint])? yes</span><br></pre></td></tr></table></figure>

<p>Lets’ check the current status of cluster’s host list.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph001 ~]# ceph orch host ls --detail</span><br><span class="line">HOST                ADDR         LABELS  STATUS  VENDOR/MODEL               CPU    RAM    HDD  SSD      NIC</span><br><span class="line">ceph001.haoyang.cn  172.16.173.129  _admin          VMware, Inc. (VMware20,1)  4C/4T  4 GiB  -    4/2.1TB  1</span><br><span class="line">1 hosts in cluster</span><br></pre></td></tr></table></figure>

<p>When adding a host to a Ceph cluster, it is typically necessary to specify both the hostname and the IP address. This is because:</p>
<ul>
<li><p>Hostname: Ceph uses hostnames to identify nodes in the cluster. These hostnames must be unique and resolvable throughout the cluster (usually configured via &#x2F;etc&#x2F;hosts or DNS).</p>
</li>
<li><p>IP Address: The IP address is crucial for communication between Ceph nodes. Specifying the IP address ensures that Ceph knows how to communicate with the host, especially in environments with multiple network interfaces or complex network configurations.</p>
</li>
</ul>
<p>After adding a host, <strong>the new host will automatically trigger the download of container images and the startup of containers</strong>, which might take some time to be ready. Additionally, since we previously configured automatic OSD addition, the disks on the new host will be automatically added to the cluster.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph001 ~]# ceph orch host add ceph002.haoyang.cn 172.16.173.130</span><br><span class="line">Added host &#x27;ceph002.haoyang.cn&#x27; with addr &#x27;172.16.173.130&#x27;</span><br><span class="line"></span><br><span class="line">[root@ceph001 ~]# ceph orch host add ceph003.haoyang.cn 172.16.173.131</span><br><span class="line">Added host &#x27;ceph003.haoyang.cn&#x27; with addr &#x27;172.16.173.131&#x27;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@ceph001 ~]# ceph orch host ls --detail</span><br><span class="line">HOST                ADDR            LABELS  STATUS  VENDOR/MODEL                      CPU  RAM    HDD  SSD      NIC  </span><br><span class="line">ceph001.haoyang.cn  172.16.173.129  _admin          VMware, Inc. VMware (VMware20,1)  N/A  4 GiB  -    4/2.1TB  1    </span><br><span class="line">ceph002.haoyang.cn  172.16.173.130  _admin          VMware, Inc. VMware (VMware20,1)  N/A  4 GiB  -    4/2.1TB  1    </span><br><span class="line">ceph003.haoyang.cn  172.16.173.131                  VMware, Inc. VMware (VMware20,1)  N/A  4 GiB  -    4/2.1TB  1    </span><br><span class="line">3 hosts in cluster</span><br></pre></td></tr></table></figure>

<p>The container image download and container startup in the new host will take some time. You can use the command to check if all services are running normally.</p>
<p>If everything is normal, all services will be in the “running” state.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph001 ~]# ceph orch ps</span><br><span class="line">NAME                   HOST                PORTS             STATUS             REFRESHED  AGE  MEM USE  MEM LIM  VERSION  IMAGE ID      CONTAINER ID  </span><br><span class="line">alertmanager.ceph001   ceph001.haoyang.cn  *:9093,9094       running (-11706s)     9m ago  22h    19.4M        -  0.25.0   4d8d4d8334be  d7d85f0d5f90  </span><br><span class="line">ceph-exporter.ceph001  ceph001.haoyang.cn                    running (-11706s)     9m ago  22h    18.7M        -  19.2.0   fd3234b9d664  41365c9457ee  </span><br><span class="line">ceph-exporter.ceph002  ceph002.haoyang.cn                    running (-11708s)     7m ago  22h    5553k        -  19.2.0   fd3234b9d664  37efd9d7f4e1  </span><br><span class="line">ceph-exporter.ceph003  ceph003.haoyang.cn                    running (-11709s)     7m ago  22h    5666k        -  19.2.0   fd3234b9d664  5270951d5acd  </span><br><span class="line">crash.ceph001          ceph001.haoyang.cn                    running (-11706s)     9m ago  22h    6685k        -  19.2.0   fd3234b9d664  56d8da9604fa  </span><br><span class="line">crash.ceph002          ceph002.haoyang.cn                    running (-11707s)     7m ago  22h    6681k        -  19.2.0   fd3234b9d664  5fc552cacd65  </span><br><span class="line">crash.ceph003          ceph003.haoyang.cn                    running (-11709s)     7m ago  22h    6689k        -  19.2.0   fd3234b9d664  ffd2d7310ac6  </span><br><span class="line">grafana.ceph001        ceph001.haoyang.cn  *:3000            running (-11706s)     9m ago  22h    76.1M        -  9.4.12   f3e6303dba5e  fdf44407fb4c  </span><br><span class="line">mgr.ceph001.hkkqlh     ceph001.haoyang.cn  *:9283,8765,8443  running (-11706s)     9m ago  22h     551M        -  19.2.0   fd3234b9d664  7ba2eecea18b  </span><br><span class="line">mgr.ceph002.mldtvp     ceph002.haoyang.cn  *:8443,9283,8765  running (-11707s)     7m ago  22h     452M        -  19.2.0   fd3234b9d664  bdfd928dabf9  </span><br><span class="line">mon.ceph001            ceph001.haoyang.cn                    running (-11706s)     9m ago  22h     134M    2048M  19.2.0   fd3234b9d664  2bcdeda36a41  </span><br><span class="line">mon.ceph002            ceph002.haoyang.cn                    running (-11708s)     7m ago  22h     130M    2048M  19.2.0   fd3234b9d664  91486fa9f36b  </span><br><span class="line">mon.ceph003            ceph003.haoyang.cn                    running (-11709s)     7m ago  22h     129M    2048M  19.2.0   fd3234b9d664  345686a5334d  </span><br><span class="line">node-exporter.ceph001  ceph001.haoyang.cn  *:9100            running (-11706s)     9m ago  22h    14.7M        -  1.5.0    68cb0c05b3f2  9cbaabb099cc  </span><br><span class="line">node-exporter.ceph002  ceph002.haoyang.cn  *:9100            running (-11708s)     7m ago  22h    15.0M        -  1.5.0    68cb0c05b3f2  1b8fdb1f51c0  </span><br><span class="line">node-exporter.ceph003  ceph003.haoyang.cn  *:9100            running (-11709s)     7m ago  22h    12.6M        -  1.5.0    68cb0c05b3f2  0796493a5f8e  </span><br><span class="line">osd.0                  ceph001.haoyang.cn                    running (-11709s)     9m ago  22h    40.4M    4096M  19.2.0   fd3234b9d664  490045e69852  </span><br><span class="line">osd.1                  ceph001.haoyang.cn                    running (-11709s)     9m ago  22h    43.8M    4096M  19.2.0   fd3234b9d664  d0ce9e899dd7  </span><br><span class="line">osd.2                  ceph001.haoyang.cn                    running (-11709s)     9m ago  22h    54.2M    4096M  19.2.0   fd3234b9d664  c3678e3dc74e  </span><br><span class="line">osd.3                  ceph002.haoyang.cn                    running (4h)          7m ago   4h    50.6M    4096M  19.2.0   fd3234b9d664  8787bc6caa84  </span><br><span class="line">osd.4                  ceph003.haoyang.cn                    running (4h)          7m ago   4h    51.9M    4096M  19.2.0   fd3234b9d664  be6e18374b5a  </span><br><span class="line">osd.5                  ceph002.haoyang.cn                    running (4h)          7m ago   4h    49.2M    4096M  19.2.0   fd3234b9d664  1877027bdbab  </span><br><span class="line">osd.6                  ceph003.haoyang.cn                    running (4h)          7m ago   4h    47.6M    4096M  19.2.0   fd3234b9d664  8236520080e4  </span><br><span class="line">osd.7                  ceph003.haoyang.cn                    running (4h)          7m ago   4h    52.9M    4096M  19.2.0   fd3234b9d664  93ee38964a01  </span><br><span class="line">osd.8                  ceph002.haoyang.cn                    running (4h)          7m ago   4h    50.1M    4096M  19.2.0   fd3234b9d664  a737972f17c7  </span><br><span class="line">prometheus.ceph001     ceph001.haoyang.cn  *:9095            running (-11706s)     9m ago  22h    85.6M        -  2.43.0   77ee200e57dc  ce155b30e24f  </span><br></pre></td></tr></table></figure>

<h2 id="Assigning-new-management-privileges"><a href="#Assigning-new-management-privileges" class="headerlink" title="Assigning new management privileges"></a>Assigning new management privileges</h2><p>For convenience in management, we will add <code>ceph002.haoyang.cn</code> as a management host.</p>
<p>Before assigning management privileges, let’s take a look at the configuration files and keys of the <code>ceph002.haoyang.cn</code> host.</p>
<p>Based on the information, there are no keys or configuration files present.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph002 ~]# ls /etc/ceph</span><br><span class="line">rbdmap</span><br></pre></td></tr></table></figure>

<p>Similarly, without the appropriate permissions, it is not possible to retrieve cluster information.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph002 ~]# ceph -s</span><br><span class="line">Error initializing cluster client: ObjectNotFound(&#x27;RADOS object not found (error calling conf_read_file)&#x27;)</span><br></pre></td></tr></table></figure>

<p>Let’s assign the <code>_admin</code> label to ceph002.haoyang.cn.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph001 ~]# ceph orch host label add ceph002.haoyang.cn _admin</span><br><span class="line">Added label _admin to host ceph002.haoyang.cn</span><br></pre></td></tr></table></figure>

<p>Checking the current status of the cluster’s host list again.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph001 ~]# ceph orch host ls --detail</span><br><span class="line">HOST                ADDR            LABELS  STATUS  VENDOR/MODEL                      CPU  RAM    HDD  SSD      NIC  </span><br><span class="line">ceph001.haoyang.cn  172.16.173.129  _admin          VMware, Inc. VMware (VMware20,1)  N/A  4 GiB  -    4/2.1TB  1    </span><br><span class="line">ceph002.haoyang.cn  172.16.173.130  _admin          VMware, Inc. VMware (VMware20,1)  N/A  4 GiB  -    4/2.1TB  1    </span><br><span class="line">ceph003.haoyang.cn  172.16.173.131                  VMware, Inc. VMware (VMware20,1)  N/A  4 GiB  -    4/2.1TB  1    </span><br><span class="line">3 hosts in cluster</span><br></pre></td></tr></table></figure>

<p>Checking the keys or configuration files again in ceph002.haoyang.cn.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph002 ~]# ls /etc/ceph</span><br><span class="line">ceph.client.admin.keyring  ceph.conf  rbdmap</span><br></pre></td></tr></table></figure>

<p>We can now confirm that <code>ceph002.haoyang.cn</code> has management privileges.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph002 ~]# ls /etc/ceph</span><br><span class="line">ceph.client.admin.keyring  ceph.conf  rbdmap</span><br></pre></td></tr></table></figure>

<p> If the following command executes successfully, it indicates that it has successfully obtained the cluster information and the permissions are working correctly.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph002 ~]# ceph -s</span><br><span class="line">  cluster:</span><br><span class="line">    id:     365472d8-d815-11ef-90ff-000c29c84d93</span><br><span class="line">    health: HEALTH_OK</span><br><span class="line"> </span><br><span class="line">  services:</span><br><span class="line">    mon: 3 daemons, quorum ceph001,ceph002,ceph003 (age 4h)</span><br><span class="line">    mgr: ceph001.hkkqlh(active, since 4h), standbys: ceph002.mldtvp</span><br><span class="line">    osd: 9 osds: 9 up (since 4h), 9 in (since 4h)</span><br><span class="line"> </span><br><span class="line">  data:</span><br><span class="line">    pools:   1 pools, 1 pgs</span><br><span class="line">    objects: 2 objects, 449 KiB</span><br><span class="line">    usage:   244 MiB used, 4.4 TiB / 4.4 TiB avail</span><br><span class="line">    pgs:     1 active+clean</span><br></pre></td></tr></table></figure>

<h2 id="Check-the-status-of-the-Ceph-cluster"><a href="#Check-the-status-of-the-Ceph-cluster" class="headerlink" title="Check the status of the Ceph cluster"></a>Check the status of the Ceph cluster</h2><p>Since we have added a new host and new OSDs to the cluster, the yellow status on the dashboard should have turned green.</p>
<p><img src="/../images/dashboard_green.png" alt="ceph_dashboard_green"></p>
<p>Finally, let’s use the command to check the cluster status!</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph001 ~]# ceph -s</span><br><span class="line">  cluster:</span><br><span class="line">    id:     365472d8-d815-11ef-90ff-000c29c84d93</span><br><span class="line">    health: HEALTH_OK</span><br><span class="line"> </span><br><span class="line">  services:</span><br><span class="line">    mon: 3 daemons, quorum ceph001,ceph002,ceph003 (age 5h)</span><br><span class="line">    mgr: ceph001.hkkqlh(active, since 5h), standbys: ceph002.mldtvp</span><br><span class="line">    osd: 9 osds: 9 up (since 5h), 9 in (since 5h)</span><br><span class="line"> </span><br><span class="line">  data:</span><br><span class="line">    pools:   1 pools, 1 pgs</span><br><span class="line">    objects: 2 objects, 449 KiB</span><br><span class="line">    usage:   244 MiB used, 4.4 TiB / 4.4 TiB avail</span><br><span class="line">    pgs:     1 active+clean</span><br></pre></td></tr></table></figure>

<p>With this, our ceph cluster deployment has been successfully completed!</p>
]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>Ceph</tag>
      </tags>
  </entry>
  <entry>
    <title>Complete Guide to Markdown shortcuts for typora</title>
    <url>//Tools/Markdown/Complete-Guide-to-Markdown-shortcuts-for-typora/index.html</url>
    <content><![CDATA[<h2 id="文字样式部分"><a href="#文字样式部分" class="headerlink" title="文字样式部分"></a>文字样式部分</h2><h3 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + 数字键`</span>快速创建各种等级的标题。(P.s.标题最小分化到6级标题。)</span><br><span class="line">使用<span class="code">`ctrl + 0`</span>可以快速将选中标题调成普通文本。</span><br><span class="line">使用<span class="code">`ctrl + 加号/减号`</span>对标题的级别进行升高和降低。</span><br></pre></td></tr></table></figure>

<h3 id="下划线"><a href="#下划线" class="headerlink" title="下划线"></a>下划线</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + u`</span>添加下划线。</span><br></pre></td></tr></table></figure>

<p>P.s.下划线(<font color=red><b>U</b></font>nderline)，因此 <u><strong>+u</strong></u>。</p>
<h3 id="删除线"><a href="#删除线" class="headerlink" title="删除线"></a>删除线</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`alt + shift + 5`</span>添加删除线。</span><br></pre></td></tr></table></figure>

<h3 id="字体加粗"><a href="#字体加粗" class="headerlink" title="字体加粗"></a>字体加粗</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + b`</span>加粗文字。</span><br></pre></td></tr></table></figure>

<p>P.s.粗体的(<font color=red><b>B</b></font>old)，因此 **<u>+b</u>**。</p>
<h3 id="字体倾斜"><a href="#字体倾斜" class="headerlink" title="字体倾斜"></a>字体倾斜</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + i`</span>倾斜文字。</span><br></pre></td></tr></table></figure>

<p>P.s.斜体的(<font color=red><b>I</b></font>talic)，因此 **<u>+i</u>**。</p>
<hr>
<h2 id="内容部分"><a href="#内容部分" class="headerlink" title="内容部分"></a>内容部分</h2><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + shift + q`</span>创建引用。</span><br></pre></td></tr></table></figure>

<p>P.s.引用(<font color=red><b>Q</b></font>uote)，因此 **<u>+q</u>**。</p>
<h3 id="插入链接"><a href="#插入链接" class="headerlink" title="插入链接"></a>插入链接</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + k`</span>插入链接。</span><br></pre></td></tr></table></figure>

<p>P.s.超链接(Hyper<font color=red><b>link</b></font>)，因此 **<u>+k</u>**。</p>
<h3 id="插入图片"><a href="#插入图片" class="headerlink" title="插入图片"></a>插入图片</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + shift + i`</span>插入图片。</span><br></pre></td></tr></table></figure>

<p>P.s.超链接(<font color=red><b>I</b></font>mage)，因此 **<u>+i</u>**。</p>
<h3 id="文档内部跳转"><a href="#文档内部跳转" class="headerlink" title="文档内部跳转"></a>文档内部跳转</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + home`</span>跳转至文档开头,使用<span class="code">`ctrl + end`</span> 跳转至文档末尾。</span><br></pre></td></tr></table></figure>

<p>P.s.home：起始 end：终止</p>
<h3 id="选择英文单词-中文"><a href="#选择英文单词-中文" class="headerlink" title="选择英文单词&#x2F;中文"></a>选择英文单词&#x2F;中文</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + d`</span>选中文本；使用<span class="code">`ctrl + shift + left/right`</span> 左右移动进行文本选中。</span><br></pre></td></tr></table></figure>

<p>P.s.向下填充(<font color=red><b>D</b></font>own)，因此 **<u>+d</u>**。</p>
<h3 id="按行选中文本"><a href="#按行选中文本" class="headerlink" title="按行选中文本"></a>按行选中文本</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + l`</span>选中光标所在行文本。</span><br></pre></td></tr></table></figure>

<p>P.s.排成一行(<font color=red><b>L</b></font>ine)，因此 **<u>+l</u>**。</p>
<h3 id="快速搜索文本内容"><a href="#快速搜索文本内容" class="headerlink" title="快速搜索文本内容"></a>快速搜索文本内容</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + f`</span>对全文本进行关键词搜索。</span><br></pre></td></tr></table></figure>

<p>P.s.找寻(<font color=red><b>F</b></font>ind)，因此 **<u>+f</u>**。</p>
<h3 id="快速替换文本"><a href="#快速替换文本" class="headerlink" title="快速替换文本"></a>快速替换文本</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + h`</span>对全文本进行指定词替换。</span><br></pre></td></tr></table></figure>

<p>P.s.替换(<font color=red><b>R</b></font>eplace)，但R键位被占用，转而使用 **<u>+h</u>**。</p>
<h3 id="快速生成表格"><a href="#快速生成表格" class="headerlink" title="快速生成表格"></a>快速生成表格</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + t`</span>创建自定义表格。</span><br></pre></td></tr></table></figure>

<p>P.s.表格(<font color=red><b>T</b></font>able)，因此 **<u>+t</u>**。</p>
<h3 id="快速打开最近浏览笔记"><a href="#快速打开最近浏览笔记" class="headerlink" title="快速打开最近浏览笔记"></a>快速打开最近浏览笔记</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + p`</span>打开最近浏览笔记。</span><br></pre></td></tr></table></figure>

<p>P.s.呈现(<font color=red><b>P</b></font>resent)，因此 **<u>+p</u>**。</p>
<h3 id="快速生成目录"><a href="#快速生成目录" class="headerlink" title="快速生成目录"></a>快速生成目录</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用 <span class="code">`[toc] + enter`</span>快速生成目录。</span><br></pre></td></tr></table></figure>

<p>P.s.目录表(<font color=red><b>T</b></font>able <font color=red><b>O</b></font>f <font color=red><b>C</b></font>ontents )，因此 **<u>[toc]</u>**。</p>
<h3 id="着重关键字"><a href="#着重关键字" class="headerlink" title="着重关键字"></a>着重关键字</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + shift + 反引号键(tab键上面那个键)`</span></span><br></pre></td></tr></table></figure>

<h3 id="快速创建代码块-自定义语言类型"><a href="#快速创建代码块-自定义语言类型" class="headerlink" title="快速创建代码块(自定义语言类型)"></a>快速创建代码块(自定义语言类型)</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + shift + k`</span>快速创建代码块，可自定义输入语言类型。</span><br></pre></td></tr></table></figure>

<div STYLE="page-break-after: always;"></div>

<h3 id="数学表达式-支持Latex语法"><a href="#数学表达式-支持Latex语法" class="headerlink" title="数学表达式(支持Latex语法)"></a>数学表达式(支持Latex语法)</h3><ul>
<li><p>行内公式</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用两个<span class="code">`$`</span>一前一后将公式内容包裹起来。</span><br></pre></td></tr></table></figure>

<p>例如不定积分公式：$\int f(x)dx &#x3D; F(x) + c (c\in {\forall} constants)$</p>
</li>
<li><p>行外公式</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + shift + m`</span>创建数学公式块</span><br></pre></td></tr></table></figure>

<p>P.s.数学(<font color=red><b>M</b></font>athematics)，因此 **<u>+m</u>**。</p>
<p>例如单调收敛定理：</p>
<p>$$<br>\forall x \in E , 0 \leq f_n(x) \leq f_{n+1}(x),n\in {N_+}.且\lim\limits_{n\to\infty}f_n(x)&#x3D;f(x).<br>那么，\lim\limits_{n\to\infty}\int_Ef(x)dx&#x3D;\int_Ef(x)dx.<br>$$</p>
<hr>
</li>
</ul>
<h2 id="工具自身部分"><a href="#工具自身部分" class="headerlink" title="工具自身部分"></a>工具自身部分</h2><h3 id="新建文件"><a href="#新建文件" class="headerlink" title="新建文件"></a>新建文件</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + n`</span>创建新的.md文件。</span><br></pre></td></tr></table></figure>

<p>P.s.新建(<font color=red><b>N</b></font>ew)，因此 **<u>+n</u>**。</p>
<h3 id="打开已有-md文件"><a href="#打开已有-md文件" class="headerlink" title="打开已有.md文件"></a>打开已有.md文件</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + o`</span>选择打开已有.md文件。</span><br></pre></td></tr></table></figure>

<p>P.s.打开(<font color=red><b>O</b></font>pen)，因此 **<u>+o</u>**。</p>
<h3 id="保存-md文件"><a href="#保存-md文件" class="headerlink" title="保存.md文件"></a>保存.md文件</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + s`</span>保存已编辑好的.md文件。</span><br></pre></td></tr></table></figure>

<p>P.s.保存(<font color=red><b>S</b></font>ave)，因此 **<u>+s</u>**。</p>
<h3 id="关闭-md文件"><a href="#关闭-md文件" class="headerlink" title="关闭.md文件"></a>关闭.md文件</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + w`</span>关闭已保存.md文件。</span><br></pre></td></tr></table></figure>

<p>P.s.窗口(<font color=red><b>W</b></font>indow)，因此 **<u>+w</u>**。</p>
<h3 id="显示和隐藏侧边栏"><a href="#显示和隐藏侧边栏" class="headerlink" title="显示和隐藏侧边栏"></a>显示和隐藏侧边栏</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + shift + l`</span>来显示/隐藏侧边栏。</span><br></pre></td></tr></table></figure>

<h3 id="偏好设置"><a href="#偏好设置" class="headerlink" title="偏好设置"></a>偏好设置</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + comma`</span>打开偏好设置栏。</span><br></pre></td></tr></table></figure>

<h3 id="源代码模式"><a href="#源代码模式" class="headerlink" title="源代码模式"></a>源代码模式</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + /`</span>进入源代码模式。</span><br></pre></td></tr></table></figure>

<h3 id="全屏切换"><a href="#全屏切换" class="headerlink" title="全屏切换"></a>全屏切换</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`F11`</span>进入/退出全屏模式。</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>Complete Guide to Markdown Features</title>
    <url>//Tools/Markdown/Complete-Guide-to-Markdown-Features/index.html</url>
    <content><![CDATA[<h2 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h2><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">语法：# 标题名字（井号的个数代表标题的级数，最多到六级标题）</span><br></pre></td></tr></table></figure>

<h1 id="一级标题"><a href="#一级标题" class="headerlink" title="一级标题"></a>一级标题</h1><h2 id="二级标题"><a href="#二级标题" class="headerlink" title="二级标题"></a>二级标题</h2><h3 id="三级标题"><a href="#三级标题" class="headerlink" title="三级标题"></a>三级标题</h3><h4 id="四级标题"><a href="#四级标题" class="headerlink" title="四级标题"></a>四级标题</h4><h5 id="五级标题"><a href="#五级标题" class="headerlink" title="五级标题"></a>五级标题</h5><h6 id="六级标题"><a href="#六级标题" class="headerlink" title="六级标题"></a>六级标题</h6><hr>
<div STYLE="page-break-after: always;"></div>

<h2 id="文字样式"><a href="#文字样式" class="headerlink" title="文字样式"></a>文字样式</h2><h3 id="删除线"><a href="#删除线" class="headerlink" title="删除线"></a>删除线</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">语法：用两个 ~ 来包裹删除的内容</span><br><span class="line">~~文本内容被删除~~</span><br></pre></td></tr></table></figure>

<p><del>文本内容被删除</del></p>
<h3 id="斜体"><a href="#斜体" class="headerlink" title="斜体"></a>斜体</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">语法：用一个 \* 来包裹斜体的内容</span><br><span class="line"></span><br><span class="line"><span class="emphasis">_文本内容倾斜_</span></span><br></pre></td></tr></table></figure>

<p><em>文本内容倾斜</em></p>
<p>快捷键：选中需要斜体的内容后 <code>Ctrl</code>+<code>I</code></p>
<h3 id="加粗"><a href="#加粗" class="headerlink" title="加粗"></a>加粗</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">语法：用两个 \* 来包裹加粗的内容</span><br><span class="line"></span><br><span class="line"><span class="strong">**文本内容加粗**</span></span><br></pre></td></tr></table></figure>

<p><strong>文本内容加粗</strong></p>
<p>快捷键：选中需要加粗的内容后 <code>Ctrl</code>+<code>B</code></p>
<h3 id="斜体-加粗"><a href="#斜体-加粗" class="headerlink" title="斜体+加粗"></a>斜体+加粗</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">语法：用三个 \* 来包裹斜体+加粗的内容</span><br><span class="line"></span><br><span class="line"><span class="strong">**<span class="emphasis">_文本内容既倾斜又加粗_</span>**</span></span><br></pre></td></tr></table></figure>

<p><strong><em>文本内容既倾斜又加粗</em></strong></p>
<h3 id="下划线"><a href="#下划线" class="headerlink" title="下划线"></a>下划线</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">下划线是HTML语法：用 <span class="language-xml"><span class="tag">&lt;<span class="name">u</span>&gt;</span></span>&lt;\u&gt; 来包裹添加下划线内容</span><br><span class="line"></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">u</span>&gt;</span></span>文本内容添加下划线<span class="language-xml"><span class="tag">&lt;/<span class="name">u</span>&gt;</span></span></span><br></pre></td></tr></table></figure>

<p><u>文本内容添加下划线</u></p>
<p>快捷键：选中需要添加下划线的内容后 <code>Ctrl</code>+<code>U</code></p>
<h3 id="高亮（需在偏好设置勾选扩展语法）"><a href="#高亮（需在偏好设置勾选扩展语法）" class="headerlink" title="高亮（需在偏好设置勾选扩展语法）"></a>高亮（需在偏好设置勾选扩展语法）</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">语法：用 == 来包裹高亮内容</span><br><span class="line"></span><br><span class="line">==文本内容高亮==</span><br></pre></td></tr></table></figure>

<p>&#x3D;&#x3D;文本内容高亮&#x3D;&#x3D;</p>
<h3 id="下标（需在偏好设置勾选扩展语法）"><a href="#下标（需在偏好设置勾选扩展语法）" class="headerlink" title="下标（需在偏好设置勾选扩展语法）"></a>下标（需在偏好设置勾选扩展语法）</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">语法：用 ~ 来包裹下标内容</span><br><span class="line"></span><br><span class="line">水 H~2~O</span><br><span class="line">双氧水 H~2~O~2~</span><br></pre></td></tr></table></figure>

<p>水 H<del>2</del>O</p>
<p>双氧水 H<del>2</del>O<del>2</del></p>
<h3 id="上标（需在偏好设置内选扩展语法）"><a href="#上标（需在偏好设置内选扩展语法）" class="headerlink" title="上标（需在偏好设置内选扩展语法）"></a>上标（需在偏好设置内选扩展语法）</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">语法：用 ^ 来包裹上标内容</span><br><span class="line"></span><br><span class="line">平方米 m^2^</span><br><span class="line">立方米 m^3^</span><br></pre></td></tr></table></figure>

<p>平方米 m^2^<br>立方米 m^3^</p>
<hr>
<h2 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h2><p>表格的源码格式：</p>
<p>使用 <code>|</code> 来分隔不同的单元格，使用 <code>-</code> 来分隔表头和其他行：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">| name     | gender |</span><br><span class="line">| -------- | ------ |</span><br><span class="line">| Torvalds | Male   |</span><br><span class="line">| Tove     | Female |</span><br></pre></td></tr></table></figure>

<blockquote>
<p>为了使 Markdown 更清晰，<code>|</code> 和 <code>-</code> 两侧需要至少有一个空格（最左侧和最右侧的 <code>|</code> 外就不需要了）。</p>
</blockquote>
<p>可以跳过以上描述，因为表格的 markdown 源代码是由typora自动生成的。</p>
<p>实际上输入 <code>| Name | Gender |</code> 并按下 <code>enter</code> 键将创建一个包含两列的表。</p>
<p>创建表后，焦点在该表上将弹出一个表格工具栏，您可以在左上角调整表格，居中居左居右对齐或删除表格。您还可以右上角使用上下文菜单来移动，复制和添加&#x2F;删除列&#x2F;行。还可以在表格中包括内联 Markdown 语法，例如链接，粗体，斜体或删除线。</p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Gender</th>
</tr>
</thead>
<tbody><tr>
<td>Torvalds</td>
<td>Male</td>
</tr>
<tr>
<td>Tove</td>
<td>Female</td>
</tr>
</tbody></table>
<p>除此之外可以使用空格对齐不同行的单元格，并在左右两侧都使用 <code>|</code> 来标记单元格边界，在表头下方的分隔线标记中加入 <code>:</code>，即可标记下方单元格内容的对齐方式：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">| Name     | Gender | Age |</span><br><span class="line">| :------- | :----: | --: |</span><br><span class="line">| Torvalds |  Male  |  55 |</span><br><span class="line">| Tove     | Female |  58 |</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th align="left">Name</th>
<th align="center">Gender</th>
<th align="center">Age</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Torvalds</td>
<td align="center">Male</td>
<td align="center">55</td>
</tr>
<tr>
<td align="left">Tove</td>
<td align="center">Female</td>
<td align="center">58</td>
</tr>
</tbody></table>
<p>使用快捷键<code>Ctrl</code>+<code>T</code>更方便(段落→表格→插入表格，即可查看快捷键)可以自定义表格大小。</p>
<h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">语法：&gt;引用文本内容</span><br></pre></td></tr></table></figure>

<blockquote>
<p>引用文本内容</p>
</blockquote>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="quote">&gt; 可以在引用中</span></span><br><span class="line"><span class="quote">&gt;</span></span><br><span class="line"><span class="quote">&gt; &gt; 使用嵌套的引用</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>可以在引用中</p>
<blockquote>
<p>使用嵌套的引用</p>
</blockquote>
</blockquote>
<hr>
<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><p>语法：[TOC] + <code>enter</code></p>
<p>生成的目录内容会随笔者编辑而自动更新。</p>
<hr>
<div STYLE="page-break-after: always;"></div>

<h2 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h2><h3 id="无序列表–符号-空格"><a href="#无序列表–符号-空格" class="headerlink" title="无序列表–符号 空格"></a>无序列表–符号 空格</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> 可以使用 <span class="code">`*`</span> 作为标记</span><br><span class="line"></span><br><span class="line"><span class="bullet">*</span> 也可以使用 <span class="code">`+`</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> 或者 <span class="code">`-`</span></span><br></pre></td></tr></table></figure>

<ul>
<li><p>可以使用 <code>*</code> 作为标记（不推荐使用星号）</p>
</li>
<li><p>也可以使用 <code>+</code></p>
</li>
<li><p>或者 <code>-</code></p>
</li>
</ul>
<h3 id="有序列表–数字-空格"><a href="#有序列表–数字-空格" class="headerlink" title="有序列表–数字 . 空格"></a>有序列表–数字 <code>.</code> 空格</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> 有序列表以数字和 <span class="code">`.`</span> 开始；</span><br><span class="line"><span class="bullet">2.</span> 数字的序列并不会影响生成的列表序列；</span><br><span class="line"><span class="bullet">3.</span> 但仍然推荐按照自然顺序（1.2.3...）编写。</span><br></pre></td></tr></table></figure>

<ol>
<li><p>有序列表以数字和 <code>.</code> 开始；</p>
</li>
<li><p>数字的序列并不会影响生成的列表序列；</p>
</li>
<li><p>但仍然推荐按照自然顺序（1.2.3…）编写。</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">可以使用：数字\. 来取消显示为列表（用反斜杠进行转义）</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><h3 id="代码块"><a href="#代码块" class="headerlink" title="代码块"></a>代码块</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="code">```语言名称</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code">```</span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<h3 id="行内代码"><a href="#行内代码" class="headerlink" title="行内代码"></a>行内代码</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">也可以通过 <span class="code">``，插入行内代码（`</span> 是 <span class="code">`Tab`</span> 键上边、<span class="code">`ESC`</span>下面的、数字 <span class="code">`1`</span> 键左侧的那个按键）：</span><br><span class="line"></span><br><span class="line">例如 <span class="code">`Markdown`</span></span><br></pre></td></tr></table></figure>

<p><code>Markdown</code></p>
<hr>
<h2 id="分隔线"><a href="#分隔线" class="headerlink" title="分隔线"></a>分隔线</h2><p>可以在一行中使用三个或更多的 <code>*</code>、<code>-</code> 或 <code>_</code> 来添加分隔线（&#96;&#96;）：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="section">---</span></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">---</span><br></pre></td></tr></table></figure>

<hr>
<hr>
<hr>
<h2 id="任务列表"><a href="#任务列表" class="headerlink" title="任务列表"></a>任务列表</h2><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">语法：</span><br><span class="line">未完成事项:- [ ]</span><br><span class="line">已完成事项:- [x]</span><br><span class="line">可以通过鼠标左键勾选或取消方框内的√。</span><br></pre></td></tr></table></figure>

<ul>
<li><input checked="" disabled="" type="checkbox"> 任务1</li>
<li><input disabled="" type="checkbox"> 任务2</li>
<li><input checked="" disabled="" type="checkbox"> 任务3</li>
</ul>
<hr>
<h2 id="跳转"><a href="#跳转" class="headerlink" title="跳转"></a>跳转</h2><h3 id="外部跳转–超链接"><a href="#外部跳转–超链接" class="headerlink" title="外部跳转–超链接"></a>外部跳转–超链接</h3><p>语法： <code>[注释/命名](具体链接)</code></p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">[<span class="string">帮助文档</span>](<span class="link">https://support.typoraio.cn/Markdown-Reference/</span>)</span><br></pre></td></tr></table></figure>

<p><a href="https://support.typoraio.cn/Markdown-Reference/">帮助文档</a></p>
<h3 id="内部跳转–本文件内跳"><a href="#内部跳转–本文件内跳" class="headerlink" title="内部跳转–本文件内跳"></a>内部跳转–本文件内跳</h3><p>语法： <code>[注释/命名](#要去的目的地--标题）</code>。</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">[<span class="string">跳转到文字</span>](<span class="link">#文字样式</span>)</span><br></pre></td></tr></table></figure>

<p><a href="#%E6%96%87%E5%AD%97%E6%A0%B7%E5%BC%8F">跳转到文字</a></p>
<h3 id="自动链接"><a href="#自动链接" class="headerlink" title="自动链接"></a>自动链接</h3><p>使用 <code>&lt;&gt;</code> 包括的 URL 或邮箱地址会被自动转换为超链接：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="language-xml">&lt;https://www.baidu.com&gt;</span></span><br></pre></td></tr></table></figure>

<p><a href="https://www.baidu.com/">https://www.baidu.com</a></p>
<hr>
<h3 id="本地图片"><a href="#本地图片" class="headerlink" title="本地图片"></a>本地图片</h3><p>图像与链接类似， 但在链接语法之前需要添加额外的 <code>!</code> 字符。 图像语法如下所示：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">![<span class="string">图片命名</span>](<span class="link">图片本地存储的路径</span>) P.s.用相对路径或绝对路径都可以</span><br><span class="line">或者直接拷贝到Typora内。</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="数学表达式-支持Latex语法"><a href="#数学表达式-支持Latex语法" class="headerlink" title="数学表达式(支持Latex语法)"></a>数学表达式(支持Latex语法)</h2><h3 id="内联公式"><a href="#内联公式" class="headerlink" title="内联公式"></a>内联公式</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用两个<span class="code">`$`</span>一前一后将公式内容包裹起来。</span><br></pre></td></tr></table></figure>

<p>例如不定积分公式：$\int f(x)dx &#x3D; F(x) + c (c\in {\forall} constants)$</p>
<h3 id="行外公式"><a href="#行外公式" class="headerlink" title="行外公式"></a>行外公式</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + shift + m`</span>创建数学公式块</span><br></pre></td></tr></table></figure>

<p>P.s.数学(<font color=red><b>M</b></font>athematics)，因此 **<u>+m</u>**。</p>
<p>例如单调收敛定理：</p>
<p>$$<br>\forall x \in E , 0 \leq f_n(x) \leq f_{n+1}(x),n\in {N_+}.且\lim\limits_{n\to\infty}f_n(x)&#x3D;f(x).<br>那么，\lim\limits_{n\to\infty}\int_Ef(x)dx&#x3D;\int_Ef(x)dx.<br>$$</p>
<hr>
<div STYLE="page-break-after: always;"></div>

<h2 id="利用Markdown画图"><a href="#利用Markdown画图" class="headerlink" title="利用Markdown画图"></a>利用Markdown画图</h2><p>MarkDown画图也是轻量级的，功能并不全。</p>
<p>但是MarkDown支持sequence，flowchart和mermaid三种图表类型。</p>
<p>sequence使用的是js-sequence-diagrams。</p>
<p>flowchart使用的是flowchart.js。</p>
<p>Mermaid 是一个用于画流程图、状态图、时序图、甘特图的库，使用 JS 进行本地渲染，广泛集成于许多 Markdown 编辑器中。Mermaid 作为一个使用 JS 渲染的库，生成的不是一个“图片”，而是一段 HTML 代码。</p>
<p>（不同的编辑器渲染的可能不一样）</p>
<table>
<thead>
<tr>
<th>图表类型</th>
<th>支持来源</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>Sequence</td>
<td>js-sequence-diagrams</td>
<td>UML 时序图</td>
</tr>
<tr>
<td>Flowchart</td>
<td>flowchart.js</td>
<td>流程图</td>
</tr>
<tr>
<td>Mermaid</td>
<td>mermaid</td>
<td>集成的强大的图表库，支持时序图、流程图、甘特图、类图、饼图等</td>
</tr>
</tbody></table>
<p>接下来我将一一介绍上述三种类型的图表。</p>
<h3 id="Sequence-Diagrams"><a href="#Sequence-Diagrams" class="headerlink" title="Sequence Diagrams"></a>Sequence Diagrams</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">Title: MarkDown时序图实例</span><br><span class="line">participant 客户端</span><br><span class="line">participant 控制器</span><br><span class="line">participant 业务</span><br><span class="line">participant 数据库</span><br><span class="line"></span><br><span class="line"><span class="code">     客户端-&gt;&gt;数据库:提交数据店铺</span></span><br><span class="line"><span class="code">     Note right of 客户端:提交数据进行验证</span></span><br><span class="line"><span class="code">     控制器-&gt;&gt;控制器:验证数据完整性</span></span><br><span class="line"><span class="code">     Note left of 控制器:返回错误的字段信息</span></span><br><span class="line"><span class="code">     控制器--&gt;&gt;客户端:数据不完整</span></span><br><span class="line"><span class="code">     Note over 客户端: 用户输入通行证的账号、密码</span></span><br><span class="line"><span class="code">     控制器-&gt;&gt;业务:保存店铺到数据库</span></span><br><span class="line"><span class="code">     业务-&gt;&gt;业务:save店铺数据</span></span><br><span class="line"><span class="code">     业务--&gt;&gt;控制器:保存出现异常</span></span><br><span class="line"><span class="code">     控制器--&gt;&gt;客户端:保存成功</span></span><br><span class="line"><span class="code">     数据库--&gt;&gt;业务:success</span></span><br><span class="line"><span class="code">     业务--&gt;&gt;控制器:success</span></span><br><span class="line"><span class="code">     控制器--&gt;&gt;客户端:success 客户端</span></span><br><span class="line"><span class="code">     Note left of 控制器:返回正确的提示，并跳转到审核第二步</span></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Title: MarkDown时序图实例</span><br><span class="line"></span><br><span class="line">    participant 客户端</span><br><span class="line">    participant 控制器</span><br><span class="line">    participant 业务</span><br><span class="line">    participant 数据库</span><br><span class="line"></span><br><span class="line">     客户端-&gt;&gt;数据库:提交数据店铺</span><br><span class="line">     Note right of 客户端:提交数据进行验证</span><br><span class="line">     控制器-&gt;&gt;控制器:验证数据完整性</span><br><span class="line">     Note left of 控制器:返回错误的字段信息</span><br><span class="line">     控制器--&gt;&gt;客户端:数据不完整</span><br><span class="line">     Note over 客户端: 用户输入通行证的账号、密码</span><br><span class="line">     控制器-&gt;&gt;业务:保存店铺到数据库</span><br><span class="line">     业务-&gt;&gt;业务:save店铺数据</span><br><span class="line">     业务--&gt;&gt;控制器:保存出现异常</span><br><span class="line">     控制器--&gt;&gt;客户端:保存成功</span><br><span class="line">     数据库--&gt;&gt;业务:success</span><br><span class="line">     业务--&gt;&gt;控制器:success</span><br><span class="line">     控制器--&gt;&gt;客户端:success 客户端</span><br><span class="line">     Note left of 控制器:返回正确的提示，并跳转到审核第二步</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> 代表实线 ， 主动发送消息，比如 request请求</span><br><span class="line">  &gt; 代表实心箭头 ， 同步消息，比如 AJAX 的同步请求</span><br><span class="line">  &gt; -- 代表虚线，表示返回消息，spring Controller return</span><br><span class="line">  &gt;</span><br><span class="line">  &gt; &gt; 代表非实心箭头 ，异步消息，比如AJAX请求</span><br></pre></td></tr></table></figure>

<div STYLE="page-break-after: always;"></div>

<h3 id="Flowcharts"><a href="#Flowcharts" class="headerlink" title="Flowcharts"></a>Flowcharts</h3><ul>
<li><strong>标准竖向流程图</strong></li>
</ul>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">st=&gt;start: 开始框</span><br><span class="line"></span><br><span class="line">op=&gt;operation: 处理框</span><br><span class="line"></span><br><span class="line">cond=&gt;condition: 判断框(是或否?)</span><br><span class="line"></span><br><span class="line">sub1=&gt;subroutine: 子流程</span><br><span class="line"></span><br><span class="line">io=&gt;inputoutput: 输入输出框</span><br><span class="line"></span><br><span class="line">e=&gt;end: 结束框</span><br><span class="line"></span><br><span class="line">st-&gt;op-&gt;cond</span><br><span class="line"></span><br><span class="line">cond(yes)-&gt;io-&gt;e</span><br><span class="line"></span><br><span class="line">cond(no)-&gt;sub1(right)-&gt;op</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">st=&gt;start: 出发</span><br><span class="line"></span><br><span class="line">op=&gt;operation: 下雨</span><br><span class="line"></span><br><span class="line">cond=&gt;condition: 带雨伞</span><br><span class="line"></span><br><span class="line">sub1=&gt;subroutine: 回家取伞</span><br><span class="line"></span><br><span class="line">io=&gt;inputoutput: 继续出行</span><br><span class="line"></span><br><span class="line">e=&gt;end: 到达目的地</span><br><span class="line"></span><br><span class="line">st-&gt;op-&gt;cond</span><br><span class="line"></span><br><span class="line">cond(yes)-&gt;io-&gt;e</span><br><span class="line"></span><br><span class="line">cond(no)-&gt;sub1(right)-&gt;op</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>标准横向流程图</strong></li>
</ul>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">st=&gt;start: 开始框</span><br><span class="line"></span><br><span class="line">op=&gt;operation: 处理框</span><br><span class="line"></span><br><span class="line">cond=&gt;condition: 判断框(是或否?)</span><br><span class="line"></span><br><span class="line">sub1=&gt;subroutine: 子流程</span><br><span class="line"></span><br><span class="line">io=&gt;inputoutput: 输入输出框</span><br><span class="line"></span><br><span class="line">e=&gt;end: 结束框</span><br><span class="line"></span><br><span class="line">st(right)-&gt;op(right)-&gt;cond</span><br><span class="line"></span><br><span class="line">cond(yes)-&gt;io(bottom)-&gt;e</span><br><span class="line"></span><br><span class="line">cond(no)-&gt;sub1(right)-&gt;op</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">st=&gt;start: 出发</span><br><span class="line"></span><br><span class="line">op=&gt;operation: 下雨</span><br><span class="line"></span><br><span class="line">cond=&gt;condition: 带雨伞</span><br><span class="line"></span><br><span class="line">sub1=&gt;subroutine: 回家取伞</span><br><span class="line"></span><br><span class="line">io=&gt;inputoutput: 继续出行</span><br><span class="line"></span><br><span class="line">e=&gt;end: 到达目的地</span><br><span class="line"></span><br><span class="line">st(right)-&gt;op(right)-&gt;cond</span><br><span class="line"></span><br><span class="line">cond(yes)-&gt;io(bottom)-&gt;e</span><br><span class="line"></span><br><span class="line">cond(no)-&gt;sub1(right)-&gt;op</span><br></pre></td></tr></table></figure>

<div STYLE="page-break-after: always;"></div>

<h3 id="Mermaid"><a href="#Mermaid" class="headerlink" title="Mermaid"></a>Mermaid</h3><h4 id="流程图"><a href="#流程图" class="headerlink" title="流程图"></a>流程图</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">graph 方向描述</span><br><span class="line">图表中的其他语句...</span><br></pre></td></tr></table></figure>

<p>关键字graph表示一个流程图的开始，同时需要指定该图的方向。</p>
<p>其中“方向描述”为：</p>
<table>
<thead>
<tr>
<th align="left">用词</th>
<th align="left">含义</th>
</tr>
</thead>
<tbody><tr>
<td align="left">TB</td>
<td align="left">从上到下</td>
</tr>
<tr>
<td align="left">BT</td>
<td align="left">从下到上</td>
</tr>
<tr>
<td align="left">RL</td>
<td align="left">从右到左</td>
</tr>
<tr>
<td align="left">LR</td>
<td align="left">从左到右</td>
</tr>
</tbody></table>
<blockquote>
<p>T &#x3D; TOP，B &#x3D; BOTTOM，L &#x3D; LEFT，R &#x3D; RIGHT，D &#x3D; DOWN</p>
</blockquote>
<p>最常用的布局方向是TB、LR。</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">graph TB;</span><br><span class="line">A--&gt;B</span><br><span class="line">B--&gt;C</span><br><span class="line">C--&gt;A</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph TB;</span><br><span class="line">  A--&gt;B</span><br><span class="line">  B--&gt;C</span><br><span class="line">  C--&gt;A</span><br></pre></td></tr></table></figure>

<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">graph LR;</span><br><span class="line">A--&gt;B</span><br><span class="line">B--&gt;C</span><br><span class="line">C--&gt;A</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph LR;</span><br><span class="line">  A--&gt;B</span><br><span class="line">  B--&gt;C</span><br><span class="line">  C--&gt;A</span><br></pre></td></tr></table></figure>

<h5 id="节点形状"><a href="#节点形状" class="headerlink" title="节点形状"></a>节点形状</h5><table>
<thead>
<tr>
<th align="left">表述</th>
<th align="left">说明</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td align="left">id[文字]</td>
<td align="left">矩形节点</td>
<td>表示过程，也就是整个流程中的一个环节。</td>
</tr>
<tr>
<td align="left">id(文字)</td>
<td align="left">圆角矩形节点</td>
<td>表示开始和结束。</td>
</tr>
<tr>
<td align="left">id((文字))</td>
<td align="left">圆形节点</td>
<td>表示连接。为避免流程过长或有交叉，可将流程切开。</td>
</tr>
<tr>
<td align="left">id{文字}</td>
<td align="left">菱形节点</td>
<td>表示判断、决策。</td>
</tr>
<tr>
<td align="left">id&gt;文字]</td>
<td align="left">右向旗帜状节点</td>
<td></td>
</tr>
</tbody></table>
<p><strong>单向箭头线段</strong>：表示流程进行方向</p>
<blockquote>
<p>id即为节点的唯一标识，A~F 是当前节点名字，类似于变量名，画图时便于引用</p>
<p>括号内是节点中要显示的文字，默认节点的名字和显示的文字都为A</p>
</blockquote>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">graph TB</span><br><span class="line">A</span><br><span class="line">B(圆角矩形节点)</span><br><span class="line">C[矩形节点]</span><br><span class="line">D((圆形节点))</span><br><span class="line">E&#123;菱形节点&#125;</span><br><span class="line">F&gt;右向旗帜状节点]</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph TB</span><br><span class="line">  A</span><br><span class="line">  B(圆角矩形节点)</span><br><span class="line">  C[矩形节点]</span><br><span class="line">  D((圆形节点))</span><br><span class="line">  E&#123;菱形节点&#125;</span><br><span class="line">  F&gt;右向旗帜状节点]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">%% 语法示例</span><br><span class="line">graph TB</span><br><span class="line"><span class="code">    sport(出发运动)--&gt; badminton[羽毛球]</span></span><br><span class="line"><span class="code">    badminton --&gt; IsWin&#123;&quot;有没有赢下单打比赛？&quot;&#125;</span></span><br><span class="line"><span class="code">    IsWin --&gt;|有|happy[赢下比赛]--&gt;goBack(回家)</span></span><br><span class="line"><span class="code">    IsWin --&gt;|没有|sad[再接再厉]--&gt;goBack</span></span><br><span class="line"><span class="code"></span></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph TB</span><br><span class="line">    sport(出发运动)--&gt; badminton[羽毛球]</span><br><span class="line">    badminton --&gt; IsWin&#123;&quot;有没有赢下单打比赛？&quot;&#125;</span><br><span class="line">    IsWin --&gt;|有|happy[赢下比赛]--&gt;goBack(回家)</span><br><span class="line">    IsWin --&gt;|没有|sad[再接再厉]--&gt;goBack</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="连线"><a href="#连线" class="headerlink" title="连线"></a>连线</h5><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">graph TB</span><br><span class="line">A1--&gt;B1</span><br><span class="line">A2---B2</span><br><span class="line">A3--text---B3</span><br><span class="line">A4--text--&gt;B4</span><br><span class="line">A5-.-B5</span><br><span class="line">A6-.-&gt;B6</span><br><span class="line">A7-.text.-B7</span><br><span class="line">A8-.text.-&gt;B8</span><br><span class="line">A9===B9</span><br><span class="line">A10==&gt;B10</span><br><span class="line">A11==text===B11</span><br><span class="line">A12==text==&gt;B12</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph TB</span><br><span class="line">  A1--&gt;B1</span><br><span class="line">  A2---B2</span><br><span class="line">  A3--text---B3</span><br><span class="line">  A4--text--&gt;B4</span><br><span class="line">  A5-.-B5</span><br><span class="line">  A6-.-&gt;B6</span><br><span class="line">  A7-.text.-B7</span><br><span class="line">  A8-.text.-&gt;B8</span><br><span class="line">  A9===B9</span><br><span class="line">  A10==&gt;B10</span><br><span class="line">  A11==text===B11</span><br><span class="line">  A12==text==&gt;B12</span><br></pre></td></tr></table></figure>

<h4 id="UML时序图"><a href="#UML时序图" class="headerlink" title="UML时序图"></a>UML时序图</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">顾客--&gt;API: 预约产品</span><br><span class="line">API--&gt;预约服务: 开始预约流程</span><br><span class="line">break 当预约失败时</span><br><span class="line">API--&gt;顾客: 展示预约失败原因</span><br><span class="line">end</span><br><span class="line">API--&gt;支付账单服务: 开始支付账单流程</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line"> 顾客--&gt;API: 预约产品</span><br><span class="line"> API--&gt;预约服务: 开始预约流程</span><br><span class="line"> break 当预约失败时</span><br><span class="line">  API--&gt;顾客: 展示预约失败原因</span><br><span class="line"> end</span><br><span class="line"> API--&gt;支付账单服务: 开始支付账单流程</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>​</p>
<p>​</p>
<h4 id="甘特图"><a href="#甘特图" class="headerlink" title="甘特图"></a>甘特图</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">%% 语法示例</span><br><span class="line">gantt</span><br><span class="line">dateFormat YYYY-MM-DD</span><br><span class="line">title 软件开发甘特图</span><br><span class="line">section 设计</span><br><span class="line">需求 :done, des1, 2014-01-06,2014-01-08</span><br><span class="line">原型 :active, des2, 2014-01-09, 3d</span><br><span class="line">UI设计 : des3, after des2, 5d</span><br><span class="line">未来任务 : des4, after des3, 5d</span><br><span class="line">section 开发</span><br><span class="line">学习准备理解需求 :crit, done, 2014-01-06,24h</span><br><span class="line">设计框架 :crit, done, after des2, 2d</span><br><span class="line">开发 :crit, active, 3d</span><br><span class="line">未来任务 :crit, 5d</span><br><span class="line">耍 :2d</span><br><span class="line"></span><br><span class="line"><span class="code">        section 测试</span></span><br><span class="line"><span class="code">        功能测试                              :active, a1, after des3, 3d</span></span><br><span class="line"><span class="code">        压力测试                               :after a1  , 20h</span></span><br><span class="line"><span class="code">        测试报告                               : 48h</span></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">gantt</span><br><span class="line">        dateFormat  YYYY-MM-DD</span><br><span class="line">        title 软件开发甘特图</span><br><span class="line">        section 设计</span><br><span class="line">        需求                      :done,    des1, 2014-01-06,2014-01-08</span><br><span class="line">        原型                      :active,  des2, 2014-01-09, 3d</span><br><span class="line">        UI设计                     :         des3, after des2, 5d</span><br><span class="line">        未来任务                     :         des4, after des3, 5d</span><br><span class="line"></span><br><span class="line">        section 开发</span><br><span class="line">        学习准备理解需求                      :crit, done, 2014-01-06,24h</span><br><span class="line">        设计框架                             :crit, done, after des2, 2d</span><br><span class="line">        开发                                 :crit, active, 3d</span><br><span class="line">        未来任务                              :crit, 5d</span><br><span class="line"></span><br><span class="line">        section 测试</span><br><span class="line">        功能测试                              :active, a1, after des3, 3d</span><br><span class="line">        压力测试                               :after a1  , 20h</span><br><span class="line">        测试报告                               : 48h</span><br></pre></td></tr></table></figure>

<div STYLE="page-break-after: always;"></div>

<h4 id="类图"><a href="#类图" class="headerlink" title="类图"></a>类图</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">语法解释：&lt;|-- 表示继承，+ 表示 public，- 表示 private。</span><br></pre></td></tr></table></figure>

<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">classDiagram</span><br><span class="line">动物 &lt;|-- 鸭子</span><br><span class="line">动物 &lt;|-- 鱼</span><br><span class="line">动物 &lt;|-- 斑马</span><br><span class="line">动物 : +int age</span><br><span class="line">动物 : +String gender</span><br><span class="line">动物: +isMammal()</span><br><span class="line">动物: +mate()</span><br><span class="line">class 鸭子&#123;</span><br><span class="line">+String beakColor</span><br><span class="line">+swim()</span><br><span class="line">+quack()</span><br><span class="line">&#125;</span><br><span class="line">class 鱼&#123;</span><br><span class="line">-int sizeInFeet</span><br><span class="line">-canEat()</span><br><span class="line">&#125;</span><br><span class="line">class 斑马&#123;</span><br><span class="line">+bool is<span class="emphasis">_wild</span></span><br><span class="line"><span class="emphasis">+run()</span></span><br><span class="line"><span class="emphasis">&#125;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">classDiagram</span><br><span class="line">      动物 &lt;|-- 鸭子</span><br><span class="line">      动物 &lt;|-- 鱼</span><br><span class="line">      动物 &lt;|-- 斑马</span><br><span class="line">      动物 : +int age</span><br><span class="line">      动物 : +String gender</span><br><span class="line">      动物: +isMammal()</span><br><span class="line">      动物: +mate()</span><br><span class="line">      class 鸭子&#123;</span><br><span class="line">          +String beakColor</span><br><span class="line">          +swim()</span><br><span class="line">          +quack()</span><br><span class="line">      &#125;</span><br><span class="line">      class 鱼&#123;</span><br><span class="line">          -int sizeInFeet</span><br><span class="line">          -canEat()</span><br><span class="line">      &#125;</span><br><span class="line">      class 斑马&#123;</span><br><span class="line">          +bool is_wild</span><br><span class="line">          +run()</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure>

<div STYLE="page-break-after: always;"></div>

<h4 id="状态图"><a href="#状态图" class="headerlink" title="状态图"></a>状态图</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">stateDiagram</span><br><span class="line">[<span class="emphasis">*] --&gt; Still</span></span><br><span class="line"><span class="emphasis">Still --&gt; [*</span>]</span><br><span class="line">Still --&gt; Moving</span><br><span class="line">Moving --&gt; Still</span><br><span class="line">Moving --&gt; Crash</span><br><span class="line">Crash --&gt; [<span class="emphasis">*]</span></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">stateDiagram</span><br><span class="line"> [*] --&gt; 静止</span><br><span class="line"> 静止 --&gt; [*]</span><br><span class="line"></span><br><span class="line"> 静止 --&gt; 运动</span><br><span class="line"> 运动 --&gt; 静止</span><br><span class="line"> 运动 --&gt; 碰撞</span><br><span class="line"> 碰撞 --&gt; [*]</span><br></pre></td></tr></table></figure>

<div STYLE="page-break-after: always;"></div>

<h4 id="饼图"><a href="#饼图" class="headerlink" title="饼图"></a>饼图</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">pie</span><br><span class="line">title Pie Chart</span><br><span class="line">&quot;狗&quot; : 386</span><br><span class="line">&quot;猫&quot; : 85</span><br><span class="line">&quot;老鼠&quot; : 150</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pie</span><br><span class="line"> title Pie Chart</span><br><span class="line"> &quot;狗&quot; : 386</span><br><span class="line"> &quot;猫&quot; : 85</span><br><span class="line"> &quot;老鼠&quot; : 150</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>2025/01/15 English accumulation</title>
    <url>//Language/English/20250115/index.html</url>
    <content><![CDATA[<ul>
<li><p><strong>hands-on activity</strong>: It is an expression that means <strong>practical, active involvement or direct experience with something</strong>, rather than just theoretical or observational.It refers to doing something yourself rather than just studying or observing it.</p>
</li>
<li><p><strong>get to do something</strong>: It is an expression that means “<strong>have the opportunity or permission to do something</strong>“. It often conveys a sense of <strong>privillege or enjoyment</strong> in being able to do it.</p>
</li>
<li><p><strong>the bulk of</strong>: It is an expression that means “<strong>the majority</strong>“ or “<strong>the largest part</strong>“ of something.</p>
</li>
<li><p><strong>be provisioned to</strong>: It is an expression that means “<strong>be set up or prepared</strong> for a specific purpose or function”, typically with the necessary resources, equipment, or configuration required to perform a task or service.</p>
</li>
<li><p><strong>persona</strong>: “Persona” originally comes from <em>Latin</em>, where it referred to a mask worn by actors in ancient Roman theatre, and later came to mean the character an individual presents to the outside world. It is often used in psychology to describe the social or public identity someone assumes. Currently, it is the <strong>identity or role</strong> that someone presents to the outside world, often shaped by social expectations or context.</p>
</li>
<li><p><strong>foremost</strong>: It is used to describe something that is <strong>the most important</strong> or <strong>the leading</strong> in a given situation, whether in terms of importance, position, or rank. It’s a formal word and often used in more serious or academic contexts to <strong>highlight priorities or leadership</strong>.</p>
</li>
<li><p><strong>as distinct from</strong>: It is used to <strong>show the contrast, highlight differences or to make a clear distinction between two things</strong>, indicating that they are different from each other in significant ways. It’s typically used to clarify or emphasize the separation between ideas, objects, or concepts.</p>
</li>
<li><p><strong>correlate</strong>: It means to <strong>establish or indicate a relationship or connection between two things</strong>, where changes in one thing are associated with changes in another. It can be used in contexts involving statistics, research, or any situation where there is a noticeable relationship between two factors.</p>
</li>
<li><p><strong>consultant</strong>: It generally refers to a <strong>professional</strong> who offers expert advice or guidance in a particular field. A consultant’s role is generally focused on <strong>advisory</strong> work rather than direct implementation or execution.</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Language</category>
      </categories>
      <tags>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title>Ceph Series (Chapter 1): Introducing Red Hat Ceph Storage Architecture</title>
    <url>//Cloud/Ceph/Introducing-Red-Hat-Ceph-Storage-Architecture/index.html</url>
    <content><![CDATA[<h2 id="Personas"><a href="#Personas" class="headerlink" title="Personas"></a>Personas</h2><p>The personas that are presented here embody the most common roles of Red Hat Ceph Storage users. You can simply understand the meaning of the word as “user role”.</p>
<p>In Red Hat Ceph Storage, there are three types of personas, namely the Storage Administrator, the Storage Operator and other Storage-related personas.</p>
<h3 id="Storage-Administrator"><a href="#Storage-Administrator" class="headerlink" title="Storage Administrator"></a><strong>Storage Administrator</strong></h3><p>The primary persona for Red Hat Ceph is the storage administrator. A Ceph storage administrator performs the following tasks:</p>
<ul>
<li><blockquote>
<p>Installs, configures, and maintains a Ceph storage cluster.</p>
</blockquote>
</li>
<li><blockquote>
<p>Educates infrastructure architects about Ceph capabilities and features.</p>
</blockquote>
</li>
<li><blockquote>
<p>Informs users about Ceph data presentation and methods, as choices for their data applications.</p>
</blockquote>
</li>
<li><blockquote>
<p>Provides resilience and recovery, such as replication, backup, and disaster recovery methods.</p>
</blockquote>
</li>
<li><blockquote>
<p>Automates and integrates through Infrastructure as Code.</p>
</blockquote>
</li>
<li><blockquote>
<p>Provides access for data analytics and advanced mass data mining.</p>
</blockquote>
</li>
</ul>
<h3 id="Storage-Operator"><a href="#Storage-Operator" class="headerlink" title="Storage Operator"></a><strong>Storage Operator</strong></h3><p>The secondary persona for Red Hat Ceph is the storage operator.Storage operators primarily use <em>the Ceph Dashboard GUI</em> to view and respond to cluster alerts and statistics. They also perform routine storage administration tasks that are defined as Dashboard workflows, such as replacing a failed storage device.</p>
<h3 id="Other-Storage-related-Personas"><a href="#Other-Storage-related-Personas" class="headerlink" title="Other Storage-related Personas"></a><strong>Other Storage-related Personas</strong></h3><p>Other personas that use Ceph directly include <em>application developers, project managers, and service administrators</em> with data processing, data warehouse, big data, and similar application needs. The storage administrator frequently communicates with these personas.</p>
<ul>
<li><p>Cloud Operator</p>
<blockquote>
<p>A cloud operator administers cloud resources at their organization, such as OpenStack or OpenShift infrastructures. The storage administrator works closely with a cloud operator to maintain the Ceph cluster that is configured to provide storage for those platforms.</p>
</blockquote>
</li>
<li><p>Automation Engineer</p>
<blockquote>
<p>Automation engineers frequently use Ceph directly. An automation engineer is responsible for creating playbooks for commonly repeated tasks. Storage administrators would be familiar with these same actions because they are typically the foremost Ceph subject matter experts.</p>
</blockquote>
</li>
<li><p>Application Developer (DevOps Developer)</p>
<blockquote>
<p>An application developer can be an original coder, maintainer, or other cloud user who is responsible for the correct deployment and behavior of an application. A storage administrator coordinates with the application developer to ensure that storage resources are available, sets quotas, and secures the application storage.</p>
</blockquote>
</li>
<li><p>Deployment Engineer (DevOps Engineer)</p>
<blockquote>
<p>In larger environments, dedicated personnel perform, manage, and tune application deployments, working with the storage administrator and the application developer.</p>
</blockquote>
</li>
<li><p>Application Architect</p>
<blockquote>
<p>A storage administrator relies on the application architect as a subject matter expert who can correlate between Ceph infrastructure layout and resource availability, scaling, and latency. This archicture expertise helps the storage administrator to design complex application deployments effectively. To support the cloud users and their applications, a storage administrator must comprehend those same aspects of resource availability, scaling, and latency.</p>
</blockquote>
</li>
<li><p>Infrastructure Architect</p>
<blockquote>
<p>A storage administrator must master the storage cluster’s architectural layout to manage resource location, capacity, and latency. The infrastructure architect for the Ceph cluster deployment and maintenance is a primary source of information for the storage administrator. The infrastructure architect might be a cloud service provider employee or a vendor solutions architect or consultant.</p>
</blockquote>
</li>
<li><p>Data Center Operator</p>
<blockquote>
<p>Personas at the lower Ceph storage infrastructure layer support data provisioning. Data center operators are typically employed by the public cloud service provider or the organization’s internal IT group in a private data center cloud. The storage administrator opens service tickets with the relevant public cloud service provider or internal IT group.</p>
</blockquote>
</li>
</ul>
<hr>
<h2 id="The-Basic-Architecture"><a href="#The-Basic-Architecture" class="headerlink" title="The Basic Architecture"></a>The Basic Architecture</h2><p>Ceph Storage is essentially a distributed data object store, based on <code>RADOS</code>(Reliable Autonomic Distributed Object Storage), which provides highly reliable, scalable, and self-healing distributed object storage.</p>
]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>Ceph</tag>
      </tags>
  </entry>
</search>
