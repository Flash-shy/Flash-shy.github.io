<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>2025/01/15 English accumulation</title>
    <url>//Language/English/20250115/index.html</url>
    <content><![CDATA[<ul>
<li><p><strong>hands-on activity</strong>: It is an expression that means <strong>practical, active involvement or direct experience with something</strong>, rather than just theoretical or observational.It refers to doing something yourself rather than just studying or observing it.</p>
</li>
<li><p><strong>get to do something</strong>: It is an expression that means “<strong>have the opportunity or permission to do something</strong>“. It often conveys a sense of <strong>privillege or enjoyment</strong> in being able to do it.</p>
</li>
<li><p><strong>the bulk of</strong>: It is an expression that means “<strong>the majority</strong>“ or “<strong>the largest part</strong>“ of something.</p>
</li>
<li><p><strong>be provisioned to</strong>: It is an expression that means “<strong>be set up or prepared</strong> for a specific purpose or function”, typically with the necessary resources, equipment, or configuration required to perform a task or service.</p>
</li>
<li><p><strong>persona</strong>: “Persona” originally comes from <em>Latin</em>, where it referred to a mask worn by actors in ancient Roman theatre, and later came to mean the character an individual presents to the outside world. It is often used in psychology to describe the social or public identity someone assumes. Currently, it is the <strong>identity or role</strong> that someone presents to the outside world, often shaped by social expectations or context.</p>
</li>
<li><p><strong>foremost</strong>: It is used to describe something that is <strong>the most important</strong> or <strong>the leading</strong> in a given situation, whether in terms of importance, position, or rank. It’s a formal word and often used in more serious or academic contexts to <strong>highlight priorities or leadership</strong>.</p>
</li>
<li><p><strong>as distinct from</strong>: It is used to <strong>show the contrast, highlight differences or to make a clear distinction between two things</strong>, indicating that they are different from each other in significant ways. It’s typically used to clarify or emphasize the separation between ideas, objects, or concepts.</p>
</li>
<li><p><strong>correlate</strong>: It means to <strong>establish or indicate a relationship or connection between two things</strong>, where changes in one thing are associated with changes in another. It can be used in contexts involving statistics, research, or any situation where there is a noticeable relationship between two factors.</p>
</li>
<li><p><strong>consultant</strong>: It generally refers to a <strong>professional</strong> who offers expert advice or guidance in a particular field. A consultant’s role is generally focused on <strong>advisory</strong> work rather than direct implementation or execution.</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Language</category>
      </categories>
      <tags>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title>2025/01/23 English accumulation</title>
    <url>//Language/English/20250123/index.html</url>
    <content><![CDATA[<ul>
<li><p><strong>utilize</strong>: It means to make practical or effective use of something. It often conveys a slightly more formal tone compared to “use.” Utilize is typically reserved for professional, academic, or technical contexts, whereas “use” is more versatile and widely applicable in casual settings.</p>
</li>
<li><p><strong>okra</strong>: Okra is a green, pod-shaped vegetable that is commonly used in cooking, particularly in dishes from South Asia, Africa, and the Caribbean. It is sometimes referred to as “ladies’ fingers” because of its slender shape.</p>
</li>
<li><p><strong>cephalopods</strong>: It is a type of marine animal belonging to the mollusc family, characterized by bilateral body symmetry, a prominent head, and a set of tentacles or arms. Common examples of cephalopods include octopuses, squids, cuttlefish, and nautiluses. Cephalopods are fascinating and highly adaptable creatures of the sea, admired for their complex behaviors and unique physiology.</p>
</li>
<li><p><strong>prerequisites</strong>: Prerequisites refer to the essential requirements or conditions that must be met before something else can happen or be achieved. prerequisites is a formal word than “requirement”.</p>
</li>
<li><p><strong>anchor</strong>: A heavy object, usually made of metal, attached to a ship or boat by a cable or chain and dropped into the water to keep the vessel in place.</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Language</category>
      </categories>
      <tags>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title>2025/01/24 English accumulation</title>
    <url>//Language/English/20250124/index.html</url>
    <content><![CDATA[<ul>
<li><p><strong>and so forth</strong>: It is used to mean <code>and other similar things</code> or <code>and so on</code>. It’s a way of indicating that the list or examples given could continue, but you’re leaving out additional details because they’re understood to follow the same pattern. It is more formal than <code>etc.</code></p>
</li>
<li><p><strong>oversight</strong>: It generally refers to <code>supervision</code> or <code>monitoring</code> of a process, activity, or organization to ensure that it is functioning properly, ethically, and in compliance with regulations or standards.</p>
</li>
<li><p><strong>manifesto</strong>: It is a public declaration of principles, beliefs, or intentions, often issued by a political party, organization, or individual. A manifesto is typically a formal and structured statement that conveys the direction or ideology behind a movement, election campaign, or cause.</p>
</li>
<li><p><strong>retrieve</strong>: It means to <code>get something back</code> or <code>bring something back</code> from a particular place, especially after it has been lost, misplaced, or taken away. It can refer to physically <code>fetching</code> or <code>recovering</code> an item, or to accessing and recovering information.</p>
</li>
<li><p><strong>viable</strong>: It refers to something that is <code>practical</code>, <code>feasible</code>, or <code>capable of working successfully</code>. It is used to describe a plan, idea, solution, or course of action that is likely to be successful or achievable, given the available resources, constraints, and conditions.</p>
</li>
<li><p><strong>adversarial</strong>: It describes a situation, relationship, or environment where there is <code>opposition</code>, <code>conflict</code>, or <code>competition</code> between two parties or groups. It often implies a hostile, competitive, or antagonistic nature, where one side’s success or position is seen as being in direct conflict with the other’s.</p>
</li>
<li><p><strong>hostile</strong>: It refers to an attitude, environment, or action that is <code>unfriendly</code>, <code>aggressive</code>, or <code>antagonistic</code>. It describes behaviour or conditions that reflect opposition, enmity, or a desire to cause harm or discomfort to someone or something.</p>
</li>
<li><p><strong>antagonistic</strong>: It describes someone or something that is opposed, hostile, or actively unfriendly. It refers to actions, attitudes, or behaviours that create or reflect conflict, opposition, or rivalry. An antagonistic person or force is one that creates tension or hostility, often in a deliberate way.</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Language</category>
      </categories>
      <tags>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title>2025/02/05 English accumulation</title>
    <url>//Language/English/20250205/index.html</url>
    <content><![CDATA[<ul>
<li><p><strong>subtle</strong>: It refers to something that is delicate, understated, or not immediately obvious. It’s often used to describe things that are complex or nuanced but don’t make an obvious or loud impression. Here’s an example sentence: <code>She has a subtle sense of humor, often making witty remarks that go unnoticed at first but leave you thinking and laughing later.</code></p>
</li>
<li><p><strong>understated</strong>: It refers to something that is presented in a restrained or modest way, often deliberately avoiding excessive decoration or emphasis. It’s used to describe things that are elegant or impressive in a subtle, non-showy manner. Here’s an example sentence: <code>The interior of the restaurant was beautifully understated, with minimal decoration and soft lighting that created a calm, inviting atmosphere.</code></p>
</li>
<li><p><strong>delicate</strong>: It’s about something that needs to be treated with care, whether it’s a physical object, a situation, or a person’s feelings. Here’s an example sentence: <code>The delicate fabric of the dress shimmered in the light, and she handled it with great care to avoid damaging it.</code></p>
</li>
<li><p><strong>let alone</strong>: It is a phrase used to emphasize that something is even less likely or more extreme than the previous statement. It’s typically used when you’re talking about something that would be more surprising or difficult to do, in comparison to a previous, simpler action or condition. <code>[Negative statement], let alone [something more extreme].</code> Here’s an example sentence: <code>He can&#39;t even swim, let alone dive.</code><br>let alone” with a verb, the verb is typically in its <strong>original (base) form</strong> (i.e., the infinitive without “to”).</p>
</li>
<li><p><strong>native</strong>: It refers to something that is originally from or naturally associated with a particular place, environment, or system. Here’s an example sentence: <code>The kangaroo is native to Australia, meaning it is naturally found only in that region.</code></p>
</li>
<li><p><strong>identical</strong>: It means <strong>exactly the same in every way, without any differences</strong> as well as <strong>completely matching or alike in appearance, characteristics, or nature</strong>. Here’s an example: <code>The two houses are identical, with the same layout, size, and colour.</code></p>
</li>
<li><p><strong>volatility</strong>: It refers to <strong>the tendency of something to change rapidly and unpredictably</strong> as well as <strong>the tendency of a substance to evaporate or turn into a gas at a relatively low temperature in a chemical or physical context</strong>. Here’s an example sentence: <code>The volatility of the stock market makes it difficult for investors to predict future trends.</code> What’s more, <code>The volatility of the liquid makes it dangerous to handle at high temperatures.</code></p>
</li>
</ul>
]]></content>
      <categories>
        <category>Language</category>
      </categories>
      <tags>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title>20250212-English-accumulation</title>
    <url>//Language/English/20250212/index.html</url>
    <content><![CDATA[<ul>
<li><strong>on-premises</strong></li>
</ul>
]]></content>
      <categories>
        <category>Language</category>
      </categories>
      <tags>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title>2025/03/08 English accumulation</title>
    <url>//Language/English/20250308/index.html</url>
    <content><![CDATA[<ul>
<li><p><strong>accomplishment</strong>: It refers to something successfully completed or achieved, often through effort, skill, or perseverance. It can describe a notable achievement in a particular field, a personal success, or even a refined skill or ability. E.g. <code>Speaking multiple languages is an impressive accomplishment.</code></p>
</li>
<li><p><strong>savor&#x2F;savour</strong>: It means to fully enjoy or appreciate something, especially a taste, smell, or experience. It often implies taking one’s time to relish and delight in the moment. E.g. <code>Savour the moment—you’ve worked hard for this success.</code></p>
</li>
<li><p><strong>catapult</strong>: It refers to propel something or someone suddenly and forcefully into motion or a new situation. E.g. <code>The film’s success catapulted the young actor to fame.</code></p>
</li>
<li><p><strong>anniversary</strong>: I refers to the annual recurrence of a significant date, marking an event that happened in a previous year. It is commonly used for celebrations or commemorations. E.g. <code>They celebrated their tenth wedding anniversary with a holiday in Italy.</code></p>
</li>
<li><p><strong>outlast</strong>: <code>outlast</code> is a verb meaning to endure or last longer than something or someone else. It implies surpassing in duration, resilience, or survival. E.g. <code>These sturdy boots will outlast cheaper alternatives.</code></p>
</li>
<li><p><strong>innovation</strong>: <code>innovation</code> refers to the introduction of new ideas, methods, or products, often involving improvement or creativity. It can apply to technology, business, science, or any field where progress is made through new developments. E.g. <code>Innovation is key to staying ahead in a competitive market.</code></p>
</li>
<li><p><strong>pressing need for</strong>: It refers to an urgent or immediate requirement for something. It emphasises the importance and necessity of taking swift action. E.g. <code>After the storm, there was a pressing need for emergency supplies and assistance.</code></p>
</li>
<li><p><strong>mainstay</strong>: <code>mainstay</code> refers to something or someone that is the most important or essential part of a system, organisation, or group, providing support and stability. E.g. <code>Agriculture is the mainstay of the country’s economy.</code></p>
</li>
<li><p><strong>be humbled by</strong>: <code>to be humbled by</code> means to feel a deep sense of modesty, gratitude, or humility due to an experience, recognition, or comparison. It often implies being moved or gaining perspective, especially when faced with something inspiring, overwhelming, or greater than oneself. E.g. <code>He was humbled by the generosity of the community after the disaster.</code></p>
</li>
<li><p><strong>hindsight</strong>: <code>hindsight</code> refers to the understanding or realisation of a situation or event after it has happened, often with the benefit of knowing the outcome. It is commonly used to reflect on past decisions or actions. E.g. <code>Hindsight is a wonderful thing, but at the time, we did what we thought was best.</code></p>
</li>
<li><p><strong>no-nonsense</strong>: <code>no-nonsense</code> describes a practical, straightforward, and efficient approach to something, without unnecessary fuss or distractions. It is often used to describe people, attitudes, or methods that are serious, direct, and focused on getting things done. E.g. <code>His no-nonsense approach to problem-solving made him highly respected.</code></p>
</li>
<li><p><strong>mentors</strong>: <code>mentors</code> are experienced and knowledgeable individuals who provide guidance, support, and advice to less experienced people, often in a professional, academic, or personal development context. A mentor helps someone grow by sharing wisdom, offering encouragement, and providing constructive feedback. E.g. <code>Good mentors can make a significant difference in a young professional’s development.</code></p>
</li>
<li><p><strong>dedication</strong>: <code>dedication</code> refers to the quality of being committed or devoted to a particular task, cause, or person. It often implies hard work, persistence, and focus in achieving goals or supporting something important. E.g. <code>The success of the project is a testament to the team’s dedication and effort.</code></p>
</li>
<li><p><strong>departure</strong>: <code>departure</code> refers to the act of leaving or moving away from a place, situation, or position. It can also refer to the moment or event when someone or something departs. E.g. <code>The departure of the flight has been delayed due to bad weather.</code></p>
</li>
</ul>
]]></content>
      <categories>
        <category>Language</category>
      </categories>
      <tags>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title>Ansible Series Chapter1: The introduction of Ansible Automation Platform 2(RHAAP2)</title>
    <url>//Linux/Ansible/the-introduction-of-ansible-automation-platform2/index.html</url>
    <content><![CDATA[<h2 id="Introduction-to-Red-Hat-Ansible-Automation-Platform-2"><a href="#Introduction-to-Red-Hat-Ansible-Automation-Platform-2" class="headerlink" title="Introduction to Red Hat Ansible Automation Platform 2"></a>Introduction to Red Hat Ansible Automation Platform 2</h2><h3 id="What-is-the-Red-Hat-Ansible-Automaion-Platform2"><a href="#What-is-the-Red-Hat-Ansible-Automaion-Platform2" class="headerlink" title="What is the Red Hat Ansible Automaion Platform2?"></a>What is the Red Hat Ansible Automaion Platform2?</h3><p>An enterprise-grade automation platform that offers a complete set of integrated automation tools and resources. </p>
<p>It provides a new level of customisation and control, delivering a higher standard of automation experience.</p>
<h3 id="What-could-you-do-with-Ansible-Automation-Platform2"><a href="#What-could-you-do-with-Ansible-Automation-Platform2" class="headerlink" title="What could you do with Ansible Automation Platform2?"></a>What could you do with Ansible Automation Platform2?</h3><ul>
<li><p>Accelerating business outcomes through automation</p>
</li>
<li><p>Achieving automation in team collaboration and orchestration</p>
</li>
<li><p>Realising automation for scalable growth and innovation</p>
</li>
</ul>
<h2 id="The-components-of-Ansible-Automation-Platform2"><a href="#The-components-of-Ansible-Automation-Platform2" class="headerlink" title="The components of Ansible Automation Platform2"></a>The components of Ansible Automation Platform2</h2><h3 id="Ansible-Core"><a href="#Ansible-Core" class="headerlink" title="Ansible Core"></a>Ansible Core</h3><p>Ansible Core is the <code>core</code> component of the Ansible project, primarily responsible for automation configuration management, application deployment, and task execution.</p>
<p>It provides the basic functionality to run Ansible Playbooks.</p>
<h3 id="Ansible-Content-Collections"><a href="#Ansible-Content-Collections" class="headerlink" title="Ansible Content Collections"></a>Ansible Content Collections</h3><p><code>Modules</code>, <code>roles</code>, and <code>plugins</code> form a <code>collection</code> of resources.</p>
<h3 id="Automation-Content-Navigator"><a href="#Automation-Content-Navigator" class="headerlink" title="Automation Content Navigator"></a>Automation Content Navigator</h3><ul>
<li><p>Introducing the <code>new top-level tool</code>, <code>ansible-navigator</code>, for developing and testing Ansible Playbooks. This tool replaces and extends several commands, including the <code>ansible-playbook</code>, <code>ansible-playbook</code>, <code>ansible-inventory</code>, <code>ansible-config</code>, <code>ansible-doc</code>, etc.</p>
</li>
<li><p>Navigator <code>runs playbooks within a container</code>, separating the Ansible control node from the automation execution environment in which it operates. This allows different automation execution environments to accommodate varying Python environment requirements.</p>
</li>
</ul>
<h3 id="Automation-Execution-Environments-EE"><a href="#Automation-Execution-Environments-EE" class="headerlink" title="Automation Execution Environments(EE)"></a>Automation Execution Environments(EE)</h3><p>EE is a container image that includes <code>Ansible Core</code>, <code>Ansible Content Collections</code>, and any <code>required Python libraries</code> for running playbooks.</p>
<p><img src="/../images/EE.png" alt="User experience: Adapting execution environments to your needs"></p>
<ul>
<li><p><code>ansible-builder</code>: This command is used to create an image. </p>
<p>Eg. We use <code>Dockerfile</code> to build up an image in docker-engine. While, we use <code>Containerfile</code> in podman. Depend on what kind of container management tool do you use.</p>
</li>
<li><p><code>ansible-navigator</code>: This command will run the playbook in EE.</p>
<p>Eg. <code>sunhaoyang.yml</code> is the playbook you could specify in the command. While, you could use the option <code>--eei</code> to specify the execution environment as you want at the same time.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-navigator run sunhaoyang.yml -m stdout --eei ee-supported-rhel8:latest</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="Automation-Controller"><a href="#Automation-Controller" class="headerlink" title="Automation Controller"></a>Automation Controller</h3><ul>
<li><p>The Automation Controller, previously known as Red Hat Ansible <code>Tower (Open source:AWX)</code>, provides a <code>central location</code> for running playbooks. It offers a <code>web UI</code> and <code>REST API</code>, which can be used for configuring, running, and evaluating automation jobs.</p>
</li>
<li><p>The new Automation Controller <code>separates the control node from the automation execution environment</code>.</p>
</li>
</ul>
<p><img src="/../images/Controller.png" alt="Components of automation controller"></p>
<h3 id="Automation-hub"><a href="#Automation-hub" class="headerlink" title="Automation hub"></a>Automation hub</h3><ul>
<li><p>The Ansible Automation Hub is a platform for managing and distributing automation content. It provides a way to manage and distribute automation content, <code>similar to an online repository</code> from which content can be downloaded.</p>
</li>
<li><p>Public service access is available on <code>console.redhat.com</code>, providing Red Hat-certified Ansible content collections.</p>
</li>
<li><p>In the practice environment, eg.<code>hub.lab.example.com</code> serves as a private automation hub for managing private Ansible content collections.</p>
</li>
</ul>
<p><img src="/../images/Hub.png" alt="Creator experience: Working with Ansible Automation Platform"></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title>Ansible Series Chapter2: The introduction of ansible-navigator</title>
    <url>//Linux/Ansible/the-introduction-of-ansible-navigator/index.html</url>
    <content><![CDATA[<h2 id="Automation-Content-Navigator"><a href="#Automation-Content-Navigator" class="headerlink" title="Automation Content Navigator"></a>Automation Content Navigator</h2><p>Automation content navigator (ansible-navigator) is a new tool in Red Hat Ansible Automation Platform 2, and is designed to make it easier for you to write playbooks that can be<br>run in a reproducible manner. It combines the features formerly provided by <code>ansible-playbook</code>, <code>ansible-inventory</code>, <code>ansible-config</code>, and <code>ansible-doc</code> in one top-level interface.</p>
<p>Automation content navigator offers a new <code>interactive mode</code> with a text-based user interface (<code>TUI</code>), and can also be run using the <code>--mode stdout</code> (or <code>-m stdout</code>) option to provide output in the original format used by the earlier tools.</p>
<p>Here are its main features:</p>
<ol>
<li><p>Unified CLI Experience</p>
<ul>
<li><p>Replaces multiple Ansible commands (ansible-playbook, ansible-inventory, ansible-config, ansible-doc) with a single interface.</p>
</li>
<li><p>Provides a streamlined and consistent way to interact with Ansible.</p>
</li>
</ul>
</li>
<li><p>Containerized Execution</p>
<ul>
<li><p>Runs Ansible playbooks within a container, separating the control node from the execution environment.</p>
</li>
<li><p>Ensures compatibility across different Python versions and dependencies.</p>
</li>
<li><p>Reduces the need for local Ansible installations and dependencies.</p>
</li>
</ul>
</li>
<li><p>Interactive TUI (Text User Interface)</p>
<ul>
<li><p>Offers an interactive, user-friendly text-based interface.</p>
</li>
<li><p>Enables easier navigation through playbook results, inventory, and documentation.</p>
</li>
<li><p>Provides real-time insights into playbook execution.</p>
</li>
</ul>
</li>
<li><p>Enhanced Playbook Execution and Debugging</p>
<ul>
<li><p>Supports interactive viewing of playbook execution with detailed logs.</p>
</li>
<li><p>Allows users to explore playbook results step by step.</p>
</li>
<li><p>Helps in debugging with real-time feedback.</p>
</li>
</ul>
</li>
<li><p>Seamless Integration with Automation Hub</p>
<ul>
<li><p>Can access certified and private content collections from Automation Hub.</p>
</li>
<li><p>Helps manage and distribute automation content efficiently.</p>
</li>
</ul>
</li>
<li><p>Supports Various Execution Environments</p>
<ul>
<li><p>Works with Ansible execution environments (EEs), allowing flexibility in managing dependencies.</p>
</li>
<li><p>Users can switch between different execution environments as needed.</p>
</li>
</ul>
</li>
<li><p>Inventory and Documentation Management</p>
<ul>
<li><p>Provides easy access to inventory information with interactive views.</p>
</li>
<li><p>Enables browsing of Ansible documentation and content collections directly from the CLI.</p>
</li>
</ul>
</li>
</ol>
<p>Compared with the original method, for example, to run a playbook with <code>ansible-playbook</code>, you might enter the following command:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[student@workstation ~]$ ansible-playbook -i inventory playbook.yml </span><br></pre></td></tr></table></figure>

<p>Currently, You can use the <code>ansible-navigator</code> command to do the same thing and get output from the playbook in the same format, as follows:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[student@workstation ~]$ ansible-navigator run playbook.yml -i inventory -m stdout</span><br></pre></td></tr></table></figure>

<p>However, if you <code>omit the -m stdout option</code> for the ansible-navigator command, it starts an <code>interactive mode</code> that summarizes the output of the playbook run in real time. This enables you to investigate the results in a TUI after the run completes.</p>
<p><img src="/../images/ansible-navigator.png" alt="Output of a playbook run with automation content navigator"></p>
<p>In the preceding image, you can see that ansible-navigator ran a playbook containing three plays. </p>
<p>You can get more information about the tasks that were run by the first play by <code>pressing 0, or by typing :0</code> in ansible-navigator:</p>
<p><img src="/../images/ansible-navigator1.png" alt="Output of a playbook run with automation content navigator"></p>
<p>You can also get detailed information about particular tasks. In the preceding example, if you <code>press 2 or type :2</code>, then details of the “Ensure HAProxy is started and enabled” task are displayed, and you can use the arrow keys to scroll through the results:</p>
<p><img src="/../images/ansible-navigator2.png" alt="Output of a playbook run with automation content navigator"></p>
<p>To <code>go back</code> to previous pages or <code>exit</code> from ansible-navigator at the top-level page, <code>press Esc</code>.</p>
<h2 id="Using-Automation-Execution-Environments-to-Improve-Portability"><a href="#Using-Automation-Execution-Environments-to-Improve-Portability" class="headerlink" title="Using Automation Execution Environments to Improve Portability"></a>Using Automation Execution Environments to Improve Portability</h2><p>Automation Execution Environments (EEs) enhance portability by providing a consistent and isolated environment for running Ansible automation. Here’s how they help:</p>
<ol>
<li><p>Consistency Across Different Systems</p>
<ul>
<li><p>EEs encapsulate Ansible, dependencies, and Python libraries into a container image.</p>
</li>
<li><p>Ensures that automation runs the same way across different environments, avoiding “works on my machine” issues.</p>
</li>
</ul>
</li>
<li><p>Simplified Dependency Management</p>
<ul>
<li><p>No need to install Ansible and its dependencies on each system manually.</p>
</li>
<li><p>Eliminates conflicts between different versions of Python and Ansible modules.</p>
</li>
</ul>
</li>
<li><p>Improved Reproducibility</p>
<ul>
<li><p>   Playbooks always run within a controlled, versioned environment.</p>
</li>
<li><p>   Ensures that automation behaves predictably across development, testing, and production.</p>
</li>
</ul>
</li>
<li><p>Seamless Collaboration</p>
<ul>
<li><p>   Teams can share predefined execution environments, reducing setup inconsistencies.</p>
</li>
<li><p>   Developers and operators can work with the same automation stack, minimizing configuration drift.</p>
</li>
</ul>
</li>
<li><p>Integration with Ansible Navigator</p>
<ul>
<li><p>   ansible-navigator uses execution environments to run playbooks, making automation portable and self-contained.</p>
</li>
<li><p>   Users can easily switch between different EEs to match specific automation needs.</p>
</li>
</ul>
</li>
</ol>
<p>When you use <code>ansible-navigator</code> to run a playbook, and do not specify a particular automation execution environment, <code>ansible-navigator</code> automatically attempts to pull the default automation execution environment from <code>registry.redhat.io</code> if it is not already present on the system. For Red Hat Ansible Automation Platform 2.2, this default environment includes Ansible Core 2.13 and a standard set of Red Hat Ansible Certified Content Collections.</p>
<p>By default, the ansible-navigator command in Ansible Automation Platform 2.2 attempts to download and use the container image available at <code>registry.redhat.io/ansible-automation-platform-22/ee-supported-rhel8:latest</code>s if the automation execution environment is not specified in some other way.</p>
<p>You can also use the <code>--pull-policy (--pp)</code> option to control how ansible-navigator pulls container images. When the value of this option is set to <code>missing</code>, automation content navigator only pulls the container image if the image does not exist on the local system.</p>
<blockquote>
<p>Note:</p>
<p>Depending on your container runtime, use the corresponding command to log in to the image registry.</p>
<p>e.g. podman&#x2F;docker login <registry_url></p>
</blockquote>
<h2 id="Installing-ansible-navigator"><a href="#Installing-ansible-navigator" class="headerlink" title="Installing ansible-navigator"></a>Installing ansible-navigator</h2><p>Ansible is a <code>non-intrusive</code> automation platform, meaning it only needs to <code>be installed on the control node</code> without requiring any software or agents on managed nodes.</p>
<blockquote>
<p>Note: </p>
<p>Installation requires <code>an active Red Hat subscription</code>, but in our environment, it is already pre-configured.</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[student@workstation ~]$ <span class="built_in">sudo</span> yum -y install ansible-navigator</span><br></pre></td></tr></table></figure>

<p>After installation, you also need to generate the <code>ansible.cfg</code> configuration file and the <code>ansible-navigator.yml</code> configuration file.</p>
<ul>
<li><p><code>ansible.cfg</code> is a crucial file that controls the core behavior of Ansible.</p>
<p>ansible.cfg is the core configuration file for Ansible, used to define Ansible’s global behaviour. It mainly controls the execution of tasks, the method of connecting to remote hosts, and important parameters such as logging and role paths. This file is automatically read when running Ansible, and users can customise Ansible’s runtime environment through it.</p>
<p>Main Functions:</p>
<ul>
<li><p>Inventory Configuration: Specifies the default path for the inventory file.</p>
</li>
<li><p>Connection Management: Configures SSH connection parameters, such as timeout and control path.</p>
</li>
<li><p>Log Management: Defines the location and format of log files to record the execution process.</p>
</li>
<li><p>Role and Module Paths: Configures the search paths for custom roles and modules, facilitating the extension of functionalities.</p>
</li>
</ul>
<p>This file has a <code>high priority</code> and affects the operation of all Ansible tasks. It is the <code>core tool for controlling</code> Ansible’s behaviour.</p>
</li>
<li><p><code>ansible-navigator.yml</code> is a customization tool for configuring the Navigator interface and interactive experience.</p>
<p>ansible-navigator.yml is a configuration file designed specifically for Ansible Navigator, used to control the interactive interface behaviour, execution environment, and the interaction with inventories and content collections. It is more focused on optimising the user experience and providing a <code>customised</code> operational approach.</p>
<p>Main Functions:</p>
<ul>
<li><p>Interactive Mode: Specifies the operating mode of Navigator, such as interactive interface mode or standard output mode.</p>
</li>
<li><p>   Execution Environment: Defines whether to enable a containerised execution environment and configures the container image and runtime engine (e.g., Podman or Docker).</p>
</li>
<li><p>   Resource Management: Sets the default inventory file and playbook paths for quicker loading and usage.</p>
</li>
<li><p>   Logging and Debugging: Controls the location and level of detail for logging, making it easier for users to trace and troubleshoot issues.</p>
</li>
<li><p>   Interface Optimisation: Adjusts the behaviour and layout of the user interface to improve interaction efficiency.</p>
</li>
</ul>
<p>This file’s settings focus more on <code>user experience</code>, mainly influencing the operation of the Navigator tool, rather than the core execution logic of Ansible.</p>
</li>
</ul>
<p>These two files complement each other, providing a flexible and efficient automation environment for users.</p>
<h2 id="Configuring-Authentication-to-Managed-Hosts"><a href="#Configuring-Authentication-to-Managed-Hosts" class="headerlink" title="Configuring Authentication to Managed Hosts"></a>Configuring Authentication to Managed Hosts</h2><p>Automation content navigator needs to be able to log in to managed hosts and gain <code>superuser privileges</code> on those hosts. The easiest way to implement this is by using <code>SSH key-based authentication</code> to an account that allows privilege escalation through sudo without a password.</p>
<p>To begin with, you need to <code>generate an SSH key pair on the control node</code> for the automation user, and then <code>distribute the public key to the remote hosts</code>. This enables passwordless SSH authentication between the control node and the remote systems, where user is the remote user and host is one of the managed hosts.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[student@workstation ~]$ ssh-keygen</span><br><span class="line">[student@workstation ~]$ ssh-copy-id student@servera</span><br></pre></td></tr></table></figure>

<p>Then configure ansible.cfg on the control node or have ansible.cfg in the current directory. Set a remote_user directive to the name of the user account you plan to use on the managed hosts in the [defaults] section of your Ansible configuration file on the control node.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /etc/ansible/ansible.cfg</span><br></pre></td></tr></table></figure>

<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="section">[defaults]</span></span><br><span class="line"><span class="attr">remote_user</span>=student</span><br></pre></td></tr></table></figure>

<p>You need to configure sudo privilege escalation on all managed hosts.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[student@workstation ~]$ <span class="built_in">sudo</span> vim /etc/sudoers</span><br><span class="line">...</span><br><span class="line">student ALL=(ALL)       NOPASSWD: ALL</span><br></pre></td></tr></table></figure>

<p>The main difference between <code>authenticating ansible-navigator and ansible-playbook</code> to managed hosts is that ansible-navigator runs the playbook inside a container that cannot access your ~&#x2F;.ssh directory. However, if you are running <code>ssh-agent</code> on your control node to store SSH private keys, when you run ansible-navigator it can automatically provide those keys to the execution environment.</p>
<p>If you logged in to the control node through the graphical desktop environment, ssh-agent is automatically started and the ssh-add command is automatically run to add your private keys to the agent. If any of your SSH private keys are passphrase protected, you are prompted for the password after you log in. Authentication then automatically works for all terminals in that graphical login session.</p>
<p>If you logged in to the control node through a text-based virtual console or remotely using ssh, you must start ssh-agent yourself by running the <code>eval $(ssh-agent)</code> command. In the same shell, you then run ssh-add and if necessary provide the passphrase for your private key. You can then run ansible-navigator in the same shell and authenticate.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[student@workstation ~]$ <span class="built_in">eval</span> $(ssh-agent)</span><br><span class="line">[student@workstation ~]$ ssh-add</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>Earlier Ansible command</th>
<th>Automation content navigator subcommand</th>
</tr>
</thead>
<tbody><tr>
<td>ansible-config</td>
<td>ansible-navigator config</td>
</tr>
<tr>
<td>ansible-doc</td>
<td>ansible-navigator doc</td>
</tr>
<tr>
<td>ansible-inventory</td>
<td>ansible-navigator inventory</td>
</tr>
<tr>
<td>ansible-playbook</td>
<td>ansible-navigator run</td>
</tr>
</tbody></table>
<p>Automation content navigator also provides additional functionality. Most subcommands can be run from either the command line or from within an interactive automation content navigator session, but some commands do not support the <code>-m stdout</code> option. </p>
<p>When running a subcommand in an interactive session, type : to start the command, such as <code>:config</code>.</p>
<p>The following chart introduces some ansible-navigator subcommands.</p>
<table>
<thead>
<tr>
<th>Subcommand</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td>collections</td>
<td>Get information about installed collections.</td>
</tr>
<tr>
<td>config</td>
<td>Examine the current Ansible configuration.</td>
</tr>
<tr>
<td>doc</td>
<td>Examine the Ansible documentation for a plug-in.</td>
</tr>
<tr>
<td>help</td>
<td>Display detailed help for ansible-navigator.</td>
</tr>
<tr>
<td>images</td>
<td>Examine an execution environment.</td>
</tr>
<tr>
<td>inventory</td>
<td>Explore an inventory.</td>
</tr>
<tr>
<td>log</td>
<td>Review the current log file.</td>
</tr>
<tr>
<td>open</td>
<td>Open the current page in a text editor.</td>
</tr>
<tr>
<td>replay</td>
<td>Replay a playbook artifact.</td>
</tr>
<tr>
<td>run</td>
<td>Run a playbook.</td>
</tr>
</tbody></table>
<h3 id="Reviewing-Previous-Playbook-Runs"><a href="#Reviewing-Previous-Playbook-Runs" class="headerlink" title="Reviewing Previous Playbook Runs"></a>Reviewing Previous Playbook Runs</h3><p>Automation content navigator provides a new <code>replay</code> feature that displays the output of a previous playbook run. If playbook artifacts are enabled (the default), then the ansible-navigator run command generates an artifact file, which use names such as <code>PlaybookName-artifact-xxxxx.json</code> or similar.</p>
<p>One advantage of the replay file is that if the playbook fails then you can share the replay file with another developer or a support team. They can proceed with <code>troubleshooting without needing to have access to all the files in the project directory</code>, such as playbooks, roles, inventory files, variable<br>files, and so on.</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title>Ansible Series Chapter3: Implementing Recommended Ansible Practices</title>
    <url>//Linux/Ansible/implementing-recommended-ansible-practices/index.html</url>
    <content><![CDATA[<h2 id="The-Effectiveness-of-Ansible"><a href="#The-Effectiveness-of-Ansible" class="headerlink" title="The Effectiveness of Ansible"></a>The Effectiveness of Ansible</h2><p>As you work with more advanced features and larger, more complex projects, it becomes more difficult to manage and maintain Ansible Playbooks, or to use them effectively.</p>
<p>To paraphrase Ansible developer Jeff Geerling, using Ansible effectively relies on three key practices:</p>
<ul>
<li><p>Keeping things simple</p>
</li>
<li><p>Staying organized</p>
</li>
<li><p>Testing often</p>
</li>
</ul>
<h3 id="Keeping-things-simple"><a href="#Keeping-things-simple" class="headerlink" title="Keeping things simple"></a>Keeping things simple</h3><ul>
<li><p>Keeping Your Playbooks Readable</p>
<ol>
<li><p>Add Comments: Ensure that playbooks and tasks include meaningful comments to improve readability and maintainability.</p>
</li>
<li><p>   Use Blank Lines to Separate Logic: Insert blank lines between logical sections to enhance clarity.</p>
</li>
<li><p>   Always Name Plays and Tasks Meaningfully: Every play and task should have a clear and descriptive name to convey its purpose.</p>
</li>
<li><p>Maintain a Consistent Style: Use a uniform coding style, including consistent indentation, variable naming conventions, and structured comments.</p>
</li>
<li><p>   Leverage Roles for Efficiency: Utilize roles to modularize and organize automation tasks efficiently.</p>
</li>
<li><p>   Stick to Native YAML Syntax: Avoid writing parameters in a single line—use proper YAML formatting to ensure readability and maintainability.</p>
</li>
</ol>
<p>The following syntax is <code>easier</code> for most people to read:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Postfix</span> <span class="string">is</span> <span class="string">installed</span> <span class="string">and</span> <span class="string">updated</span></span><br><span class="line">  <span class="attr">ansible.builtin.yum:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">postfix</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">latest</span></span><br><span class="line">  <span class="attr">notify:</span> <span class="string">update_postfix</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Postfix</span> <span class="string">is</span> <span class="string">running</span></span><br><span class="line">  <span class="attr">ansible.builtin.service:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">postfix</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">started</span></span><br></pre></td></tr></table></figure>

<p>Use native YAML syntax, not the “folded” syntax. For example, the following example is <code>not a recommended format</code>:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Postfix</span> <span class="string">is</span> <span class="string">installed</span> <span class="string">and</span> <span class="string">updated</span></span><br><span class="line">  <span class="attr">ansible.builtin.yum:</span> <span class="string">name=postfix</span> <span class="string">state=latest</span></span><br><span class="line">  <span class="attr">notify:</span> <span class="string">restart_postfix</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Postfix</span> <span class="string">is</span> <span class="string">running</span></span><br><span class="line">  <span class="attr">ansible.builtin.service:</span> <span class="string">name=postfix</span> <span class="string">state=started</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Use Existing Modules</p>
<ol>
<li><p>When writing a new playbook, start with a <code>basic playbook</code> and, if possible, a <code>static inventory</code>. Use <code>ansible.builtin.debug</code> tasks as stubs as you build your design. When your playbook functions as expected, break up your playbook into smaller, logical components by using <code>imports</code> and <code>includes</code>.</p>
</li>
<li><p>Ansible playbooks are designed to be idempotent, meaning that running the same playbook multiple times should produce the same result without unintended changes. </p>
<p> It is easier to make your playbook idempotent and easier to maintain if you use the modules designed for a specific task.</p>
<p> However, using the following modules can break idempotency:</p>
<ul>
<li><code>ansible.builtin.command</code></li>
<li><code>ansible.builtin.shell</code></li>
<li><code>ansible.builtin.raw</code></li>
</ul>
</li>
<li><p>Many modules have a default state or other variables that control what they do. For example, the yum module currently assumes that the package you name should be <code>present</code> in most cases.</p>
</li>
</ol>
</li>
<li><p>Adhering to a Standard Style</p>
<p>Consider having a standard “style” that your team follows when writing Ansible projects. For example:</p>
<ol>
<li><p>How many spaces do you indent? </p>
</li>
<li><p>How do you want vertical white space used? </p>
</li>
<li><p>How should tasks, plays, roles, and variables be named? </p>
</li>
<li><p>What should get commented on and how?</p>
</li>
</ol>
<p>Having a consistent standard can help improve maintainability and readability.</p>
</li>
</ul>
<h3 id="Staying-Organized"><a href="#Staying-Organized" class="headerlink" title="Staying Organized"></a>Staying Organized</h3><ul>
<li><p>Following Conventions for Naming Variables</p>
<ol>
<li><p>Variable names should <code>clarify contents</code>.</p>
</li>
<li><p>When defining role variables, it is best to <code>prefix them with the role name</code> to avoid conflicts and improve clarity. If the name of your role is myapp then prefix your variables with myapp_ so that you can easily identify them from variables in other roles and the playbook.</p>
</li>
<li><p>Use <code>descriptive variables</code>, such as apache_tls_port rather than a less explanatory variable such as p. In roles, it is a good practice to prefix role variables with the role name.</p>
</li>
</ol>
</li>
<li><p>Standardizing the Project Structure</p>
<p>Use a consistent pattern when structuring the files of your Ansible project on a file system. The following is a good example:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">├── dbservers.yml</span><br><span class="line">├── inventories/</span><br><span class="line">│ ├── prod/</span><br><span class="line">│ │ ├── group_vars/</span><br><span class="line">│ │ ├── host_vars/</span><br><span class="line">│ │ └── inventory/</span><br><span class="line">│ └── stage/</span><br><span class="line">│ ├── group_vars/</span><br><span class="line">│ ├── host_vars/</span><br><span class="line">│ └── inventory/</span><br><span class="line">├── roles/</span><br><span class="line">│ └── std_server/</span><br><span class="line">├── site.yml</span><br><span class="line">├── storage.yml</span><br><span class="line">└── webservers.yml</span><br></pre></td></tr></table></figure>

<p>One of the playbook structure benefits is that you can divide up your extensive playbook into smaller files to make it more readable. Those smaller playbooks can contain plays for a specific purpose that you can run independently.</p>
</li>
<li><p>Using Dynamic Inventories</p>
<ol>
<li><p>Using Dynamic Inventory。</p>
</li>
<li><p>Dynamic inventory is particularly powerful when integrated with cloud providers, container platforms, and virtual machine management systems.</p>
</li>
<li><p>If dynamic inventory is not an option, other tools can be used to dynamically construct groups or gather additional information.</p>
</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Generate</span> <span class="string">dynamic</span> <span class="string">groups</span></span><br><span class="line">  <span class="attr">hosts:</span> <span class="string">all</span></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Generate</span> <span class="string">dynamic</span> <span class="string">groups</span> <span class="string">based</span> <span class="string">on</span> <span class="string">architecture</span></span><br><span class="line">      <span class="attr">ansible.builtin.group_by:</span></span><br><span class="line">        <span class="attr">key:</span> <span class="string">arch_&quot;&#123;&#123;</span> <span class="string">ansible_facts[&#x27;architecture&#x27;]</span> <span class="string">&#125;&#125;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Configure</span> <span class="string">x86_64</span> <span class="string">systems</span></span><br><span class="line">  <span class="attr">hosts:</span> <span class="string">arch_x86_64</span></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">First</span> <span class="string">task</span> <span class="string">for</span> <span class="string">x86_64</span> <span class="string">configuration</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Taking Advantage of Groups</p>
<ol>
<li><p>Geographical: Differentiate hosts from different regions, countries, continents, or data centers.</p>
</li>
<li><p>Environmental: Differentiate hosts dedicated to different stages of the software lifecycle, including development, staging, testing, and production.</p>
</li>
<li><p>Sites or services: Group hosts that offer or link to a subset of functions, such as a specific website, an application, or a subset of features.</p>
</li>
</ol>
</li>
<li><p>Reusing Content with Collections and Roles</p>
<p>Roles and collections help keep playbooks simple and enable code reuse across different projects, reducing workload. When necessary, you can also create a custom automation execution environment.</p>
<p>Common Sources for Collections and Roles:</p>
<ul>
<li>Red Hat Official Website</li>
<li>Ansible Galaxy</li>
<li>GitHub</li>
<li>   Internal Company Repository</li>
</ul>
</li>
<li><p>Running Playbooks Centrally </p>
<p>Consider using a <code>dedicated control node</code> to run all Ansible Playbooks from a single location. Ideally, an Automation <code>Controller</code> should be used.</p>
<p>The reason is simple: Ansible requires control over the managed hosts. Frequently changing the control node may lead to Playbook execution failures or security issues.</p>
</li>
</ul>
<h3 id="Performing-Regular-Testing"><a href="#Performing-Regular-Testing" class="headerlink" title="Performing Regular Testing"></a>Performing Regular Testing</h3><ul>
<li><p>Test Your Playbooks and Tasks Regularly During Development</p>
<ol>
<li><p>When confirming the success of a task, validate the task’s actual result rather than relying solely on the module’s return code.</p>
</li>
<li><p>In addition to using the <code>debug</code> module, you can also utilise the <code>uri</code> module to check whether web-based services are functioning correctly.</p>
 <figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Start</span> <span class="string">web</span> <span class="string">server</span></span><br><span class="line">  <span class="attr">ansible.builtin.service:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">httpd</span></span><br><span class="line">    <span class="attr">status:</span> <span class="string">started</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Check</span> <span class="string">web</span> <span class="string">site</span> <span class="string">from</span> <span class="string">web</span> <span class="string">server</span></span><br><span class="line">  <span class="attr">ansible.builtin.uri:</span></span><br><span class="line">    <span class="attr">url:</span> <span class="string">http://&#123;&#123;</span> <span class="string">ansible_fqdn</span> <span class="string">&#125;&#125;</span></span><br><span class="line">    <span class="attr">return_content:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">register:</span> <span class="string">example_webpage</span></span><br><span class="line">  <span class="attr">failed_when:</span> <span class="string">example_webpage.status</span> <span class="type">!=</span> <span class="number">200</span></span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p>Implement Recovery and Rollback with block&#x2F;rescue</p>
<p>The block directive is useful for grouping tasks. When combined with the rescue directive, it helps in recovering from errors or failures, making it an effective approach for implementing recovery and rollback mechanisms.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">block:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Check</span> <span class="string">web</span> <span class="string">site</span> <span class="string">from</span> <span class="string">web</span> <span class="string">server</span></span><br><span class="line">    <span class="attr">ansible.builtin.uri:</span></span><br><span class="line">      <span class="attr">url:</span> <span class="string">http://&#123;&#123;</span> <span class="string">ansible_fqdn</span> <span class="string">&#125;&#125;</span></span><br><span class="line">      <span class="attr">return_content:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">register:</span> <span class="string">example_webpage</span></span><br><span class="line">    <span class="attr">failed_when:</span> <span class="string">example_webpage.status</span> <span class="type">!=</span> <span class="number">200</span></span><br><span class="line"></span><br><span class="line"><span class="attr">rescue:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Restart</span> <span class="string">web</span> <span class="string">server</span></span><br><span class="line">    <span class="attr">ansible.builtin.service:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">httpd</span></span><br><span class="line">      <span class="attr">status:</span> <span class="string">restarted</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Using Test Tools</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[student@workstation ~]$ ansible-navigator run playbook --syntax-check -m stdout</span><br></pre></td></tr></table></figure>
</li>
<li><p>Analyzing the Playbooks</p>
<ul>
<li><p>ansible-lint </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[student@workstation ~]$ ansible-lint xxx.yaml</span><br></pre></td></tr></table></figure>
</li>
<li><p>yamllint</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[student@workstation ~]$ yamllint xxx.yaml</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>Testing with New Versions</p>
<p>Regularly test your playbooks and automation workflows against newer versions of Ansible Core. This ensures compatibility and helps identify potential issues before upgrading your production environment.</p>
<p>If your playbook displays warnings or deprecation messages during execution, you should pay attention to them and make the necessary adjustments.</p>
<p>When a feature in Ansible Core is deprecated or changed, a deprecation notice is provided <code>four minor versions</code> in advance before it is removed or modified.</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title>Ansible Series Chapter4: Detailed Explanation of Ansible Content Collections</title>
    <url>//Linux/Ansible/detailed-explanation-of-ansible-content-collections/index.html</url>
    <content><![CDATA[<h2 id="Explanation-of-Ansible-Content-Collections"><a href="#Explanation-of-Ansible-Content-Collections" class="headerlink" title="Explanation of Ansible Content Collections"></a>Explanation of Ansible Content Collections</h2><h3 id="Introductions"><a href="#Introductions" class="headerlink" title="Introductions"></a>Introductions</h3><p>What Are Ansible Content Collections?</p>
<p>Ansible Content Collections are a structured approach within the Ansible ecosystem for organising and distributing automation resources. </p>
<p>They bundle together <code>modules</code>, <code>plugins</code>, <code>roles</code>, <code>documentation</code>, and other <code>related files</code> into a reusable and independently managed unit, allowing users to easily access and utilise the necessary resources.</p>
<p>Core Components of a Content Collection:</p>
<ul>
<li><p>Modules: Small scripts that perform specific tasks, such as managing files or installing software.</p>
</li>
<li><p>   Plugins: Pluggable components that extend Ansible’s functionality, such as callback plugins or filter plugins.</p>
</li>
<li><p>   Roles: Structured directories used to organise and reuse automation tasks.</p>
</li>
<li><p>   Documentation and Examples: Includes usage guides, YAML example files, and other resources to help users understand and implement the collection effectively.</p>
</li>
</ul>
<h3 id="Advantages"><a href="#Advantages" class="headerlink" title="Advantages"></a>Advantages</h3><ul>
<li><p>Modularity and Decoupling: Separates resources from the Ansible core, allowing independent updates.</p>
</li>
<li><pre><code>Ease of Distribution and Management: Enables quick installation and management of collections using the ansible-galaxy command.
</code></pre>
</li>
<li><pre><code>Namespace Support: Utilises the namespace.collection_name structure to prevent naming conflicts.
</code></pre>
</li>
<li><pre><code>Community-Driven: Developers and organisations can share content collections, fostering the growth of the open-source ecosystem.
</code></pre>
</li>
</ul>
<h3 id="Differences-Between-Using-Content-Collections-and-the-Traditional-Approach"><a href="#Differences-Between-Using-Content-Collections-and-the-Traditional-Approach" class="headerlink" title="Differences Between Using Content Collections and the Traditional Approach"></a>Differences Between Using Content Collections and the Traditional Approach</h3><p>Before the introduction of Ansible Content Collections, Ansible relied on role directory structures and core module packages.</p>
<p>This traditional approach had several limitations:</p>
<ul>
<li><p>Difficult Module Updates: All modules were bundled with the Ansible core version, meaning that updating a module required upgrading the entire Ansible version.</p>
</li>
<li><p>Lack of Flexibility: Roles and modules were managed separately, requiring users to handle multiple independent resources manually.</p>
</li>
</ul>
<p>In contrast, Content Collections unify these resources by packaging modules, plugins, roles, and documentation into a single, standalone distribution unit. This design eliminates the limitations of the traditional approach, making automation more modular, flexible, and easier to manage.</p>
<h3 id="Namespace"><a href="#Namespace" class="headerlink" title="Namespace"></a>Namespace</h3><p>Why Are Namespaces Needed?</p>
<p>To make it easier to specify collections and their contents by name, collection names are organized into <code>namespaces</code>.</p>
<p>The introduction of namespaces helps prevent conflicts and improve organisation when managing Ansible content.</p>
<p>In the early stages of Ansible’s development, all modules, plugins, and roles were structured in a flat manner, leading to several issues:</p>
<ul>
<li><p>Naming Conflicts: Different developers might create modules or roles with the same name, causing conflicts and confusion.</p>
</li>
<li><p>Difficult Organisation and Management: As the Ansible ecosystem expanded, the growing number of resources became harder to manage without a structured hierarchy.</p>
</li>
</ul>
<p>With namespaces, Ansible creates separate logical spaces for different sources, such as individual developers or organisations. Using the structure namespace.collection_name.module_name, resources are ensured to <code>be unique</code> while also improving code readability and maintainability.</p>
<p>The namespace is the first part of a collection name. For example, all the collections that the Ansible <code>community maintain</code> are in the community namespace, and have names such as<br><code>community.crypto</code>, <code>community.postgresql</code>, and <code>community.rabbitmq</code>. Collections that <code>Red Hat maintain</code> and support might use the redhat namespace, and have names such as <code>redhat.rhv</code>, <code>redhat.satellite</code>, and <code>redhat.insights</code>. </p>
<p>Names of namespaces are limited to <code>ASCII lowercase letters</code>, <code>numbers</code>, and <code>underscores</code>, must be <code>at least two characters long</code>, and <code>must not start with an underscore</code>.</p>
<h3 id="Accessing-Ansible-Content-Collection-Documentation"><a href="#Accessing-Ansible-Content-Collection-Documentation" class="headerlink" title="Accessing Ansible Content Collection Documentation"></a>Accessing Ansible Content Collection Documentation</h3><p>Use the <code>ansible-navigator collections</code> command to list the collections available in automation execution environments.  Type a colon before the collection number, you could check the number x line available module. Enter the module number to access its documentation.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">  Name                    Version Shadowed Type      Path</span><br><span class="line">0│amazon.aws              3.2.0   False    contained /usr/share/ansible/collec</span><br><span class="line">1│ansible.builtin         2.13.3  False    contained /usr/lib/python3.9/site-p</span><br><span class="line">2│ansible.controller      4.2.1   False    contained /usr/share/ansible/collec</span><br><span class="line">3│ansible.netcommon       3.0.0   False    contained /usr/share/ansible/collec</span><br><span class="line">4│ansible.network         1.2.0   False    contained /usr/share/ansible/collec</span><br><span class="line">5│ansible.posix           1.3.0   False    contained /usr/share/ansible/collec</span><br><span class="line">6│ansible.security        1.0.0   False    contained /usr/share/ansible/collec</span><br><span class="line">7│ansible.utils           2.6.1   False    contained /usr/share/ansible/collec</span><br><span class="line">8│ansible.windows         1.9.0   False    contained /usr/share/ansible/collec</span><br><span class="line">9│ansible.yang            1.0.0   False    contained /usr/share/ansible/collec</span><br></pre></td></tr></table></figure>

<p>Use the following command to display the help documentation in plain text format:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible-navigator doc &lt;module_name&gt; -m stdout</span><br></pre></td></tr></table></figure>

<p>E.g.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[student@workstation ~]$ ansible-navigator doc redhat.insights.insights_register \</span><br><span class="line">&gt; --mode stdout</span><br><span class="line">&gt; REDHAT.INSIGHTS.INSIGHTS_REGISTER    (/usr/share/ansible/collections/ansible_&gt;</span><br><span class="line"></span><br><span class="line">        This module will check the current registration status,</span><br><span class="line">        unregister if needed, and then register the insights client</span><br><span class="line">        (and update the display_name if needed)</span><br><span class="line"></span><br><span class="line">OPTIONS (= is mandatory):</span><br><span class="line"></span><br><span class="line">- display_name</span><br><span class="line">        This option is here to enable registering with a display_name</span><br><span class="line">        outside of using a configuration file. Some may be used to</span><br><span class="line">        doing it this way so I left this in as an optional parameter.</span><br><span class="line">        [Default: (null)]</span><br><span class="line">        type: str</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="Using-Ansible-Content-Collections-in-Playbooks"><a href="#Using-Ansible-Content-Collections-in-Playbooks" class="headerlink" title="Using Ansible Content Collections in Playbooks"></a>Using Ansible Content Collections in Playbooks</h3><p>To use a module or a role from a collection, refer to it with its <code>fully qualified collection name</code> (FQCN).<br>For example, use redhat.insights.insights_register to refer to the insights_register module.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Register</span> <span class="string">new</span> <span class="string">systems</span></span><br><span class="line">  <span class="attr">hosts:</span> <span class="string">db.example.com</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Ensure</span> <span class="string">the</span> <span class="string">new</span> <span class="string">system</span> <span class="string">is</span> <span class="string">registered</span> <span class="string">with</span> <span class="string">Red</span> <span class="string">Hat</span> <span class="string">Insights</span></span><br><span class="line">      <span class="attr">redhat.insights.insights_register:</span></span><br><span class="line">        <span class="attr">state:</span> <span class="string">present</span></span><br><span class="line">        <span class="attr">force_reregister:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<p>The play in the following playbook uses the organizations role from the redhat.satellite collection.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Add</span> <span class="string">the</span> <span class="string">test</span> <span class="string">organizations</span> <span class="string">to</span> <span class="string">Red</span> <span class="string">Hat</span> <span class="string">Satellite</span></span><br><span class="line">  <span class="attr">hosts:</span> <span class="string">localhost</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Ensure</span> <span class="string">the</span> <span class="string">organizations</span> <span class="string">exist</span></span><br><span class="line">      <span class="attr">ansible.builtin.include_role:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">redhat.satellite.organizations</span></span><br><span class="line">      <span class="attr">vars:</span></span><br><span class="line">        <span class="attr">satellite_server_url:</span> <span class="string">https://sat.example.com</span></span><br><span class="line">        <span class="attr">satellite_username:</span> <span class="string">admin</span></span><br><span class="line">        <span class="attr">satellite_password:</span> <span class="string">Sup3r53cr3t</span></span><br><span class="line">        <span class="attr">satellite_organizations:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test1</span></span><br><span class="line">            <span class="attr">label:</span> <span class="string">tst1</span></span><br><span class="line">            <span class="attr">state:</span> <span class="string">present</span></span><br></pre></td></tr></table></figure>

<p>Many Ansible Content Collections also use this <code>redirection mechanism</code> to translate old short names into Fully Qualified Collection Names (FQCN). </p>
<p>For example, the acl module is now part of the ansible.posix collection, and it uses ansible.posix.acl as its FQCN.</p>
<h3 id="Using-the-Built-in-Ansible-Content-Collection"><a href="#Using-the-Built-in-Ansible-Content-Collection" class="headerlink" title="Using the Built-in Ansible Content Collection"></a>Using the Built-in Ansible Content Collection</h3><p>Ansible always includes a special collection named ansible.builtin. This collection includes a set of common modules, such as <code>copy</code>, <code>template</code>, <code>file</code>, <code>yum</code>, <code>command</code>, and <code>service</code>.</p>
<p>You can use the <code>short names</code> of these modules in your playbooks. For example, you can use <code>file</code> to refer to the <code>ansible.builtin.file</code> module. </p>
<p>However, Red Hat recommends that you use the FQCN notation to prevent conflicts with collections that might use the same module names.</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title>Artificial Intelligence Series (Chapter 0): Local Deployment of Large Models</title>
    <url>//Artificial-Intelligence/Deepseek/Local-deployment-of-large-models/index.html</url>
    <content><![CDATA[<h2 id="The-Ice-breaking-Topic"><a href="#The-Ice-breaking-Topic" class="headerlink" title="The Ice-breaking Topic"></a>The Ice-breaking Topic</h2><p>Why should we try to deploy the AI Models in my local environment?</p>
<ol>
<li><code>Data Privacy and Security</code></li>
</ol>
<ul>
<li><p>Protecting Sensitive Data: When dealing with sensitive data (such as healthcare, finance, or personal privacy), deploying AI models locally can prevent data from being uploaded to the cloud, thereby reducing the risk of data breaches.</p>
</li>
<li><p>Compliance Requirements: Some industries have stringent regulations regarding data storage and processing, such as the GDPR in Europe, which encourages businesses to deploy AI models locally.</p>
</li>
</ul>
<ol start="2">
<li><code>Latency and Performance</code></li>
</ol>
<ul>
<li><p>Reducing Network Latency: Deploying models locally can reduce the latency associated with data transmission, particularly for applications that require real-time or low-latency processing, such as autonomous driving or video surveillance.</p>
</li>
<li><p>High-Performance Computing: Local deployment allows full utilisation of local hardware resources, providing higher computational performance. The cloud may face limitations in bandwidth and computational resources, while local hardware can be optimised and tailored to the specific needs of the task.</p>
</li>
</ul>
<ol start="3">
<li><code>Cost Control</code></li>
</ol>
<ul>
<li><p>Avoiding Cloud Service Costs: While cloud computing is flexible, it can become costly over the long term. Especially in scenarios with high computational and storage needs, local deployment can help businesses reduce their reliance on cloud resources and lower costs.</p>
</li>
<li><p>On-Demand Hardware Expansion: Businesses can purchase appropriate hardware resources as needed, avoiding the fixed costs of cloud service providers.</p>
</li>
</ul>
<ol start="4">
<li><code>Control and Customisation</code></li>
</ol>
<ul>
<li><p>Complete Control: Deploying AI models locally ensures full control over both hardware and software, allowing businesses to customise and optimise the deployment environment to meet specific needs.</p>
</li>
<li><p>Flexibility: Companies have the freedom to choose the computing platform (e.g., GPU, TPU, CPU) and system architecture, enabling finer-grained optimisation.</p>
</li>
</ul>
<ol start="5">
<li><code>Offline Operation and High Availability</code></li>
</ol>
<ul>
<li><p>No Reliance on the Internet: For certain application scenarios (such as remote areas or offshore platforms), local deployment ensures that the system continues to function without an internet connection.</p>
</li>
<li><p>High Availability: Local deployment reduces dependence on external cloud service providers, helping businesses avoid disruptions caused by network issues or cloud service outages.</p>
</li>
</ul>
<ol start="6">
<li><code>Environment Adaptation</code></li>
</ol>
<ul>
<li><p>Optimising Hardware Resources: AI models deployed locally can be optimised according to the specific hardware environment (e.g., dedicated GPUs or custom hardware accelerators).</p>
</li>
<li><p>Reducing Shared Cloud Resources: Cloud platforms often share resources among multiple customers, which can lead to performance fluctuations. Local deployment can avoid this resource contention.</p>
</li>
</ul>
<hr>
<h2 id="Deploying-Large-Models-in-local"><a href="#Deploying-Large-Models-in-local" class="headerlink" title="Deploying Large Models in local"></a>Deploying Large Models in local</h2><p>Here, I would like to introduce how to deploy <code>ollama</code> by using docker.</p>
<p>In fact, there are many methods to deploy.</p>
<p>Eg. Install in pysical machine by using <code>curl</code> command in Linux, Download compressions and unzip the packages to install in Windows&#x2F;MacOS operating system. What’s more, you could install ollama by <code>pip</code> as well.</p>
<p>More detailed information, please visit <a href="https://github.com/ollama/ollama">the ollama GitHub</a>.</p>
<h3 id="Deploying-the-Ollama"><a href="#Deploying-the-Ollama" class="headerlink" title="Deploying the Ollama"></a>Deploying the Ollama</h3><h4 id="Deploying-in-docker"><a href="#Deploying-in-docker" class="headerlink" title="Deploying in docker"></a>Deploying in docker</h4><p>The official <a href="https://hub.docker.com/r/ollama/ollama">Ollama Docker image</a> ollama&#x2F;ollama is available on Docker Hub.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># CPU Only</span></span><br><span class="line">docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama</span><br></pre></td></tr></table></figure>

<p>About the docker knowledge, I have already introduced before. You could review <a href="https://blog.sunhaoyang.net/Cloud/Docker/Installing-docker-engine-in-Ubuntu/index.html">here</a>.</p>
<p>After pulling the image from DockerHub, you could use the command <code>ollama -v</code> to check the version of the current ollama.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Check the version of ollama</span></span><br><span class="line">ollama -v</span><br></pre></td></tr></table></figure>

<h4 id="Deploying-in-the-physical-machine"><a href="#Deploying-in-the-physical-machine" class="headerlink" title="Deploying in the physical machine"></a>Deploying in the physical machine</h4><p>Different operating system has different methods to deploy ollama in physical.</p>
<p>Here, in this case we will use <code>curl</code> command for local deployment in Linux OS.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Download the deploy script from the official website and execute the installation shell</span></span><br><span class="line">curl -fsSL https://ollama.com/install.sh | sh</span><br></pre></td></tr></table></figure>

<p>After completing the download process, you could check the status of ollama service.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Use the systemctl command to check the service status</span></span><br><span class="line"><span class="built_in">sudo</span> systemctl status ollama</span><br></pre></td></tr></table></figure>

<p>Similarly, you could use the command <code>ollama -v</code> to check the version of ollama you have installed.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Check the version of ollama</span></span><br><span class="line">ollama -v</span><br></pre></td></tr></table></figure>

<p>For even more information about downloading ollama, please refer to <a href="https://ollama.com/download">the official website</a>.</p>
<h3 id="Pulling-the-models-from-ollama-library"><a href="#Pulling-the-models-from-ollama-library" class="headerlink" title="Pulling the models from ollama library"></a>Pulling the models from ollama library</h3><p>There are plenty of models you could pull from <a href="https://ollama.com/search">the ollama library</a>.</p>
<blockquote>
<p>Please refer to your own server’s performance and configuration to choose the model.</p>
</blockquote>
<p>Eg. <code>12 cores CPU + 32 GB Memory</code> &#x3D;&gt; <code>deepseek-r1:8b</code> is recommended.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Pull the model from the ollama library</span></span><br><span class="line">ollama pull deepseek-r1:8b</span><br><span class="line"></span><br><span class="line"><span class="comment"># Pull and run the model in local</span></span><br><span class="line">ollama run deepseek-r1:8b</span><br></pre></td></tr></table></figure>

<p>If you pulled the model successfully, you could use the command <code>ollama list(ls)</code> to confirm the result.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ollama list/ls</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="Interact-with-the-local-models"><a href="#Interact-with-the-local-models" class="headerlink" title="Interact with the local models"></a>Interact with the local models</h2><p>There are two ways to interact with local models.</p>
<ul>
<li><p>Use the <code>ollama run</code> command in CLI.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ollama run [the model name:tag]</span><br></pre></td></tr></table></figure>

<p>It will guide you in the CLI. You could use <code>ctrl+d</code> or <code>/bye</code> to quit the interaction in CLI.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Run the LLM in local as you specifiy</span></span><br><span class="line">ollama run deepseek-r1:8b</span><br><span class="line">&gt;&gt;&gt; Send a message (/? <span class="keyword">for</span> <span class="built_in">help</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>Visit and question in front-end website <code>open-webui</code>.</p>
<ul>
<li><p>Deploying the <code>open-webui</code> in docker.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># If Ollama is on your computer, use this command</span></span><br><span class="line">docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main</span><br><span class="line"></span><br><span class="line"><span class="comment"># If Ollama is on a Different Server, use this command</span></span><br><span class="line">docker run -d -p 3000:8080 -e OLLAMA_BASE_URL=https://example.com -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main</span><br></pre></td></tr></table></figure>
</li>
<li><p>Deploying the <code>open-webui</code> by <code>pip</code>.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Install</span></span><br><span class="line">pip install open-webui</span><br><span class="line"></span><br><span class="line"><span class="comment"># Execute</span></span><br><span class="line">open-webui serve </span><br></pre></td></tr></table></figure></li>
</ul>
<p>By the way, Deploying in docker is recommended.</p>
</li>
</ul>
<hr>
<h2 id="Login-and-Question-offline"><a href="#Login-and-Question-offline" class="headerlink" title="Login and Question offline"></a>Login and Question offline</h2><p>The final step for you here is to login the open-webui website and let’s question!</p>
<p>You could use <code>http://ip:port</code> or <code>http://localhost:port</code> to visit your local UI.</p>
<p>Set the administrator (name + email + password) and then you could login.</p>
<p>Selecting the various types of models you’ve already downloaded in local.</p>
<p>You could also select more than one model and compare the results at the same time.</p>
<p>The demo representation is shown as below.</p>
<p><img src="/../images/open-webui.png" alt="Local open-webui"></p>
<p>Congratulations to you! Now you can have a good time experimenting with large models locally ：）</p>
]]></content>
      <categories>
        <category>Artificial Intelligence</category>
      </categories>
      <tags>
        <tag>Deepseek</tag>
      </tags>
  </entry>
  <entry>
    <title>Ceph Series (Chapter 0): Deploying the ceph cluster by cephadm</title>
    <url>//Cloud/Ceph/Deploying-the-ceph-cluster-by-cephadm/index.html</url>
    <content><![CDATA[<h2 id="What-is-Ceph"><a href="#What-is-Ceph" class="headerlink" title="What is Ceph?"></a>What is Ceph?</h2><p>At first, the phonetic transcription of ‘Ceph’ is &#x2F;sɛf&#x2F;. The name ‘Ceph’ comes from ‘cephalopod,’ which refers to marine animals such as octopuses and squids. </p>
<p>Similarly, Ceph, as an open-source distributed storage system, has garnered widespread attention and application due to its high scalability, reliability, and performance. </p>
<p>Ceph supports multiple storage interfaces such as <strong><code>object storage</code></strong>, <strong><code>block storage</code></strong>, and <strong><code>file system storage</code></strong>, meeting the storage needs in various business scenarios.</p>
<p>This article will provide a detailed guide on how to deploy a Ceph distributed storage cluster from scratch using containerization on the Rocky 9.5 operating system. Through this guide, you will be able to master the installation, configuration, and management of Ceph.</p>
<p>Replacing ceph-ansible, through containerization, <code>cephadm</code> provides a standardized approach to operate Ceph clusters, effectively reducing operational complexity.</p>
<hr>
<h2 id="Deployment-Plan-Table"><a href="#Deployment-Plan-Table" class="headerlink" title="Deployment Plan Table"></a>Deployment Plan Table</h2><p>Most readers are encountering Ceph for the first time. To make it clearer and more intuitive, I have created the following deployment plan table to help you deploy the ceph cluster in VMware virtual environment.</p>
<table>
<thead>
<tr>
<th align="center">Number</th>
<th align="center">Operating System</th>
<th align="center">Ceph Version</th>
<th align="center">Role</th>
<th align="center">IP</th>
<th align="center">Configuration</th>
<th align="center">Hostname</th>
</tr>
</thead>
<tbody><tr>
<td align="center">001</td>
<td align="center">Rocky9.5(x86_64)</td>
<td align="center">squid (latest 19.2.0)</td>
<td align="center">bootstrap，mon，mgr，osd</td>
<td align="center">172.16.173.129</td>
<td align="center">core(s):4, memeory:4G, disk: 500G*4</td>
<td align="center">ceph001.haoyang.cn</td>
</tr>
<tr>
<td align="center">002</td>
<td align="center">Rocky9.5(x86_64)</td>
<td align="center">squid (latest 19.2.0)</td>
<td align="center">mon，mgr，osd</td>
<td align="center">172.16.173.130</td>
<td align="center">core(s):4, memeory:4G, disk: 500G*4</td>
<td align="center">ceph002.haoyang.cn</td>
</tr>
<tr>
<td align="center">003</td>
<td align="center">Rocky9.5(x86_64)</td>
<td align="center">squid (latest 19.2.0)</td>
<td align="center">mon，mgr，osd</td>
<td align="center">172.16.173.131</td>
<td align="center">core(s):4, memeory:4G, disk: 500G*4</td>
<td align="center">ceph003.haoyang.cn</td>
</tr>
</tbody></table>
<ul>
<li><p>Because you will deploy the ceph cluster in VMware, you need to download the x86_64 structure iso image from <strong><a href="https://download.rockylinux.org/pub/rocky/9/isos/x86_64/Rocky-9.5-x86_64-minimal.iso">Rocky Linux Official Website</a></strong> to install the Rocky9.5 operating system as the base. I used the minimal version to install rocky, so you could not copy&#x2F;paste from your desktop to rocky. You’d better use <strong>ssh command</strong> to login in Rocky Linux remotely.</p>
</li>
<li><p>More information about the Ceph Release Version, please visit the <strong><a href ="https://docs.ceph.com/en/latest/releases/">Official Website</a></strong>.</p>
</li>
<li><p>More detailed information about the Role, for example: “What’s the meaning of mon&#x2F;mgr&#x2F;osd?” or “What do these words stand for?” .etc, please visit my another blog: <strong><a href="https://blog.sunhaoyang.net/Cloud/Ceph/Introducing-Red-Hat-Ceph-Storage-Architecture/index.html">Ceph Series (Chapter 1):Introducing Red Hat Ceph Storage Architecture</a></strong>. </p>
</li>
<li><p>From the aspect of IP address, I just set the network adaptor to NAT mode and I used the default subnet IP as well as the default generated IP address here. It doesn’t matter if you’d like to modify the subnet IP as what you want, and you may get another random IP address finally. As long as these three virtual machines can communicate with each other, that’s enough.</p>
</li>
<li><p>According to the performance of your hardware, I recommend you to set 4C&#x2F;4G&#x2F;500G*4 here. Don’t worry about disk space issues because of the <strong><code>Thin Provisioning Mechanism</code></strong>. When creating virtual disks, only the space for the actual data used is allocated. The total capacity declared by the virtual disk is just a logical value, and the actual storage space is dynamically allocated as the data grows.</p>
</li>
<li><p>As for the hostname, it’s fine as long as it’s simple and easy to understand. You can name it however you like. I used my Chinese name to represent the hostname here.</p>
</li>
</ul>
<hr>
<h2 id="Prerequisites"><a href="#Prerequisites" class="headerlink" title="Prerequisites"></a>Prerequisites</h2><p><span style="color: red;">Please note that, unless specified，otherwise, the following prerequisites must be completed on all nodes.</span></p>
<h3 id="Setting-the-specified-hostname"><a href="#Setting-the-specified-hostname" class="headerlink" title="Setting the specified hostname"></a>Setting the specified hostname</h3><p>Set an appropriate hostname on each node for resolution.</p>
<p>Take the first node, 001, as an example here.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hostnamectl hostname ceph001.haoyang.cn</span><br></pre></td></tr></table></figure>

<h3 id="Setting-the-resolution-between-the-cluster"><a href="#Setting-the-resolution-between-the-cluster" class="headerlink" title="Setting the resolution between the cluster"></a>Setting the resolution between the cluster</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /etc/hosts &lt;&lt;-<span class="string">&#x27;EOF&#x27;</span></span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">172.16.173.129 ceph001.haoyang.cn ceph001</span><br><span class="line">172.16.173.130 ceph002.haoyang.cn ceph002</span><br><span class="line">172.16.173.131 ceph003.haoyang.cn ceph003</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="Configuring-the-dnf-software-repository"><a href="#Configuring-the-dnf-software-repository" class="headerlink" title="Configuring the dnf software repository"></a>Configuring the dnf software repository</h3><p>I provided two configurations here.</p>
<blockquote>
<p>The repository provided by Ceph’s official site.</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /etc/yum.repos.d/ceph.repo &lt;&lt;-<span class="string">&#x27;EOF&#x27;</span></span><br><span class="line">[ceph]</span><br><span class="line">name=Ceph packages <span class="keyword">for</span> x86_64</span><br><span class="line">baseurl=https://download.ceph.com/rpm-squid/el9/x86_64</span><br><span class="line">enabled=1</span><br><span class="line">priority=2</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://download.ceph.com/keys/release.asc</span><br><span class="line"></span><br><span class="line">[ceph-noarch]</span><br><span class="line">name=Ceph noarch packages</span><br><span class="line">baseurl=https://download.ceph.com/rpm-squid/el9/noarch</span><br><span class="line">enabled=1</span><br><span class="line">priority=2</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://download.ceph.com/keys/release.asc</span><br><span class="line"></span><br><span class="line">[ceph-source]</span><br><span class="line">name=Ceph <span class="built_in">source</span> packages</span><br><span class="line">baseurl=https://download.ceph.com/rpm-squid/el9/SRPMS</span><br><span class="line">enabled=0</span><br><span class="line">priority=2</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://download.ceph.com/keys/release.asc</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Using Nanjing University for repository acceleration.</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /etc/yum.repos.d/ceph.repo &lt;&lt;-<span class="string">&#x27;EOF&#x27;</span></span><br><span class="line">[ceph]</span><br><span class="line">name=Ceph packages <span class="keyword">for</span> x86_64</span><br><span class="line">baseurl=https://mirrors.nju.edu.cn/ceph/rpm-squid/el9/x86_64</span><br><span class="line">enabled=1</span><br><span class="line">priority=2</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://mirrors.nju.edu.cn/ceph/keys/release.asc</span><br><span class="line"></span><br><span class="line">[ceph-noarch]</span><br><span class="line">name=Ceph noarch packages</span><br><span class="line">baseurl=https://mirrors.nju.edu.cn/ceph/rpm-squid/el9/noarch</span><br><span class="line">enabled=1</span><br><span class="line">priority=2</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://mirrors.nju.edu.cn/ceph/keys/release.asc</span><br><span class="line"></span><br><span class="line">[ceph-source]</span><br><span class="line">name=Ceph <span class="built_in">source</span> packages</span><br><span class="line">baseurl=https://mirrors.nju.edu.cn/ceph/rpm-squid/el9/SRPMS</span><br><span class="line">enabled=0</span><br><span class="line">priority=2</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=https://mirrors.nju.edu.cn/ceph/keys/release.asc</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="Updating-and-generating-the-cache-for-the-dnf-package-manager"><a href="#Updating-and-generating-the-cache-for-the-dnf-package-manager" class="headerlink" title="Updating and generating the cache for the dnf package manager"></a>Updating and generating the cache for the dnf package manager</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">dnf makecache</span><br></pre></td></tr></table></figure>

<h3 id="Installing-the-necessary-software-packages"><a href="#Installing-the-necessary-software-packages" class="headerlink" title="Installing the necessary software packages"></a>Installing the necessary software packages</h3><ul>
<li>Python 3</li>
<li>Systemd</li>
<li>Podman</li>
<li>Chrony</li>
<li>LVM2</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">dnf install podman chrony lvm2 systemd python3 bash-completion wget curl epel-release -y</span><br></pre></td></tr></table></figure>

<p>It may update critical components like systemd, so please <strong><code>restart</code></strong> the server after the installation.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">reboot</span><br></pre></td></tr></table></figure>

<h3 id="Enabling-NTP-synchronization"><a href="#Enabling-NTP-synchronization" class="headerlink" title="Enabling NTP synchronization"></a>Enabling NTP synchronization</h3><p>By default, it syncs from public network sources, but you can specify your own time source. Here, I use <em><strong>ntp.aliyun.com</strong></em>.</p>
<p>Edit the configuration file and add the following line <code>pool ntp.aliyun.com iburst</code> at the very beginning.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vi /etc/chrony.conf</span><br><span class="line"><span class="comment"># Use public servers from the pool.ntp.org project.</span></span><br><span class="line"><span class="comment"># Please consider joining the pool (https://www.pool.ntp.org/join.html).</span></span><br><span class="line">pool ntp.aliyun.com iburst</span><br><span class="line">pool 2.rocky.pool.ntp.org iburst</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<p>After editing the <code>/etc/chrony.conf</code> file, please set the <code>chronyd.service</code> to start automatically at boot and take effect immediately.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl <span class="built_in">enable</span> chronyd --now</span><br><span class="line">systemctl restart chronyd</span><br></pre></td></tr></table></figure>

<h3 id="Installing-cephadm"><a href="#Installing-cephadm" class="headerlink" title="Installing cephadm"></a>Installing cephadm</h3><p>Installing the cephadm tool is sufficient, but I also install the <code>ceph-common</code> package to execute various Ceph commands like ceph and rados directly on the host. Since Ceph is deployed in a containerized manner with cephadm, these commands are not available on the host by default. By installing <code>ceph-common</code>, you can avoid logging into the container each time, making it more efficient.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">dnf install cephadm ceph-common -y</span><br></pre></td></tr></table></figure>

<p>Up to this point, all prerequisites have been completed.</p>
<hr>
<h2 id="Deploying-a-new-ceph-cluster"><a href="#Deploying-a-new-ceph-cluster" class="headerlink" title="Deploying a new ceph cluster"></a>Deploying a new ceph cluster</h2><p>Cephadm bootstrap is the first step in initializing a Ceph cluster. It creates a small initial Ceph cluster by bootstrapping, which includes a monitor (mon) and a manager (mgr). This is the foundational step for the entire Ceph cluster deployment and management process.</p>
<p>The <code>cephadm bootstrap</code> command will perform the following actions:</p>
<ul>
<li><p>Create a monitor (mon) and a manager (mgr) <code>daemon</code> on the local host for the new cluster.</p>
</li>
<li><p>Generate a new SSH key for the Ceph cluster and add it to the root user’s <code>/root/.ssh/authorized_keys</code> file.</p>
</li>
<li><p>Write a copy of the public key to the <code>/etc/ceph/ceph.pub</code> file.</p>
</li>
<li><p>Write a minimal configuration file to <code>/etc/ceph/ceph.conf</code>, which is used for communication with the Ceph daemons.</p>
</li>
<li><p>Write a copy of the client.admin administrator (privileged) key to the <code>/etc/ceph/ceph.client.admin.keyring</code> file.</p>
</li>
<li><p>Add the _admin label to the bootstrap host. By default, any host with this label will also receive copies of the <code>/etc/ceph/ceph.conf</code> and <code>/etc/ceph/ceph.client.admin.keyring</code> files.</p>
</li>
</ul>
<p>If the hostname is <strong><u>Fully Qualified Domain Name</u></strong>(<code>FQDN</code>), you need to add the specific parameter: <code>--allow-fqdn-hostname</code>.</p>
<p>P.S. FQDN format could be like that, for example: <code>host.example.com.</code></p>
<p>host name: <code>host</code></p>
<p>domain name: <code>example.com</code></p>
<p>root domain: <code>.</code> (Omitted in daily use)</p>
<p>If you are doing a <strong><u>single-node</u></strong> deployment, you need to add the specific parameter: <code>--single-host-defaults</code>. </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cephadm bootstrap --mon-ip 172.16.173.129 --single-host-defaults --initial-dashboard-user admin --initial-dashboard-password Sunhaoyang --dashboard-password-noupdate --allow-fqdn-hostname</span><br></pre></td></tr></table></figure>

<p>This deployment uses a <strong><u>multi-node</u></strong> setup.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cephadm bootstrap --mon-ip 172.16.173.129 --initial-dashboard-user admin --initial-dashboard-password Sunhaoyang --dashboard-password-noupdate --allow-fqdn-hostname</span><br></pre></td></tr></table></figure>

<p>More than these parameters, all usage of all parameters could be checked by using <code>cephadm bootstrap --help</code>.</p>
<ul>
<li><p><code>--mon-ip</code> specifies the IP address of the monitor (mon) that will be created during the bootstrap process. This is the IP address of the host where the initial MON daemon will run.</p>
</li>
<li><p><code>--initial-dashboard-user</code> sets the username for the Ceph dashboard’s initial administrative user. In this case, the username will be admin.</p>
</li>
<li><p><code>--initial-dashboard-password</code> specifies the password for the initial administrative user of the Ceph dashboard. The password will be set to Sunhaoyang.</p>
</li>
<li><p><code>--dashboard-password-noupdate</code> prevents the Ceph cluster from automatically updating the dashboard password after the bootstrap process. This ensures the password specified in <code>--initial-dashboard-password</code> remains unchanged.</p>
</li>
<li><p><code>--allow-fqdn-hostname</code> allows the use of a Fully Qualified Domain Name (FQDN) as the hostname for the Ceph cluster’s initial node. This is useful when the hostname includes domain information, such as ceph.example.com.</p>
</li>
</ul>
<p>Finally, the installation console output looks like this.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Ceph Dashboard is now available at:</span><br><span class="line"></span><br><span class="line">             URL: https://ceph001.haoyang.cn:8443/</span><br><span class="line">            User: admin</span><br><span class="line">        Password: Sunhaoyang</span><br><span class="line">...</span><br><span class="line">Bootstrap complete.</span><br></pre></td></tr></table></figure>

<p>You could not use the promption <code>URL</code> to visit the front-end ceph website, because you did not set the resolution in your local <code>/etc/hosts</code> file. While, you could use IP address + port to visit it directly, such as: <a href="https://172.16.173.129:8443/">https://172.16.173.129:8443/</a>.</p>
<p>When you are opening the website, you may be reminded that the website is unsafe. Now, you need to agree with it by clicking <code>advanced</code> button and then clicking <code>continue</code> button.</p>
<p><img src="/../images/dashboard_yellow.png" alt="ceph_dashboard_yellow"></p>
<p>As shown in the image, the page has already prompted us to expand the cluster, and there is a yellow warning next to the dashboard icon in the top left corner. Next, let’s add some disks to the cluster.</p>
<h2 id="Deploying-OSD-resources"><a href="#Deploying-OSD-resources" class="headerlink" title="Deploying OSD resources"></a>Deploying OSD resources</h2><p>In Ceph, OSD (Object Storage Daemon) is one of the essential components of the storage cluster. Its main responsibilities include storing data, handling data replication, recovery, backfilling, and rebalancing operations.</p>
<p>Key Concepts of Ceph OSD:</p>
<ul>
<li><p>Data Storage:</p>
<p>OSDs are responsible for storing data objects. Each OSD usually corresponds to a physical storage device, such as a hard drive or SSD.</p>
</li>
<li><p>Data Replication:</p>
<p>To ensure high availability and durability, OSDs replicate data among themselves. Ceph uses the CRUSH algorithm to determine the placement of data.</p>
</li>
<li><p>Data Recovery:</p>
<p>When an OSD fails or goes offline, the cluster automatically recovers data from other OSDs and replicates it to new OSDs.</p>
</li>
<li><p>Backfilling and Rebalancing:</p>
<p>Backfilling refers to redistributing data after an OSD is restored or new OSDs are added to ensure data is evenly distributed.</p>
<p>Rebalancing ensures load balancing across OSDs to prevent overloading certain OSDs.</p>
</li>
<li><p>Monitoring and Management:</p>
<p>OSDs use a heartbeat mechanism to report their status to the Ceph cluster, ensuring cluster health and consistency.</p>
</li>
</ul>
<p>Having understood Ceph OSDs, let’s proceed to add some OSDs to the cluster to complete the expansion of the Ceph cluster.</p>
<p>Based on the <a href="#Deployment-Plan-Table">Deployment Plan Table</a>, you have already added four disks in total for each node. </p>
<p>Excluding the partation used for installing the operating system, there are three remaining disks: <code>nvme0n2</code>, <code>nvme0n3</code> and <code>nvme0n4</code>.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph001 ~]# lsblk</span><br><span class="line">NAME        MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS</span><br><span class="line">sr0          11:0    1  1024M  0 rom</span><br><span class="line">nvme0n1     259:0    0   500G  0 disk</span><br><span class="line">├─nvme0n1p1 259:1    0   600M  0 part /boot/efi</span><br><span class="line">├─nvme0n1p2 259:2    0     1G  0 part /boot</span><br><span class="line">└─nvme0n1p3 259:3    0 498.4G  0 part</span><br><span class="line">  ├─rl-root 253:0    0 494.5G  0 lvm  /var/lib/containers/storage/overlay</span><br><span class="line">  │                                   /</span><br><span class="line">  └─rl-swap 253:1    0   3.9G  0 lvm  [SWAP]</span><br><span class="line">nvme0n2     259:4    0   500G  0 disk</span><br><span class="line">nvme0n3     259:5    0   500G  0 disk</span><br><span class="line">nvme0n4     259:6    0   500G  0 disk</span><br></pre></td></tr></table></figure>

<p>Then, you could use these three remaining disks and add OSD daemon into the cluster.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph001 ~]# ceph orch daemon add osd ceph001.haoyang.cn:/dev/nvme0n2</span><br><span class="line">Created osd(s) 0 on host &#x27;ceph001.haoyang.cn&#x27;</span><br><span class="line">[root@ceph001 ~]# ceph orch daemon add osd ceph001.haoyang.cn:/dev/nvme0n3</span><br><span class="line">Created osd(s) 1 on host &#x27;ceph001.haoyang.cn&#x27;</span><br><span class="line">[root@ceph001 ~]# ceph orch daemon add osd ceph001.haoyang.cn:/dev/nvme0n4</span><br><span class="line">Created osd(s) 2 on host &#x27;ceph001.haoyang.cn&#x27;</span><br></pre></td></tr></table></figure>

<p>Let’s check the list of OSD now.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph001 ~]# ceph osd crush tree</span><br><span class="line">ID  CLASS  WEIGHT   TYPE NAME</span><br><span class="line">-1         1.46489  root default</span><br><span class="line">-3         1.46489      host ceph001</span><br><span class="line"> 0    ssd  0.48830          osd.0</span><br><span class="line"> 1    ssd  0.48830          osd.1</span><br><span class="line"> 2    ssd  0.48830          osd.2</span><br></pre></td></tr></table></figure>

<p>If we manually add all the disks on each node one by one, it would be too tedious. Fortunately, we can use the parameter <code>--all-available-devices</code> to automatically detect and utilize all available storage devices in the system as OSDs. This simplifies the process of adding OSDs, eliminating the need to specify each device manually.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph001 ~]# ceph orch apply osd --all-available-devices</span><br><span class="line">Scheduled osd.all-available-devices update...</span><br></pre></td></tr></table></figure>

<h2 id="Add-new-hosts-to-the-cluster"><a href="#Add-new-hosts-to-the-cluster" class="headerlink" title="Add new hosts to the cluster"></a>Add new hosts to the cluster</h2><p><span style="color: red;">The New host must meet all the <a href="#Prerequisites">Prerequisites</a> of this article before it can be added to the cluster.</span></p>
<p>Distribute the cluster’s SSH key to the authorized_keys file of the root user on all hosts to enable passwordless operations.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph001 ~]# ssh-copy-id -f -i /etc/ceph/ceph.pub root@ceph001.haoyang.cn</span><br><span class="line">Are you sure you want to continue connecting (yes/no/[fingerprint])? yes</span><br><span class="line"></span><br><span class="line">[root@ceph001 ~]# ssh-copy-id -f -i /etc/ceph/ceph.pub root@ceph002.haoyang.cn</span><br><span class="line">Are you sure you want to continue connecting (yes/no/[fingerprint])? yes</span><br><span class="line"></span><br><span class="line">[root@ceph001 ~]# ssh-copy-id -f -i /etc/ceph/ceph.pub root@ceph003.haoyang.cn</span><br><span class="line">Are you sure you want to continue connecting (yes/no/[fingerprint])? yes</span><br></pre></td></tr></table></figure>

<p>Lets’ check the current status of cluster’s host list.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph001 ~]# ceph orch host ls --detail</span><br><span class="line">HOST                ADDR         LABELS  STATUS  VENDOR/MODEL               CPU    RAM    HDD  SSD      NIC</span><br><span class="line">ceph001.haoyang.cn  172.16.173.129  _admin          VMware, Inc. (VMware20,1)  4C/4T  4 GiB  -    4/2.1TB  1</span><br><span class="line">1 hosts in cluster</span><br></pre></td></tr></table></figure>

<p>When adding a host to a Ceph cluster, it is typically necessary to specify both the hostname and the IP address. This is because:</p>
<ul>
<li><p>Hostname: Ceph uses hostnames to identify nodes in the cluster. These hostnames must be unique and resolvable throughout the cluster (usually configured via &#x2F;etc&#x2F;hosts or DNS).</p>
</li>
<li><p>IP Address: The IP address is crucial for communication between Ceph nodes. Specifying the IP address ensures that Ceph knows how to communicate with the host, especially in environments with multiple network interfaces or complex network configurations.</p>
</li>
</ul>
<p>After adding a host, <strong>the new host will automatically trigger the download of container images and the startup of containers</strong>, which might take some time to be ready. Additionally, since we previously configured automatic OSD addition, the disks on the new host will be automatically added to the cluster.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph001 ~]# ceph orch host add ceph002.haoyang.cn 172.16.173.130</span><br><span class="line">Added host &#x27;ceph002.haoyang.cn&#x27; with addr &#x27;172.16.173.130&#x27;</span><br><span class="line"></span><br><span class="line">[root@ceph001 ~]# ceph orch host add ceph003.haoyang.cn 172.16.173.131</span><br><span class="line">Added host &#x27;ceph003.haoyang.cn&#x27; with addr &#x27;172.16.173.131&#x27;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@ceph001 ~]# ceph orch host ls --detail</span><br><span class="line">HOST                ADDR            LABELS  STATUS  VENDOR/MODEL                      CPU  RAM    HDD  SSD      NIC  </span><br><span class="line">ceph001.haoyang.cn  172.16.173.129  _admin          VMware, Inc. VMware (VMware20,1)  N/A  4 GiB  -    4/2.1TB  1    </span><br><span class="line">ceph002.haoyang.cn  172.16.173.130  _admin          VMware, Inc. VMware (VMware20,1)  N/A  4 GiB  -    4/2.1TB  1    </span><br><span class="line">ceph003.haoyang.cn  172.16.173.131                  VMware, Inc. VMware (VMware20,1)  N/A  4 GiB  -    4/2.1TB  1    </span><br><span class="line">3 hosts in cluster</span><br></pre></td></tr></table></figure>

<p>The container image download and container startup in the new host will take some time. You can use the command to check if all services are running normally.</p>
<p>If everything is normal, all services will be in the “running” state.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph001 ~]# ceph orch ps</span><br><span class="line">NAME                   HOST                PORTS             STATUS             REFRESHED  AGE  MEM USE  MEM LIM  VERSION  IMAGE ID      CONTAINER ID  </span><br><span class="line">alertmanager.ceph001   ceph001.haoyang.cn  *:9093,9094       running (-11706s)     9m ago  22h    19.4M        -  0.25.0   4d8d4d8334be  d7d85f0d5f90  </span><br><span class="line">ceph-exporter.ceph001  ceph001.haoyang.cn                    running (-11706s)     9m ago  22h    18.7M        -  19.2.0   fd3234b9d664  41365c9457ee  </span><br><span class="line">ceph-exporter.ceph002  ceph002.haoyang.cn                    running (-11708s)     7m ago  22h    5553k        -  19.2.0   fd3234b9d664  37efd9d7f4e1  </span><br><span class="line">ceph-exporter.ceph003  ceph003.haoyang.cn                    running (-11709s)     7m ago  22h    5666k        -  19.2.0   fd3234b9d664  5270951d5acd  </span><br><span class="line">crash.ceph001          ceph001.haoyang.cn                    running (-11706s)     9m ago  22h    6685k        -  19.2.0   fd3234b9d664  56d8da9604fa  </span><br><span class="line">crash.ceph002          ceph002.haoyang.cn                    running (-11707s)     7m ago  22h    6681k        -  19.2.0   fd3234b9d664  5fc552cacd65  </span><br><span class="line">crash.ceph003          ceph003.haoyang.cn                    running (-11709s)     7m ago  22h    6689k        -  19.2.0   fd3234b9d664  ffd2d7310ac6  </span><br><span class="line">grafana.ceph001        ceph001.haoyang.cn  *:3000            running (-11706s)     9m ago  22h    76.1M        -  9.4.12   f3e6303dba5e  fdf44407fb4c  </span><br><span class="line">mgr.ceph001.hkkqlh     ceph001.haoyang.cn  *:9283,8765,8443  running (-11706s)     9m ago  22h     551M        -  19.2.0   fd3234b9d664  7ba2eecea18b  </span><br><span class="line">mgr.ceph002.mldtvp     ceph002.haoyang.cn  *:8443,9283,8765  running (-11707s)     7m ago  22h     452M        -  19.2.0   fd3234b9d664  bdfd928dabf9  </span><br><span class="line">mon.ceph001            ceph001.haoyang.cn                    running (-11706s)     9m ago  22h     134M    2048M  19.2.0   fd3234b9d664  2bcdeda36a41  </span><br><span class="line">mon.ceph002            ceph002.haoyang.cn                    running (-11708s)     7m ago  22h     130M    2048M  19.2.0   fd3234b9d664  91486fa9f36b  </span><br><span class="line">mon.ceph003            ceph003.haoyang.cn                    running (-11709s)     7m ago  22h     129M    2048M  19.2.0   fd3234b9d664  345686a5334d  </span><br><span class="line">node-exporter.ceph001  ceph001.haoyang.cn  *:9100            running (-11706s)     9m ago  22h    14.7M        -  1.5.0    68cb0c05b3f2  9cbaabb099cc  </span><br><span class="line">node-exporter.ceph002  ceph002.haoyang.cn  *:9100            running (-11708s)     7m ago  22h    15.0M        -  1.5.0    68cb0c05b3f2  1b8fdb1f51c0  </span><br><span class="line">node-exporter.ceph003  ceph003.haoyang.cn  *:9100            running (-11709s)     7m ago  22h    12.6M        -  1.5.0    68cb0c05b3f2  0796493a5f8e  </span><br><span class="line">osd.0                  ceph001.haoyang.cn                    running (-11709s)     9m ago  22h    40.4M    4096M  19.2.0   fd3234b9d664  490045e69852  </span><br><span class="line">osd.1                  ceph001.haoyang.cn                    running (-11709s)     9m ago  22h    43.8M    4096M  19.2.0   fd3234b9d664  d0ce9e899dd7  </span><br><span class="line">osd.2                  ceph001.haoyang.cn                    running (-11709s)     9m ago  22h    54.2M    4096M  19.2.0   fd3234b9d664  c3678e3dc74e  </span><br><span class="line">osd.3                  ceph002.haoyang.cn                    running (4h)          7m ago   4h    50.6M    4096M  19.2.0   fd3234b9d664  8787bc6caa84  </span><br><span class="line">osd.4                  ceph003.haoyang.cn                    running (4h)          7m ago   4h    51.9M    4096M  19.2.0   fd3234b9d664  be6e18374b5a  </span><br><span class="line">osd.5                  ceph002.haoyang.cn                    running (4h)          7m ago   4h    49.2M    4096M  19.2.0   fd3234b9d664  1877027bdbab  </span><br><span class="line">osd.6                  ceph003.haoyang.cn                    running (4h)          7m ago   4h    47.6M    4096M  19.2.0   fd3234b9d664  8236520080e4  </span><br><span class="line">osd.7                  ceph003.haoyang.cn                    running (4h)          7m ago   4h    52.9M    4096M  19.2.0   fd3234b9d664  93ee38964a01  </span><br><span class="line">osd.8                  ceph002.haoyang.cn                    running (4h)          7m ago   4h    50.1M    4096M  19.2.0   fd3234b9d664  a737972f17c7  </span><br><span class="line">prometheus.ceph001     ceph001.haoyang.cn  *:9095            running (-11706s)     9m ago  22h    85.6M        -  2.43.0   77ee200e57dc  ce155b30e24f  </span><br></pre></td></tr></table></figure>

<h2 id="Assigning-new-management-privileges"><a href="#Assigning-new-management-privileges" class="headerlink" title="Assigning new management privileges"></a>Assigning new management privileges</h2><p>For convenience in management, we will add <code>ceph002.haoyang.cn</code> as a management host.</p>
<p>Before assigning management privileges, let’s take a look at the configuration files and keys of the <code>ceph002.haoyang.cn</code> host.</p>
<p>Based on the information, there are no keys or configuration files present.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph002 ~]# ls /etc/ceph</span><br><span class="line">rbdmap</span><br></pre></td></tr></table></figure>

<p>Similarly, without the appropriate permissions, it is not possible to retrieve cluster information.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph002 ~]# ceph -s</span><br><span class="line">Error initializing cluster client: ObjectNotFound(&#x27;RADOS object not found (error calling conf_read_file)&#x27;)</span><br></pre></td></tr></table></figure>

<p>Let’s assign the <code>_admin</code> label to ceph002.haoyang.cn.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph001 ~]# ceph orch host label add ceph002.haoyang.cn _admin</span><br><span class="line">Added label _admin to host ceph002.haoyang.cn</span><br></pre></td></tr></table></figure>

<p>Checking the current status of the cluster’s host list again.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph001 ~]# ceph orch host ls --detail</span><br><span class="line">HOST                ADDR            LABELS  STATUS  VENDOR/MODEL                      CPU  RAM    HDD  SSD      NIC  </span><br><span class="line">ceph001.haoyang.cn  172.16.173.129  _admin          VMware, Inc. VMware (VMware20,1)  N/A  4 GiB  -    4/2.1TB  1    </span><br><span class="line">ceph002.haoyang.cn  172.16.173.130  _admin          VMware, Inc. VMware (VMware20,1)  N/A  4 GiB  -    4/2.1TB  1    </span><br><span class="line">ceph003.haoyang.cn  172.16.173.131                  VMware, Inc. VMware (VMware20,1)  N/A  4 GiB  -    4/2.1TB  1    </span><br><span class="line">3 hosts in cluster</span><br></pre></td></tr></table></figure>

<p>Checking the keys or configuration files again in ceph002.haoyang.cn.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph002 ~]# ls /etc/ceph</span><br><span class="line">ceph.client.admin.keyring  ceph.conf  rbdmap</span><br></pre></td></tr></table></figure>

<p>We can now confirm that <code>ceph002.haoyang.cn</code> has management privileges.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph002 ~]# ls /etc/ceph</span><br><span class="line">ceph.client.admin.keyring  ceph.conf  rbdmap</span><br></pre></td></tr></table></figure>

<p> If the following command executes successfully, it indicates that it has successfully obtained the cluster information and the permissions are working correctly.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph002 ~]# ceph -s</span><br><span class="line">  cluster:</span><br><span class="line">    id:     365472d8-d815-11ef-90ff-000c29c84d93</span><br><span class="line">    health: HEALTH_OK</span><br><span class="line"> </span><br><span class="line">  services:</span><br><span class="line">    mon: 3 daemons, quorum ceph001,ceph002,ceph003 (age 4h)</span><br><span class="line">    mgr: ceph001.hkkqlh(active, since 4h), standbys: ceph002.mldtvp</span><br><span class="line">    osd: 9 osds: 9 up (since 4h), 9 in (since 4h)</span><br><span class="line"> </span><br><span class="line">  data:</span><br><span class="line">    pools:   1 pools, 1 pgs</span><br><span class="line">    objects: 2 objects, 449 KiB</span><br><span class="line">    usage:   244 MiB used, 4.4 TiB / 4.4 TiB avail</span><br><span class="line">    pgs:     1 active+clean</span><br></pre></td></tr></table></figure>

<h2 id="Check-the-status-of-the-Ceph-cluster"><a href="#Check-the-status-of-the-Ceph-cluster" class="headerlink" title="Check the status of the Ceph cluster"></a>Check the status of the Ceph cluster</h2><p>Since we have added a new host and new OSDs to the cluster, the yellow status on the dashboard should have turned green.</p>
<p><img src="/../images/dashboard_green.png" alt="ceph_dashboard_green"></p>
<p>Finally, let’s use the command to check the cluster status!</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@ceph001 ~]# ceph -s</span><br><span class="line">  cluster:</span><br><span class="line">    id:     365472d8-d815-11ef-90ff-000c29c84d93</span><br><span class="line">    health: HEALTH_OK</span><br><span class="line"> </span><br><span class="line">  services:</span><br><span class="line">    mon: 3 daemons, quorum ceph001,ceph002,ceph003 (age 5h)</span><br><span class="line">    mgr: ceph001.hkkqlh(active, since 5h), standbys: ceph002.mldtvp</span><br><span class="line">    osd: 9 osds: 9 up (since 5h), 9 in (since 5h)</span><br><span class="line"> </span><br><span class="line">  data:</span><br><span class="line">    pools:   1 pools, 1 pgs</span><br><span class="line">    objects: 2 objects, 449 KiB</span><br><span class="line">    usage:   244 MiB used, 4.4 TiB / 4.4 TiB avail</span><br><span class="line">    pgs:     1 active+clean</span><br></pre></td></tr></table></figure>

<p>With this, our ceph cluster deployment has been successfully completed!</p>
]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>Ceph</tag>
      </tags>
  </entry>
  <entry>
    <title>Ceph Series (Chapter 1): Introducing Red Hat Ceph Storage Architecture</title>
    <url>//Cloud/Ceph/Introducing-Red-Hat-Ceph-Storage-Architecture/index.html</url>
    <content><![CDATA[<h2 id="Personas"><a href="#Personas" class="headerlink" title="Personas"></a>Personas</h2><p>The personas that are presented here embody the most common roles of Red Hat Ceph Storage users. You can simply understand the meaning of the word as “user role”.</p>
<p>In Red Hat Ceph Storage, there are three types of personas, namely the Storage Administrator, the Storage Operator and other Storage-related personas.</p>
<h3 id="Storage-Administrator"><a href="#Storage-Administrator" class="headerlink" title="Storage Administrator"></a><strong>Storage Administrator</strong></h3><p>The primary persona for Red Hat Ceph is the storage administrator. A Ceph storage administrator performs the following tasks:</p>
<ul>
<li><blockquote>
<p>Installs, configures, and maintains a Ceph storage cluster.</p>
</blockquote>
</li>
<li><blockquote>
<p>Educates infrastructure architects about Ceph capabilities and features.</p>
</blockquote>
</li>
<li><blockquote>
<p>Informs users about Ceph data presentation and methods, as choices for their data applications.</p>
</blockquote>
</li>
<li><blockquote>
<p>Provides resilience and recovery, such as replication, backup, and disaster recovery methods.</p>
</blockquote>
</li>
<li><blockquote>
<p>Automates and integrates through Infrastructure as Code.</p>
</blockquote>
</li>
<li><blockquote>
<p>Provides access for data analytics and advanced mass data mining.</p>
</blockquote>
</li>
</ul>
<h3 id="Storage-Operator"><a href="#Storage-Operator" class="headerlink" title="Storage Operator"></a><strong>Storage Operator</strong></h3><p>The secondary persona for Red Hat Ceph is the storage operator.Storage operators primarily use <em>the Ceph Dashboard GUI</em> to view and respond to cluster alerts and statistics. They also perform routine storage administration tasks that are defined as Dashboard workflows, such as replacing a failed storage device.</p>
<h3 id="Other-Storage-related-Personas"><a href="#Other-Storage-related-Personas" class="headerlink" title="Other Storage-related Personas"></a><strong>Other Storage-related Personas</strong></h3><p>Other personas that use Ceph directly include <em>application developers, project managers, and service administrators</em> with data processing, data warehouse, big data, and similar application needs. The storage administrator frequently communicates with these personas.</p>
<ul>
<li><p>Cloud Operator</p>
<blockquote>
<p>A cloud operator administers cloud resources at their organization, such as OpenStack or OpenShift infrastructures. The storage administrator works closely with a cloud operator to maintain the Ceph cluster that is configured to provide storage for those platforms.</p>
</blockquote>
</li>
<li><p>Automation Engineer</p>
<blockquote>
<p>Automation engineers frequently use Ceph directly. An automation engineer is responsible for creating playbooks for commonly repeated tasks. Storage administrators would be familiar with these same actions because they are typically the foremost Ceph subject matter experts.</p>
</blockquote>
</li>
<li><p>Application Developer (DevOps Developer)</p>
<blockquote>
<p>An application developer can be an original coder, maintainer, or other cloud user who is responsible for the correct deployment and behavior of an application. A storage administrator coordinates with the application developer to ensure that storage resources are available, sets quotas, and secures the application storage.</p>
</blockquote>
</li>
<li><p>Deployment Engineer (DevOps Engineer)</p>
<blockquote>
<p>In larger environments, dedicated personnel perform, manage, and tune application deployments, working with the storage administrator and the application developer.</p>
</blockquote>
</li>
<li><p>Application Architect</p>
<blockquote>
<p>A storage administrator relies on the application architect as a subject matter expert who can correlate between Ceph infrastructure layout and resource availability, scaling, and latency. This archicture expertise helps the storage administrator to design complex application deployments effectively. To support the cloud users and their applications, a storage administrator must comprehend those same aspects of resource availability, scaling, and latency.</p>
</blockquote>
</li>
<li><p>Infrastructure Architect</p>
<blockquote>
<p>A storage administrator must master the storage cluster’s architectural layout to manage resource location, capacity, and latency. The infrastructure architect for the Ceph cluster deployment and maintenance is a primary source of information for the storage administrator. The infrastructure architect might be a cloud service provider employee or a vendor solutions architect or consultant.</p>
</blockquote>
</li>
<li><p>Data Center Operator</p>
<blockquote>
<p>Personas at the lower Ceph storage infrastructure layer support data provisioning. Data center operators are typically employed by the public cloud service provider or the organization’s internal IT group in a private data center cloud. The storage administrator opens service tickets with the relevant public cloud service provider or internal IT group.</p>
</blockquote>
</li>
</ul>
<hr>
<h2 id="The-Basic-Architecture"><a href="#The-Basic-Architecture" class="headerlink" title="The Basic Architecture"></a>The Basic Architecture</h2><p>Ceph Storage is essentially a distributed data object store, based on <code>RADOS</code>(Reliable Autonomic Distributed Object Storage), which provides highly reliable, scalable, and self-healing distributed object storage.</p>
]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>Ceph</tag>
      </tags>
  </entry>
  <entry>
    <title>Complete Guide to Markdown Features</title>
    <url>//Tools/Markdown/Complete-Guide-to-Markdown-Features/index.html</url>
    <content><![CDATA[<h2 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h2><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">语法：# 标题名字（井号的个数代表标题的级数，最多到六级标题）</span><br></pre></td></tr></table></figure>

<h1 id="一级标题"><a href="#一级标题" class="headerlink" title="一级标题"></a>一级标题</h1><h2 id="二级标题"><a href="#二级标题" class="headerlink" title="二级标题"></a>二级标题</h2><h3 id="三级标题"><a href="#三级标题" class="headerlink" title="三级标题"></a>三级标题</h3><h4 id="四级标题"><a href="#四级标题" class="headerlink" title="四级标题"></a>四级标题</h4><h5 id="五级标题"><a href="#五级标题" class="headerlink" title="五级标题"></a>五级标题</h5><h6 id="六级标题"><a href="#六级标题" class="headerlink" title="六级标题"></a>六级标题</h6><hr>
<div STYLE="page-break-after: always;"></div>

<h2 id="文字样式"><a href="#文字样式" class="headerlink" title="文字样式"></a>文字样式</h2><h3 id="删除线"><a href="#删除线" class="headerlink" title="删除线"></a>删除线</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">语法：用两个 ~ 来包裹删除的内容</span><br><span class="line">~~文本内容被删除~~</span><br></pre></td></tr></table></figure>

<p><del>文本内容被删除</del></p>
<h3 id="斜体"><a href="#斜体" class="headerlink" title="斜体"></a>斜体</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">语法：用一个 \* 来包裹斜体的内容</span><br><span class="line"></span><br><span class="line"><span class="emphasis">_文本内容倾斜_</span></span><br></pre></td></tr></table></figure>

<p><em>文本内容倾斜</em></p>
<p>快捷键：选中需要斜体的内容后 <code>Ctrl</code>+<code>I</code></p>
<h3 id="加粗"><a href="#加粗" class="headerlink" title="加粗"></a>加粗</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">语法：用两个 \* 来包裹加粗的内容</span><br><span class="line"></span><br><span class="line"><span class="strong">**文本内容加粗**</span></span><br></pre></td></tr></table></figure>

<p><strong>文本内容加粗</strong></p>
<p>快捷键：选中需要加粗的内容后 <code>Ctrl</code>+<code>B</code></p>
<h3 id="斜体-加粗"><a href="#斜体-加粗" class="headerlink" title="斜体+加粗"></a>斜体+加粗</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">语法：用三个 \* 来包裹斜体+加粗的内容</span><br><span class="line"></span><br><span class="line"><span class="strong">**<span class="emphasis">_文本内容既倾斜又加粗_</span>**</span></span><br></pre></td></tr></table></figure>

<p><strong><em>文本内容既倾斜又加粗</em></strong></p>
<h3 id="下划线"><a href="#下划线" class="headerlink" title="下划线"></a>下划线</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">下划线是HTML语法：用 <span class="language-xml"><span class="tag">&lt;<span class="name">u</span>&gt;</span></span>&lt;\u&gt; 来包裹添加下划线内容</span><br><span class="line"></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">u</span>&gt;</span></span>文本内容添加下划线<span class="language-xml"><span class="tag">&lt;/<span class="name">u</span>&gt;</span></span></span><br></pre></td></tr></table></figure>

<p><u>文本内容添加下划线</u></p>
<p>快捷键：选中需要添加下划线的内容后 <code>Ctrl</code>+<code>U</code></p>
<h3 id="高亮（需在偏好设置勾选扩展语法）"><a href="#高亮（需在偏好设置勾选扩展语法）" class="headerlink" title="高亮（需在偏好设置勾选扩展语法）"></a>高亮（需在偏好设置勾选扩展语法）</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">语法：用 == 来包裹高亮内容</span><br><span class="line"></span><br><span class="line">==文本内容高亮==</span><br></pre></td></tr></table></figure>

<p>&#x3D;&#x3D;文本内容高亮&#x3D;&#x3D;</p>
<h3 id="下标（需在偏好设置勾选扩展语法）"><a href="#下标（需在偏好设置勾选扩展语法）" class="headerlink" title="下标（需在偏好设置勾选扩展语法）"></a>下标（需在偏好设置勾选扩展语法）</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">语法：用 ~ 来包裹下标内容</span><br><span class="line"></span><br><span class="line">水 H~2~O</span><br><span class="line">双氧水 H~2~O~2~</span><br></pre></td></tr></table></figure>

<p>水 H<del>2</del>O</p>
<p>双氧水 H<del>2</del>O<del>2</del></p>
<h3 id="上标（需在偏好设置内选扩展语法）"><a href="#上标（需在偏好设置内选扩展语法）" class="headerlink" title="上标（需在偏好设置内选扩展语法）"></a>上标（需在偏好设置内选扩展语法）</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">语法：用 ^ 来包裹上标内容</span><br><span class="line"></span><br><span class="line">平方米 m^2^</span><br><span class="line">立方米 m^3^</span><br></pre></td></tr></table></figure>

<p>平方米 m^2^<br>立方米 m^3^</p>
<hr>
<h2 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h2><p>表格的源码格式：</p>
<p>使用 <code>|</code> 来分隔不同的单元格，使用 <code>-</code> 来分隔表头和其他行：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">| name     | gender |</span><br><span class="line">| -------- | ------ |</span><br><span class="line">| Torvalds | Male   |</span><br><span class="line">| Tove     | Female |</span><br></pre></td></tr></table></figure>

<blockquote>
<p>为了使 Markdown 更清晰，<code>|</code> 和 <code>-</code> 两侧需要至少有一个空格（最左侧和最右侧的 <code>|</code> 外就不需要了）。</p>
</blockquote>
<p>可以跳过以上描述，因为表格的 markdown 源代码是由typora自动生成的。</p>
<p>实际上输入 <code>| Name | Gender |</code> 并按下 <code>enter</code> 键将创建一个包含两列的表。</p>
<p>创建表后，焦点在该表上将弹出一个表格工具栏，您可以在左上角调整表格，居中居左居右对齐或删除表格。您还可以右上角使用上下文菜单来移动，复制和添加&#x2F;删除列&#x2F;行。还可以在表格中包括内联 Markdown 语法，例如链接，粗体，斜体或删除线。</p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Gender</th>
</tr>
</thead>
<tbody><tr>
<td>Torvalds</td>
<td>Male</td>
</tr>
<tr>
<td>Tove</td>
<td>Female</td>
</tr>
</tbody></table>
<p>除此之外可以使用空格对齐不同行的单元格，并在左右两侧都使用 <code>|</code> 来标记单元格边界，在表头下方的分隔线标记中加入 <code>:</code>，即可标记下方单元格内容的对齐方式：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">| Name     | Gender | Age |</span><br><span class="line">| :------- | :----: | --: |</span><br><span class="line">| Torvalds |  Male  |  55 |</span><br><span class="line">| Tove     | Female |  58 |</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th align="left">Name</th>
<th align="center">Gender</th>
<th align="center">Age</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Torvalds</td>
<td align="center">Male</td>
<td align="center">55</td>
</tr>
<tr>
<td align="left">Tove</td>
<td align="center">Female</td>
<td align="center">58</td>
</tr>
</tbody></table>
<p>使用快捷键<code>Ctrl</code>+<code>T</code>更方便(段落→表格→插入表格，即可查看快捷键)可以自定义表格大小。</p>
<h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">语法：&gt;引用文本内容</span><br></pre></td></tr></table></figure>

<blockquote>
<p>引用文本内容</p>
</blockquote>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="quote">&gt; 可以在引用中</span></span><br><span class="line"><span class="quote">&gt;</span></span><br><span class="line"><span class="quote">&gt; &gt; 使用嵌套的引用</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>可以在引用中</p>
<blockquote>
<p>使用嵌套的引用</p>
</blockquote>
</blockquote>
<hr>
<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><p>语法：[TOC] + <code>enter</code></p>
<p>生成的目录内容会随笔者编辑而自动更新。</p>
<hr>
<div STYLE="page-break-after: always;"></div>

<h2 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h2><h3 id="无序列表–符号-空格"><a href="#无序列表–符号-空格" class="headerlink" title="无序列表–符号 空格"></a>无序列表–符号 空格</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> 可以使用 <span class="code">`*`</span> 作为标记</span><br><span class="line"></span><br><span class="line"><span class="bullet">*</span> 也可以使用 <span class="code">`+`</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> 或者 <span class="code">`-`</span></span><br></pre></td></tr></table></figure>

<ul>
<li><p>可以使用 <code>*</code> 作为标记（不推荐使用星号）</p>
</li>
<li><p>也可以使用 <code>+</code></p>
</li>
<li><p>或者 <code>-</code></p>
</li>
</ul>
<h3 id="有序列表–数字-空格"><a href="#有序列表–数字-空格" class="headerlink" title="有序列表–数字 . 空格"></a>有序列表–数字 <code>.</code> 空格</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">1.</span> 有序列表以数字和 <span class="code">`.`</span> 开始；</span><br><span class="line"><span class="bullet">2.</span> 数字的序列并不会影响生成的列表序列；</span><br><span class="line"><span class="bullet">3.</span> 但仍然推荐按照自然顺序（1.2.3...）编写。</span><br></pre></td></tr></table></figure>

<ol>
<li><p>有序列表以数字和 <code>.</code> 开始；</p>
</li>
<li><p>数字的序列并不会影响生成的列表序列；</p>
</li>
<li><p>但仍然推荐按照自然顺序（1.2.3…）编写。</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">可以使用：数字\. 来取消显示为列表（用反斜杠进行转义）</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><h3 id="代码块"><a href="#代码块" class="headerlink" title="代码块"></a>代码块</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="code">```语言名称</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code">```</span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<h3 id="行内代码"><a href="#行内代码" class="headerlink" title="行内代码"></a>行内代码</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">也可以通过 <span class="code">``，插入行内代码（`</span> 是 <span class="code">`Tab`</span> 键上边、<span class="code">`ESC`</span>下面的、数字 <span class="code">`1`</span> 键左侧的那个按键）：</span><br><span class="line"></span><br><span class="line">例如 <span class="code">`Markdown`</span></span><br></pre></td></tr></table></figure>

<p><code>Markdown</code></p>
<hr>
<h2 id="分隔线"><a href="#分隔线" class="headerlink" title="分隔线"></a>分隔线</h2><p>可以在一行中使用三个或更多的 <code>*</code>、<code>-</code> 或 <code>_</code> 来添加分隔线（&#96;&#96;）：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="section">---</span></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">---</span><br></pre></td></tr></table></figure>

<hr>
<hr>
<hr>
<h2 id="任务列表"><a href="#任务列表" class="headerlink" title="任务列表"></a>任务列表</h2><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">语法：</span><br><span class="line">未完成事项:- [ ]</span><br><span class="line">已完成事项:- [x]</span><br><span class="line">可以通过鼠标左键勾选或取消方框内的√。</span><br></pre></td></tr></table></figure>

<ul>
<li><input checked="" disabled="" type="checkbox"> 任务1</li>
<li><input disabled="" type="checkbox"> 任务2</li>
<li><input checked="" disabled="" type="checkbox"> 任务3</li>
</ul>
<hr>
<h2 id="跳转"><a href="#跳转" class="headerlink" title="跳转"></a>跳转</h2><h3 id="外部跳转–超链接"><a href="#外部跳转–超链接" class="headerlink" title="外部跳转–超链接"></a>外部跳转–超链接</h3><p>语法： <code>[注释/命名](具体链接)</code></p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">[<span class="string">帮助文档</span>](<span class="link">https://support.typoraio.cn/Markdown-Reference/</span>)</span><br></pre></td></tr></table></figure>

<p><a href="https://support.typoraio.cn/Markdown-Reference/">帮助文档</a></p>
<h3 id="内部跳转–本文件内跳"><a href="#内部跳转–本文件内跳" class="headerlink" title="内部跳转–本文件内跳"></a>内部跳转–本文件内跳</h3><p>语法： <code>[注释/命名](#要去的目的地--标题）</code>。</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">[<span class="string">跳转到文字</span>](<span class="link">#文字样式</span>)</span><br></pre></td></tr></table></figure>

<p><a href="#%E6%96%87%E5%AD%97%E6%A0%B7%E5%BC%8F">跳转到文字</a></p>
<h3 id="自动链接"><a href="#自动链接" class="headerlink" title="自动链接"></a>自动链接</h3><p>使用 <code>&lt;&gt;</code> 包括的 URL 或邮箱地址会被自动转换为超链接：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="language-xml">&lt;https://www.baidu.com&gt;</span></span><br></pre></td></tr></table></figure>

<p><a href="https://www.baidu.com/">https://www.baidu.com</a></p>
<hr>
<h3 id="本地图片"><a href="#本地图片" class="headerlink" title="本地图片"></a>本地图片</h3><p>图像与链接类似， 但在链接语法之前需要添加额外的 <code>!</code> 字符。 图像语法如下所示：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">![<span class="string">图片命名</span>](<span class="link">图片本地存储的路径</span>) P.s.用相对路径或绝对路径都可以</span><br><span class="line">或者直接拷贝到Typora内。</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="数学表达式-支持Latex语法"><a href="#数学表达式-支持Latex语法" class="headerlink" title="数学表达式(支持Latex语法)"></a>数学表达式(支持Latex语法)</h2><h3 id="内联公式"><a href="#内联公式" class="headerlink" title="内联公式"></a>内联公式</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用两个<span class="code">`$`</span>一前一后将公式内容包裹起来。</span><br></pre></td></tr></table></figure>

<p>例如不定积分公式：$\int f(x)dx &#x3D; F(x) + c (c\in {\forall} constants)$</p>
<h3 id="行外公式"><a href="#行外公式" class="headerlink" title="行外公式"></a>行外公式</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + shift + m`</span>创建数学公式块</span><br></pre></td></tr></table></figure>

<p>P.s.数学(<font color=red><b>M</b></font>athematics)，因此 **<u>+m</u>**。</p>
<p>例如单调收敛定理：</p>
<p>$$<br>\forall x \in E , 0 \leq f_n(x) \leq f_{n+1}(x),n\in {N_+}.且\lim\limits_{n\to\infty}f_n(x)&#x3D;f(x).<br>那么，\lim\limits_{n\to\infty}\int_Ef(x)dx&#x3D;\int_Ef(x)dx.<br>$$</p>
<hr>
<div STYLE="page-break-after: always;"></div>

<h2 id="利用Markdown画图"><a href="#利用Markdown画图" class="headerlink" title="利用Markdown画图"></a>利用Markdown画图</h2><p>MarkDown画图也是轻量级的，功能并不全。</p>
<p>但是MarkDown支持sequence，flowchart和mermaid三种图表类型。</p>
<p>sequence使用的是js-sequence-diagrams。</p>
<p>flowchart使用的是flowchart.js。</p>
<p>Mermaid 是一个用于画流程图、状态图、时序图、甘特图的库，使用 JS 进行本地渲染，广泛集成于许多 Markdown 编辑器中。Mermaid 作为一个使用 JS 渲染的库，生成的不是一个“图片”，而是一段 HTML 代码。</p>
<p>（不同的编辑器渲染的可能不一样）</p>
<table>
<thead>
<tr>
<th>图表类型</th>
<th>支持来源</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>Sequence</td>
<td>js-sequence-diagrams</td>
<td>UML 时序图</td>
</tr>
<tr>
<td>Flowchart</td>
<td>flowchart.js</td>
<td>流程图</td>
</tr>
<tr>
<td>Mermaid</td>
<td>mermaid</td>
<td>集成的强大的图表库，支持时序图、流程图、甘特图、类图、饼图等</td>
</tr>
</tbody></table>
<p>接下来我将一一介绍上述三种类型的图表。</p>
<h3 id="Sequence-Diagrams"><a href="#Sequence-Diagrams" class="headerlink" title="Sequence Diagrams"></a>Sequence Diagrams</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">Title: MarkDown时序图实例</span><br><span class="line">participant 客户端</span><br><span class="line">participant 控制器</span><br><span class="line">participant 业务</span><br><span class="line">participant 数据库</span><br><span class="line"></span><br><span class="line"><span class="code">     客户端-&gt;&gt;数据库:提交数据店铺</span></span><br><span class="line"><span class="code">     Note right of 客户端:提交数据进行验证</span></span><br><span class="line"><span class="code">     控制器-&gt;&gt;控制器:验证数据完整性</span></span><br><span class="line"><span class="code">     Note left of 控制器:返回错误的字段信息</span></span><br><span class="line"><span class="code">     控制器--&gt;&gt;客户端:数据不完整</span></span><br><span class="line"><span class="code">     Note over 客户端: 用户输入通行证的账号、密码</span></span><br><span class="line"><span class="code">     控制器-&gt;&gt;业务:保存店铺到数据库</span></span><br><span class="line"><span class="code">     业务-&gt;&gt;业务:save店铺数据</span></span><br><span class="line"><span class="code">     业务--&gt;&gt;控制器:保存出现异常</span></span><br><span class="line"><span class="code">     控制器--&gt;&gt;客户端:保存成功</span></span><br><span class="line"><span class="code">     数据库--&gt;&gt;业务:success</span></span><br><span class="line"><span class="code">     业务--&gt;&gt;控制器:success</span></span><br><span class="line"><span class="code">     控制器--&gt;&gt;客户端:success 客户端</span></span><br><span class="line"><span class="code">     Note left of 控制器:返回正确的提示，并跳转到审核第二步</span></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Title: MarkDown时序图实例</span><br><span class="line"></span><br><span class="line">    participant 客户端</span><br><span class="line">    participant 控制器</span><br><span class="line">    participant 业务</span><br><span class="line">    participant 数据库</span><br><span class="line"></span><br><span class="line">     客户端-&gt;&gt;数据库:提交数据店铺</span><br><span class="line">     Note right of 客户端:提交数据进行验证</span><br><span class="line">     控制器-&gt;&gt;控制器:验证数据完整性</span><br><span class="line">     Note left of 控制器:返回错误的字段信息</span><br><span class="line">     控制器--&gt;&gt;客户端:数据不完整</span><br><span class="line">     Note over 客户端: 用户输入通行证的账号、密码</span><br><span class="line">     控制器-&gt;&gt;业务:保存店铺到数据库</span><br><span class="line">     业务-&gt;&gt;业务:save店铺数据</span><br><span class="line">     业务--&gt;&gt;控制器:保存出现异常</span><br><span class="line">     控制器--&gt;&gt;客户端:保存成功</span><br><span class="line">     数据库--&gt;&gt;业务:success</span><br><span class="line">     业务--&gt;&gt;控制器:success</span><br><span class="line">     控制器--&gt;&gt;客户端:success 客户端</span><br><span class="line">     Note left of 控制器:返回正确的提示，并跳转到审核第二步</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> 代表实线 ， 主动发送消息，比如 request请求</span><br><span class="line">  &gt; 代表实心箭头 ， 同步消息，比如 AJAX 的同步请求</span><br><span class="line">  &gt; -- 代表虚线，表示返回消息，spring Controller return</span><br><span class="line">  &gt;</span><br><span class="line">  &gt; &gt; 代表非实心箭头 ，异步消息，比如AJAX请求</span><br></pre></td></tr></table></figure>

<div STYLE="page-break-after: always;"></div>

<h3 id="Flowcharts"><a href="#Flowcharts" class="headerlink" title="Flowcharts"></a>Flowcharts</h3><ul>
<li><strong>标准竖向流程图</strong></li>
</ul>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">st=&gt;start: 开始框</span><br><span class="line"></span><br><span class="line">op=&gt;operation: 处理框</span><br><span class="line"></span><br><span class="line">cond=&gt;condition: 判断框(是或否?)</span><br><span class="line"></span><br><span class="line">sub1=&gt;subroutine: 子流程</span><br><span class="line"></span><br><span class="line">io=&gt;inputoutput: 输入输出框</span><br><span class="line"></span><br><span class="line">e=&gt;end: 结束框</span><br><span class="line"></span><br><span class="line">st-&gt;op-&gt;cond</span><br><span class="line"></span><br><span class="line">cond(yes)-&gt;io-&gt;e</span><br><span class="line"></span><br><span class="line">cond(no)-&gt;sub1(right)-&gt;op</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">st=&gt;start: 出发</span><br><span class="line"></span><br><span class="line">op=&gt;operation: 下雨</span><br><span class="line"></span><br><span class="line">cond=&gt;condition: 带雨伞</span><br><span class="line"></span><br><span class="line">sub1=&gt;subroutine: 回家取伞</span><br><span class="line"></span><br><span class="line">io=&gt;inputoutput: 继续出行</span><br><span class="line"></span><br><span class="line">e=&gt;end: 到达目的地</span><br><span class="line"></span><br><span class="line">st-&gt;op-&gt;cond</span><br><span class="line"></span><br><span class="line">cond(yes)-&gt;io-&gt;e</span><br><span class="line"></span><br><span class="line">cond(no)-&gt;sub1(right)-&gt;op</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>标准横向流程图</strong></li>
</ul>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">st=&gt;start: 开始框</span><br><span class="line"></span><br><span class="line">op=&gt;operation: 处理框</span><br><span class="line"></span><br><span class="line">cond=&gt;condition: 判断框(是或否?)</span><br><span class="line"></span><br><span class="line">sub1=&gt;subroutine: 子流程</span><br><span class="line"></span><br><span class="line">io=&gt;inputoutput: 输入输出框</span><br><span class="line"></span><br><span class="line">e=&gt;end: 结束框</span><br><span class="line"></span><br><span class="line">st(right)-&gt;op(right)-&gt;cond</span><br><span class="line"></span><br><span class="line">cond(yes)-&gt;io(bottom)-&gt;e</span><br><span class="line"></span><br><span class="line">cond(no)-&gt;sub1(right)-&gt;op</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">st=&gt;start: 出发</span><br><span class="line"></span><br><span class="line">op=&gt;operation: 下雨</span><br><span class="line"></span><br><span class="line">cond=&gt;condition: 带雨伞</span><br><span class="line"></span><br><span class="line">sub1=&gt;subroutine: 回家取伞</span><br><span class="line"></span><br><span class="line">io=&gt;inputoutput: 继续出行</span><br><span class="line"></span><br><span class="line">e=&gt;end: 到达目的地</span><br><span class="line"></span><br><span class="line">st(right)-&gt;op(right)-&gt;cond</span><br><span class="line"></span><br><span class="line">cond(yes)-&gt;io(bottom)-&gt;e</span><br><span class="line"></span><br><span class="line">cond(no)-&gt;sub1(right)-&gt;op</span><br></pre></td></tr></table></figure>

<div STYLE="page-break-after: always;"></div>

<h3 id="Mermaid"><a href="#Mermaid" class="headerlink" title="Mermaid"></a>Mermaid</h3><h4 id="流程图"><a href="#流程图" class="headerlink" title="流程图"></a>流程图</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">graph 方向描述</span><br><span class="line">图表中的其他语句...</span><br></pre></td></tr></table></figure>

<p>关键字graph表示一个流程图的开始，同时需要指定该图的方向。</p>
<p>其中“方向描述”为：</p>
<table>
<thead>
<tr>
<th align="left">用词</th>
<th align="left">含义</th>
</tr>
</thead>
<tbody><tr>
<td align="left">TB</td>
<td align="left">从上到下</td>
</tr>
<tr>
<td align="left">BT</td>
<td align="left">从下到上</td>
</tr>
<tr>
<td align="left">RL</td>
<td align="left">从右到左</td>
</tr>
<tr>
<td align="left">LR</td>
<td align="left">从左到右</td>
</tr>
</tbody></table>
<blockquote>
<p>T &#x3D; TOP，B &#x3D; BOTTOM，L &#x3D; LEFT，R &#x3D; RIGHT，D &#x3D; DOWN</p>
</blockquote>
<p>最常用的布局方向是TB、LR。</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">graph TB;</span><br><span class="line">A--&gt;B</span><br><span class="line">B--&gt;C</span><br><span class="line">C--&gt;A</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph TB;</span><br><span class="line">  A--&gt;B</span><br><span class="line">  B--&gt;C</span><br><span class="line">  C--&gt;A</span><br></pre></td></tr></table></figure>

<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">graph LR;</span><br><span class="line">A--&gt;B</span><br><span class="line">B--&gt;C</span><br><span class="line">C--&gt;A</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph LR;</span><br><span class="line">  A--&gt;B</span><br><span class="line">  B--&gt;C</span><br><span class="line">  C--&gt;A</span><br></pre></td></tr></table></figure>

<h5 id="节点形状"><a href="#节点形状" class="headerlink" title="节点形状"></a>节点形状</h5><table>
<thead>
<tr>
<th align="left">表述</th>
<th align="left">说明</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td align="left">id[文字]</td>
<td align="left">矩形节点</td>
<td>表示过程，也就是整个流程中的一个环节。</td>
</tr>
<tr>
<td align="left">id(文字)</td>
<td align="left">圆角矩形节点</td>
<td>表示开始和结束。</td>
</tr>
<tr>
<td align="left">id((文字))</td>
<td align="left">圆形节点</td>
<td>表示连接。为避免流程过长或有交叉，可将流程切开。</td>
</tr>
<tr>
<td align="left">id{文字}</td>
<td align="left">菱形节点</td>
<td>表示判断、决策。</td>
</tr>
<tr>
<td align="left">id&gt;文字]</td>
<td align="left">右向旗帜状节点</td>
<td></td>
</tr>
</tbody></table>
<p><strong>单向箭头线段</strong>：表示流程进行方向</p>
<blockquote>
<p>id即为节点的唯一标识，A~F 是当前节点名字，类似于变量名，画图时便于引用</p>
<p>括号内是节点中要显示的文字，默认节点的名字和显示的文字都为A</p>
</blockquote>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">graph TB</span><br><span class="line">A</span><br><span class="line">B(圆角矩形节点)</span><br><span class="line">C[矩形节点]</span><br><span class="line">D((圆形节点))</span><br><span class="line">E&#123;菱形节点&#125;</span><br><span class="line">F&gt;右向旗帜状节点]</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph TB</span><br><span class="line">  A</span><br><span class="line">  B(圆角矩形节点)</span><br><span class="line">  C[矩形节点]</span><br><span class="line">  D((圆形节点))</span><br><span class="line">  E&#123;菱形节点&#125;</span><br><span class="line">  F&gt;右向旗帜状节点]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">%% 语法示例</span><br><span class="line">graph TB</span><br><span class="line"><span class="code">    sport(出发运动)--&gt; badminton[羽毛球]</span></span><br><span class="line"><span class="code">    badminton --&gt; IsWin&#123;&quot;有没有赢下单打比赛？&quot;&#125;</span></span><br><span class="line"><span class="code">    IsWin --&gt;|有|happy[赢下比赛]--&gt;goBack(回家)</span></span><br><span class="line"><span class="code">    IsWin --&gt;|没有|sad[再接再厉]--&gt;goBack</span></span><br><span class="line"><span class="code"></span></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph TB</span><br><span class="line">    sport(出发运动)--&gt; badminton[羽毛球]</span><br><span class="line">    badminton --&gt; IsWin&#123;&quot;有没有赢下单打比赛？&quot;&#125;</span><br><span class="line">    IsWin --&gt;|有|happy[赢下比赛]--&gt;goBack(回家)</span><br><span class="line">    IsWin --&gt;|没有|sad[再接再厉]--&gt;goBack</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="连线"><a href="#连线" class="headerlink" title="连线"></a>连线</h5><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">graph TB</span><br><span class="line">A1--&gt;B1</span><br><span class="line">A2---B2</span><br><span class="line">A3--text---B3</span><br><span class="line">A4--text--&gt;B4</span><br><span class="line">A5-.-B5</span><br><span class="line">A6-.-&gt;B6</span><br><span class="line">A7-.text.-B7</span><br><span class="line">A8-.text.-&gt;B8</span><br><span class="line">A9===B9</span><br><span class="line">A10==&gt;B10</span><br><span class="line">A11==text===B11</span><br><span class="line">A12==text==&gt;B12</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph TB</span><br><span class="line">  A1--&gt;B1</span><br><span class="line">  A2---B2</span><br><span class="line">  A3--text---B3</span><br><span class="line">  A4--text--&gt;B4</span><br><span class="line">  A5-.-B5</span><br><span class="line">  A6-.-&gt;B6</span><br><span class="line">  A7-.text.-B7</span><br><span class="line">  A8-.text.-&gt;B8</span><br><span class="line">  A9===B9</span><br><span class="line">  A10==&gt;B10</span><br><span class="line">  A11==text===B11</span><br><span class="line">  A12==text==&gt;B12</span><br></pre></td></tr></table></figure>

<h4 id="UML时序图"><a href="#UML时序图" class="headerlink" title="UML时序图"></a>UML时序图</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line">顾客--&gt;API: 预约产品</span><br><span class="line">API--&gt;预约服务: 开始预约流程</span><br><span class="line">break 当预约失败时</span><br><span class="line">API--&gt;顾客: 展示预约失败原因</span><br><span class="line">end</span><br><span class="line">API--&gt;支付账单服务: 开始支付账单流程</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sequenceDiagram</span><br><span class="line"> 顾客--&gt;API: 预约产品</span><br><span class="line"> API--&gt;预约服务: 开始预约流程</span><br><span class="line"> break 当预约失败时</span><br><span class="line">  API--&gt;顾客: 展示预约失败原因</span><br><span class="line"> end</span><br><span class="line"> API--&gt;支付账单服务: 开始支付账单流程</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>​</p>
<p>​</p>
<h4 id="甘特图"><a href="#甘特图" class="headerlink" title="甘特图"></a>甘特图</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">%% 语法示例</span><br><span class="line">gantt</span><br><span class="line">dateFormat YYYY-MM-DD</span><br><span class="line">title 软件开发甘特图</span><br><span class="line">section 设计</span><br><span class="line">需求 :done, des1, 2014-01-06,2014-01-08</span><br><span class="line">原型 :active, des2, 2014-01-09, 3d</span><br><span class="line">UI设计 : des3, after des2, 5d</span><br><span class="line">未来任务 : des4, after des3, 5d</span><br><span class="line">section 开发</span><br><span class="line">学习准备理解需求 :crit, done, 2014-01-06,24h</span><br><span class="line">设计框架 :crit, done, after des2, 2d</span><br><span class="line">开发 :crit, active, 3d</span><br><span class="line">未来任务 :crit, 5d</span><br><span class="line">耍 :2d</span><br><span class="line"></span><br><span class="line"><span class="code">        section 测试</span></span><br><span class="line"><span class="code">        功能测试                              :active, a1, after des3, 3d</span></span><br><span class="line"><span class="code">        压力测试                               :after a1  , 20h</span></span><br><span class="line"><span class="code">        测试报告                               : 48h</span></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">gantt</span><br><span class="line">        dateFormat  YYYY-MM-DD</span><br><span class="line">        title 软件开发甘特图</span><br><span class="line">        section 设计</span><br><span class="line">        需求                      :done,    des1, 2014-01-06,2014-01-08</span><br><span class="line">        原型                      :active,  des2, 2014-01-09, 3d</span><br><span class="line">        UI设计                     :         des3, after des2, 5d</span><br><span class="line">        未来任务                     :         des4, after des3, 5d</span><br><span class="line"></span><br><span class="line">        section 开发</span><br><span class="line">        学习准备理解需求                      :crit, done, 2014-01-06,24h</span><br><span class="line">        设计框架                             :crit, done, after des2, 2d</span><br><span class="line">        开发                                 :crit, active, 3d</span><br><span class="line">        未来任务                              :crit, 5d</span><br><span class="line"></span><br><span class="line">        section 测试</span><br><span class="line">        功能测试                              :active, a1, after des3, 3d</span><br><span class="line">        压力测试                               :after a1  , 20h</span><br><span class="line">        测试报告                               : 48h</span><br></pre></td></tr></table></figure>

<div STYLE="page-break-after: always;"></div>

<h4 id="类图"><a href="#类图" class="headerlink" title="类图"></a>类图</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">语法解释：&lt;|-- 表示继承，+ 表示 public，- 表示 private。</span><br></pre></td></tr></table></figure>

<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">classDiagram</span><br><span class="line">动物 &lt;|-- 鸭子</span><br><span class="line">动物 &lt;|-- 鱼</span><br><span class="line">动物 &lt;|-- 斑马</span><br><span class="line">动物 : +int age</span><br><span class="line">动物 : +String gender</span><br><span class="line">动物: +isMammal()</span><br><span class="line">动物: +mate()</span><br><span class="line">class 鸭子&#123;</span><br><span class="line">+String beakColor</span><br><span class="line">+swim()</span><br><span class="line">+quack()</span><br><span class="line">&#125;</span><br><span class="line">class 鱼&#123;</span><br><span class="line">-int sizeInFeet</span><br><span class="line">-canEat()</span><br><span class="line">&#125;</span><br><span class="line">class 斑马&#123;</span><br><span class="line">+bool is<span class="emphasis">_wild</span></span><br><span class="line"><span class="emphasis">+run()</span></span><br><span class="line"><span class="emphasis">&#125;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">classDiagram</span><br><span class="line">      动物 &lt;|-- 鸭子</span><br><span class="line">      动物 &lt;|-- 鱼</span><br><span class="line">      动物 &lt;|-- 斑马</span><br><span class="line">      动物 : +int age</span><br><span class="line">      动物 : +String gender</span><br><span class="line">      动物: +isMammal()</span><br><span class="line">      动物: +mate()</span><br><span class="line">      class 鸭子&#123;</span><br><span class="line">          +String beakColor</span><br><span class="line">          +swim()</span><br><span class="line">          +quack()</span><br><span class="line">      &#125;</span><br><span class="line">      class 鱼&#123;</span><br><span class="line">          -int sizeInFeet</span><br><span class="line">          -canEat()</span><br><span class="line">      &#125;</span><br><span class="line">      class 斑马&#123;</span><br><span class="line">          +bool is_wild</span><br><span class="line">          +run()</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure>

<div STYLE="page-break-after: always;"></div>

<h4 id="状态图"><a href="#状态图" class="headerlink" title="状态图"></a>状态图</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">stateDiagram</span><br><span class="line">[<span class="emphasis">*] --&gt; Still</span></span><br><span class="line"><span class="emphasis">Still --&gt; [*</span>]</span><br><span class="line">Still --&gt; Moving</span><br><span class="line">Moving --&gt; Still</span><br><span class="line">Moving --&gt; Crash</span><br><span class="line">Crash --&gt; [<span class="emphasis">*]</span></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">stateDiagram</span><br><span class="line"> [*] --&gt; 静止</span><br><span class="line"> 静止 --&gt; [*]</span><br><span class="line"></span><br><span class="line"> 静止 --&gt; 运动</span><br><span class="line"> 运动 --&gt; 静止</span><br><span class="line"> 运动 --&gt; 碰撞</span><br><span class="line"> 碰撞 --&gt; [*]</span><br></pre></td></tr></table></figure>

<div STYLE="page-break-after: always;"></div>

<h4 id="饼图"><a href="#饼图" class="headerlink" title="饼图"></a>饼图</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">pie</span><br><span class="line">title Pie Chart</span><br><span class="line">&quot;狗&quot; : 386</span><br><span class="line">&quot;猫&quot; : 85</span><br><span class="line">&quot;老鼠&quot; : 150</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pie</span><br><span class="line"> title Pie Chart</span><br><span class="line"> &quot;狗&quot; : 386</span><br><span class="line"> &quot;猫&quot; : 85</span><br><span class="line"> &quot;老鼠&quot; : 150</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>Complete Guide to deploy Gerrit</title>
    <url>//Tools/Markdown/Complete-Guide-to-Deploy-Gerrit/index.html</url>
    <content><![CDATA[<h2 id="Deployment-Plan-Table"><a href="#Deployment-Plan-Table" class="headerlink" title="Deployment Plan Table"></a>Deployment Plan Table</h2><table>
<thead>
<tr>
<th>Operating System</th>
<th>IP</th>
<th>NGINX Version</th>
<th>Hostname</th>
<th>Role</th>
</tr>
</thead>
<tbody><tr>
<td>Rocky9.5(x86_64)</td>
<td>192.168.225.30</td>
<td>1.26.3</td>
<td>loadbalance.haoyang.cn</td>
<td>gerrit service 1</td>
</tr>
<tr>
<td>Rocky9.5(x86_64)</td>
<td>192.168.225.31</td>
<td>1.26.3</td>
<td>gerrit1.haoyang.cn</td>
<td>gerrit service 2</td>
</tr>
<tr>
<td>Rocky9.5(x86_64)</td>
<td>192.168.225.32</td>
<td>1.26.3</td>
<td>gerrit2.haoyang.cn</td>
<td>Loadbalance service</td>
</tr>
</tbody></table>
<h2 id="Prerequisites"><a href="#Prerequisites" class="headerlink" title="Prerequisites"></a>Prerequisites</h2><p>To run the Gerrit service, the following requirement must be met on the host:</p>
<p>JRE, versions <code>17</code> or <code>21</code>.</p>
<blockquote>
<p>Oracle’s java is paid not free any more.</p>
<p>Openjdk is available <a href="https://openjdk.org/">here</a>.</p>
</blockquote>
<h2 id="Download-the-gerrit-war-tarball"><a href="#Download-the-gerrit-war-tarball" class="headerlink" title="Download the gerrit.war tarball"></a>Download the gerrit.war tarball</h2><p>You could download the <code>gerrit.war</code> file from <a href="https://gerrit-releases.storage.googleapis.com/index.html">Gerrit official site here</a> as you want.</p>
<p>Download any current <code>*.war</code> package. The war will be referred to as <code>gerrit.war</code> from this point forward, so you may find it easier to rename the downloaded file.</p>
<h2 id="Initialize-the-Site"><a href="#Initialize-the-Site" class="headerlink" title="Initialize the Site"></a>Initialize the Site</h2><p>Gerrit stores configuration files, the server’s SSH keys, and the managed Git repositories under a local directory, typically referred to as ‘$site_path’.</p>
<p>Initialize a new site directory by running the init command, passing the path of the site directory to be created as an argument to the ‘-d’ option.</p>
<p>Its recommended that Gerrit Code Review be given its own user account on the host system:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create a new user called gerrit</span></span><br><span class="line"><span class="built_in">sudo</span> adduser gerrit</span><br><span class="line"><span class="comment"># Swith the privilages to root for gerrit user account and start it up:(inherit the environment variables from root)</span></span><br><span class="line"><span class="built_in">sudo</span> su gerrit</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize a new site directory for Gerrit: (replace /path/to/your/gerrit_application_directory with your actual path)</span></span><br><span class="line">java -jar gerrit.war init -d /path/to/your/gerrit_application_directory</span><br></pre></td></tr></table></figure>

<h2 id="Initial-Configuration"><a href="#Initial-Configuration" class="headerlink" title="Initial Configuration"></a>Initial Configuration</h2><p>I would like to show the whole process I’ve experienced here. Don’t worry, just follow my guidance.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create a new user called gerrit</span></span><br><span class="line"><span class="built_in">sudo</span> adduser gerrit</span><br><span class="line"><span class="comment"># Swith the privilages to root for gerrit user account and start it up:(inherit the environment variables from root)</span></span><br><span class="line"><span class="built_in">sudo</span> su gerrit</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make a new directory</span></span><br><span class="line"><span class="built_in">cd</span> /home/gerrit</span><br><span class="line"><span class="built_in">mkdir</span> gerrit_war</span><br></pre></td></tr></table></figure>

<p>The structure should be same as me as followed.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[gerrit@gerrit2 ~]$ pwd</span><br><span class="line">/home/gerrit</span><br><span class="line">[gerrit@gerrit2 ~]$ tree -L 2</span><br><span class="line">.</span><br><span class="line">└── gerrit_war</span><br><span class="line"></span><br><span class="line">2 directories, 0 files</span><br></pre></td></tr></table></figure>

<p>Then, download the <code>gerrit.war</code> from the <a href="https://gerrit-releases.storage.googleapis.com/index.html">Gerrit official site here</a> as you want. Then, move the <code>gerrit</code> application to your gerrit directory.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[gerrit@gerrit2 gerrit_war]$ scp root@192.168.225.30:/home/gerrit/gerrit_war/gerrit-3.11.1.war .</span><br><span class="line">The authenticity of host &#x27;192.168.225.30 (192.168.225.30)&#x27; can&#x27;t be established.</span><br><span class="line">ED25519 key fingerprint is SHA256:QZY7LFi5pVYhQHY56cn96boDi59JBU55x9o8/uyTlic.</span><br><span class="line">This key is not known by any other names</span><br><span class="line">Are you sure you want to continue connecting (yes/no/[fingerprint])? yes</span><br><span class="line">Warning: Permanently added &#x27;192.168.225.30&#x27; (ED25519) to the list of known hosts.</span><br><span class="line">root@192.168.225.30&#x27;s password:</span><br><span class="line">gerrit-3.11.1.war                                                                                                              100%   82MB 111.7MB/s   00:00</span><br><span class="line">[gerrit@gerrit2 gerrit_war]$ ls</span><br><span class="line">gerrit-3.11.1.war</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Init the gerrir.war tarball</span></span><br><span class="line"><span class="built_in">cd</span> /home/gerrit/gerrit_war</span><br><span class="line">java -jar gerrit-3.11.1.war init -d /home/gerrit/gerrit_application</span><br></pre></td></tr></table></figure>

<p>The detailed information you could based on my settings and change it as you want.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[gerrit@gerrit2 gerrit_war]$ java -jar gerrit-3.11.1.war init -d /home/gerrit/gerrit_application</span><br><span class="line">Using secure store: com.google.gerrit.server.securestore.DefaultSecureStore</span><br><span class="line">[2025-03-11 15:07:00,893] [main] INFO  com.google.gerrit.server.config.GerritServerConfigProvider : No /home/gerrit/gerrit_application/etc/gerrit.config; assuming defaults</span><br><span class="line"></span><br><span class="line">*** Gerrit Code Review 3.11.1</span><br><span class="line">***</span><br><span class="line"></span><br><span class="line">Create &#x27;/home/gerrit/gerrit_application&#x27; [Y/n]? Y</span><br><span class="line"></span><br><span class="line">*** Git Repositories</span><br><span class="line">***</span><br><span class="line"></span><br><span class="line">Location of Git repositories   [git]:</span><br><span class="line"></span><br><span class="line">*** JGit Configuration</span><br><span class="line">***</span><br><span class="line"></span><br><span class="line">Auto-configured &quot;receive.autogc = false&quot; to disable auto-gc after git-receive-pack.</span><br><span class="line"></span><br><span class="line">*** Index</span><br><span class="line">***</span><br><span class="line"></span><br><span class="line">Type                           [lucene]:</span><br><span class="line"></span><br><span class="line">*** User Authentication</span><br><span class="line">***</span><br><span class="line"></span><br><span class="line">Authentication method          [openid/?]: HTTP</span><br><span class="line">Get username from custom HTTP header [y/N]? N</span><br><span class="line">SSO logout URL                 :</span><br><span class="line">Enable signed push support     [y/N]? N</span><br><span class="line">Use case insensitive usernames [Y/n]? Y</span><br><span class="line"></span><br><span class="line">*** Review Labels</span><br><span class="line">***</span><br><span class="line"></span><br><span class="line">Install Verified label         [y/N]? y</span><br><span class="line"></span><br><span class="line">*** Email Delivery</span><br><span class="line">***</span><br><span class="line"></span><br><span class="line">SMTP server hostname           [localhost]: ***</span><br><span class="line">SMTP server port               [(default)]: **</span><br><span class="line">SMTP encryption                [none/?]: none</span><br><span class="line">SMTP username                  [gerrit]: ***@***.com</span><br><span class="line">***@***.com&#x27;s password :</span><br><span class="line">              confirm password :</span><br><span class="line"></span><br><span class="line">*** Container Process</span><br><span class="line">***</span><br><span class="line"></span><br><span class="line">Run as                         [gerrit]: gerrit</span><br><span class="line">Java runtime                   [/usr/lib/jvm/java-21-openjdk-21.0.6.0.7-1.el9.x86_64]:</span><br><span class="line">Copy gerrit-3.11.1.war to /home/gerrit/gerrit_application/bin/gerrit.war [Y/n]? Y</span><br><span class="line">Copying gerrit-3.11.1.war to /home/gerrit/gerrit_application/bin/gerrit.war</span><br><span class="line"></span><br><span class="line">*** SSH Daemon</span><br><span class="line">***</span><br><span class="line"></span><br><span class="line">Listen on address              [*]:</span><br><span class="line">Listen on port                 [29418]:</span><br><span class="line">Generating SSH host key ... rsa... ed25519... ecdsa 256... ecdsa 384... ecdsa 521... done</span><br><span class="line"></span><br><span class="line">*** HTTP Daemon</span><br><span class="line">***</span><br><span class="line"></span><br><span class="line">Behind reverse proxy           [y/N]? y</span><br><span class="line">Proxy uses SSL (https://)      [y/N]? N</span><br><span class="line">Subdirectory on proxy server   [/]:</span><br><span class="line">Listen on address              [*]:</span><br><span class="line">Listen on port                 [8081]: 8080</span><br><span class="line">Canonical URL                  [http://***/]: http://***</span><br><span class="line"></span><br><span class="line">*** Cache</span><br><span class="line">***</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">*** Plugins</span><br><span class="line">***</span><br><span class="line"></span><br><span class="line">Installing plugins.</span><br><span class="line">Install plugin codemirror-editor version v3.11.1 [y/N]? y</span><br><span class="line">Installed codemirror-editor v3.11.1</span><br><span class="line">Install plugin commit-message-length-validator version v3.11.1 [y/N]? y</span><br><span class="line">Installed commit-message-length-validator v3.11.1</span><br><span class="line">Install plugin delete-project version v3.11.1 [y/N]? y</span><br><span class="line">Installed delete-project v3.11.1</span><br><span class="line">Install plugin download-commands version v3.11.1 [y/N]? y</span><br><span class="line">Installed download-commands v3.11.1</span><br><span class="line">Install plugin gitiles version v3.11.1 [y/N]? y</span><br><span class="line">Installed gitiles v3.11.1</span><br><span class="line">Install plugin hooks version v3.11.1 [y/N]? y</span><br><span class="line">Installed hooks v3.11.1</span><br><span class="line">Install plugin plugin-manager version v3.11.1 [y/N]? y</span><br><span class="line">Installed plugin-manager v3.11.1</span><br><span class="line">Install plugin replication version v3.11.1 [y/N]? y</span><br><span class="line">Installed replication v3.11.1</span><br><span class="line">Install plugin replication-api version v3.11.1 [y/N]? y</span><br><span class="line">Installed replication-api v3.11.1</span><br><span class="line">Install plugin reviewnotes version v3.11.1 [y/N]? y</span><br><span class="line">Installed reviewnotes v3.11.1</span><br><span class="line">Install plugin singleusergroup version v3.11.1 [y/N]? y</span><br><span class="line">Installed singleusergroup v3.11.1</span><br><span class="line">Install plugin webhooks version v3.11.1 [y/N]? y</span><br><span class="line">Installed webhooks v3.11.1</span><br><span class="line">Initializing plugins.</span><br><span class="line"></span><br><span class="line">Mar 11, 2025 3:09:49 PM org.apache.lucene.store.MemorySegmentIndexInputProvider &lt;init&gt;</span><br><span class="line">INFO: Using MemorySegmentIndexInput with Java 21; to disable start with -Dorg.apache.lucene.store.MMapDirectory.enableMemorySegments=false</span><br><span class="line">============================================================================</span><br><span class="line">Welcome to the Gerrit community</span><br><span class="line"></span><br><span class="line">Find more information on the homepage: https://www.gerritcodereview.com</span><br><span class="line">Discuss Gerrit on the mailing list: https://groups.google.com/g/repo-discuss</span><br><span class="line">============================================================================</span><br><span class="line">Initialized /home/gerrit/gerrit_application</span><br><span class="line">Init complete, reindexing accounts,changes,groups,projects with: reindex --site-path /home/gerrit/gerrit_application --threads 1 --index accounts --index changes --index groups --index projectsReindexed 0 documents in accounts index in 0.0s (0.0/s)</span><br><span class="line">Index accounts in version 14 is ready</span><br><span class="line">Reindexing groups:      100% (3/3)</span><br><span class="line">Reindexed 3 documents in groups index in 0.3s (11.3/s)</span><br><span class="line">Index groups in version 11 is ready</span><br><span class="line">Reindexing changes: Slicing projects: 100% (2/2), done</span><br><span class="line">Reindexed 0 documents in changes index in 0.0s (0.0/s)</span><br><span class="line">Index changes in version 86 is ready</span><br><span class="line">Reindexing projects:    100% (2/2)</span><br><span class="line">Reindexed 2 documents in projects index in 0.1s (27.0/s)</span><br><span class="line">Index projects in version 9 is ready</span><br><span class="line">Executing /home/gerrit/gerrit_application/bin/gerrit.sh start</span><br><span class="line">Starting Gerrit Code Review: WARNING: Could not adjust Gerrit&#x27;s process for the kernel&#x27;s out-of-memory killer.</span><br><span class="line">         This may be caused by /home/gerrit/gerrit_application/bin/gerrit.sh not being run as root.</span><br><span class="line">         Consider changing the OOM score adjustment manually for Gerrit&#x27;s PID=1859 with e.g.:</span><br><span class="line">         echo &#x27;-1000&#x27; | sudo tee /proc/1859/oom_score_adj</span><br><span class="line">OK</span><br><span class="line">Waiting for server on 192.168.225.31:8080 ... OK</span><br><span class="line">Please open the following URL in the browser: http://192.168.225.31:8080/#/admin/projects/</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Tips:</p>
<p>If you would like to use reverse-proxy, the Authentication method must be set as <code>http</code>.<br>Other configurations could set as default, type <code>enter</code> to skip.</p>
<p>What’s more, please rememer to allow the <code>8080</code> port by using:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@gerrit2 ~]# firewall-cmd --permanent --add-port=8080/tcp</span><br><span class="line">success</span><br><span class="line">[root@gerrit2 ~]# firewall-cmd --reload</span><br><span class="line">success</span><br></pre></td></tr></table></figure>
</blockquote>
<p>If you see this page, please do not worry!</p>
<p>It represents you’ve deployed the gerrit application successfully.</p>
<p>For the next step, you should handle with the NGINX configuration.</p>
<p><img src="/../images/reverse_proxy.png" alt="Revers-proxy error"></p>
<h2 id="Configuring-NGINX-as-a-Reverse-Proxy-for-Gerrit"><a href="#Configuring-NGINX-as-a-Reverse-Proxy-for-Gerrit" class="headerlink" title="Configuring NGINX as a Reverse Proxy for Gerrit"></a>Configuring NGINX as a Reverse Proxy for Gerrit</h2><p>Please refer to <a href="https://blog.sunhaoyang.net/Linux/NGINX_1.Deploying-NGINX/index.html">NGIXN Series Chapter 1: Deploying NGINX</a> to deploy NGINX in your local.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@loadbalance conf.d]# pwd</span><br><span class="line">/etc/nginx/conf.d</span><br><span class="line">[root@loadbalance conf.d]# ls</span><br><span class="line">default.conf.bak  gerrit.conf</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Tips:</p>
<p>You’d better to rename the <code>default.conf</code> in <code>/etc/nginx/conf.d</code>.</p>
</blockquote>
<p>Create a new configuration file, here called <code>gerrit.conf</code>.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">upstream gerrit_backend &#123;</span><br><span class="line">    ip_hash;</span><br><span class="line">    server 192.168.225.30:8080 weight=1 max_fails=3 fail_timeout=10s;</span><br><span class="line">    server 192.168.225.31:8080 weight=1 max_fails=3 fail_timeout=10s;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    server_name loadbalance.haoyang.cn;</span><br><span class="line"></span><br><span class="line">    auth_basic &quot;Gerrit Code Review&quot;;</span><br><span class="line">    auth_basic_user_file /etc/nginx/conf.d/htpasswd;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass http://gerrit_backend;</span><br><span class="line"></span><br><span class="line">        proxy_set_header X-Real-IP $remote_addr;</span><br><span class="line">        proxy_set_header X-Forwarded-For $remote_addr;</span><br><span class="line">        proxy_set_header X-Forwarded-Proto $scheme;</span><br><span class="line"></span><br><span class="line">        proxy_set_header Host $host;</span><br><span class="line">        proxy_set_header Authorization $http_authorization;</span><br><span class="line"></span><br><span class="line">        proxy_redirect off;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Finally, install the httpd-tools to generate http-authentification account and password.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install httpd-tools -y</span><br></pre></td></tr></table></figure>

<p>Create the gerrit administrator user.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@loadbalance ~]# htpasswd -b -c /etc/nginx/conf.d/htpasswd gerritadmin ***</span><br><span class="line">Adding password <span class="keyword">for</span> user gerritadmin</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@loadbalance conf.d]# curl http://192.168.225.32:80</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;&lt;title&gt;401 Authorization Required&lt;/title&gt;&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;center&gt;&lt;h1&gt;401 Authorization Required&lt;/h1&gt;&lt;/center&gt;</span><br><span class="line">&lt;hr&gt;&lt;center&gt;nginx/1.26.3&lt;/center&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure>

<p>We could find that it needs to be authorized.</p>
<p>If you open the website in the browser(e.g. chrome), A pop-up window will appear asking you to enter your password.</p>
<p><img src="/../images/pop-up.png" alt="pop-up window"></p>
<p>Congratulations to you! Up to now, you have completed the whole process of deploying gerrit.</p>
<p><img src="/../images/gerrit.png" alt="gerrit"><br>Please enjoy yourself in using such a code review application :D</p>
<blockquote>
<p>Tips:</p>
<p>It is normal phenomenon if you could not sign out in the website.</p>
<p>Here is the reason: You are using HTTP Basic authentication. There is no way to tell a browser to quit sending basic authentication credentials, to logout with basic authentication is to close the Web browser.</p>
<p>What’s more, clear all cookies and data cache does work as well.</p>
</blockquote>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Gerrit</tag>
      </tags>
  </entry>
  <entry>
    <title>Complete Guide to Markdown shortcuts for typora</title>
    <url>//Tools/Markdown/Complete-Guide-to-Markdown-shortcuts-for-typora/index.html</url>
    <content><![CDATA[<h2 id="文字样式部分"><a href="#文字样式部分" class="headerlink" title="文字样式部分"></a>文字样式部分</h2><h3 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + 数字键`</span>快速创建各种等级的标题。(P.s.标题最小分化到6级标题。)</span><br><span class="line">使用<span class="code">`ctrl + 0`</span>可以快速将选中标题调成普通文本。</span><br><span class="line">使用<span class="code">`ctrl + 加号/减号`</span>对标题的级别进行升高和降低。</span><br></pre></td></tr></table></figure>

<h3 id="下划线"><a href="#下划线" class="headerlink" title="下划线"></a>下划线</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + u`</span>添加下划线。</span><br></pre></td></tr></table></figure>

<p>P.s.下划线(<font color=red><b>U</b></font>nderline)，因此 <u><strong>+u</strong></u>。</p>
<h3 id="删除线"><a href="#删除线" class="headerlink" title="删除线"></a>删除线</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`alt + shift + 5`</span>添加删除线。</span><br></pre></td></tr></table></figure>

<h3 id="字体加粗"><a href="#字体加粗" class="headerlink" title="字体加粗"></a>字体加粗</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + b`</span>加粗文字。</span><br></pre></td></tr></table></figure>

<p>P.s.粗体的(<font color=red><b>B</b></font>old)，因此 **<u>+b</u>**。</p>
<h3 id="字体倾斜"><a href="#字体倾斜" class="headerlink" title="字体倾斜"></a>字体倾斜</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + i`</span>倾斜文字。</span><br></pre></td></tr></table></figure>

<p>P.s.斜体的(<font color=red><b>I</b></font>talic)，因此 **<u>+i</u>**。</p>
<hr>
<h2 id="内容部分"><a href="#内容部分" class="headerlink" title="内容部分"></a>内容部分</h2><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + shift + q`</span>创建引用。</span><br></pre></td></tr></table></figure>

<p>P.s.引用(<font color=red><b>Q</b></font>uote)，因此 **<u>+q</u>**。</p>
<h3 id="插入链接"><a href="#插入链接" class="headerlink" title="插入链接"></a>插入链接</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + k`</span>插入链接。</span><br></pre></td></tr></table></figure>

<p>P.s.超链接(Hyper<font color=red><b>link</b></font>)，因此 **<u>+k</u>**。</p>
<h3 id="插入图片"><a href="#插入图片" class="headerlink" title="插入图片"></a>插入图片</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + shift + i`</span>插入图片。</span><br></pre></td></tr></table></figure>

<p>P.s.超链接(<font color=red><b>I</b></font>mage)，因此 **<u>+i</u>**。</p>
<h3 id="文档内部跳转"><a href="#文档内部跳转" class="headerlink" title="文档内部跳转"></a>文档内部跳转</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + home`</span>跳转至文档开头,使用<span class="code">`ctrl + end`</span> 跳转至文档末尾。</span><br></pre></td></tr></table></figure>

<p>P.s.home：起始 end：终止</p>
<h3 id="选择英文单词-中文"><a href="#选择英文单词-中文" class="headerlink" title="选择英文单词&#x2F;中文"></a>选择英文单词&#x2F;中文</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + d`</span>选中文本；使用<span class="code">`ctrl + shift + left/right`</span> 左右移动进行文本选中。</span><br></pre></td></tr></table></figure>

<p>P.s.向下填充(<font color=red><b>D</b></font>own)，因此 **<u>+d</u>**。</p>
<h3 id="按行选中文本"><a href="#按行选中文本" class="headerlink" title="按行选中文本"></a>按行选中文本</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + l`</span>选中光标所在行文本。</span><br></pre></td></tr></table></figure>

<p>P.s.排成一行(<font color=red><b>L</b></font>ine)，因此 **<u>+l</u>**。</p>
<h3 id="快速搜索文本内容"><a href="#快速搜索文本内容" class="headerlink" title="快速搜索文本内容"></a>快速搜索文本内容</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + f`</span>对全文本进行关键词搜索。</span><br></pre></td></tr></table></figure>

<p>P.s.找寻(<font color=red><b>F</b></font>ind)，因此 **<u>+f</u>**。</p>
<h3 id="快速替换文本"><a href="#快速替换文本" class="headerlink" title="快速替换文本"></a>快速替换文本</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + h`</span>对全文本进行指定词替换。</span><br></pre></td></tr></table></figure>

<p>P.s.替换(<font color=red><b>R</b></font>eplace)，但R键位被占用，转而使用 **<u>+h</u>**。</p>
<h3 id="快速生成表格"><a href="#快速生成表格" class="headerlink" title="快速生成表格"></a>快速生成表格</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + t`</span>创建自定义表格。</span><br></pre></td></tr></table></figure>

<p>P.s.表格(<font color=red><b>T</b></font>able)，因此 **<u>+t</u>**。</p>
<h3 id="快速打开最近浏览笔记"><a href="#快速打开最近浏览笔记" class="headerlink" title="快速打开最近浏览笔记"></a>快速打开最近浏览笔记</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + p`</span>打开最近浏览笔记。</span><br></pre></td></tr></table></figure>

<p>P.s.呈现(<font color=red><b>P</b></font>resent)，因此 **<u>+p</u>**。</p>
<h3 id="快速生成目录"><a href="#快速生成目录" class="headerlink" title="快速生成目录"></a>快速生成目录</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用 <span class="code">`[toc] + enter`</span>快速生成目录。</span><br></pre></td></tr></table></figure>

<p>P.s.目录表(<font color=red><b>T</b></font>able <font color=red><b>O</b></font>f <font color=red><b>C</b></font>ontents )，因此 **<u>[toc]</u>**。</p>
<h3 id="着重关键字"><a href="#着重关键字" class="headerlink" title="着重关键字"></a>着重关键字</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + shift + 反引号键(tab键上面那个键)`</span></span><br></pre></td></tr></table></figure>

<h3 id="快速创建代码块-自定义语言类型"><a href="#快速创建代码块-自定义语言类型" class="headerlink" title="快速创建代码块(自定义语言类型)"></a>快速创建代码块(自定义语言类型)</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + shift + k`</span>快速创建代码块，可自定义输入语言类型。</span><br></pre></td></tr></table></figure>

<div STYLE="page-break-after: always;"></div>

<h3 id="数学表达式-支持Latex语法"><a href="#数学表达式-支持Latex语法" class="headerlink" title="数学表达式(支持Latex语法)"></a>数学表达式(支持Latex语法)</h3><ul>
<li><p>行内公式</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用两个<span class="code">`$`</span>一前一后将公式内容包裹起来。</span><br></pre></td></tr></table></figure>

<p>例如不定积分公式：$\int f(x)dx &#x3D; F(x) + c (c\in {\forall} constants)$</p>
</li>
<li><p>行外公式</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + shift + m`</span>创建数学公式块</span><br></pre></td></tr></table></figure>

<p>P.s.数学(<font color=red><b>M</b></font>athematics)，因此 **<u>+m</u>**。</p>
<p>例如单调收敛定理：</p>
<p>$$<br>\forall x \in E , 0 \leq f_n(x) \leq f_{n+1}(x),n\in {N_+}.且\lim\limits_{n\to\infty}f_n(x)&#x3D;f(x).<br>那么，\lim\limits_{n\to\infty}\int_Ef(x)dx&#x3D;\int_Ef(x)dx.<br>$$</p>
<hr>
</li>
</ul>
<h2 id="工具自身部分"><a href="#工具自身部分" class="headerlink" title="工具自身部分"></a>工具自身部分</h2><h3 id="新建文件"><a href="#新建文件" class="headerlink" title="新建文件"></a>新建文件</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + n`</span>创建新的.md文件。</span><br></pre></td></tr></table></figure>

<p>P.s.新建(<font color=red><b>N</b></font>ew)，因此 **<u>+n</u>**。</p>
<h3 id="打开已有-md文件"><a href="#打开已有-md文件" class="headerlink" title="打开已有.md文件"></a>打开已有.md文件</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + o`</span>选择打开已有.md文件。</span><br></pre></td></tr></table></figure>

<p>P.s.打开(<font color=red><b>O</b></font>pen)，因此 **<u>+o</u>**。</p>
<h3 id="保存-md文件"><a href="#保存-md文件" class="headerlink" title="保存.md文件"></a>保存.md文件</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + s`</span>保存已编辑好的.md文件。</span><br></pre></td></tr></table></figure>

<p>P.s.保存(<font color=red><b>S</b></font>ave)，因此 **<u>+s</u>**。</p>
<h3 id="关闭-md文件"><a href="#关闭-md文件" class="headerlink" title="关闭.md文件"></a>关闭.md文件</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + w`</span>关闭已保存.md文件。</span><br></pre></td></tr></table></figure>

<p>P.s.窗口(<font color=red><b>W</b></font>indow)，因此 **<u>+w</u>**。</p>
<h3 id="显示和隐藏侧边栏"><a href="#显示和隐藏侧边栏" class="headerlink" title="显示和隐藏侧边栏"></a>显示和隐藏侧边栏</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + shift + l`</span>来显示/隐藏侧边栏。</span><br></pre></td></tr></table></figure>

<h3 id="偏好设置"><a href="#偏好设置" class="headerlink" title="偏好设置"></a>偏好设置</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + comma`</span>打开偏好设置栏。</span><br></pre></td></tr></table></figure>

<h3 id="源代码模式"><a href="#源代码模式" class="headerlink" title="源代码模式"></a>源代码模式</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`ctrl + /`</span>进入源代码模式。</span><br></pre></td></tr></table></figure>

<h3 id="全屏切换"><a href="#全屏切换" class="headerlink" title="全屏切换"></a>全屏切换</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">使用<span class="code">`F11`</span>进入/退出全屏模式。</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Series (Chapter 0/4): Installing docker-engine in Ubuntu</title>
    <url>//Cloud/Docker/Installing-docker-engine-in-Ubuntu/index.html</url>
    <content><![CDATA[<h2 id="What-is-Docker"><a href="#What-is-Docker" class="headerlink" title="What is Docker?"></a>What is Docker?</h2><p>The name <code>Docker</code> is derived from the term used in maritime shipping, referring to <code>dockworkers</code>. It serves as a metaphorical representation.</p>
<p>In traditional shipping, goods are packed into standardized containers, enabling seamless transfer across different modes of transportation, such as trucks, trains, and ships. Similarly, Docker provides a <code>standardized container</code> that packages applications and all their dependencies together, allowing them to run efficiently and reliably across different environments, such as development, testing, and production. Docker is just one of the most commmon technical tools in the area of containerization. What’s more, such as: Podman, CRI-O, Containerd are also useful containerization tools.</p>
<p>Containerization leverages Linux container technologies such as LXC and cgroups to provide a lightweight method for running applications in isolation. Container looks like a box including all dependencies files or applications, developers only need to develop in this environment. After developing, they could delivery programs&#x2F;projects to operation teams by image directly. This method avoid the confliction between development &amp; production environment due to configuration differences or dependency conflicts.</p>
<h2 id="Prerequisites"><a href="#Prerequisites" class="headerlink" title="Prerequisites"></a>Prerequisites</h2><h3 id="Firewall"><a href="#Firewall" class="headerlink" title="Firewall"></a>Firewall</h3><blockquote>
<p>Docker is only compatible with <code>iptables-nft</code> and <code>iptables-legacy</code>. Firewall rules created with <code>nft</code> are not supported on a system with Docker installed. Make sure that any firewall rulesets you use are created with <code>iptables</code> or <code>ip6tables</code>, and that you add them to the <code>DOCKER-USER</code> chain.</p>
</blockquote>
<h3 id="Operating-system"><a href="#Operating-system" class="headerlink" title="Operating system"></a>Operating system</h3><ul>
<li><p>Ubuntu Oracular 24.10</p>
</li>
<li><p>Ubuntu Noble 24.04 (LTS)</p>
</li>
<li><p>Ubuntu Jammy 22.04 (LTS)</p>
</li>
<li><p>Ubuntu Focal 20.04 (LTS)</p>
</li>
</ul>
<blockquote>
<p>Docker Engine for Ubuntu is compatible with x86_64 (or amd64), armhf, arm64, s390x, and ppc64le (ppc64el) architectures.</p>
</blockquote>
<h2 id="Installing-docker-engine"><a href="#Installing-docker-engine" class="headerlink" title="Installing docker-engine"></a>Installing docker-engine</h2><p>I followed the <a href="https://docs.docker.com/engine/install/ubuntu/">Docker official website</a> for the installation.</p>
<h3 id="Uninstalling-the-old-version"><a href="#Uninstalling-the-old-version" class="headerlink" title="Uninstalling the old version"></a>Uninstalling the old version</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> pkg <span class="keyword">in</span> docker.io docker-doc docker-compose docker-compose-v2 podman-docker containerd runc; <span class="keyword">do</span> <span class="built_in">sudo</span> apt-get remove <span class="variable">$pkg</span>; <span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<h3 id="Installing-by-using-apt-repository"><a href="#Installing-by-using-apt-repository" class="headerlink" title="Installing by using apt repository"></a>Installing by using <code>apt</code> repository</h3><p>There are many various methods to install docker-engine, I will use the recommended method to install here.</p>
<h4 id="Setting-up-Docker’s-apt-repository"><a href="#Setting-up-Docker’s-apt-repository" class="headerlink" title="Setting up Docker’s apt repository"></a>Setting up Docker’s apt repository</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Add Docker&#x27;s official GPG key:</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get update</span><br><span class="line"><span class="built_in">sudo</span> apt-get install ca-certificates curl</span><br><span class="line"><span class="built_in">sudo</span> install -m 0755 -d /etc/apt/keyrings</span><br><span class="line"><span class="built_in">sudo</span> curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">chmod</span> a+r /etc/apt/keyrings/docker.asc</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add the repository to Apt sources:</span></span><br><span class="line"><span class="built_in">echo</span> \</span><br><span class="line">  <span class="string">&quot;deb [arch=<span class="subst">$(dpkg --print-architecture)</span> signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \</span></span><br><span class="line"><span class="string">  <span class="subst">$(. /etc/os-release &amp;&amp; echo <span class="string">&quot;<span class="variable">$VERSION_CODENAME</span>&quot;</span>)</span> stable&quot;</span> | \</span><br><span class="line">  <span class="built_in">sudo</span> <span class="built_in">tee</span> /etc/apt/sources.list.d/docker.list &gt; /dev/null</span><br><span class="line"><span class="built_in">sudo</span> apt-get update</span><br></pre></td></tr></table></figure>

<h4 id="Installing-the-latest-version"><a href="#Installing-the-latest-version" class="headerlink" title="Installing the latest version"></a>Installing the latest version</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin</span><br></pre></td></tr></table></figure>

<h3 id="Setting-auto-start-automatically-at-boot-and-take-effect-immediately"><a href="#Setting-auto-start-automatically-at-boot-and-take-effect-immediately" class="headerlink" title="Setting auto-start automatically at boot and take effect immediately"></a>Setting auto-start automatically at boot and take effect immediately</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> systemctl <span class="built_in">enable</span> docker.service</span><br><span class="line"><span class="built_in">sudo</span> systemctl <span class="built_in">enable</span> containerd.service</span><br></pre></td></tr></table></figure>

<h3 id="Confirming-the-installation-result"><a href="#Confirming-the-installation-result" class="headerlink" title="Confirming the installation result"></a>Confirming the installation result</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> docker run hello-world</span><br></pre></td></tr></table></figure>

<p>If you install the docker-engine successfully, there is a sentence to inform and congratulate to you.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:~$ sudo docker run hello-world</span><br><span class="line">Unable to find image &#x27;hello-world:latest&#x27; locally</span><br><span class="line">latest: Pulling from library/hello-world</span><br><span class="line">e6590344b1a5: Pull complete</span><br><span class="line">Digest: sha256:d715f14f9eca81473d9112df50457893aa4d099adeb4729f679006bf5ea12407</span><br><span class="line">Status: Downloaded newer image for hello-world:latest</span><br><span class="line"></span><br><span class="line">Hello from Docker!</span><br><span class="line">This message shows that your installation appears to be working correctly.</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<p>And then, you could find the image called <code>hello-world</code> in the image list.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:~$ sudo docker images</span><br><span class="line">REPOSITORY                                                                                               TAG       IMAGE ID       CREATED         SIZE</span><br><span class="line">hello-world                                                                                              latest    74cc54e27dc4   32 hours ago    10.1kB</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<h3 id="Granting-regular-users-access-to-the-docker-engine"><a href="#Granting-regular-users-access-to-the-docker-engine" class="headerlink" title="Granting regular users access to the docker-engine"></a>Granting regular users access to the docker-engine</h3><p>You must receive errors when trying to run without root. The reason is that the docker user group exists but contains no users, which is why you’re required to use sudo to run Docker commands.</p>
<p>The Docker daemon binds to a Unix socket, not a TCP port. By default it’s the root user that owns the Unix socket, and other users can only access it using sudo. The Docker daemon always runs as the root user.</p>
<h4 id="Creating-the-docker-group-and-add-your-user"><a href="#Creating-the-docker-group-and-add-your-user" class="headerlink" title="Creating the docker group and add your user"></a>Creating the docker group and add your user</h4><p>Sometimes, you could skip this step because the docker group has already been created.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> groupadd docker</span><br></pre></td></tr></table></figure>

<h4 id="Adding-your-user-to-the-docker-group"><a href="#Adding-your-user-to-the-docker-group" class="headerlink" title="Adding your user to the docker group"></a>Adding your user to the docker group</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> usermod -aG docker <span class="variable">$USER</span></span><br></pre></td></tr></table></figure>

<h4 id="Restarting"><a href="#Restarting" class="headerlink" title="Restarting"></a>Restarting</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">reboot</span><br></pre></td></tr></table></figure>

<h3 id="Confirming-without-root-privilege"><a href="#Confirming-without-root-privilege" class="headerlink" title="Confirming without root privilege"></a>Confirming without root privilege</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:~$ docker images</span><br><span class="line">REPOSITORY                                                                                               TAG       IMAGE ID       CREATED         SIZE</span><br><span class="line">hello-world                                                                                              latest    74cc54e27dc4   32 hours ago    10.1kB</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<p>Congratulations to you! Up to now, you installed docker-engine successfully!</p>
]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Series (Chapter 1/4): Building and using images</title>
    <url>//Cloud/Docker/Building-and-using-images/index.html</url>
    <content><![CDATA[<h2 id="Overview-of-the-image"><a href="#Overview-of-the-image" class="headerlink" title="Overview of the image"></a>Overview of the image</h2><p>An image is a <code>read-only template</code> used to <code>create containers</code>. Typically, it includes some additional customizations.</p>
<p>For example, we could build an image based on rocky operating system that directly includes some applications like Nginx, Apache or other programs during the image build process.</p>
<p>Once the image is built, we could directly launch containers based on it to quickly achieve the desired business functionality to ensure consistent behavior across different environments.</p>
<h2 id="Sources-of-the-image"><a href="#Sources-of-the-image" class="headerlink" title="Sources of the image"></a>Sources of the image</h2><ul>
<li><p>Pull from the image repository(public:Docker Hub&#x2F;private: harbor,quay,etc)</p>
<ul>
<li><a href="https://hub.docker.com/">Public image repository</a></li>
<li><a href="https://github.com/goharbor/harbor">Private image repository</a></li>
</ul>
<p><code>Registry</code> is a <strong>stateless</strong>, highly <strong>scalable</strong> service that allows us to store and distribute images. Registry is an open source service licensed under the Apache License.</p>
<p>The public image repository is a cloud-based registry service.</p>
<p>Compared with the public image repository, the private repository has these merits:</p>
<ul>
<li>We could strictly control where images are stored.</li>
<li>We have a mirror distribution channel that belongs entirely to us.</li>
<li>We could tightly integrate image storage and distribution into internal development workflows.</li>
</ul>
</li>
<li><p>Customize and build manually from Dockerfile</p>
</li>
</ul>
<h2 id="Build-images-manually"><a href="#Build-images-manually" class="headerlink" title="Build images manually"></a>Build images manually</h2><p>There are two methods to build image.</p>
<ul>
<li><code>docker commit</code> based on original containers</li>
</ul>
<p>We could modify the applications&#x2F;services&#x2F;environments and something else based on the original dokcer image in the containers. After that, we could use <code>docker commit</code> command to export a new image from containers.</p>
<ul>
<li><code>docker build</code> by using Dockerfile</li>
</ul>
<p>Build the image you need from scratch. At the beginning of creating the image, set the various settings and requirements you need.<br>Various applications are included, and the generated images can be directly used for business deployment.</p>
<p>Dockerfile high frequency instruction set</p>
<table>
<thead>
<tr>
<th align="center">Command</th>
<th align="center">Function</th>
<th align="center">Format</th>
</tr>
</thead>
<tbody><tr>
<td align="center">FROM</td>
<td align="center">Specify the base image</td>
<td align="center">FROM image:tag</td>
</tr>
<tr>
<td align="center">MAINTAINER</td>
<td align="center">Specify the image author</td>
<td align="center">MAINTAINER name</td>
</tr>
<tr>
<td align="center">RUN</td>
<td align="center">Excute the Specified command</td>
<td align="center">RUN command</td>
</tr>
<tr>
<td align="center">ADD</td>
<td align="center">Copy files from build context copied into mirror</td>
<td align="center">ADD [–chown&#x3D;user:group]src…dest</td>
</tr>
<tr>
<td align="center">COPY</td>
<td align="center">Copy files from build context copied into mirror</td>
<td align="center">COPY -chown&#x3D;user:groupsrc…dest</td>
</tr>
<tr>
<td align="center">ENV</td>
<td align="center">Set the environmental variables</td>
<td align="center">ENV key value</td>
</tr>
<tr>
<td align="center">EXPOSE</td>
<td align="center">Specify the listen port for applications</td>
<td align="center">EXPOSE port [port&#x2F;protocol]</td>
</tr>
<tr>
<td align="center">USER</td>
<td align="center">Specify the user at boot</td>
<td align="center">USER user</td>
</tr>
<tr>
<td align="center">CMD</td>
<td align="center">Specify the command or scripts at boot</td>
<td align="center">CMD command param1 param2</td>
</tr>
<tr>
<td align="center">ENTRYPOINT</td>
<td align="center">Specify an excutable script or program path</td>
<td align="center">ENTRYPOINT command param1 param2</td>
</tr>
<tr>
<td align="center">VOLUME</td>
<td align="center">Declare files or directories as volume and mount to containers</td>
<td align="center">VOLUME [“&#x2F;data”]</td>
</tr>
<tr>
<td align="center">WORKDIR</td>
<td align="center">Specify the current working directory</td>
<td align="center">WORKDIR &#x2F;path&#x2F;to&#x2F;workdir</td>
</tr>
</tbody></table>
<p>You could use all Dockerfile commands to develop the Dockerfile.</p>
<p>After coding, you should use this command to build an image.</p>
<p>The default name of dockerfile is <code>Dockerfile</code>, you could name it as what you want. However, you should specify the file name when you build an image.</p>
<p>The dot represents the context, you also could specify the path as what you want here.</p>
<p>If you do not specify the tag name, the default name of tag is <code>latest</code>. So, please do not misunderstand and remember to set the appropriate name for easily understand!</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker build (-f Dockerfile_name) -t image_name:tag_name .(/path/to/context)</span><br></pre></td></tr></table></figure>

<h2 id="Using-an-image-to-create-containers"><a href="#Using-an-image-to-create-containers" class="headerlink" title="Using an image to create containers"></a>Using an image to create containers</h2><p>There are two methods to create containers.</p>
<ul>
<li><code>docker run</code></li>
</ul>
<p>This command can only start one container at a time.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d -p 8000:80 customized_image:v1</span><br></pre></td></tr></table></figure>

<ul>
<li><code>docker compose up -d</code></li>
</ul>
<p><span style="color:red;">You must develop a docker-compose.yaml file first, and then change the directory to it. By the way, a container that remain running only if it has a process that sustains its execution.</span></p>
<p><code>docker-compose.yaml</code> is an inventory listing all needed services, it is so convenient that you could start more than one container at a time.</p>
<h3 id="Creating-the-docker-compose-yaml-file"><a href="#Creating-the-docker-compose-yaml-file" class="headerlink" title="Creating the docker-compose.yaml file"></a>Creating the docker-compose.yaml file</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># change the directory into the docker-compose file</span></span><br><span class="line"><span class="built_in">cd</span> ~/docker</span><br><span class="line"><span class="comment"># create docker-compose.yml file</span></span><br><span class="line">vim docker-compose.yaml</span><br><span class="line"><span class="comment"># specify Docker Compose file version as 3.8</span></span><br><span class="line">version: <span class="string">&#x27;3.8&#x27;</span></span><br><span class="line"><span class="comment"># Define services，for example: &quot;build&quot;</span></span><br><span class="line">services:</span><br><span class="line">build:</span><br><span class="line"><span class="comment"># specify the based on what image to build</span></span><br><span class="line">image: nginx:latest</span><br><span class="line"><span class="comment"># specify the container name as build</span></span><br><span class="line">container_name: build</span><br><span class="line"><span class="comment"># Start the tty console terminal for interacting</span></span><br><span class="line"><span class="built_in">tty</span>: <span class="literal">true</span></span><br><span class="line"><span class="comment"># specify auto-restart when container crashed</span></span><br><span class="line">restart: always</span><br><span class="line"><span class="comment"># configure the volumes to mount into containers</span></span><br><span class="line">volumes:</span><br><span class="line">- ./src/:/root/nginx/</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Series (Chapter 2/4): Creating and Using containers</title>
    <url>//Cloud/Docker/Creating-and-using-containers/index.html</url>
    <content><![CDATA[<blockquote>
<p>For information on how to install Docker, please refer to: <a href="https://blog.sunhaoyang.net/Cloud/Docker/Installing-docker-engine-in-Ubuntu/index.html">Docker Series (Chapter 0): Installing docker-engine in Ubuntu</a>.</p>
</blockquote>
<blockquote>
<p>For guidance on how to create and use Docker images, please refer to: <a href="https://blog.sunhaoyang.net/Cloud/Docker/Building-and-using-images/index.html">Docker Series (Chapter 1): Building and using images</a>.</p>
</blockquote>
<p>Alright, let’s continue learning the following Chapter.</p>
<h2 id="Best-Practices-for-Building-Dockerfiles"><a href="#Best-Practices-for-Building-Dockerfiles" class="headerlink" title="Best Practices for Building Dockerfiles"></a>Best Practices for Building Dockerfiles</h2><ol>
<li><p>Containers should be ephemeral&#x2F;temporary.</p>
</li>
<li><p>Avoid installing unnecessary packages.</p>
</li>
<li><p>Each container should have only one purpose.</p>
</li>
<li><p>Avoid having too many layers in a container.</p>
</li>
<li><p>Multi-line sorting.</p>
</li>
<li><p>Leveraging cache.</p>
</li>
</ol>
<p>Let me list an example here.</p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Base image</span></span><br><span class="line"><span class="keyword">FROM</span> httpd</span><br><span class="line"><span class="comment"># The person who creates and maintains it</span></span><br><span class="line"><span class="keyword">MAINTAINER</span> Haoyang Sun</span><br><span class="line"><span class="comment"># RUN command to execute</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">echo</span> hello container &gt; \</span></span><br><span class="line"><span class="language-bash">/usr/local/apache2/htdocs/index.html</span></span><br><span class="line"><span class="comment"># expose port as 80</span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">80</span></span><br><span class="line"><span class="comment"># Define the working directory</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> /usr/local/apache2/htdocs</span></span><br></pre></td></tr></table></figure>

<p>Let’s use the Dockerfile to create a new image here.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker build -t web:v1 .</span><br><span class="line">[+] Building 14.4s (8/8) FINISHED                                docker:default</span><br><span class="line"> =&gt; [internal] load build definition from Dockerfile                       0.0s</span><br><span class="line"> =&gt; =&gt; transferring dockerfile: 189B                                       0.0s</span><br><span class="line"> =&gt; WARN: MaintainerDeprecated: Maintainer instruction is deprecated in f  0.0s</span><br><span class="line"> =&gt; [internal] load metadata for docker.io/library/httpd:latest            4.8s</span><br><span class="line"> =&gt; [auth] library/httpd:pull token for registry-1.docker.io               0.0s</span><br><span class="line"> =&gt; [internal] load .dockerignore                                          0.0s</span><br><span class="line"> =&gt; =&gt; transferring context: 2B                                            0.0s</span><br><span class="line"> =&gt; [1/3] FROM docker.io/library/httpd:latest@sha256:437b9f7d469dd606fa6d  8.9s</span><br><span class="line"> =&gt; =&gt; resolve docker.io/library/httpd:latest@sha256:437b9f7d469dd606fa6d  0.0s</span><br><span class="line"> =&gt; =&gt; sha256:3b71e7157e7a19c02c985d0962e01b5bbda6e329b24 2.10kB / 2.10kB  0.0s</span><br><span class="line"> =&gt; =&gt; sha256:c14eb63a15a0449b7f25117f57bc1846c023cd706769acb 145B / 145B  1.7s</span><br><span class="line"> =&gt; =&gt; sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d 32B / 32B  0.5s</span><br><span class="line"> =&gt; =&gt; sha256:437b9f7d469dd606fa6d2a5f9a3be55fe3af7e0c6 10.16kB / 10.16kB  0.0s</span><br><span class="line"> =&gt; =&gt; sha256:f7d8bafbd9a9fc570c19628411a8441e8dc6697aa43 7.88kB / 7.88kB  0.0s</span><br><span class="line"> =&gt; =&gt; sha256:af302e5c37e9dc1dbe2eadc8f5059d82a914066b5 28.21MB / 28.21MB  7.1s</span><br><span class="line"> =&gt; =&gt; sha256:abbcd5aab3664cf64a964a4c608f66689db8bcfe8ab 4.20MB / 4.20MB  4.9s</span><br><span class="line"> =&gt; =&gt; sha256:04e5e6c6b4973d97b8b076a550d50ef5ddbfc6d12 26.06MB / 26.06MB  8.4s</span><br><span class="line"> =&gt; =&gt; sha256:7f5fb3689eaee4c87c2455a8e061d6bb52da300369b0325 293B / 293B  5.4s</span><br><span class="line"> =&gt; =&gt; extracting sha256:af302e5c37e9dc1dbe2eadc8f5059d82a914066b541b0d1a  0.6s</span><br><span class="line"> =&gt; =&gt; extracting sha256:c14eb63a15a0449b7f25117f57bc1846c023cd706769acb8  0.0s</span><br><span class="line"> =&gt; =&gt; extracting sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6  0.0s</span><br><span class="line"> =&gt; =&gt; extracting sha256:abbcd5aab3664cf64a964a4c608f66689db8bcfe8abea5b9  0.1s</span><br><span class="line"> =&gt; =&gt; extracting sha256:04e5e6c6b4973d97b8b076a550d50ef5ddbfc6d125439f26  0.3s</span><br><span class="line"> =&gt; =&gt; extracting sha256:7f5fb3689eaee4c87c2455a8e061d6bb52da300369b03257  0.0s</span><br><span class="line"> =&gt; [2/3] RUN echo hello container &gt;   /usr/local/apache2/htdocs/index.ht  0.5s</span><br><span class="line"> =&gt; [3/3] WORKDIR /usr/local/apache2/htdocs                                0.0s</span><br><span class="line"> =&gt; exporting to image                                                     0.1s</span><br><span class="line"> =&gt; =&gt; exporting layers                                                    0.0s</span><br><span class="line"> =&gt; =&gt; writing image sha256:e30e7b98cd48deef0229fbdea27d499b039bf06f2bf3c  0.0s</span><br><span class="line"> =&gt; =&gt; naming to docker.io/library/web:v1                                  0.0s</span><br><span class="line"></span><br><span class="line"> 1 warning found (use docker --debug to expand):</span><br><span class="line"> - MaintainerDeprecated: Maintainer instruction is deprecated in favor of using label (line 3)</span><br></pre></td></tr></table></figure>

<p>After building the iamge called: web:v1, let’s check the list of images.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker images</span><br><span class="line">REPOSITORY                                                                                               TAG       IMAGE ID       CREATED         SIZE</span><br><span class="line">web                                                                                                      v1        e30e7b98cd48   7 seconds ago   148MB</span><br><span class="line">ubuntu                                                                                                   20.04     9df6d6105df2   5 months ago    72.8MB</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<h2 id="Best-Practices-for-naming-the-image"><a href="#Best-Practices-for-naming-the-image" class="headerlink" title="Best Practices for naming the image"></a>Best Practices for naming the image</h2><p>Obviously, We successfully creating a new images about 7 seconds ago. The image’s name is web and its tag is v1. Its size is about 148MB.</p>
<p>So, what is the reason we could quickly find the image we want?</p>
<h3 id="Image-naming-format"><a href="#Image-naming-format" class="headerlink" title="Image naming format"></a>Image naming format</h3><p><code>REPOSITORY+TAG</code>. It is recommended to use <code>version number</code> as the naming convention.</p>
<p>A simple and clear image naming format allows users to quickly identify the image they need without the need for testing.</p>
<h3 id="Explanation-of-the-‘latest’-tag-and-its-usage"><a href="#Explanation-of-the-‘latest’-tag-and-its-usage" class="headerlink" title="Explanation of the ‘latest’ tag and its usage"></a>Explanation of the ‘latest’ tag and its usage</h3><p>If <code>no tag</code> is specified when building the image, the default <code>latest</code> tag will be used.</p>
<p>Therefore, when you see ‘latest’ as the tag of an image, it does not necessarily mean that this is the latest version. It simply means that no tag was specified when the image was created, and nothing more.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker build -t web .</span><br><span class="line">[+] Building 2.4s (8/8) FINISHED                                                                                                                                               docker:default</span><br><span class="line"> =&gt; [internal] load build definition from Dockerfile                                                                                                                                     0.0s</span><br><span class="line"> =&gt; =&gt; transferring dockerfile: 189B                                                                                                                                                     0.0s</span><br><span class="line"> =&gt; WARN: MaintainerDeprecated: Maintainer instruction is deprecated in favor of using label (line 3)                                                                                    0.0s</span><br><span class="line"> =&gt; [internal] load metadata for docker.io/library/httpd:latest                                                                                                                          2.3s</span><br><span class="line"> =&gt; [auth] library/httpd:pull token for registry-1.docker.io                                                                                                                             0.0s</span><br><span class="line"> =&gt; [internal] load .dockerignore                                                                                                                                                        0.0s</span><br><span class="line"> =&gt; =&gt; transferring context: 2B                                                                                                                                                          0.0s</span><br><span class="line"> =&gt; [1/3] FROM docker.io/library/httpd:latest@sha256:437b9f7d469dd606fa6d2a5f9a3be55fe3af7e0c66e0329da8c14b291ae0d31c                                                                    0.0s</span><br><span class="line"> =&gt; CACHED [2/3] RUN echo hello container &gt;   /usr/local/apache2/htdocs/index.html                                                                                                       0.0s</span><br><span class="line"> =&gt; CACHED [3/3] WORKDIR /usr/local/apache2/htdocs                                                                                                                                       0.0s</span><br><span class="line"> =&gt; exporting to image                                                                                                                                                                   0.0s</span><br><span class="line"> =&gt; =&gt; exporting layers                                                                                                                                                                  0.0s</span><br><span class="line"> =&gt; =&gt; writing image sha256:e30e7b98cd48deef0229fbdea27d499b039bf06f2bf3c1d137230e5266cd40a5                                                                                             0.0s</span><br><span class="line"> =&gt; =&gt; naming to docker.io/library/web                                                                                                                                                   0.0s</span><br><span class="line"></span><br><span class="line"> 1 warning found (use docker --debug to expand):</span><br><span class="line"> - MaintainerDeprecated: Maintainer instruction is deprecated in favor of using label (line 3)</span><br></pre></td></tr></table></figure>

<p>It is visibly that each period of creating the same image is <code>zero</code>.</p>
<p>Here is the function of <code>cache</code>. Because I have already creating the same image before, it may reuse the cache this time.</p>
<p>Therefore, it will dramatically shorten the creating time.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker images</span><br><span class="line">REPOSITORY                                                                                               TAG       IMAGE ID       CREATED          SIZE</span><br><span class="line">web                                                                                                      latest    e30e7b98cd48   15 minutes ago   148MB</span><br><span class="line">web                                                                                                      v1        e30e7b98cd48   15 minutes ago   148MB</span><br><span class="line">ubuntu                                                                                                   20.04     9df6d6105df2   5 months ago     72.8MB</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<p>We could find there are two images, both of them are called web and the image id are the same. The difference is <code>tag</code>, this time I did not add the tag after the image name.</p>
<p>Therefore, the default tag is <code>latest</code>.</p>
<h2 id="Basic-commands-about-images"><a href="#Basic-commands-about-images" class="headerlink" title="Basic commands about images"></a>Basic commands about images</h2><ul>
<li><code>docker build -t image_name:tag_name .</code></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker build -t web:v1 .</span><br></pre></td></tr></table></figure>

<ul>
<li><code>docker commit container_name image_name:tag_name</code></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker commit web web:v2</span><br></pre></td></tr></table></figure>

<ul>
<li><code>docker save image_name:tag_name -o compression_name.tar</code></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker save web:v2 -o web_v2.tar</span><br></pre></td></tr></table></figure>

<ul>
<li><code>docker load -i compression_name</code></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">scp web_v2.tar user@ip:/path/to/images</span><br><span class="line">docker load -i web_v2.tar</span><br></pre></td></tr></table></figure>

<h2 id="2-Methods-of-creating-containers-with-image"><a href="#2-Methods-of-creating-containers-with-image" class="headerlink" title="2 Methods of creating containers with image"></a>2 Methods of creating containers with image</h2><p>As we discuss in <a href="https://blog.sunhaoyang.net/Cloud/Docker/Building-and-using-images/index.html">Docker Series (Chapter 1): Building and using images</a>, there are two methods to create a container by using an image.</p>
<ul>
<li><p><code>docker run</code></p>
<p><strong>docker run</strong> is a basic Docker command used to directly start a new container. It is ideal for running a container individually to perform simple tasks or experiments.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d -p 8080:80 --name my-container nginx</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>docker compose</code></p>
<p><strong>docker-compose</strong> is a tool used to define and manage <code>multi-container</code> Docker applications.</p>
<p>It configures services, networks, volumes, and more through a <code>docker-compose.yaml</code> file. docker-compose is ideal for managing applications made up of multiple containers, simplifying the configuration and startup of containers.</p>
<p>It is used for one-click start, stop, and management of multiple containers.</p>
<p>So, <code>docker-compose</code> builds on top of <code>docker run</code>, providing a more efficient and manageable way to handle multiple containers. It is especially useful for managing microservices architectures in development, testing, and production environments.</p>
</li>
</ul>
<table>
<thead>
<tr>
<th align="center">Feature</th>
<th align="center">docker run</th>
<th align="center">docker-compose</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><strong>Use Case</strong></td>
<td align="center">Single container, simple tasks or testing</td>
<td align="center">Multiple containers, complex applications, service dependencies management</td>
</tr>
<tr>
<td align="center"><strong>Configuration Method</strong></td>
<td align="center">Configured through command-line arguments</td>
<td align="center">Defined through the <code>docker-compose.yml</code> file with multiple containers, networks, volumes, etc.</td>
</tr>
<tr>
<td align="center"><strong>Start Multiple Containers</strong></td>
<td align="center">Need to start each container individually</td>
<td align="center">Use <code>docker-compose up</code> to start all containers at once</td>
</tr>
<tr>
<td align="center"><strong>Service Dependency Management</strong></td>
<td align="center">Manually manage dependencies between containers</td>
<td align="center">Define dependencies between containers in the <code>docker-compose.yml</code> file</td>
</tr>
<tr>
<td align="center"><strong>Port Mapping</strong></td>
<td align="center">Manually map ports, set individually for each container</td>
<td align="center">Unified port mapping management for multiple containers in the <code>docker-compose.yml</code> file</td>
</tr>
<tr>
<td align="center"><strong>File Management</strong></td>
<td align="center">No file configuration, relies on command-line arguments</td>
<td align="center">Uses docker-compose.yml file for centralized configuration and service management</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Series (Chapter 3/4): Managing Container Resources</title>
    <url>//Cloud/Docker/Managing-container-resources/index.html</url>
    <content><![CDATA[<blockquote>
<p>For information on how to install Docker, please refer to: <a href="https://blog.sunhaoyang.net/Cloud/Docker/Installing-docker-engine-in-Ubuntu/index.html">Docker Series (Chapter 0): Installing docker-engine in Ubuntu</a>.</p>
</blockquote>
<blockquote>
<p>For guidance on how to create and use Docker images, please refer to: <a href="https://blog.sunhaoyang.net/Cloud/Docker/Building-and-using-images/index.html">Docker Series (Chapter 1): Building and using images</a>.</p>
</blockquote>
<blockquote>
<p>For guidance on how to create and use Docker containers, please refer to: <a href="https://blog.sunhaoyang.net/Cloud/Docker/Creating-and-using-containers/index.html">Docker Series (Chapter 2): Creating and Using containers</a>.</p>
</blockquote>
<p>Up to now, you could install the docker-engine in Ubuntu operating system, pull docker images from public&#x2F;private image repositories, develop Dockerfile, use the Dockerfile to create containers and use some command to do some execution interacting with containers.</p>
<p>However, do you have some ideas about how are the resources of a created container bound? How much memory, how much disk, and what are the allocated IOPS?</p>
<p>In this Chapter3, let’s find the answer.</p>
<h2 id="Memory-Quotas"><a href="#Memory-Quotas" class="headerlink" title="Memory Quotas"></a>Memory Quotas</h2><h3 id="Identifying-issues-by-observing-memory-usage"><a href="#Identifying-issues-by-observing-memory-usage" class="headerlink" title="Identifying issues by observing memory usage"></a>Identifying issues by observing memory usage</h3><p>At first, let me create two containers.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker run -d --name=http1 httpd</span><br><span class="line">9871abf3948eeec881498356073c4ce2b11c1631d533a92ce44be64b088af880</span><br><span class="line"></span><br><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker run -d --name=http2 httpd</span><br><span class="line">92cfd46a822b69bdc55fc1460e8698a79a4af7382cda9b038b45654017aef0a2</span><br></pre></td></tr></table></figure>

<p>Then, let’s observe the memory size of each container.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker exec -it http1 grep MemTotal /proc/meminfo</span><br><span class="line">MemTotal:       32741384 kB</span><br><span class="line"></span><br><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker exec -it http2 grep MemTotal /proc/meminfo</span><br><span class="line">MemTotal:       32741384 kB</span><br></pre></td></tr></table></figure>

<p>Finally, let’s check the memory size of local physical machine.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ free -h</span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:           31Gi       7.5Gi       1.7Gi        13Gi        22Gi       9.2Gi</span><br><span class="line">Swap:          31Gi       335Mi        31Gi</span><br></pre></td></tr></table></figure>

<p>Based on the hands-on exercise just now, it is obviously that <code>the memory allocation for each container equals the total memory of the physical host</code>. This means better performance, but it also means that as business demands increase, resource contention may occur. This is something that should generally be avoided during operational planning.</p>
<h3 id="Managing-memory-quotas"><a href="#Managing-memory-quotas" class="headerlink" title="Managing memory quotas"></a>Managing memory quotas</h3><p>We could use <code>-m</code> or <code>--memory</code> parameter to specify the limitation of memory usage, to allocate the memory quotas to containers.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker run -it --name=memlimit -m 500M progrium/stress \</span><br><span class="line">--vm 1 --vm-bytes 400M</span><br><span class="line">stress: dbug: [1] using backoff sleep of 3000us</span><br><span class="line">stress: info: [1] dispatching hogs: 0 cpu, 0 io, 1 vm, 0 hdd</span><br><span class="line">stress: dbug: [1] --&gt; hogvm worker 1 [8] forked</span><br><span class="line">stress: dbug: [8] allocating 524288000 bytes ...</span><br><span class="line">stress: dbug: [8] touching bytes in strides of 4096 bytes ...</span><br><span class="line">stress: dbug: [8] freed 524288000 bytes</span><br><span class="line">stress: dbug: [8] allocating 524288000 bytes ...</span><br><span class="line">stress: dbug: [8] touching bytes in strides of 4096 bytes ...</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker run -it --name=memfailed -m 500M progrium/stress \</span><br><span class="line">--vm 1 --vm-bytes 700M</span><br><span class="line">stress: info: [1] dispatching hogs: 0 cpu, 0 io, 1 vm, 0 hdd</span><br><span class="line">stress: dbug: [1] using backoff sleep of 3000us</span><br><span class="line">stress: dbug: [1] --&gt; hogvm worker 1 [8] forked</span><br><span class="line">stress: dbug: [8] allocating 734003200 bytes ...</span><br><span class="line">stress: dbug: [8] touching bytes in strides of 4096 bytes ...</span><br><span class="line">stress: FAIL: [1] (416) &lt;-- worker 8 got signal 9</span><br><span class="line">stress: WARN: [1] (418) now reaping child worker processes</span><br><span class="line">stress: FAIL: [1] (422) kill error: No such process</span><br><span class="line">stress: FAIL: [1] (452) failed run completed in 0s</span><br></pre></td></tr></table></figure>

<ol>
<li><p>-it</p>
<p>-i: Keep the container’s standard input (stdin) open, allowing you to interact with the container.</p>
<p>-t: Allocate a pseudo-TTY (terminal) for the container, so you can see the output and interact with the container. These two flags are usually used together, meaning you want to enter the container and interact with it.</p>
</li>
<li><p>–name&#x3D;memfailed</p>
<p>Assigns a name to the container. In this case, the container is named memfailed. This allows you to reference the container by its name rather than its ID in future commands.</p>
</li>
<li><p>-m 500M</p>
<p>Limits the container’s maximum memory usage to 500MB. If the container exceeds this limit, it will be killed, and an “Out of Memory” (OOM) error will occur.</p>
</li>
<li><p>progrium&#x2F;stress</p>
<p>Specifies the Docker image to run. In this case, it’s the progrium&#x2F;stress image, which contains the stress tool that can be used to generate load on the system.</p>
</li>
<li><p>–vm 1</p>
<p>This means that the stress tool will start one virtual memory load (vm) process. The number 1 indicates that one such process will be started.</p>
</li>
<li><p>–vm-bytes 700M</p>
<p>The –vm-bytes parameter specifies the amount of memory to allocate for each virtual memory load process. In this case, it is set to 700MB. Therefore, the stress tool will attempt to allocate 700MB of virtual memory for the load process.</p>
</li>
</ol>
<p>It is clear for us why the result is different. 400M is legal, 700M is illegal.</p>
<p>Therefore, we set the parameter <code>-m</code> or <code>--memory</code> works to our containers.</p>
<h2 id="Managing-CPU-Quotas"><a href="#Managing-CPU-Quotas" class="headerlink" title="Managing CPU Quotas"></a>Managing CPU Quotas</h2><p>By default, all containers can use the same CPU resources without any restrictions.</p>
<p>Similar to memory, when the CPU demand of a container increases, it will lead to CPU resource contention. <code>However, unlike memory, where an absolute amount is specified, CPU allocation is done by specifying a relative weight.</code></p>
<p>The <code>--cpu-shares parameter</code> is used to allocate CPU resources.</p>
<p><code>By default, this value is set to 1024</code>.</p>
<p><code>Note that when the workload in the current container is idle, other containers have the right to use its idle CPU cycles, which ensures the performance of the workloads.</code></p>
<blockquote>
<p>CPU resource limits only take effect when the physical machine’s resources are insufficient, and the allocation is based on priority. When other containers are idle, the busy containers can utilize all available CPU resources.</p>
</blockquote>
<h2 id="Managing-I-O-Quotas"><a href="#Managing-I-O-Quotas" class="headerlink" title="Managing I&#x2F;O Quotas"></a>Managing I&#x2F;O Quotas</h2><p>We could use the parameter <code>--blkio-weight 300</code> to set the limitation of I&#x2F;O quotas.</p>
<p>Under normal circumstances, a container with a weight of 600 will have twice the I&#x2F;O capacity compared to one with a weight of 300. You can test the I&#x2F;O performance using the following command.</p>
<p>In actual tests, there is no resource contention. <code>This setting will only be reflected during I/O contention.</code> So, 600 weight is faster than 300 weight, but it is not twice the I&#x2F;O capacity.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker run -d --name 600io --blkio-weight 600 httpd</span><br><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker exec -it 600io /bin/bash</span><br><span class="line">root@fda33d6184a5:/usr/local/apache2# time dd if=/dev/zero of=test.out bs=1M count=10240</span><br><span class="line">10240+0 records in</span><br><span class="line">10240+0 records out</span><br><span class="line">10737418240 bytes (11 GB, 10 GiB) copied, 35.8148 s, 300 MB/s</span><br><span class="line"></span><br><span class="line">real 0m35.959s</span><br><span class="line">user 0m0.011s</span><br><span class="line">sys 0m14.162s</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker run -d --name 300io --blkio-weight 300 httpd</span><br><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker exec -it 300io /bin/bash</span><br><span class="line">root@7d406deec8ac:/usr/local/apache2# time dd if=/dev/zero of=test.out bs=1M count=10240</span><br><span class="line">10240+0 records in</span><br><span class="line">10240+0 records out</span><br><span class="line">10737418240 bytes (11 GB, 10 GiB) copied, 44.8088 s, 240 MB/s</span><br><span class="line"></span><br><span class="line">real 0m44.897s</span><br><span class="line">user 0m0.025s</span><br><span class="line">sys 0m16.777s</span><br></pre></td></tr></table></figure>

<h2 id="The-underlying-implementation-of-resource-limits"><a href="#The-underlying-implementation-of-resource-limits" class="headerlink" title="The underlying implementation of resource limits"></a>The underlying implementation of resource limits</h2><p>Linux uses <code>cgroups</code> to allocate CPU, memory, and I&#x2F;O resource quotas for processes.</p>
<p>We can view the resource quotas for containers through the settings under <code>/sys/fs/cgroup/</code>.</p>
<p>In Linux, cgroups (control groups) allow you to manage and allocate resources to processes. For Docker containers, cgroups are used to enforce resource limitations like CPU usage, memory consumption, and disk I&#x2F;O. The resource settings for these containers can be viewed in the &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F; directory, where cgroup-related files and parameters are exposed.</p>
<p>You can find specific resource limit details for a container by navigating to directories under &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F; that correspond to the container’s cgroup, and checking the values for CPU, memory, and I&#x2F;O usage.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:/HDD/learn/docker/apache2$ docker exec -it http1 /bin/bash</span><br><span class="line">root@9871abf3948e:/usr/local/apache2# ls /sys/fs/cgroup/</span><br><span class="line">blkio  cpu  cpu,cpuacct  cpuacct  cpuset  devices  freezer  hugetlb  memory  misc  net_cls  net_cls,net_prio  net_prio perf_event  pids  rdma systemd</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@9871abf3948e:/usr/local/apache2# ls /sys/fs/cgroup/blkio/</span><br><span class="line">blkio.prio.class   blkio.throttle.io_service_bytes_recursive  blkio.throttle.read_bps_device   blkio.throttle.write_iops_device  notify_on_release</span><br><span class="line">blkio.reset_stats   blkio.throttle.io_serviced      blkio.throttle.read_iops_device  cgroup.clone_children        tasks</span><br><span class="line">blkio.throttle.io_service_bytes  blkio.throttle.io_serviced_recursive     blkio.throttle.write_bps_device  cgroup.procs</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Series (Chapter 4/4): Introducing Container Network and Practising Container Data Management</title>
    <url>//Cloud/Docker/Introducing-container-network-and-practising-container-data-management/index.html</url>
    <content><![CDATA[<blockquote>
<p>For information on how to install Docker, please refer to: <a href="https://blog.sunhaoyang.net/Cloud/Docker/Installing-docker-engine-in-Ubuntu/index.html">Docker Series (Chapter 0): Installing docker-engine in Ubuntu</a>.</p>
</blockquote>
<blockquote>
<p>For guidance on how to create and use Docker images, please refer to: <a href="https://blog.sunhaoyang.net/Cloud/Docker/Building-and-using-images/index.html">Docker Series (Chapter 1): Building and using images</a>.</p>
</blockquote>
<blockquote>
<p>For guidance on how to create and use Docker containers, please refer to: <a href="https://blog.sunhaoyang.net/Cloud/Docker/Creating-and-using-containers/index.html">Docker Series (Chapter 2): Creating and Using containers</a>.</p>
</blockquote>
<blockquote>
<p>For guidance on how to manage Docker resources, please refer to: <a href="https://blog.sunhaoyang.net/Cloud/Docker/Managing-container-resources/index.html">Docker Series (Chapter 3): Managing Container Resources</a>.</p>
</blockquote>
<p>This will be the final chapter of the Docker series. In this chapter, I will introduce the native networking and data management aspects of Docker containers.</p>
<h2 id="Ice-breaking-topic"><a href="#Ice-breaking-topic" class="headerlink" title="Ice-breaking topic"></a>Ice-breaking topic</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run --rm -it centos /bin/bash</span><br></pre></td></tr></table></figure>

<p>At first, let’s begin to create a container using the above command here.</p>
<p>Then, we are trying to <code>ping</code> <em>&lt;<a href="http://www.baidu.com>">www.baidu.com&gt;</a></em> in the interactive interior terminal console in the container.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:~$ docker run --rm -it centos /bin/bash</span><br><span class="line">Unable to find image &#x27;centos:latest&#x27; locally</span><br><span class="line">latest: Pulling from library/centos</span><br><span class="line">a1d0c7532777: Pull complete</span><br><span class="line">Digest: sha256:a27fd8080b517143cbbbab9dfb7c8571c40d67d534bbdee55bd6c473f432b177</span><br><span class="line">Status: Downloaded newer image for centos:latest</span><br><span class="line">[root@e82126d4b596 /]# ping www.baidu.com</span><br><span class="line">PING www.wshifen.com (119.63.197.139) 56(84) bytes of data.</span><br><span class="line">64 bytes from 119.63.197.139 (119.63.197.139): icmp_seq=1 ttl=47 time=83.3 ms</span><br><span class="line">64 bytes from 119.63.197.139 (119.63.197.139): icmp_seq=2 ttl=47 time=83.3 ms</span><br><span class="line">64 bytes from 119.63.197.139 (119.63.197.139): icmp_seq=3 ttl=47 time=83.2 ms</span><br><span class="line">64 bytes from 119.63.197.139 (119.63.197.139): icmp_seq=4 ttl=47 time=83.1 ms</span><br><span class="line">64 bytes from 119.63.197.139 (119.63.197.139): icmp_seq=5 ttl=47 time=83.1 ms</span><br><span class="line">64 bytes from 119.63.197.139 (119.63.197.139): icmp_seq=6 ttl=47 time=83.1 ms</span><br><span class="line">^C</span><br><span class="line">--- www.wshifen.com ping statistics ---</span><br><span class="line">6 packets transmitted, 6 received, 0% packet loss, time 5005ms</span><br><span class="line">rtt min/avg/max/mdev = 83.115/83.173/83.266/0.063 ms</span><br></pre></td></tr></table></figure>

<p>It’s interesting we just use these parameters when creating the container.</p>
<ul>
<li><p><code>--rm</code>: This option tells Docker to automatically remove the container once it stops running. This is useful for keeping things clean when you’re running a container for a short-term task (like we are debugging or testing).</p>
</li>
<li><p><code>-i</code>: This option stands for <strong>interactive</strong>, which keeps the container’s standard input open. i is the abbreviation of the Capital letter in interactive.</p>
</li>
<li><p><code>-t</code>: This option allocates a pseudo-TTY (a terminal interface) for the container. This is what allows you to interact with the container via a command line.</p>
</li>
<li><p><code>centos</code>: This specifies the Docker image to use.</p>
</li>
<li><p><code>/bin/bash</code>: This is the command to run inside the container. It will start a bash shell session inside the CentOS container, allowing you to interact with it like you’re logged into a normal Linux system.</p>
</li>
</ul>
<p>When we create a container, we haven’t attached a network interface card (NIC), nor have we set an IP address, let alone configured an external network route. So, how is it that our ping operation is successful?</p>
<hr>
<h2 id="Container-Original-Network"><a href="#Container-Original-Network" class="headerlink" title="Container Original Network"></a>Container Original Network</h2><p>Docker natively provides several types of networks. If we are not satisfied with the default networks, we can also create custom networks. The default networks are: none, bridge, and host. These networks are automatically created when Docker is installed. We can view them using the following command.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:~$ docker network ls</span><br><span class="line">NETWORK ID     NAME      DRIVER    SCOPE</span><br><span class="line">1b42685dde7f   bridge    bridge    local</span><br><span class="line">610f1e7d2013   host      host      local</span><br><span class="line">11d5d9017fcd   none      null      local</span><br></pre></td></tr></table></figure>

<h3 id="none-network"><a href="#none-network" class="headerlink" title="none network"></a>none network</h3><p>If a container uses the <code>none</code> network, it will not have a typical network interface card (NIC) as we generally understand it. Instead, it will only have the loopback (lo) network. To use this network, you simply need to specify <code>--network=none</code> when creating the container.</p>
<p>Now, let’s think: What might be the use case for this network?</p>
<p>The <code>none</code> network is a more <code>isolated</code> network, suitable for scenarios that require high security and no network connectivity. For instance, applications like <strong>receiving verification codes</strong> or <strong>generating random numbers on your phone</strong> could benefit from being placed on the ‘none’ network to prevent data from being intercepted.</p>
<h3 id="host-network"><a href="#host-network" class="headerlink" title="host network"></a>host network</h3><p>The <code>host</code> network, on the other hand, is a network where a container shares the host’s network stack. You can specify this network using <code>--network=host</code> when creating the container. When a container is in host network mode, its network configuration is identical to that of the host machine. This means the container can see all the network interfaces of the host, and its hostname will match that of the host as well. The major advantage of using the host network is <code>its performance</code>, as it offers <code>high speed and excellent data transfer rates</code>. However, any ports already in use by the host are unavailable to the container.”</p>
<h3 id="bridge-network"><a href="#bridge-network" class="headerlink" title="bridge network"></a>bridge network</h3><p>The <code>bridge</code> network is the <code>default network driver</code> used by Docker containers when no other network is specified. It creates a <code>private internal</code> network on the host system, and each container that uses this network can <code>communicate with other containers</code> on the same bridge network, as well as with the <code>host machine</code>.</p>
<p>In a bridge network, Docker <code>automatically assigns a private IP address to each container</code>. Containers can talk to each other using these private IPs, but they <code>can&#39;t directly communicate with the external network</code> unless you configure port forwarding. To access services running inside a container from outside, you’d typically <code>map the container&#39;s internal ports to ports on the host machine</code>.</p>
<h3 id="Key-Points-of-three-types-network"><a href="#Key-Points-of-three-types-network" class="headerlink" title="Key Points of three types network"></a>Key Points of three types network</h3><ul>
<li><p><code>None Network</code>: Completely isolated with no external network access, ideal for high-security, non-networked tasks.</p>
</li>
<li><p><code>Host Network</code>: Shares the host machine’s network stack, offering high performance, but limits port usage since the host’s ports are already in use.</p>
</li>
<li><p><code>Bridge Network</code>:</p>
<ul>
<li><p><code>Isolation</code>: Containers are isolated from the outside world, but can communicate with each other within the same network.</p>
</li>
<li><p><code>Port Mapping</code>: If you want external access to a container’s services, you have to map its internal ports to the host machine’s ports.</p>
</li>
<li><p><code>Default Mode</code>: When you create a container without specifying a network, it will automatically use the bridge network.</p>
</li>
</ul>
</li>
</ul>
<hr>
<h2 id="Container-Storage"><a href="#Container-Storage" class="headerlink" title="Container Storage"></a>Container Storage</h2><h3 id="The-Container-and-Layer"><a href="#The-Container-and-Layer" class="headerlink" title="The Container and Layer"></a>The Container and Layer</h3><p>The biggest difference between a container and an image lies in <code>the topmost writable layer</code>. Any data written or modified within the container is directly stored in this writable layer. This means that <code>when a container is deleted, the data in the writable layer is lost</code>. Although each container has its own distinct writable layer, the underlying image can be shared across multiple containers.</p>
<blockquote>
<p>The image picture here is based on <a href="https://docker-docs.uclv.cu/storage/storagedriver/#container-and-layers">the Official Website</a>.<br><img src="/./../images/sharing-layers.jpg" alt="sharing-layers"></p>
</blockquote>
<h3 id="Widely-Used-Storage-Drivers"><a href="#Widely-Used-Storage-Drivers" class="headerlink" title="Widely Used Storage Drivers"></a>Widely Used Storage Drivers</h3><p>When designing and using containers, the amount of data written to the container’s writable layer is usually very small. However, in operations, most of the data needs to be persistently stored. To address the volatility of the data in the writable layer, several storage drivers have been introduced in containers.</p>
<p>The mainstream supported storage drivers currently include as below.</p>
<blockquote>
<p>Here, I referred to <a href="https://docker-docs.uclv.cu/storage/storagedriver/select-storage-driver/#supported-storage-drivers-per-linux-distribution">the Official Website</a> and created the following table.</p>
</blockquote>
<table>
<thead>
<tr>
<th align="center">Linux distribution</th>
<th align="center">Recommended storage drivers</th>
<th align="center">Alternative drivers</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Docker Engine - Community on Ubuntu</td>
<td align="center">overlay2 or aufs (for Ubuntu 14.04 running on kernel 3.13)</td>
<td align="center">overlay¹, devicemapper², zfs, vfs</td>
</tr>
<tr>
<td align="center">Docker Engine - Community on Debian</td>
<td align="center">overlay2 (Debian Stretch), aufs or devicemapper (older versions)</td>
<td align="center">overlay¹, vfs</td>
</tr>
<tr>
<td align="center">Docker Engine - Community on CentOS</td>
<td align="center">overlay2</td>
<td align="center">overlay¹, devicemapper², zfs, vfs</td>
</tr>
<tr>
<td align="center">Docker Engine - Community on Fedora</td>
<td align="center">overlay2</td>
<td align="center">overlay¹, devicemapper², zfs, vfs</td>
</tr>
</tbody></table>
<h3 id="Copy-on-write-Strategy"><a href="#Copy-on-write-Strategy" class="headerlink" title="Copy-on-write Strategy"></a>Copy-on-write Strategy</h3><blockquote>
<p>More detailed information, please visit <a href="https://docker-docs.uclv.cu/storage/storagedriver/#the-copy-on-write-cow-strategy">the Official Website</a> here.</p>
</blockquote>
<table>
<thead>
<tr>
<th align="center">Operation</th>
<th align="center">Execution</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Create files</td>
<td align="center">A new file can only be added to the container layer.</td>
</tr>
<tr>
<td align="center">Delete files</td>
<td align="center">Following the container’s layered structure, Docker looks from top to bottom. When the file is found, the delete operation is recorded in the container layer. The actual implementation is that UnionFS creates a “whiteout” file in the container layer, which effectively “masks” the deleted file.</td>
</tr>
<tr>
<td align="center">Modify files</td>
<td align="center">Docker follows the container’s layered structure from top to bottom. Once the file is found, the data from the image layer is copied to the container layer for modification. The modified data is then saved in the container layer (using copy-on-write).</td>
</tr>
<tr>
<td align="center">Read files</td>
<td align="center">Docker follows the container’s layered structure from top to bottom when reading files.</td>
</tr>
</tbody></table>
<hr>
<h2 id="Data-Management"><a href="#Data-Management" class="headerlink" title="Data Management"></a>Data Management</h2><p>There are generally two methods for persisting data in containers:</p>
<ol>
<li>volume</li>
<li>bind mount</li>
</ol>
<h3 id="Volume"><a href="#Volume" class="headerlink" title="Volume"></a>Volume</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:~$ docker run -d --name volumetest -v /usr/local/apache2/htdocs httpd:latest</span><br><span class="line">6bd77a7a04bc9f0628135ccdf30d07f4e92f29cd631f9b5f54f196e7e04ebdd0</span><br><span class="line"></span><br><span class="line">shy@flash-shy:~$ docker exec -it volumetest /bin/bash</span><br><span class="line">root@6bd77a7a04bc:/usr/local/apache2# touch sunhaoyangfile</span><br><span class="line">root@6bd77a7a04bc:/usr/local/apache2#</span><br><span class="line">exit</span><br><span class="line"></span><br><span class="line">shy@flash-shy:~$ sudo find / -name sunhaoyangfile</span><br><span class="line">/var/lib/docker/overlay2/db6115d1b68b483e5a799e74aad3e51d1d4aa0fb7376916c38a09165e6ceaf21/diff/usr/local/apache2/sunhaoyangfile</span><br><span class="line">/var/lib/docker/overlay2/db6115d1b68b483e5a799e74aad3e51d1d4aa0fb7376916c38a09165e6ceaf21/merged/usr/local/apache2/sunhaoyangfile</span><br></pre></td></tr></table></figure>

<h3 id="Bind-Mount"><a href="#Bind-Mount" class="headerlink" title="Bind Mount"></a>Bind Mount</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:~$ docker run -d --name volumetest2 -v /mnt:/usr/local/apache2/htdocs httpd:latest</span><br><span class="line">e0fd1f0d04f4875060a6a248b666662972625a491f2739ca1547ba678a8703fe</span><br><span class="line"></span><br><span class="line">shy@flash-shy:~$ docker exec -it volumetest2 /bin/bash</span><br><span class="line">root@e0fd1f0d04f4:/usr/local/apache2# cd htdocs/</span><br><span class="line">root@e0fd1f0d04f4:/usr/local/apache2/htdocs# ls</span><br><span class="line">root@e0fd1f0d04f4:/usr/local/apache2/htdocs# echo sunhaoyang &gt; index.html</span><br><span class="line">root@e0fd1f0d04f4:/usr/local/apache2/htdocs#</span><br><span class="line">exit</span><br><span class="line"></span><br><span class="line">shy@flash-shy:~$ ls -altF /mnt/</span><br><span class="line">total 12</span><br><span class="line">drwxr-xr-x  2 root root 4096 Feb  6 13:46 ./</span><br><span class="line">-rw-r--r--  1 root root   11 Feb  6 13:46 index.html</span><br><span class="line">drwxr-xr-x 25 root root 4096 Sep 13 19:40 ../</span><br></pre></td></tr></table></figure>

<h2 id="Sharing-data-between-the-host-machine-and-the-container"><a href="#Sharing-data-between-the-host-machine-and-the-container" class="headerlink" title="Sharing data between the host machine and the container"></a>Sharing data between the host machine and the container</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:~$ docker run -d -p 9000:80 -v /mnt:/usr/local/apache2/htdocs httpd:latest</span><br><span class="line">81026dd8cafb6279974c56eaea04defe849dedbcda7361f4b9c805f2a2825682</span><br><span class="line"></span><br><span class="line">shy@flash-shy:~$ sudo cp index.html /mnt/index.html</span><br><span class="line"></span><br><span class="line">shy@flash-shy:~$ curl http://127.0.0.1:9000</span><br><span class="line">Hello, world!</span><br><span class="line">shy@flash-shy:~$ cat index.html</span><br><span class="line">Hello, world!</span><br></pre></td></tr></table></figure>

<h2 id="Sharing-data-between-containers"><a href="#Sharing-data-between-containers" class="headerlink" title="Sharing data between containers"></a>Sharing data between containers</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">shy@flash-shy:~$ docker run -d --name share01 -v /mnt:/usr/local/apache2/htdocs httpd:latest</span><br><span class="line">35a5398e8dde088dc17740115abcd9b3ab84b4db2363588c0dd7445c5856a251</span><br><span class="line"></span><br><span class="line">shy@flash-shy:~$ docker run -d --name share02 -v /mnt:/usr/local/apache2/htdocs httpd:latest</span><br><span class="line">f97301cbca77fda7b6e9127acc78577d6c2d23d52e71a7e16b90bf30629e7a78</span><br><span class="line"></span><br><span class="line">shy@flash-shy:~$ sudo cp index.html /mnt/index.html</span><br><span class="line"></span><br><span class="line">shy@flash-shy:~$ docker inspect -f &#x27;&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;&#x27; share01</span><br><span class="line">172.17.0.3</span><br><span class="line"></span><br><span class="line">shy@flash-shy:~$ docker inspect -f &#x27;&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;&#x27; share02</span><br><span class="line">172.17.0.4</span><br><span class="line"></span><br><span class="line">shy@flash-shy:~$ curl http://172.17.0.3</span><br><span class="line">Hello, world!</span><br><span class="line"></span><br><span class="line">shy@flash-shy:~$ curl http://172.17.0.4</span><br><span class="line">Hello, world!</span><br></pre></td></tr></table></figure>

<h2 id="Key-Points-about-sharing-data"><a href="#Key-Points-about-sharing-data" class="headerlink" title="Key Points about sharing data"></a>Key Points about sharing data</h2><ul>
<li><p>Sharing data between the host machine and the container:</p>
<ul>
<li><p>bind mount: <code>Mount a directory or file from the host machine into the container.</code></p>
</li>
<li><p>volume: <code>Copy data from the host machine to the container&#39;s volume by using the cp command to copy the required data into the volume&#39;s directory.</code></p>
</li>
</ul>
</li>
<li><p>Sharing data between containers:</p>
<ul>
<li><p>bind mount: <code>Mount a directory or file from the host machine into multiple containers.</code></p>
</li>
<li><p>volume: <code>Mount a volume into multiple containers.</code></p>
</li>
</ul>
</li>
</ul>
<p>Congratulations to you!</p>
<p>Up to now, I have already introduced all basic knowledge about docker to you.</p>
<p>That’s all I want to discuss here, thank you for your patience~</p>
]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>NGINX Series Chapter1: Deploying NGINX</title>
    <url>/Linux/NGINX_1.Deploying-NGINX/index.html</url>
    <content><![CDATA[<h2 id="Deployment-Plan-Table"><a href="#Deployment-Plan-Table" class="headerlink" title="Deployment Plan Table"></a>Deployment Plan Table</h2><table>
<thead>
<tr>
<th>Operating System</th>
<th>IP</th>
<th>NGINX Version</th>
</tr>
</thead>
<tbody><tr>
<td>Rocky9.5(x86_64)</td>
<td>192.168.225.32</td>
<td>1.26.3</td>
</tr>
</tbody></table>
<p>Here, I’ll only introduce how to install nginx by <code>the rpm repository</code>. As to the build-install method, I’ll introduce in the later chapter.</p>
<h2 id="Prerequisites"><a href="#Prerequisites" class="headerlink" title="Prerequisites"></a>Prerequisites</h2><h3 id="Preparing-the-software-repository"><a href="#Preparing-the-software-repository" class="headerlink" title="Preparing the software repository"></a>Preparing the software repository</h3><p>I would like to add a new repository in the path <code>/etc/yum.repos.d/nginx.repo</code>.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /etc/yum.repos.d/nginx.repo &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">[nginx]</span></span><br><span class="line"><span class="string">name=nginx repo</span></span><br><span class="line"><span class="string">baseurl=http://nginx.org/packages/centos/9/x86_64/</span></span><br><span class="line"><span class="string">gpgcheck=0</span></span><br><span class="line"><span class="string">enabled=1</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<h3 id="Generating-the-index-of-repository"><a href="#Generating-the-index-of-repository" class="headerlink" title="Generating the index of repository"></a>Generating the index of repository</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# dnf makecache</span><br><span class="line">nginx repo                                     8.7 kB/s | 2.9 kB     00:00</span><br><span class="line">Rocky Linux 9 - BaseOS                         4.8 kB/s | 4.1 kB     00:00</span><br><span class="line">Rocky Linux 9 - BaseOS                         1.0 MB/s | 2.3 MB     00:02</span><br><span class="line">Rocky Linux 9 - AppStream                      1.8 kB/s | 4.5 kB     00:02</span><br><span class="line">Rocky Linux 9 - AppStream                      8.4 MB/s | 8.5 MB     00:01</span><br><span class="line">Rocky Linux 9 - Extras                         3.7 kB/s | 2.9 kB     00:00</span><br><span class="line">Rocky Linux 9 - Extras                          15 kB/s |  16 kB     00:01</span><br><span class="line">Metadata cache created.</span><br></pre></td></tr></table></figure>

<p>&#96;&#96; Installing NGINX</p>
<p>Similarly, you can install nginx using the following command in RockyLinux terminal : <code>sudo yum -y install nginx</code> . After installation is complete it will be available for use via http.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# dnf install nginx -y</span><br><span class="line">...</span><br><span class="line">==============================================================================================================================================================================================================</span><br><span class="line"> Package                                       Architecture                                   Version                                                     Repository                                     Size</span><br><span class="line">==============================================================================================================================================================================================================</span><br><span class="line">Installing:</span><br><span class="line"> nginx                                         x86_64                                         2:1.26.2-2.el9.ngx                                          nginx                                         996 k</span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">==============================================================================================================================================================================================================</span><br><span class="line">Install  1 Package</span><br><span class="line"></span><br><span class="line">Total download size: 996 k</span><br><span class="line">Installed size: 3.3 M</span><br><span class="line">Downloading Packages:</span><br><span class="line">nginx-1.26.3-2.el9.ngx.x86_64.rpm                                                                                                                                             428 kB/s | 996 kB     00:02</span><br><span class="line">--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">Installed:</span><br><span class="line">  nginx-2:1.26.3-2.el9.ngx.x86_64</span><br><span class="line">...</span><br><span class="line">Complete!</span><br><span class="line">[root@localhost ~]#</span><br></pre></td></tr></table></figure>

<h2 id="Preparing-the-test-webpage"><a href="#Preparing-the-test-webpage" class="headerlink" title="Preparing the test webpage"></a>Preparing the test webpage</h2><p>NGINX has been installed, so let’s test whether it can serve a webpage. By default, NGINX requires us to place web pages in the <code>/usr/share/nginx/html</code> directory, with the homepage named either <code>index.html</code> or <code>index.htm</code>.</p>
<p>I have prepared a homepage with the content: <strong>“Hello nginx, I’m Haoyang Sun!”</strong>.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# echo &quot;Hello nginx, I&#x27;m Haoyang Sun!&quot; &gt; /usr/share/nginx/html/index.html</span><br><span class="line">[root@localhost ~]# cat /usr/share/nginx/html/index.html</span><br><span class="line">Hello nginx, I&#x27;m Haoyang Sun!</span><br></pre></td></tr></table></figure>

<h2 id="Enabling-and-starting-the-service"><a href="#Enabling-and-starting-the-service" class="headerlink" title="Enabling and starting the service"></a>Enabling and starting the service</h2><p>Here, we use the <code>enable</code> <code>--now</code> syntax to perform both the enable and start operations on the NGINX service.</p>
<p>This ensures that the NGINX service starts immediately and is configured to launch automatically on boot.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# systemctl enable nginx --now</span><br><span class="line">Created symlink /etc/systemd/system/multi-user.target.wants/nginx.service → /usr/lib/systemd/system/nginx.service.</span><br></pre></td></tr></table></figure>

<p>Check the status of nginx service.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# systemctl status nginx</span><br><span class="line">● nginx.service - nginx - high performance web server</span><br><span class="line">     Loaded: loaded (/usr/lib/systemd/system/nginx.service; enabled; preset: disabled)</span><br><span class="line">     Active: active (running) since Sun 2025-03-09 23:47:45 EDT; 3h 2min ago</span><br><span class="line">       Docs: http://nginx.org/en/docs/</span><br><span class="line">    Process: 21534 ExecStart=/usr/sbin/nginx -c $&#123;conffile&#125; (code=exited, status=0/SUCCESS)</span><br><span class="line">   Main PID: 21535 (nginx)</span><br><span class="line">      Tasks: 5 (limit: 47268)</span><br><span class="line">     Memory: 5.1M</span><br><span class="line">        CPU: 16ms</span><br><span class="line">     CGroup: /system.slice/nginx.service</span><br><span class="line">             ├─21535 &quot;nginx: master process /usr/sbin/nginx -c /etc/nginx/nginx.conf&quot;</span><br><span class="line">             ├─21536 &quot;nginx: worker process&quot;</span><br><span class="line">             ├─21537 &quot;nginx: worker process&quot;</span><br><span class="line">             ├─21538 &quot;nginx: worker process&quot;</span><br><span class="line">             └─21539 &quot;nginx: worker process&quot;</span><br><span class="line"></span><br><span class="line">Mar 09 23:47:45 localhost.localdomain systemd[1]: Starting nginx - high performance web serv&gt;</span><br><span class="line">Mar 09 23:47:45 localhost.localdomain systemd[1]: Started nginx - high performance web serve&gt;</span><br></pre></td></tr></table></figure>

<h2 id="Opening-the-firewall"><a href="#Opening-the-firewall" class="headerlink" title="Opening the firewall"></a>Opening the firewall</h2><p>To allow access to the NGINX service, configure the firewall accordingly.</p>
<p>This ensures that incoming traffic can reach the web server.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# firewall-cmd --add-service=http --permanent</span><br><span class="line">success</span><br><span class="line">[root@localhost ~]# firewall-cmd --reload</span><br><span class="line">success</span><br></pre></td></tr></table></figure>

<h2 id="Visiting-the-test-webpage"><a href="#Visiting-the-test-webpage" class="headerlink" title="Visiting the test webpage"></a>Visiting the test webpage</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# curl http://192.168.225.32</span><br><span class="line">Hello nginx, I&#x27;m Haoyang Sun!</span><br></pre></td></tr></table></figure>

<h2 id="Gracefully-reloading-NGINX"><a href="#Gracefully-reloading-NGINX" class="headerlink" title="Gracefully reloading NGINX"></a>Gracefully reloading NGINX</h2><p>To apply configuration changes without interrupting active connections, use a graceful reload.</p>
<p>This ensures that NGINX reloads its settings smoothly without downtime.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nginx -s reload</span><br></pre></td></tr></table></figure>

<p>Sending the <code>reload</code> signal to reload the configuration files without interrupting active connections.</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>Scrum Guide (Part1 of 2)</title>
    <url>//Management/Scrum/Scrum-Guide1/index.html</url>
    <content><![CDATA[<h2 id="Icebreaking-topics"><a href="#Icebreaking-topics" class="headerlink" title="Icebreaking topics"></a>Icebreaking topics</h2><p>The evolution of agile management indeed shows how it has expanded and gained popularity across various industries over time.</p>
<p>Here’s an analysis of agile management from the perspective of being a product of “involution” in China:</p>
<table>
<thead>
<tr>
<th align="center">2000</th>
<th align="center">2005</th>
<th align="center">2010</th>
<th align="center">2015</th>
<th align="center">2020</th>
</tr>
</thead>
<tbody><tr>
<td align="center">IT TELECOM(internet 2G)</td>
<td align="center">GAMING(intranet 3G)</td>
<td align="center">INTERNET(mobile internet 4G)</td>
<td align="center">BANKING(Alibaba)</td>
<td align="center">PHARMACY(COVID-19) FMCG(Tik Tok) AutoMobile(Tesla)</td>
</tr>
</tbody></table>
<ul>
<li><p><code>2000: IT and Telecommunications Industry</code></p>
<p>The origin of agile management can be traced back to the release of the Agile Manifesto in 2001. At that time, the IT and telecommunications industries were facing rapid technological changes and uncertain market demands. The traditional waterfall development model struggled to adapt. This led to the emergence of agile methods, such as Scrum and Extreme Programming (XP), aimed at improving development efficiency and adaptability.</p>
</li>
<li><p><code>2005: Gaming Industry</code></p>
<p>The gaming industry’s demand for innovation and rapid iteration made agile methods a major trend. In game development, fast prototyping, quick incorporation of user feedback, and cross-department collaboration became critical. Agile methods helped teams manage complexity and shorten product development cycles.</p>
</li>
<li><p><code>2010: Internet Industry</code></p>
<p>The explosive growth of the internet industry brought about fierce market competition. User experience, rapid product releases, and continuous iteration became key to survival. Agile management became the standard for internet companies, enabling small, incremental progress and frequent delivery to enhance user satisfaction and market responsiveness.</p>
</li>
<li><p><code>2015: Banking and Financial Industry</code></p>
<p>Amid the wave of digital transformation, traditional financial institutions began to feel the competitive pressure from tech companies. To accelerate product development and adapt to regulatory changes, banks and financial organizations started adopting agile management methods, establishing innovation labs and implementing agile team collaboration to improve competitiveness.</p>
</li>
<li><p><code>2020: Pharmaceutical Industries</code></p>
<p>The COVID-19 pandemic further drove the adoption of agile practices, especially in vaccine development and drug production, where rapid trials, real-time feedback, and cross-team collaboration became crucial.</p>
</li>
</ul>
<p>Therefore, businesses transitioning to agile practices is not without reason. It is a means of surviving the pressures and challenges brought about by industry-wide “involution.” Survival of the fittest, as nature dictates, follows the law of natural selection.</p>
<hr>
<h2 id="Agile"><a href="#Agile" class="headerlink" title="Agile"></a>Agile</h2><h3 id="What-is-Agile"><a href="#What-is-Agile" class="headerlink" title="What is Agile?"></a>What is Agile?</h3><p><code>Agile</code> is essentially a mindset, a philosophy for responding flexibly to rapid changes, complexity, and uncertainty.</p>
<h3 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h3><p>It includes various kind of methods: Kanban, Extreme Programming(XP), BDD, Scrum and so forth.</p>
<h3 id="4-Values"><a href="#4-Values" class="headerlink" title="4 Values"></a>4 Values</h3><ul>
<li><p><code>Individuals and interactions over processes and tools</code></p>
<p>Our processes and tools should provide services for developers, for people. Effective processes and useful tools should provide convenience for our work.</p>
<p>Effectiveness-oriented processes&#x2F;tools, rather than oversight-oriented processes&#x2F;tools. Please learn more in <a href="#taylorism">Taylorism</a>.</p>
</li>
<li><p><code>Working software over comprehensive documentation</code></p>
<p>The best design documentation is actually the test cases.</p>
<p>Substance over form, code over text.</p>
</li>
<li><p><code>Customer collaboration over contract negotiation</code></p>
<p>We should strive for win-win cooperation, not adversarial negotiation.</p>
<p>Let the other party make money first, and then we can make money.</p>
</li>
<li><p><code>Responding to change over following a plan</code></p>
<p>We prefer plans in the form of actions (verbs) rather than in the form of nouns.</p>
<p>Nothing is set in stone; the only constant is change.</p>
</li>
</ul>
<h3 id="12-Principles"><a href="#12-Principles" class="headerlink" title="12 Principles"></a>12 Principles</h3><p>More detailed infomation, please follow the <a href="https://agilemanifesto.org/principles.html">agilemanifesto</a>.</p>
<h3 id="Taylorism"><a href="#Taylorism" class="headerlink" title="Taylorism"></a>Taylorism</h3><p>It is so ridiculous to treat people as resources.</p>
<p>The management in the IT and construction industries is lagging because both have been modeled after the management practices of the manufacturing industry.</p>
<p>In 1890, Taylorism gave birth to terms like ‘bean counters,’ ‘minute men,’ ‘blue-collar workers,’ and ‘time sheets,’ all of which are associated with oversight-oriented practice. This only leads to the so-called power struggles and conflict between managers and workers.</p>
<hr>
<h2 id="Scrum"><a href="#Scrum" class="headerlink" title="Scrum"></a>Scrum</h2><p>Having introduced Agile, I will now focus on the Scrum methodology.</p>
<h3 id="What-is-Scrum"><a href="#What-is-Scrum" class="headerlink" title="What is Scrum?"></a>What is Scrum?</h3><p><code>Scrum</code> originates from <code>rugby</code>.</p>
<p><strong>Business Perspective: Quickly and continuously turning innovation into value.</strong></p>
<p><strong>Managerial Perspective: Creating the maximum value with limited time and cost.</strong></p>
<h3 id="3-Core-Practices"><a href="#3-Core-Practices" class="headerlink" title="3 Core Practices"></a>3 Core Practices</h3><ul>
<li><p><code>Value Prioritisation</code></p>
<p>Prioritising tasks based on the commercial value of the product.</p>
</li>
<li><p><code>Parallel Processes</code></p>
<p>Bottlenecks and delays in a single process are addressed.</p>
</li>
<li><p><code>Superteam</code></p>
<p>Eliminate collaboration dependencies and reduce waste of unused skills.</p>
</li>
</ul>
<h3 id="Differences-between-Scrum-and-Waterfall"><a href="#Differences-between-Scrum-and-Waterfall" class="headerlink" title="Differences between Scrum and Waterfall"></a>Differences between Scrum and Waterfall</h3><p>The Project Management Triangle: Scope, Time, and Cost, all work together in a balanced way to impact quality.</p>
<ul>
<li><p><code>Scope</code></p>
</li>
<li><p><code>Time</code></p>
</li>
<li><p><code>cost</code></p>
</li>
<li><p><code>Quality</code></p>
</li>
</ul>
<p>Different management approaches handle problems in different ways.</p>
<ul>
<li><p><code>Waterfall</code></p>
<p>Fixed scope, compressed cost.</p>
</li>
<li><p><code>Scrum</code></p>
<p>Maximize value with fixed cost.</p>
<ul>
<li><input checked="" disabled="" type="checkbox"> Prioritize doing the tasks that create the most value.</li>
<li><input disabled="" type="checkbox"> Expanding the project scope while keeping the cost unchanged puts pressure on the team.</li>
</ul>
</li>
</ul>
<hr>
<p>That’s all I would like to introduce in this article.</p>
<p>More sharing about Scrum, please stay tuned for updates about <a href="https://blog.sunhaoyang.net/Management/Scrum/Scrum-Guide2/index.html">Scrum Guide (Part2 of 2)</a>.</p>
]]></content>
      <categories>
        <category>Management</category>
      </categories>
      <tags>
        <tag>Scrum</tag>
      </tags>
  </entry>
  <entry>
    <title>Scrum Guide (Part2 of 2)</title>
    <url>//Management/Scrum/Scrum-Guide2/index.html</url>
    <content><![CDATA[<p>After completing the <a href="https://blog.sunhaoyang.net/Management/Scrum/Scrum-Guide1/index.html">Scrum Guide (Part1 of 2)</a>, I will further explore the structure of Lean and Scrum, along with other related aspects in this chapter.</p>
<h2 id="Scrum-feedback-loop"><a href="#Scrum-feedback-loop" class="headerlink" title="Scrum feedback loop"></a>Scrum feedback loop</h2><p>Scrum is a <code>lightweight</code>, <code>flexible</code> <code>framework</code> that helps individuals, teams, and organisations deliver <code>adaptive solutions</code> <code>driven by value</code>, even in <code>dynamic business environments</code>. It uses an <code>iterative</code>, <code>incremental delivery</code> approach, where <code>learning occurs throughout the process</code>, enabling the delivery of maximum value in the shortest possible time and with minimal cost.</p>
<p>Such a loop includes: <code>Customer&#39;s perspective</code> -&gt; <code>Product goal</code> -&gt; <code>Product Backlog</code> -&gt; <code>Sprint Backlog</code> -&gt; <code>Execution</code> -&gt; <code>Review</code> -&gt; <code>Retrospective</code> -&gt; <code>Increments</code> -&gt; <code>linear regression testing</code> -&gt; <code>Opreation</code>-&gt;<code>Feedback</code>-&gt;<code>Validate</code>-&gt;<code>Product Backlog</code>……recycle again and again…</p>
<p>From the beginning, customers provide the perspectives for the scrum team, Product Owner generates ideas. Then Product Owner designs the product goal. In the meeting, the whole team follow the goal to design the Product Backlog, and Product Owner decide the priority based on the value in final. Then developers will pull tasks&#x2F;user stories from Product Backlog to Sprint Backlog’s TODO list. Developers are completing these tasks&#x2F;user stories in one Sprint period. In addition, the team will take the demonstration for customers during the review meeting. Finally, the whole team will hold a retrospective meeting to do the summary and look back the last sprint for the better next one.</p>
<blockquote>
<p>So, Scrum is not about cost-cutting and efficiency improvements. On the contrary, it often requires more investment.</p>
</blockquote>
<p>Here are the definitions of Working software: It meets the customer’s requirements(<code>valuable</code>) as well as has the eligible <code>quality</code>.</p>
<p>After each cycle of Scrum loop, the delivery artifact is <code>Minimal Viable Product(MVP)</code>.</p>
<p><code>Increments</code> &#x3D; <code>original functions</code> + <code>new functions</code> in total.</p>
<h2 id="Scrum-3-Accountabilities"><a href="#Scrum-3-Accountabilities" class="headerlink" title="Scrum 3 Accountabilities"></a>Scrum 3 Accountabilities</h2><ul>
<li><p><code>Developers</code></p>
<ul>
<li><p>Role: The Development Team is composed of professionals who work together to deliver potentially shippable product(PSP) increments at the end of each sprint. They are cross-functional and self-organising, with the necessary skills to design, develop, test, and deliver the product.</p>
</li>
<li><p>Key Responsibilities:</p>
<p>Deliver the product increment: Build and test features based on the requirements from the product backlog.</p>
<p>Self-organise: Decide how to organise their work and collaborate to meet the sprint goal.</p>
<p>Maintain quality: Ensure that the product is built to a high standard and is potentially shippable at the end of each sprint.</p>
<p>Continuous improvement: Participate in sprint retrospectives to reflect on the work done and look for ways to improve processes.</p>
</li>
</ul>
</li>
<li><p><code>Product Owner</code></p>
<ul>
<li><p>Role: The Product Owner is responsible for defining the product vision and managing the product backlog. They serve as the bridge between the stakeholders (such as customers, business owners, or end users) and the development team.</p>
</li>
<li><p>Key Responsibilities:</p>
<p>Define the product backlog: Prioritise the list of features, enhancements, and fixes that need to be developed.</p>
<p>Ensure value delivery: Make sure that the team works on the most valuable tasks that align with customer and business needs.</p>
<p>Clarify requirements: Provide clear requirements and make decisions on scope, priorities, and trade-offs.</p>
<p>Act as a stakeholder liaison: Communicate with customers, stakeholders, and the team to gather feedback and ensure alignment.</p>
</li>
</ul>
</li>
<li><p><code>Scrum Master</code></p>
<ul>
<li><p>Role: The Scrum Master is responsible for ensuring that the Scrum framework is followed and that the team operates efficiently. They act as a facilitator, coach, and servant leader to both the development team and the Product Owner.</p>
</li>
<li><p>Key Responsibilities:</p>
<p>Facilitate Scrum ceremonies: Help organise and facilitate Scrum events, such as daily standups, sprint planning, sprint reviews, and retrospectives.</p>
<p>Remove impediments: Identify and address obstacles that are blocking the team’s progress.</p>
<p>Coach the team: Support the team in adopting Scrum practices, encourage self-organisation, and foster continuous improvement.</p>
<p>Protect the team: Shield the team from external distractions or disruptions so they can focus on their work.</p>
</li>
</ul>
</li>
</ul>
<h2 id="Scrum-3-Artifacts"><a href="#Scrum-3-Artifacts" class="headerlink" title="Scrum 3 Artifacts"></a>Scrum 3 Artifacts</h2><ul>
<li><p><code>Product Backlog</code></p>
<ul>
<li><p>Definition: The Product Backlog is a dynamic, ordered list of everything that might be needed in the product. It is the single source of work items for the development team.</p>
</li>
<li><p>Key Characteristics:</p>
<p>Managed by the Product Owner: The Product Owner is responsible for prioritising and refining the backlog.</p>
<p>Contains user stories, features, enhancements, and bug fixes: These items are often described as Product Backlog Items (PBIs).</p>
<p>Evolves over time: The backlog is continuously updated based on new information, customer feedback, or market changes.</p>
<p>Prioritisation: Items at the top of the backlog are more important and are typically worked on first, based on their value and urgency.</p>
</li>
<li><p>Purpose: The Product Backlog provides the team with a clear view of the product’s needs and helps ensure that the most important work is always done first.</p>
</li>
</ul>
</li>
<li><p><code>Spring Backlog</code></p>
<ul>
<li><p>Definition: The Sprint Backlog is a list of tasks and Product Backlog Items (PBIs) that the development team commits to completing during a single sprint. It is derived from the Product Backlog.</p>
</li>
<li><p>Key Characteristics:</p>
<p>Owned by the Development Team: The team selects which items to work on during a sprint, based on their capacity and priorities.</p>
<p>Contains both PBIs and tasks: In addition to backlog items, the Sprint Backlog includes detailed tasks needed to complete the items.</p>
<p>Dynamic: The Sprint Backlog is updated as the team works through the sprint, adding new tasks or making adjustments as needed.</p>
<p>Visibility: It provides a clear picture of what work is currently being done and what remains to be completed during the sprint.</p>
</li>
<li><p>Purpose: The Sprint Backlog serves as a focused plan for the current sprint, enabling the team to track progress and deliver the sprint goal.</p>
</li>
</ul>
</li>
<li><p><code>Increment</code></p>
<ul>
<li><p>Definition: The Increment is the sum of all the completed Product Backlog Items during a sprint, plus the work completed in previous sprints. It represents the latest version of the product that is potentially shippable.</p>
</li>
<li><p>Key Characteristics:</p>
<p>Potentially Shippable: At the end of each sprint, the Increment should be in a usable state and could be released to customers if desired.</p>
<p>Completed and Tested: The Increment includes all the features that meet the team’s definition of “done” and are fully integrated and tested.</p>
<p>Represents Progress: Each Increment adds value and progresses the product towards meeting the overall goals and vision.</p>
<p>Visible: The Increment is typically demonstrated during the Sprint Review for inspection by stakeholders.</p>
</li>
<li><p>Purpose: The Increment represents the product’s evolution and the value delivered during a sprint. It provides a tangible result that stakeholders can see, review, and provide feedback on.</p>
</li>
</ul>
</li>
</ul>
<h2 id="Scrum-3-Commitment"><a href="#Scrum-3-Commitment" class="headerlink" title="Scrum 3 Commitment"></a>Scrum 3 Commitment</h2><ul>
<li><p><code>Product Goal</code></p>
<ul>
<li><p>Definition: The Product Goal is the commitment associated with the Product Backlog. It defines what the team is trying to achieve with the product, representing the ultimate objective or target the product is working towards.</p>
</li>
<li><p>Key Characteristics:</p>
</li>
</ul>
<p>Guiding the team: The Product Goal guides the team by providing a clear, overarching target for the product. It helps define the vision and sets direction for the work in the Product Backlog.</p>
<p>Evolving: The Product Goal may evolve over time as business priorities, market conditions, and customer needs change.</p>
<p>Focus for the Product Owner: The Product Owner is responsible for ensuring the Product Goal is well-defined and communicated to the team and stakeholders.</p>
<ul>
<li>Purpose: The Product Goal ensures the team remains focused on delivering value and aligns all product work toward a common objective.</li>
</ul>
</li>
<li><p><code>Sprint Goal</code></p>
<ul>
<li><p>Definition: The Sprint Goal is the commitment related to the Sprint Backlog. It defines what the team aims to achieve during a sprint and is created collaboratively during the Sprint Planning meeting.</p>
</li>
<li><p>Key Characteristics:</p>
</li>
</ul>
<p>Focused objective: The Sprint Goal provides the team with a clear purpose for the sprint and aligns them on what needs to be delivered.</p>
<p>Created during Sprint Planning: It is defined at the start of the sprint, and the team decides which Product Backlog items (PBIs) they will work on to achieve this goal.</p>
<p>Adaptable: The Sprint Goal may evolve slightly during the sprint if new information arises, but the team must stay focused on the overall objective.</p>
<ul>
<li>Purpose: The Sprint Goal ensures that the team is working towards a shared and specific target during the sprint, promoting alignment and providing a measure for success.</li>
</ul>
</li>
<li><p><code>Definiton of Done(DoD)</code></p>
<ul>
<li><p>Definition: The Definition of Done (DoD) is the commitment associated with the Increment. It defines the criteria that must be met for Product Backlog items to be considered complete.</p>
</li>
<li><p>Key Characteristics:</p>
</li>
</ul>
<p>Quality assurance: The DoD ensures that all work completed during the sprint is of high quality, fully tested, and integrated with the existing system.</p>
<p>Agreed by the team: The team agrees on the Definition of Done, which can evolve over time as the team improves their quality standards and practices.</p>
<p>Transparency: The Definition of Done provides transparency to stakeholders, allowing them to understand what “done” really means in terms of product quality.</p>
<ul>
<li>Purpose: The Definition of Done ensures that the Increment is truly finished and meets the necessary standards, providing confidence that the product is ready for release or further testing.</li>
</ul>
</li>
</ul>
<h2 id="Scrum-5-Events"><a href="#Scrum-5-Events" class="headerlink" title="Scrum 5 Events"></a>Scrum 5 Events</h2><ul>
<li><p><code>Sprint</code></p>
<ul>
<li><p>Definition: The Sprint is the core event in Scrum and refers to the time-boxed iteration during which the team works to complete a set of items from the Product Backlog.</p>
</li>
<li><p>Key Characteristics:</p>
<ul>
<li><p>Duration: Typically lasts between 1 to 4 weeks, depending on the team’s preference.</p>
</li>
<li><p>Goal: At the end of the Sprint, a potentially shippable product increment is delivered, which should meet the Definition of Done.</p>
</li>
<li><p>Consistency: Each Sprint follows the same cycle and is followed by a review and retrospective.</p>
</li>
</ul>
</li>
<li><p>Purpose: The Sprint serves as the fundamental cycle where all other events occur. It enables teams to focus on delivering value incrementally.</p>
</li>
</ul>
</li>
<li><p><code>Sprint Planning</code></p>
<ul>
<li><p>Definition: Sprint Planning is the event where the team and the Product Owner collaboratively define the work that will be completed in the upcoming Sprint.</p>
</li>
<li><p>Key Characteristics:</p>
<ul>
<li><p>Who: The Scrum Team (Product Owner, Scrum Master, and Development Team) participates.</p>
</li>
<li><p>What: The team defines the Sprint Goal, selects items from the Product Backlog to work on, and creates a plan for how to complete those items.</p>
</li>
<li><p>Time-box: Typically lasts between 2 to 4 hours for a 2-week Sprint.</p>
</li>
</ul>
</li>
<li><p>Purpose: Sprint Planning ensures that everyone is aligned on what needs to be achieved and how to accomplish it.</p>
</li>
</ul>
</li>
<li><p><code>Daily Scrum</code></p>
<ul>
<li><p>Definition: The Daily Scrum (also known as the Daily Standup) is a short, time-boxed meeting held every day of the Sprint to inspect progress and adapt the plan.</p>
</li>
<li><p>Key Characteristics:</p>
<ul>
<li><p>Who: Primarily the Development Team; the Product Owner and Scrum Master can attend but do not actively participate unless necessary.</p>
</li>
<li><p>Format: Each team member answers three questions:</p>
<ol>
<li><p>What did I complete yesterday to help the team achieve the Sprint Goal?</p>
</li>
<li><p>What will I do today to help the team achieve the Sprint Goal?</p>
</li>
<li><p>Are there any blockers or challenges?</p>
</li>
</ol>
</li>
<li><p>Time-box: Typically lasts 15 minutes.</p>
</li>
</ul>
</li>
<li><p>Purpose: The Daily Scrum allows the team to inspect their progress, make adjustments, and stay focused on the Sprint Goal.</p>
</li>
</ul>
</li>
<li><p><code>Sprint Review</code></p>
<ul>
<li><p>Definition: The Sprint Review is an event that occurs at the end of the Sprint where the team demonstrates the work they have completed to stakeholders and gathers feedback.</p>
</li>
<li><p>Key Characteristics:</p>
<ul>
<li><p>Who: The Scrum Team and key stakeholders (e.g., customers, managers) participate.</p>
</li>
<li><p>What: The Development Team showcases the Increment, and the Product Owner discusses the Product Backlog and progress towards the Product Goal. Stakeholders provide feedback.</p>
</li>
<li><p>Time-box: Typically lasts 1 to 2 hours for a 2-week Sprint.</p>
</li>
</ul>
</li>
<li><p>Purpose: The Sprint Review allows stakeholders to inspect the Increment, provide feedback, and ensure that the product is evolving in the right direction.</p>
</li>
</ul>
</li>
<li><p><code>Spring Retrospective</code></p>
<ul>
<li><p>Definition: The Sprint Retrospective is a meeting held after the Sprint Review and before the next Sprint Planning to reflect on the Sprint process and identify areas for improvement.</p>
</li>
<li><p>Key Characteristics:</p>
<ul>
<li><p>Who: The Scrum Team (Product Owner, Scrum Master, and Development Team) participate.</p>
</li>
<li><p>What: The team reflects on what went well, what could be improved, and what actions can be taken to improve in the next Sprint.</p>
</li>
<li><p>Time-box: Typically lasts 1 to 1.5 hours for a 2-week Sprint.</p>
</li>
</ul>
</li>
<li><p>Purpose: The Sprint Retrospective helps the team identify areas for improvement in both their processes and collaboration, fostering continuous improvement.</p>
</li>
</ul>
</li>
</ul>
<h2 id="Scrum-5-Values"><a href="#Scrum-5-Values" class="headerlink" title="Scrum 5 Values"></a>Scrum 5 Values</h2><ul>
<li><p><code>Commitment</code></p>
<ul>
<li><p>Definition: Commitment in Scrum refers to the team’s dedication to achieving the Sprint Goal and delivering the highest value possible within the agreed-upon timeframe.</p>
</li>
<li><p>Key Characteristics:</p>
<ul>
<li><p>To the Sprint Goal: The team commits to achieving the goals defined for the Sprint, ensuring that their work aligns with the overall objectives.</p>
</li>
<li><p>To the Team: Team members commit to supporting each other, sharing knowledge, and working collaboratively to achieve success.</p>
</li>
<li><p>To Continuous Improvement: The team commits to reflecting on their performance and looking for ways to improve in the future.</p>
</li>
</ul>
</li>
<li><p>Purpose: Commitment ensures that the team stays focused, works with determination, and is accountable for the work they undertake.</p>
</li>
</ul>
</li>
<li><p><code>Focus</code></p>
<ul>
<li><p>Definition: Focus refers to the ability to concentrate on the most important tasks and priorities, ensuring that the team’s energy is directed toward achieving the Sprint Goal and delivering value.</p>
</li>
<li><p>Key Characteristics:</p>
<ul>
<li><p>On the Sprint Goal: The team focuses on delivering the Sprint Goal, ensuring that they avoid distractions and work on the highest-priority tasks.</p>
</li>
<li><p>On the task at hand: During the Sprint, team members focus on completing individual tasks efficiently without being diverted by external factors.</p>
</li>
<li><p>On the customer’s needs: The team keeps the customer’s needs and the Product Goal in mind, ensuring that the work they’re doing delivers value to the end user.</p>
</li>
</ul>
</li>
<li><p>Purpose: Focus helps the team maintain alignment with the Sprint Goal and ensures that energy is not wasted on irrelevant work or distractions.</p>
</li>
</ul>
</li>
<li><p><code>Openness</code></p>
<ul>
<li><p>Definition: Openness refers to the team’s willingness to share information, feedback, and progress with each other and stakeholders, creating a culture of transparency.</p>
</li>
<li><p>Key Characteristics:</p>
<ul>
<li><p>Transparency: The team shares information openly, allowing stakeholders and each other to understand progress, challenges, and successes.</p>
</li>
<li><p>Honest communication: Team members are open and honest about what’s going well and where they might be facing difficulties, ensuring issues are addressed early.</p>
</li>
<li><p>Welcoming feedback: The team is open to receiving feedback from others, viewing it as an opportunity for improvement rather than criticism.</p>
</li>
</ul>
</li>
<li><p>Purpose: Openness fosters trust and collaboration, allowing the team to work more effectively and respond to challenges more quickly.</p>
</li>
</ul>
</li>
<li><p><code>Respect</code></p>
<ul>
<li><p>Definition: Respect in Scrum means valuing each other’s contributions, listening to different perspectives, and trusting that each person is bringing valuable expertise to the team.</p>
</li>
<li><p>Key Characteristics:</p>
<ul>
<li><p>Value each individual’s expertise: Team members respect each other’s skills, knowledge, and experiences, fostering a collaborative and supportive environment.</p>
</li>
<li><p>Listening actively: The team listens to each other’s ideas and feedback, making sure everyone’s voice is heard and valued.</p>
</li>
<li><p>Trust: Team members trust each other to do their best and contribute to the team’s success, supporting one another’s development and growth.</p>
</li>
</ul>
</li>
<li><p>Purpose: Respect ensures that team members work together harmoniously, value diversity of thought, and collaborate to achieve the best possible outcomes.</p>
</li>
</ul>
</li>
<li><p><code>Courage</code></p>
<ul>
<li><p>Definition: Courage in Scrum means having the bravery to take on challenging work, make tough decisions, and speak up when issues or concerns arise.</p>
</li>
<li><p>Key Characteristics:</p>
<ul>
<li><p>Taking on challenges: The team is willing to tackle difficult tasks, knowing that they might encounter obstacles along the way.</p>
</li>
<li><p>Speaking up: Team members have the courage to raise concerns, provide honest feedback, and address issues without fear of judgment.</p>
</li>
<li><p>Trying new things: The team is willing to experiment with new approaches or techniques to improve the product or process.</p>
</li>
</ul>
</li>
<li><p>Purpose: Courage helps the team push boundaries, innovate, and continuously improve, knowing that failure is a part of the learning process.</p>
</li>
</ul>
</li>
</ul>
<h2 id="Sprint-1-extra-activity"><a href="#Sprint-1-extra-activity" class="headerlink" title="Sprint 1 extra activity"></a>Sprint 1 extra activity</h2><p><code>Product Backlog Refinement</code></p>
<p>The entire team (PO + Dev + SM) collaborates together.</p>
<p>The PO ensures that the activity is carried out in an organised manner.</p>
<p>It typically happens before the sprint begins.</p>
<p>This is not a formal meeting: it is usually informal, offline, and happens continuously (spending a little time each day).</p>
<p>It involves a small group, with short, high-intensity brainstorming sessions.</p>
<p>The Product Owner and Developers co-create the product feature details.<br>Behaviour Driven Development (BDD) is recommended.”</p>
<p>This translation conveys the same meaning in a clear, professional British English style, highlighting the collaborative and informal nature of the process.</p>
<h2 id="Lean"><a href="#Lean" class="headerlink" title="Lean"></a>Lean</h2><p>This term was originally developed by <code>Toyota Motor Corporation</code> in the mid-20th century as a production and management philosophy aimed at improving production efficiency, reducing waste, enhancing quality, and fostering continuous improvement. This approach became known as the <code>Toyota Production System</code> (TPS), which emphasises the elimination of all forms of waste—such as time, materials, and labour and optimising processes.</p>
<p>Over time, Lean thinking has been widely adopted in various industries beyond manufacturing, including software development and services, leading to the emergence of concepts such as ‘Lean Production’ and ‘Lean Management’ in these fields.</p>
<p><code>JIT</code>: Just In Time.</p>
<h3 id="2-essential-concepts"><a href="#2-essential-concepts" class="headerlink" title="2 essential concepts"></a>2 essential concepts</h3><ul>
<li><p><code>Value</code></p>
<p>Anything that customers are prepared to pay for can be regarded as value, because it directly contributes to fulfilling their needs or solving their problems.<br>Simply to say, <code>value = customer&#39;s perspective</code>.</p>
</li>
<li><p><code>Waste</code></p>
<p>Anything that does not contribute to value can be classified as waste.</p>
<p>There are <code>8 waste in total</code>. The abbreviation of these 8 words is <code>DOWNTIME</code>.</p>
<ul>
<li><p><code>Defects</code></p>
<p>Products or services that do not meet quality standards and require rework or scrap.</p>
</li>
<li><p><code>Overproduction</code></p>
<p>Producing more than what is needed or before it is needed.</p>
</li>
<li><p><code>Waiting</code></p>
<p>Idle time where work is not being done, such as waiting for materials, information, or equipment.</p>
</li>
<li><p><code>Non-utilized Talents</code></p>
<p>Employees’ full potential, skills, and ideas are not fully utilised in the organisation’s processes or decision-making.</p>
</li>
<li><p><code>Transportation</code></p>
<p>Unnecessary movement of products, materials.</p>
</li>
<li><p><code>Inventory</code></p>
<p>Excess materials or products that are not being used immediately.</p>
</li>
<li><p><code>Motion</code></p>
<p>Unnecessary movement of people, tools, or equipment that does not add value.</p>
</li>
<li><p><code>Extra Processing</code></p>
<p>Doing more work than required or using more complex processes than necessary.</p>
</li>
</ul>
</li>
</ul>
<h3 id="Pull-vs-Push"><a href="#Pull-vs-Push" class="headerlink" title="Pull vs Push"></a>Pull vs Push</h3><ul>
<li><p><code>Pull</code></p>
<p>Developers independently pull tasks&#x2F;user stories from the Product Backlog to Sprint Backlog’s TODO list only if they completed the tasks&#x2F;user stories at hand.</p>
<p>One task&#x2F;user story at a time.</p>
</li>
<li><p><code>Push</code></p>
<p>Developers are passively receiving tasks&#x2F;user stories from the manager.</p>
<p>More than one at hand at a time. It may cause the 7 kindks of waste except for <code>Motion</code>.</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Management</category>
      </categories>
      <tags>
        <tag>Scrum</tag>
      </tags>
  </entry>
</search>
